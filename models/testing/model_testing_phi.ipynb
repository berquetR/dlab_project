{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "651adc3c",
   "metadata": {},
   "source": [
    "### Library Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "294bdc29",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/dlabscratch1/berquet/conda/envs/env2/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy\n",
    "import torch\n",
    "import transformers\n",
    "import json\n",
    "import ast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f9bd3290",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python version\n",
      "3.10.14 (main, Mar 21 2024, 16:24:04) [GCC 11.2.0]\n",
      "Version info.\n",
      "sys.version_info(major=3, minor=10, micro=14, releaselevel='final', serial=0)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(\"Python version\")\n",
    "print(sys.version)\n",
    "print(\"Version info.\")\n",
    "print(sys.version_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2ca469aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset, concatenate_datasets\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, Trainer, TrainingArguments\n",
    "from peft import prepare_model_for_kbit_training, LoraConfig, get_peft_model, PeftModel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e391a5f5",
   "metadata": {},
   "source": [
    "### Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3710484a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_dataset(\"berquetR/dlab_project_optimal_links\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f588910b",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = dataset['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "264f4cb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1250c978",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_no_prompt = dataset['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88a8af51",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = dataset['train']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af89eb53",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_no_prompt = dataset['train']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f7ff4ecb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/dlabscratch1/berquet/conda/envs/env2/lib/python3.10/site-packages/lmql/runtime/bopenai/batched_openai.py:507: OpenAIAPIWarning: OpenAI API: Underlying stream of OpenAI complete() call failed with error\n",
      "\n",
      "To use openai/<models>, you have to configure your API credentials. To do so\n",
      "you can either define the `OPENAI_API_KEY` environment variable or create a\n",
      "file `api.env` in one of the following locations:\n",
      "\n",
      " - /dlabscratch1/berquet/conda/envs/env2/lib/python3.10/site-packages/api.env\n",
      " - /dlabscratch1/berquet/project/dlab_project/api.env\n",
      " - /dlabscratch1/berquet/home/.lmql/api.env\n",
      "\n",
      "To use OpenAI models you need to create an api.env file with the following\n",
      "contents:\n",
      "        \n",
      "        openai-secret: <your openai secret>\n",
      "        openai-org: <your openai org>\n",
      "        \n",
      "For more info, check the related project docs:\n",
      "https://docs.lmql.ai/en/stable/language/openai.html#configuring-openai-api-credentials\n",
      " (<class 'FileNotFoundError'>)\n",
      "\n",
      "Retrying... (attempt: 0)\n",
      "  warnings.warn(f\"OpenAI API: Underlying stream of OpenAI complete() call failed with error\\n\\n{attempt.error} ({type(attempt.error)})\\n\\nRetrying... (attempt: {self.retries})\",\n",
      "OpenAIAPIWarning: Enable tracemalloc to get the object allocation traceback\n",
      "/dlabscratch1/berquet/conda/envs/env2/lib/python3.10/site-packages/lmql/runtime/bopenai/batched_openai.py:739: OpenAIAPIWarning: OpenAI request with ID 0 failed (timeout or other error) and will be retried\n",
      "  warnings.warn(\"OpenAI request with ID {} failed (timeout or other error) and will be retried\".format(request_id), category=OpenAIAPIWarning)\n",
      "/dlabscratch1/berquet/conda/envs/env2/lib/python3.10/site-packages/lmql/runtime/bopenai/batched_openai.py:507: OpenAIAPIWarning: OpenAI API: Underlying stream of OpenAI complete() call failed with error\n",
      "\n",
      "To use openai/<models>, you have to configure your API credentials. To do so\n",
      "you can either define the `OPENAI_API_KEY` environment variable or create a\n",
      "file `api.env` in one of the following locations:\n",
      "\n",
      " - /dlabscratch1/berquet/conda/envs/env2/lib/python3.10/site-packages/api.env\n",
      " - /dlabscratch1/berquet/project/dlab_project/api.env\n",
      " - /dlabscratch1/berquet/home/.lmql/api.env\n",
      "\n",
      "To use OpenAI models you need to create an api.env file with the following\n",
      "contents:\n",
      "        \n",
      "        openai-secret: <your openai secret>\n",
      "        openai-org: <your openai org>\n",
      "        \n",
      "For more info, check the related project docs:\n",
      "https://docs.lmql.ai/en/stable/language/openai.html#configuring-openai-api-credentials\n",
      " (<class 'FileNotFoundError'>)\n",
      "\n",
      "Retrying... (attempt: 1)\n",
      "  warnings.warn(f\"OpenAI API: Underlying stream of OpenAI complete() call failed with error\\n\\n{attempt.error} ({type(attempt.error)})\\n\\nRetrying... (attempt: {self.retries})\",\n",
      "OpenAIAPIWarning: Enable tracemalloc to get the object allocation traceback\n",
      "/dlabscratch1/berquet/conda/envs/env2/lib/python3.10/site-packages/lmql/runtime/bopenai/batched_openai.py:507: OpenAIAPIWarning: OpenAI API: Underlying stream of OpenAI complete() call failed with error\n",
      "\n",
      "To use openai/<models>, you have to configure your API credentials. To do so\n",
      "you can either define the `OPENAI_API_KEY` environment variable or create a\n",
      "file `api.env` in one of the following locations:\n",
      "\n",
      " - /dlabscratch1/berquet/conda/envs/env2/lib/python3.10/site-packages/api.env\n",
      " - /dlabscratch1/berquet/project/dlab_project/api.env\n",
      " - /dlabscratch1/berquet/home/.lmql/api.env\n",
      "\n",
      "To use OpenAI models you need to create an api.env file with the following\n",
      "contents:\n",
      "        \n",
      "        openai-secret: <your openai secret>\n",
      "        openai-org: <your openai org>\n",
      "        \n",
      "For more info, check the related project docs:\n",
      "https://docs.lmql.ai/en/stable/language/openai.html#configuring-openai-api-credentials\n",
      " (<class 'FileNotFoundError'>)\n",
      "\n",
      "Retrying... (attempt: 2)\n",
      "  warnings.warn(f\"OpenAI API: Underlying stream of OpenAI complete() call failed with error\\n\\n{attempt.error} ({type(attempt.error)})\\n\\nRetrying... (attempt: {self.retries})\",\n",
      "OpenAIAPIWarning: Enable tracemalloc to get the object allocation traceback\n",
      "/dlabscratch1/berquet/conda/envs/env2/lib/python3.10/site-packages/lmql/runtime/bopenai/batched_openai.py:507: OpenAIAPIWarning: OpenAI API: Underlying stream of OpenAI complete() call failed with error\n",
      "\n",
      "To use openai/<models>, you have to configure your API credentials. To do so\n",
      "you can either define the `OPENAI_API_KEY` environment variable or create a\n",
      "file `api.env` in one of the following locations:\n",
      "\n",
      " - /dlabscratch1/berquet/conda/envs/env2/lib/python3.10/site-packages/api.env\n",
      " - /dlabscratch1/berquet/project/dlab_project/api.env\n",
      " - /dlabscratch1/berquet/home/.lmql/api.env\n",
      "\n",
      "To use OpenAI models you need to create an api.env file with the following\n",
      "contents:\n",
      "        \n",
      "        openai-secret: <your openai secret>\n",
      "        openai-org: <your openai org>\n",
      "        \n",
      "For more info, check the related project docs:\n",
      "https://docs.lmql.ai/en/stable/language/openai.html#configuring-openai-api-credentials\n",
      " (<class 'FileNotFoundError'>)\n",
      "\n",
      "Retrying... (attempt: 3)\n",
      "  warnings.warn(f\"OpenAI API: Underlying stream of OpenAI complete() call failed with error\\n\\n{attempt.error} ({type(attempt.error)})\\n\\nRetrying... (attempt: {self.retries})\",\n",
      "OpenAIAPIWarning: Enable tracemalloc to get the object allocation traceback\n",
      "/dlabscratch1/berquet/conda/envs/env2/lib/python3.10/site-packages/lmql/runtime/bopenai/batched_openai.py:507: OpenAIAPIWarning: OpenAI API: Underlying stream of OpenAI complete() call failed with error\n",
      "\n",
      "To use openai/<models>, you have to configure your API credentials. To do so\n",
      "you can either define the `OPENAI_API_KEY` environment variable or create a\n",
      "file `api.env` in one of the following locations:\n",
      "\n",
      " - /dlabscratch1/berquet/conda/envs/env2/lib/python3.10/site-packages/api.env\n",
      " - /dlabscratch1/berquet/project/dlab_project/api.env\n",
      " - /dlabscratch1/berquet/home/.lmql/api.env\n",
      "\n",
      "To use OpenAI models you need to create an api.env file with the following\n",
      "contents:\n",
      "        \n",
      "        openai-secret: <your openai secret>\n",
      "        openai-org: <your openai org>\n",
      "        \n",
      "For more info, check the related project docs:\n",
      "https://docs.lmql.ai/en/stable/language/openai.html#configuring-openai-api-credentials\n",
      " (<class 'FileNotFoundError'>)\n",
      "\n",
      "Retrying... (attempt: 4)\n",
      "  warnings.warn(f\"OpenAI API: Underlying stream of OpenAI complete() call failed with error\\n\\n{attempt.error} ({type(attempt.error)})\\n\\nRetrying... (attempt: {self.retries})\",\n",
      "OpenAIAPIWarning: Enable tracemalloc to get the object allocation traceback\n",
      "/dlabscratch1/berquet/conda/envs/env2/lib/python3.10/site-packages/lmql/runtime/bopenai/batched_openai.py:507: OpenAIAPIWarning: OpenAI API: Underlying stream of OpenAI complete() call failed with error\n",
      "\n",
      "To use openai/<models>, you have to configure your API credentials. To do so\n",
      "you can either define the `OPENAI_API_KEY` environment variable or create a\n",
      "file `api.env` in one of the following locations:\n",
      "\n",
      " - /dlabscratch1/berquet/conda/envs/env2/lib/python3.10/site-packages/api.env\n",
      " - /dlabscratch1/berquet/project/dlab_project/api.env\n",
      " - /dlabscratch1/berquet/home/.lmql/api.env\n",
      "\n",
      "To use OpenAI models you need to create an api.env file with the following\n",
      "contents:\n",
      "        \n",
      "        openai-secret: <your openai secret>\n",
      "        openai-org: <your openai org>\n",
      "        \n",
      "For more info, check the related project docs:\n",
      "https://docs.lmql.ai/en/stable/language/openai.html#configuring-openai-api-credentials\n",
      " (<class 'FileNotFoundError'>)\n",
      "\n",
      "Retrying... (attempt: 5)\n",
      "  warnings.warn(f\"OpenAI API: Underlying stream of OpenAI complete() call failed with error\\n\\n{attempt.error} ({type(attempt.error)})\\n\\nRetrying... (attempt: {self.retries})\",\n",
      "OpenAIAPIWarning: Enable tracemalloc to get the object allocation traceback\n",
      "/dlabscratch1/berquet/conda/envs/env2/lib/python3.10/site-packages/lmql/runtime/bopenai/batched_openai.py:507: OpenAIAPIWarning: OpenAI API: Underlying stream of OpenAI complete() call failed with error\n",
      "\n",
      "To use openai/<models>, you have to configure your API credentials. To do so\n",
      "you can either define the `OPENAI_API_KEY` environment variable or create a\n",
      "file `api.env` in one of the following locations:\n",
      "\n",
      " - /dlabscratch1/berquet/conda/envs/env2/lib/python3.10/site-packages/api.env\n",
      " - /dlabscratch1/berquet/project/dlab_project/api.env\n",
      " - /dlabscratch1/berquet/home/.lmql/api.env\n",
      "\n",
      "To use OpenAI models you need to create an api.env file with the following\n",
      "contents:\n",
      "        \n",
      "        openai-secret: <your openai secret>\n",
      "        openai-org: <your openai org>\n",
      "        \n",
      "For more info, check the related project docs:\n",
      "https://docs.lmql.ai/en/stable/language/openai.html#configuring-openai-api-credentials\n",
      " (<class 'FileNotFoundError'>)\n",
      "\n",
      "Retrying... (attempt: 6)\n",
      "  warnings.warn(f\"OpenAI API: Underlying stream of OpenAI complete() call failed with error\\n\\n{attempt.error} ({type(attempt.error)})\\n\\nRetrying... (attempt: {self.retries})\",\n",
      "OpenAIAPIWarning: Enable tracemalloc to get the object allocation traceback\n",
      "/dlabscratch1/berquet/conda/envs/env2/lib/python3.10/site-packages/lmql/runtime/bopenai/batched_openai.py:507: OpenAIAPIWarning: OpenAI API: Underlying stream of OpenAI complete() call failed with error\n",
      "\n",
      "To use openai/<models>, you have to configure your API credentials. To do so\n",
      "you can either define the `OPENAI_API_KEY` environment variable or create a\n",
      "file `api.env` in one of the following locations:\n",
      "\n",
      " - /dlabscratch1/berquet/conda/envs/env2/lib/python3.10/site-packages/api.env\n",
      " - /dlabscratch1/berquet/project/dlab_project/api.env\n",
      " - /dlabscratch1/berquet/home/.lmql/api.env\n",
      "\n",
      "To use OpenAI models you need to create an api.env file with the following\n",
      "contents:\n",
      "        \n",
      "        openai-secret: <your openai secret>\n",
      "        openai-org: <your openai org>\n",
      "        \n",
      "For more info, check the related project docs:\n",
      "https://docs.lmql.ai/en/stable/language/openai.html#configuring-openai-api-credentials\n",
      " (<class 'FileNotFoundError'>)\n",
      "\n",
      "Retrying... (attempt: 7)\n",
      "  warnings.warn(f\"OpenAI API: Underlying stream of OpenAI complete() call failed with error\\n\\n{attempt.error} ({type(attempt.error)})\\n\\nRetrying... (attempt: {self.retries})\",\n",
      "OpenAIAPIWarning: Enable tracemalloc to get the object allocation traceback\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/dlabscratch1/berquet/conda/envs/env2/lib/python3.10/site-packages/lmql/runtime/bopenai/batched_openai.py:507: OpenAIAPIWarning: OpenAI API: Underlying stream of OpenAI complete() call failed with error\n",
      "\n",
      "To use openai/<models>, you have to configure your API credentials. To do so\n",
      "you can either define the `OPENAI_API_KEY` environment variable or create a\n",
      "file `api.env` in one of the following locations:\n",
      "\n",
      " - /dlabscratch1/berquet/conda/envs/env2/lib/python3.10/site-packages/api.env\n",
      " - /dlabscratch1/berquet/project/dlab_project/api.env\n",
      " - /dlabscratch1/berquet/home/.lmql/api.env\n",
      "\n",
      "To use OpenAI models you need to create an api.env file with the following\n",
      "contents:\n",
      "        \n",
      "        openai-secret: <your openai secret>\n",
      "        openai-org: <your openai org>\n",
      "        \n",
      "For more info, check the related project docs:\n",
      "https://docs.lmql.ai/en/stable/language/openai.html#configuring-openai-api-credentials\n",
      " (<class 'FileNotFoundError'>)\n",
      "\n",
      "Retrying... (attempt: 8)\n",
      "  warnings.warn(f\"OpenAI API: Underlying stream of OpenAI complete() call failed with error\\n\\n{attempt.error} ({type(attempt.error)})\\n\\nRetrying... (attempt: {self.retries})\",\n",
      "OpenAIAPIWarning: Enable tracemalloc to get the object allocation traceback\n",
      "/dlabscratch1/berquet/conda/envs/env2/lib/python3.10/site-packages/lmql/runtime/bopenai/batched_openai.py:507: OpenAIAPIWarning: OpenAI API: Underlying stream of OpenAI complete() call failed with error\n",
      "\n",
      "To use openai/<models>, you have to configure your API credentials. To do so\n",
      "you can either define the `OPENAI_API_KEY` environment variable or create a\n",
      "file `api.env` in one of the following locations:\n",
      "\n",
      " - /dlabscratch1/berquet/conda/envs/env2/lib/python3.10/site-packages/api.env\n",
      " - /dlabscratch1/berquet/project/dlab_project/api.env\n",
      " - /dlabscratch1/berquet/home/.lmql/api.env\n",
      "\n",
      "To use OpenAI models you need to create an api.env file with the following\n",
      "contents:\n",
      "        \n",
      "        openai-secret: <your openai secret>\n",
      "        openai-org: <your openai org>\n",
      "        \n",
      "For more info, check the related project docs:\n",
      "https://docs.lmql.ai/en/stable/language/openai.html#configuring-openai-api-credentials\n",
      " (<class 'FileNotFoundError'>)\n",
      "\n",
      "Retrying... (attempt: 9)\n",
      "  warnings.warn(f\"OpenAI API: Underlying stream of OpenAI complete() call failed with error\\n\\n{attempt.error} ({type(attempt.error)})\\n\\nRetrying... (attempt: {self.retries})\",\n",
      "OpenAIAPIWarning: Enable tracemalloc to get the object allocation traceback\n",
      "/dlabscratch1/berquet/conda/envs/env2/lib/python3.10/site-packages/lmql/runtime/bopenai/batched_openai.py:507: OpenAIAPIWarning: OpenAI API: Underlying stream of OpenAI complete() call failed with error\n",
      "\n",
      "To use openai/<models>, you have to configure your API credentials. To do so\n",
      "you can either define the `OPENAI_API_KEY` environment variable or create a\n",
      "file `api.env` in one of the following locations:\n",
      "\n",
      " - /dlabscratch1/berquet/conda/envs/env2/lib/python3.10/site-packages/api.env\n",
      " - /dlabscratch1/berquet/project/dlab_project/api.env\n",
      " - /dlabscratch1/berquet/home/.lmql/api.env\n",
      "\n",
      "To use OpenAI models you need to create an api.env file with the following\n",
      "contents:\n",
      "        \n",
      "        openai-secret: <your openai secret>\n",
      "        openai-org: <your openai org>\n",
      "        \n",
      "For more info, check the related project docs:\n",
      "https://docs.lmql.ai/en/stable/language/openai.html#configuring-openai-api-credentials\n",
      " (<class 'FileNotFoundError'>)\n",
      "\n",
      "Retrying... (attempt: 10)\n",
      "  warnings.warn(f\"OpenAI API: Underlying stream of OpenAI complete() call failed with error\\n\\n{attempt.error} ({type(attempt.error)})\\n\\nRetrying... (attempt: {self.retries})\",\n",
      "OpenAIAPIWarning: Enable tracemalloc to get the object allocation traceback\n",
      "/dlabscratch1/berquet/conda/envs/env2/lib/python3.10/site-packages/lmql/runtime/bopenai/batched_openai.py:507: OpenAIAPIWarning: OpenAI API: Underlying stream of OpenAI complete() call failed with error\n",
      "\n",
      "To use openai/<models>, you have to configure your API credentials. To do so\n",
      "you can either define the `OPENAI_API_KEY` environment variable or create a\n",
      "file `api.env` in one of the following locations:\n",
      "\n",
      " - /dlabscratch1/berquet/conda/envs/env2/lib/python3.10/site-packages/api.env\n",
      " - /dlabscratch1/berquet/project/dlab_project/api.env\n",
      " - /dlabscratch1/berquet/home/.lmql/api.env\n",
      "\n",
      "To use OpenAI models you need to create an api.env file with the following\n",
      "contents:\n",
      "        \n",
      "        openai-secret: <your openai secret>\n",
      "        openai-org: <your openai org>\n",
      "        \n",
      "For more info, check the related project docs:\n",
      "https://docs.lmql.ai/en/stable/language/openai.html#configuring-openai-api-credentials\n",
      " (<class 'FileNotFoundError'>)\n",
      "\n",
      "Retrying... (attempt: 11)\n",
      "  warnings.warn(f\"OpenAI API: Underlying stream of OpenAI complete() call failed with error\\n\\n{attempt.error} ({type(attempt.error)})\\n\\nRetrying... (attempt: {self.retries})\",\n",
      "OpenAIAPIWarning: Enable tracemalloc to get the object allocation traceback\n",
      "/dlabscratch1/berquet/conda/envs/env2/lib/python3.10/site-packages/lmql/runtime/bopenai/batched_openai.py:507: OpenAIAPIWarning: OpenAI API: Underlying stream of OpenAI complete() call failed with error\n",
      "\n",
      "To use openai/<models>, you have to configure your API credentials. To do so\n",
      "you can either define the `OPENAI_API_KEY` environment variable or create a\n",
      "file `api.env` in one of the following locations:\n",
      "\n",
      " - /dlabscratch1/berquet/conda/envs/env2/lib/python3.10/site-packages/api.env\n",
      " - /dlabscratch1/berquet/project/dlab_project/api.env\n",
      " - /dlabscratch1/berquet/home/.lmql/api.env\n",
      "\n",
      "To use OpenAI models you need to create an api.env file with the following\n",
      "contents:\n",
      "        \n",
      "        openai-secret: <your openai secret>\n",
      "        openai-org: <your openai org>\n",
      "        \n",
      "For more info, check the related project docs:\n",
      "https://docs.lmql.ai/en/stable/language/openai.html#configuring-openai-api-credentials\n",
      " (<class 'FileNotFoundError'>)\n",
      "\n",
      "Retrying... (attempt: 12)\n",
      "  warnings.warn(f\"OpenAI API: Underlying stream of OpenAI complete() call failed with error\\n\\n{attempt.error} ({type(attempt.error)})\\n\\nRetrying... (attempt: {self.retries})\",\n",
      "OpenAIAPIWarning: Enable tracemalloc to get the object allocation traceback\n",
      "/dlabscratch1/berquet/conda/envs/env2/lib/python3.10/site-packages/lmql/runtime/bopenai/batched_openai.py:507: OpenAIAPIWarning: OpenAI API: Underlying stream of OpenAI complete() call failed with error\n",
      "\n",
      "To use openai/<models>, you have to configure your API credentials. To do so\n",
      "you can either define the `OPENAI_API_KEY` environment variable or create a\n",
      "file `api.env` in one of the following locations:\n",
      "\n",
      " - /dlabscratch1/berquet/conda/envs/env2/lib/python3.10/site-packages/api.env\n",
      " - /dlabscratch1/berquet/project/dlab_project/api.env\n",
      " - /dlabscratch1/berquet/home/.lmql/api.env\n",
      "\n",
      "To use OpenAI models you need to create an api.env file with the following\n",
      "contents:\n",
      "        \n",
      "        openai-secret: <your openai secret>\n",
      "        openai-org: <your openai org>\n",
      "        \n",
      "For more info, check the related project docs:\n",
      "https://docs.lmql.ai/en/stable/language/openai.html#configuring-openai-api-credentials\n",
      " (<class 'FileNotFoundError'>)\n",
      "\n",
      "Retrying... (attempt: 13)\n",
      "  warnings.warn(f\"OpenAI API: Underlying stream of OpenAI complete() call failed with error\\n\\n{attempt.error} ({type(attempt.error)})\\n\\nRetrying... (attempt: {self.retries})\",\n",
      "OpenAIAPIWarning: Enable tracemalloc to get the object allocation traceback\n",
      "/dlabscratch1/berquet/conda/envs/env2/lib/python3.10/site-packages/lmql/runtime/bopenai/batched_openai.py:507: OpenAIAPIWarning: OpenAI API: Underlying stream of OpenAI complete() call failed with error\n",
      "\n",
      "To use openai/<models>, you have to configure your API credentials. To do so\n",
      "you can either define the `OPENAI_API_KEY` environment variable or create a\n",
      "file `api.env` in one of the following locations:\n",
      "\n",
      " - /dlabscratch1/berquet/conda/envs/env2/lib/python3.10/site-packages/api.env\n",
      " - /dlabscratch1/berquet/project/dlab_project/api.env\n",
      " - /dlabscratch1/berquet/home/.lmql/api.env\n",
      "\n",
      "To use OpenAI models you need to create an api.env file with the following\n",
      "contents:\n",
      "        \n",
      "        openai-secret: <your openai secret>\n",
      "        openai-org: <your openai org>\n",
      "        \n",
      "For more info, check the related project docs:\n",
      "https://docs.lmql.ai/en/stable/language/openai.html#configuring-openai-api-credentials\n",
      " (<class 'FileNotFoundError'>)\n",
      "\n",
      "Retrying... (attempt: 14)\n",
      "  warnings.warn(f\"OpenAI API: Underlying stream of OpenAI complete() call failed with error\\n\\n{attempt.error} ({type(attempt.error)})\\n\\nRetrying... (attempt: {self.retries})\",\n",
      "OpenAIAPIWarning: Enable tracemalloc to get the object allocation traceback\n",
      "/dlabscratch1/berquet/conda/envs/env2/lib/python3.10/site-packages/lmql/runtime/bopenai/batched_openai.py:507: OpenAIAPIWarning: OpenAI API: Underlying stream of OpenAI complete() call failed with error\n",
      "\n",
      "To use openai/<models>, you have to configure your API credentials. To do so\n",
      "you can either define the `OPENAI_API_KEY` environment variable or create a\n",
      "file `api.env` in one of the following locations:\n",
      "\n",
      " - /dlabscratch1/berquet/conda/envs/env2/lib/python3.10/site-packages/api.env\n",
      " - /dlabscratch1/berquet/project/dlab_project/api.env\n",
      " - /dlabscratch1/berquet/home/.lmql/api.env\n",
      "\n",
      "To use OpenAI models you need to create an api.env file with the following\n",
      "contents:\n",
      "        \n",
      "        openai-secret: <your openai secret>\n",
      "        openai-org: <your openai org>\n",
      "        \n",
      "For more info, check the related project docs:\n",
      "https://docs.lmql.ai/en/stable/language/openai.html#configuring-openai-api-credentials\n",
      " (<class 'FileNotFoundError'>)\n",
      "\n",
      "Retrying... (attempt: 15)\n",
      "  warnings.warn(f\"OpenAI API: Underlying stream of OpenAI complete() call failed with error\\n\\n{attempt.error} ({type(attempt.error)})\\n\\nRetrying... (attempt: {self.retries})\",\n",
      "OpenAIAPIWarning: Enable tracemalloc to get the object allocation traceback\n",
      "/dlabscratch1/berquet/conda/envs/env2/lib/python3.10/site-packages/lmql/runtime/bopenai/batched_openai.py:507: OpenAIAPIWarning: OpenAI API: Underlying stream of OpenAI complete() call failed with error\n",
      "\n",
      "To use openai/<models>, you have to configure your API credentials. To do so\n",
      "you can either define the `OPENAI_API_KEY` environment variable or create a\n",
      "file `api.env` in one of the following locations:\n",
      "\n",
      " - /dlabscratch1/berquet/conda/envs/env2/lib/python3.10/site-packages/api.env\n",
      " - /dlabscratch1/berquet/project/dlab_project/api.env\n",
      " - /dlabscratch1/berquet/home/.lmql/api.env\n",
      "\n",
      "To use OpenAI models you need to create an api.env file with the following\n",
      "contents:\n",
      "        \n",
      "        openai-secret: <your openai secret>\n",
      "        openai-org: <your openai org>\n",
      "        \n",
      "For more info, check the related project docs:\n",
      "https://docs.lmql.ai/en/stable/language/openai.html#configuring-openai-api-credentials\n",
      " (<class 'FileNotFoundError'>)\n",
      "\n",
      "Retrying... (attempt: 16)\n",
      "  warnings.warn(f\"OpenAI API: Underlying stream of OpenAI complete() call failed with error\\n\\n{attempt.error} ({type(attempt.error)})\\n\\nRetrying... (attempt: {self.retries})\",\n",
      "OpenAIAPIWarning: Enable tracemalloc to get the object allocation traceback\n",
      "/dlabscratch1/berquet/conda/envs/env2/lib/python3.10/site-packages/lmql/runtime/bopenai/batched_openai.py:507: OpenAIAPIWarning: OpenAI API: Underlying stream of OpenAI complete() call failed with error\n",
      "\n",
      "To use openai/<models>, you have to configure your API credentials. To do so\n",
      "you can either define the `OPENAI_API_KEY` environment variable or create a\n",
      "file `api.env` in one of the following locations:\n",
      "\n",
      " - /dlabscratch1/berquet/conda/envs/env2/lib/python3.10/site-packages/api.env\n",
      " - /dlabscratch1/berquet/project/dlab_project/api.env\n",
      " - /dlabscratch1/berquet/home/.lmql/api.env\n",
      "\n",
      "To use OpenAI models you need to create an api.env file with the following\n",
      "contents:\n",
      "        \n",
      "        openai-secret: <your openai secret>\n",
      "        openai-org: <your openai org>\n",
      "        \n",
      "For more info, check the related project docs:\n",
      "https://docs.lmql.ai/en/stable/language/openai.html#configuring-openai-api-credentials\n",
      " (<class 'FileNotFoundError'>)\n",
      "\n",
      "Retrying... (attempt: 17)\n",
      "  warnings.warn(f\"OpenAI API: Underlying stream of OpenAI complete() call failed with error\\n\\n{attempt.error} ({type(attempt.error)})\\n\\nRetrying... (attempt: {self.retries})\",\n",
      "OpenAIAPIWarning: Enable tracemalloc to get the object allocation traceback\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/dlabscratch1/berquet/conda/envs/env2/lib/python3.10/site-packages/lmql/runtime/bopenai/batched_openai.py:507: OpenAIAPIWarning: OpenAI API: Underlying stream of OpenAI complete() call failed with error\n",
      "\n",
      "To use openai/<models>, you have to configure your API credentials. To do so\n",
      "you can either define the `OPENAI_API_KEY` environment variable or create a\n",
      "file `api.env` in one of the following locations:\n",
      "\n",
      " - /dlabscratch1/berquet/conda/envs/env2/lib/python3.10/site-packages/api.env\n",
      " - /dlabscratch1/berquet/project/dlab_project/api.env\n",
      " - /dlabscratch1/berquet/home/.lmql/api.env\n",
      "\n",
      "To use OpenAI models you need to create an api.env file with the following\n",
      "contents:\n",
      "        \n",
      "        openai-secret: <your openai secret>\n",
      "        openai-org: <your openai org>\n",
      "        \n",
      "For more info, check the related project docs:\n",
      "https://docs.lmql.ai/en/stable/language/openai.html#configuring-openai-api-credentials\n",
      " (<class 'FileNotFoundError'>)\n",
      "\n",
      "Retrying... (attempt: 18)\n",
      "  warnings.warn(f\"OpenAI API: Underlying stream of OpenAI complete() call failed with error\\n\\n{attempt.error} ({type(attempt.error)})\\n\\nRetrying... (attempt: {self.retries})\",\n",
      "OpenAIAPIWarning: Enable tracemalloc to get the object allocation traceback\n",
      "/dlabscratch1/berquet/conda/envs/env2/lib/python3.10/site-packages/lmql/runtime/bopenai/batched_openai.py:507: OpenAIAPIWarning: OpenAI API: Underlying stream of OpenAI complete() call failed with error\n",
      "\n",
      "To use openai/<models>, you have to configure your API credentials. To do so\n",
      "you can either define the `OPENAI_API_KEY` environment variable or create a\n",
      "file `api.env` in one of the following locations:\n",
      "\n",
      " - /dlabscratch1/berquet/conda/envs/env2/lib/python3.10/site-packages/api.env\n",
      " - /dlabscratch1/berquet/project/dlab_project/api.env\n",
      " - /dlabscratch1/berquet/home/.lmql/api.env\n",
      "\n",
      "To use OpenAI models you need to create an api.env file with the following\n",
      "contents:\n",
      "        \n",
      "        openai-secret: <your openai secret>\n",
      "        openai-org: <your openai org>\n",
      "        \n",
      "For more info, check the related project docs:\n",
      "https://docs.lmql.ai/en/stable/language/openai.html#configuring-openai-api-credentials\n",
      " (<class 'FileNotFoundError'>)\n",
      "\n",
      "Retrying... (attempt: 19)\n",
      "  warnings.warn(f\"OpenAI API: Underlying stream of OpenAI complete() call failed with error\\n\\n{attempt.error} ({type(attempt.error)})\\n\\nRetrying... (attempt: {self.retries})\",\n",
      "OpenAIAPIWarning: Enable tracemalloc to get the object allocation traceback\n",
      "/dlabscratch1/berquet/conda/envs/env2/lib/python3.10/site-packages/lmql/runtime/bopenai/batched_openai.py:507: OpenAIAPIWarning: OpenAI API: Underlying stream of OpenAI complete() call failed with error\n",
      "\n",
      "To use openai/<models>, you have to configure your API credentials. To do so\n",
      "you can either define the `OPENAI_API_KEY` environment variable or create a\n",
      "file `api.env` in one of the following locations:\n",
      "\n",
      " - /dlabscratch1/berquet/conda/envs/env2/lib/python3.10/site-packages/api.env\n",
      " - /dlabscratch1/berquet/project/dlab_project/api.env\n",
      " - /dlabscratch1/berquet/home/.lmql/api.env\n",
      "\n",
      "To use OpenAI models you need to create an api.env file with the following\n",
      "contents:\n",
      "        \n",
      "        openai-secret: <your openai secret>\n",
      "        openai-org: <your openai org>\n",
      "        \n",
      "For more info, check the related project docs:\n",
      "https://docs.lmql.ai/en/stable/language/openai.html#configuring-openai-api-credentials\n",
      " (<class 'FileNotFoundError'>)\n",
      "\n",
      "Retrying... (attempt: 20)\n",
      "  warnings.warn(f\"OpenAI API: Underlying stream of OpenAI complete() call failed with error\\n\\n{attempt.error} ({type(attempt.error)})\\n\\nRetrying... (attempt: {self.retries})\",\n",
      "OpenAIAPIWarning: Enable tracemalloc to get the object allocation traceback\n"
     ]
    },
    {
     "ename": "MaximumRetriesExceeded",
     "evalue": "Maximum retries exceeded (21) with error <class 'FileNotFoundError'>: To use openai/<models>, you have to configure your API credentials. To do so\nyou can either define the `OPENAI_API_KEY` environment variable or create a\nfile `api.env` in one of the following locations:\n\n - /dlabscratch1/berquet/conda/envs/env2/lib/python3.10/site-packages/api.env\n - /dlabscratch1/berquet/project/dlab_project/api.env\n - /dlabscratch1/berquet/home/.lmql/api.env\n\nTo use OpenAI models you need to create an api.env file with the following\ncontents:\n        \n        openai-secret: <your openai secret>\n        openai-org: <your openai org>\n        \nFor more info, check the related project docs:\nhttps://docs.lmql.ai/en/stable/language/openai.html#configuring-openai-api-credentials\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mMaximumRetriesExceeded\u001b[0m                    Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_771/3675930847.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m \"\"\", is_async=False)\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mchain_of_thought\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"What is 2x3?\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/dlabscratch1/berquet/conda/envs/env2/lib/python3.10/site-packages/lmql/runtime/lmql_runtime.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    202\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_async\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 204\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mcall_sync\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    205\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__acall__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/dlabscratch1/berquet/conda/envs/env2/lib/python3.10/site-packages/lmql/runtime/loop.py\u001b[0m in \u001b[0;36mcall_sync\u001b[0;34m(lmql_query_function, *args, **kwargs)\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_until_complete\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mRuntimeError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m\"This event loop is already running\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m\"Cannot run the event loop while another loop is running\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/dlabscratch1/berquet/conda/envs/env2/lib/python3.10/site-packages/nest_asyncio.py\u001b[0m in \u001b[0;36mrun_until_complete\u001b[0;34m(self, future)\u001b[0m\n\u001b[1;32m     96\u001b[0m                 raise RuntimeError(\n\u001b[1;32m     97\u001b[0m                     'Event loop stopped before Future completed.')\n\u001b[0;32m---> 98\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_once\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/dlabscratch1/berquet/conda/envs/env2/lib/python3.10/asyncio/futures.py\u001b[0m in \u001b[0;36mresult\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    199\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__log_traceback\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_exception\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 201\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_exception\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_exception_tb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    202\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/dlabscratch1/berquet/conda/envs/env2/lib/python3.10/asyncio/tasks.py\u001b[0m in \u001b[0;36m__step\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m    232\u001b[0m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcoro\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 234\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcoro\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mthrow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    235\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_must_cancel\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/dlabscratch1/berquet/conda/envs/env2/lib/python3.10/site-packages/lmql/runtime/lmql_runtime.py\u001b[0m in \u001b[0;36m__acall__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    228\u001b[0m                 \u001b[0mPromptInterpreter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmain\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minterpreter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    229\u001b[0m             \u001b[0;31m# execute main prompt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 230\u001b[0;31m             \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mawait\u001b[0m \u001b[0minterpreter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfct\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mquery_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    231\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    232\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mPromptInterpreter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmain\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0minterpreter\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/dlabscratch1/berquet/conda/envs/env2/lib/python3.10/site-packages/lmql/runtime/tracing/tracer.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    238\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    239\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mContextTracer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtracer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 240\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0;32mawait\u001b[0m \u001b[0mfct\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    241\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    242\u001b[0m             \u001b[0;32mdef\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/dlabscratch1/berquet/conda/envs/env2/lib/python3.10/site-packages/lmql/runtime/interpreter.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fct, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1068\u001b[0m                 \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1069\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1070\u001b[0;31m                 \u001b[0;32masync\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdecoder_fct\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprompt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mdecoder_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1071\u001b[0m                     \u001b[0;32mawait\u001b[0m \u001b[0mdebug_out\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecoder_step\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1072\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecoder_step\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/dlabscratch1/berquet/conda/envs/env2/lib/python3.10/site-packages/lmql/runtime/dclib/decoders.py\u001b[0m in \u001b[0;36margmax\u001b[0;34m(prompt_ids, n, max_len, **kwargs)\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m         \u001b[0mh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mawait\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnoscore\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m         \u001b[0mh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mawait\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrewrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnoscore\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0mh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mh\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseparate_by\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogical_not\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meos\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_len\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/dlabscratch1/berquet/conda/envs/env2/lib/python3.10/site-packages/lmql/runtime/dclib/dclib_cache.py\u001b[0m in \u001b[0;36margmax\u001b[0;34m(self, arr, **kwargs)\u001b[0m\n\u001b[1;32m    275\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    276\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 277\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;32mawait\u001b[0m \u001b[0marr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maelement_wise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop_argmax\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    278\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    279\u001b[0m     \u001b[0;32masync\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marr\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mDataArray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_samples\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/dlabscratch1/berquet/conda/envs/env2/lib/python3.10/site-packages/lmql/runtime/dclib/dclib_array.py\u001b[0m in \u001b[0;36maelement_wise\u001b[0;34m(self, op, *args, **kwargs)\u001b[0m\n\u001b[1;32m    316\u001b[0m         \u001b[0;32masync\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mop_with_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0melement\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    317\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mawait\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melement\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 318\u001b[0;31m         \u001b[0mresult_items\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mawait\u001b[0m \u001b[0masyncio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgather\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mop_with_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseqs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseqs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msequences\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    319\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mDataArray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult_items\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    320\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/dlabscratch1/berquet/conda/envs/env2/lib/python3.10/asyncio/tasks.py\u001b[0m in \u001b[0;36m__wakeup\u001b[0;34m(self, future)\u001b[0m\n\u001b[1;32m    302\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__wakeup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfuture\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    303\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 304\u001b[0;31m             \u001b[0mfuture\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    305\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mBaseException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    306\u001b[0m             \u001b[0;31m# This may also be a cancellation.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/dlabscratch1/berquet/conda/envs/env2/lib/python3.10/asyncio/tasks.py\u001b[0m in \u001b[0;36m__step\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m    232\u001b[0m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcoro\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 234\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcoro\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mthrow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    235\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_must_cancel\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/dlabscratch1/berquet/conda/envs/env2/lib/python3.10/site-packages/lmql/runtime/dclib/dclib_array.py\u001b[0m in \u001b[0;36mop_with_path\u001b[0;34m(path, element, *args, **kwargs)\u001b[0m\n\u001b[1;32m    315\u001b[0m     \u001b[0;32masync\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0maelement_wise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    316\u001b[0m         \u001b[0;32masync\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mop_with_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0melement\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 317\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mawait\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melement\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    318\u001b[0m         \u001b[0mresult_items\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mawait\u001b[0m \u001b[0masyncio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgather\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mop_with_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseqs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseqs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msequences\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    319\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mDataArray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult_items\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/dlabscratch1/berquet/conda/envs/env2/lib/python3.10/site-packages/lmql/runtime/dclib/dclib_cache.py\u001b[0m in \u001b[0;36mop_argmax\u001b[0;34m(seqs)\u001b[0m\n\u001b[1;32m    254\u001b[0m             \u001b[0mnon_cached\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0ms\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseqs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcached_tokens\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mc\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m             \u001b[0;31m# generator over new results\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 256\u001b[0;31m             \u001b[0mnon_cached_argmax\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mawait\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdelegate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDataArray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnon_cached\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    257\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    258\u001b[0m             \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/dlabscratch1/berquet/conda/envs/env2/lib/python3.10/site-packages/lmql/runtime/openai_integration.py\u001b[0m in \u001b[0;36margmax\u001b[0;34m(self, sequences, **kwargs)\u001b[0m\n\u001b[1;32m    525\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    526\u001b[0m     \u001b[0;32masync\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msequences\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 527\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;32mawait\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msequences\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_samples\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtemperature\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    529\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mreport_stats\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprinter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder_step\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/dlabscratch1/berquet/conda/envs/env2/lib/python3.10/site-packages/lmql/runtime/openai_integration.py\u001b[0m in \u001b[0;36msample\u001b[0;34m(self, sequences, num_samples, **kwargs)\u001b[0m\n\u001b[1;32m    643\u001b[0m                 user_data=successor_user_data(continuation_buffers[i], len(next_token_ids[i]), edge_type_user_data)) for i, s, edge_type_user_data in zip(range(len(seqs)), seqs, edge_type_populated_user_data)]\n\u001b[1;32m    644\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstats\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"sample\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 645\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0;32mawait\u001b[0m \u001b[0msequences\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maelement_wise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop_sample\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    646\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    647\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfrombytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/dlabscratch1/berquet/conda/envs/env2/lib/python3.10/site-packages/lmql/runtime/dclib/dclib_array.py\u001b[0m in \u001b[0;36maelement_wise\u001b[0;34m(self, op, *args, **kwargs)\u001b[0m\n\u001b[1;32m    316\u001b[0m         \u001b[0;32masync\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mop_with_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0melement\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    317\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mawait\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melement\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 318\u001b[0;31m         \u001b[0mresult_items\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mawait\u001b[0m \u001b[0masyncio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgather\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mop_with_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseqs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseqs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msequences\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    319\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mDataArray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult_items\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    320\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/dlabscratch1/berquet/conda/envs/env2/lib/python3.10/asyncio/tasks.py\u001b[0m in \u001b[0;36m__wakeup\u001b[0;34m(self, future)\u001b[0m\n\u001b[1;32m    302\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__wakeup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfuture\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    303\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 304\u001b[0;31m             \u001b[0mfuture\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    305\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mBaseException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    306\u001b[0m             \u001b[0;31m# This may also be a cancellation.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/dlabscratch1/berquet/conda/envs/env2/lib/python3.10/asyncio/tasks.py\u001b[0m in \u001b[0;36m__step\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m    232\u001b[0m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcoro\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 234\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcoro\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mthrow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    235\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_must_cancel\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/dlabscratch1/berquet/conda/envs/env2/lib/python3.10/site-packages/lmql/runtime/dclib/dclib_array.py\u001b[0m in \u001b[0;36mop_with_path\u001b[0;34m(path, element, *args, **kwargs)\u001b[0m\n\u001b[1;32m    315\u001b[0m     \u001b[0;32masync\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0maelement_wise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    316\u001b[0m         \u001b[0;32masync\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mop_with_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0melement\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 317\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mawait\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melement\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    318\u001b[0m         \u001b[0mresult_items\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mawait\u001b[0m \u001b[0masyncio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgather\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mop_with_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseqs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseqs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msequences\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    319\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mDataArray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult_items\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/dlabscratch1/berquet/conda/envs/env2/lib/python3.10/site-packages/lmql/runtime/openai_integration.py\u001b[0m in \u001b[0;36mop_sample\u001b[0;34m(seqs)\u001b[0m\n\u001b[1;32m    558\u001b[0m                 \u001b[0medge_type_populated_user_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"dc-edge-type\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0msm\u001b[0m\u001b[0;34m}\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msm\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msampling_modes\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 560\u001b[0;31m             \u001b[0mcompletions\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mCompletionResult\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mawait\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompletion_buffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseqs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogprobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_samples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msampling_modes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msampling_modes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    561\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    562\u001b[0m             \u001b[0mnext_token_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/dlabscratch1/berquet/conda/envs/env2/lib/python3.10/site-packages/lmql/runtime/openai_integration.py\u001b[0m in \u001b[0;36mcompletion_buffer\u001b[0;34m(self, seqs, temperature, sampling_modes, **kwargs)\u001b[0m\n\u001b[1;32m    447\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mcompletion_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    448\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 449\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;32mawait\u001b[0m \u001b[0masyncio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgather\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mget_buffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseqs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    450\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    451\u001b[0m     \u001b[0;32masync\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mexpand_and_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mDecoderSequence\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompletion_result\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mCompletionResult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msampling_mode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogprobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/dlabscratch1/berquet/conda/envs/env2/lib/python3.10/asyncio/tasks.py\u001b[0m in \u001b[0;36m__wakeup\u001b[0;34m(self, future)\u001b[0m\n\u001b[1;32m    302\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__wakeup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfuture\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    303\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 304\u001b[0;31m             \u001b[0mfuture\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    305\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mBaseException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    306\u001b[0m             \u001b[0;31m# This may also be a cancellation.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/dlabscratch1/berquet/conda/envs/env2/lib/python3.10/asyncio/tasks.py\u001b[0m in \u001b[0;36m__step\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m    230\u001b[0m                 \u001b[0;31m# We use the `send` method directly, because coroutines\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    231\u001b[0m                 \u001b[0;31m# don't have `__iter__` and `__next__` methods.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 232\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcoro\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    233\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    234\u001b[0m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcoro\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mthrow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/dlabscratch1/berquet/conda/envs/env2/lib/python3.10/site-packages/lmql/runtime/openai_integration.py\u001b[0m in \u001b[0;36mget_buffer\u001b[0;34m(i, s)\u001b[0m\n\u001b[1;32m    440\u001b[0m             \u001b[0;31m# eagerly expand and cache full completion if a cache_delegate is available\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    441\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcache_delegate\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 442\u001b[0;31m                 await self.expand_and_cache(s, completion_result, \n\u001b[0m\u001b[1;32m    443\u001b[0m                                             \u001b[0msampling_modes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    444\u001b[0m                                             logprobs=kwargs.get(\"logprobs\", 1))\n",
      "\u001b[0;32m/dlabscratch1/berquet/conda/envs/env2/lib/python3.10/site-packages/lmql/runtime/openai_integration.py\u001b[0m in \u001b[0;36mexpand_and_cache\u001b[0;34m(self, s, completion_result, sampling_mode, logprobs)\u001b[0m\n\u001b[1;32m    452\u001b[0m         \u001b[0;31m# wait at least for the first completion so\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    453\u001b[0m         \u001b[0;31m# the cache is guaranteed to be ahead\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 454\u001b[0;31m         \u001b[0m_res\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mawait\u001b[0m \u001b[0mcompletion_result\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuffer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m         \u001b[0;32masync\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mtoken_stream\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/dlabscratch1/berquet/conda/envs/env2/lib/python3.10/site-packages/lmql/runtime/bopenai/batched_openai.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, i)\u001b[0m\n\u001b[1;32m    248\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    249\u001b[0m     \u001b[0;32masync\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 250\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;32mawait\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuffer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    251\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/dlabscratch1/berquet/conda/envs/env2/lib/python3.10/site-packages/lmql/runtime/bopenai/batched_openai.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, i)\u001b[0m\n\u001b[1;32m    332\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_tokens\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miterator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 334\u001b[0;31m                 \u001b[0mchunk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mawait\u001b[0m \u001b[0manext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    335\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_append\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    336\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mStopAsyncIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/dlabscratch1/berquet/conda/envs/env2/lib/python3.10/site-packages/lmql/runtime/bopenai/batched_openai.py\u001b[0m in \u001b[0;36m__anext__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    514\u001b[0m                     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Cannot recover from stream error without a configured tokenizer\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflush\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    515\u001b[0m                     \u001b[0;32mraise\u001b[0m \u001b[0mattempt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 516\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mawait\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecover\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    517\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    518\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconsumed_tokens\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"logprobs\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"tokens\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/dlabscratch1/berquet/conda/envs/env2/lib/python3.10/site-packages/lmql/runtime/bopenai/batched_openai.py\u001b[0m in \u001b[0;36mrecover\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    423\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mslice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_slice\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    424\u001b[0m         \u001b[0;31m# otherwise the chunking aligns with the old stream, so we return the next chunk\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 425\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;32mawait\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__anext__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    426\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    427\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__del__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/dlabscratch1/berquet/conda/envs/env2/lib/python3.10/site-packages/lmql/runtime/bopenai/batched_openai.py\u001b[0m in \u001b[0;36m__anext__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    514\u001b[0m                     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Cannot recover from stream error without a configured tokenizer\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflush\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    515\u001b[0m                     \u001b[0;32mraise\u001b[0m \u001b[0mattempt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 516\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mawait\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecover\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    517\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    518\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconsumed_tokens\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"logprobs\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"tokens\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/dlabscratch1/berquet/conda/envs/env2/lib/python3.10/site-packages/lmql/runtime/bopenai/batched_openai.py\u001b[0m in \u001b[0;36mrecover\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    423\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mslice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_slice\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    424\u001b[0m         \u001b[0;31m# otherwise the chunking aligns with the old stream, so we return the next chunk\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 425\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;32mawait\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__anext__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    426\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    427\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__del__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/dlabscratch1/berquet/conda/envs/env2/lib/python3.10/site-packages/lmql/runtime/bopenai/batched_openai.py\u001b[0m in \u001b[0;36m__anext__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    514\u001b[0m                     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Cannot recover from stream error without a configured tokenizer\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflush\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    515\u001b[0m                     \u001b[0;32mraise\u001b[0m \u001b[0mattempt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 516\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mawait\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecover\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    517\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    518\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconsumed_tokens\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"logprobs\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"tokens\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/dlabscratch1/berquet/conda/envs/env2/lib/python3.10/site-packages/lmql/runtime/bopenai/batched_openai.py\u001b[0m in \u001b[0;36mrecover\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    423\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mslice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_slice\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    424\u001b[0m         \u001b[0;31m# otherwise the chunking aligns with the old stream, so we return the next chunk\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 425\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;32mawait\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__anext__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    426\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    427\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__del__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/dlabscratch1/berquet/conda/envs/env2/lib/python3.10/site-packages/lmql/runtime/bopenai/batched_openai.py\u001b[0m in \u001b[0;36m__anext__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    514\u001b[0m                     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Cannot recover from stream error without a configured tokenizer\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflush\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    515\u001b[0m                     \u001b[0;32mraise\u001b[0m \u001b[0mattempt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 516\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mawait\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecover\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    517\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    518\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconsumed_tokens\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"logprobs\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"tokens\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/dlabscratch1/berquet/conda/envs/env2/lib/python3.10/site-packages/lmql/runtime/bopenai/batched_openai.py\u001b[0m in \u001b[0;36mrecover\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    423\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mslice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_slice\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    424\u001b[0m         \u001b[0;31m# otherwise the chunking aligns with the old stream, so we return the next chunk\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 425\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;32mawait\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__anext__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    426\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    427\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__del__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/dlabscratch1/berquet/conda/envs/env2/lib/python3.10/site-packages/lmql/runtime/bopenai/batched_openai.py\u001b[0m in \u001b[0;36m__anext__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    514\u001b[0m                     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Cannot recover from stream error without a configured tokenizer\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflush\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    515\u001b[0m                     \u001b[0;32mraise\u001b[0m \u001b[0mattempt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 516\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mawait\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecover\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    517\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    518\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconsumed_tokens\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"logprobs\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"tokens\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/dlabscratch1/berquet/conda/envs/env2/lib/python3.10/site-packages/lmql/runtime/bopenai/batched_openai.py\u001b[0m in \u001b[0;36mrecover\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    423\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mslice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_slice\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    424\u001b[0m         \u001b[0;31m# otherwise the chunking aligns with the old stream, so we return the next chunk\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 425\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;32mawait\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__anext__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    426\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    427\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__del__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/dlabscratch1/berquet/conda/envs/env2/lib/python3.10/site-packages/lmql/runtime/bopenai/batched_openai.py\u001b[0m in \u001b[0;36m__anext__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    514\u001b[0m                     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Cannot recover from stream error without a configured tokenizer\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflush\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    515\u001b[0m                     \u001b[0;32mraise\u001b[0m \u001b[0mattempt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 516\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mawait\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecover\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    517\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    518\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconsumed_tokens\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"logprobs\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"tokens\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/dlabscratch1/berquet/conda/envs/env2/lib/python3.10/site-packages/lmql/runtime/bopenai/batched_openai.py\u001b[0m in \u001b[0;36mrecover\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    423\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mslice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_slice\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    424\u001b[0m         \u001b[0;31m# otherwise the chunking aligns with the old stream, so we return the next chunk\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 425\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;32mawait\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__anext__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    426\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    427\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__del__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/dlabscratch1/berquet/conda/envs/env2/lib/python3.10/site-packages/lmql/runtime/bopenai/batched_openai.py\u001b[0m in \u001b[0;36m__anext__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    514\u001b[0m                     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Cannot recover from stream error without a configured tokenizer\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflush\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    515\u001b[0m                     \u001b[0;32mraise\u001b[0m \u001b[0mattempt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 516\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mawait\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecover\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    517\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    518\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconsumed_tokens\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"logprobs\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"tokens\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/dlabscratch1/berquet/conda/envs/env2/lib/python3.10/site-packages/lmql/runtime/bopenai/batched_openai.py\u001b[0m in \u001b[0;36mrecover\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    423\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mslice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_slice\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    424\u001b[0m         \u001b[0;31m# otherwise the chunking aligns with the old stream, so we return the next chunk\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 425\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;32mawait\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__anext__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    426\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    427\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__del__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/dlabscratch1/berquet/conda/envs/env2/lib/python3.10/site-packages/lmql/runtime/bopenai/batched_openai.py\u001b[0m in \u001b[0;36m__anext__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    514\u001b[0m                     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Cannot recover from stream error without a configured tokenizer\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflush\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    515\u001b[0m                     \u001b[0;32mraise\u001b[0m \u001b[0mattempt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 516\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mawait\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecover\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    517\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    518\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconsumed_tokens\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"logprobs\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"tokens\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/dlabscratch1/berquet/conda/envs/env2/lib/python3.10/site-packages/lmql/runtime/bopenai/batched_openai.py\u001b[0m in \u001b[0;36mrecover\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    423\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mslice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_slice\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    424\u001b[0m         \u001b[0;31m# otherwise the chunking aligns with the old stream, so we return the next chunk\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 425\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;32mawait\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__anext__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    426\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    427\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__del__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/dlabscratch1/berquet/conda/envs/env2/lib/python3.10/site-packages/lmql/runtime/bopenai/batched_openai.py\u001b[0m in \u001b[0;36m__anext__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    514\u001b[0m                     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Cannot recover from stream error without a configured tokenizer\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflush\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    515\u001b[0m                     \u001b[0;32mraise\u001b[0m \u001b[0mattempt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 516\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mawait\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecover\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    517\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    518\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconsumed_tokens\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"logprobs\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"tokens\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/dlabscratch1/berquet/conda/envs/env2/lib/python3.10/site-packages/lmql/runtime/bopenai/batched_openai.py\u001b[0m in \u001b[0;36mrecover\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    423\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mslice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_slice\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    424\u001b[0m         \u001b[0;31m# otherwise the chunking aligns with the old stream, so we return the next chunk\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 425\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;32mawait\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__anext__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    426\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    427\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__del__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/dlabscratch1/berquet/conda/envs/env2/lib/python3.10/site-packages/lmql/runtime/bopenai/batched_openai.py\u001b[0m in \u001b[0;36m__anext__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    514\u001b[0m                     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Cannot recover from stream error without a configured tokenizer\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflush\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    515\u001b[0m                     \u001b[0;32mraise\u001b[0m \u001b[0mattempt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 516\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mawait\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecover\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    517\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    518\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconsumed_tokens\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"logprobs\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"tokens\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/dlabscratch1/berquet/conda/envs/env2/lib/python3.10/site-packages/lmql/runtime/bopenai/batched_openai.py\u001b[0m in \u001b[0;36mrecover\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    423\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mslice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_slice\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    424\u001b[0m         \u001b[0;31m# otherwise the chunking aligns with the old stream, so we return the next chunk\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 425\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;32mawait\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__anext__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    426\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    427\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__del__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/dlabscratch1/berquet/conda/envs/env2/lib/python3.10/site-packages/lmql/runtime/bopenai/batched_openai.py\u001b[0m in \u001b[0;36m__anext__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    514\u001b[0m                     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Cannot recover from stream error without a configured tokenizer\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflush\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    515\u001b[0m                     \u001b[0;32mraise\u001b[0m \u001b[0mattempt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 516\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mawait\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecover\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    517\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    518\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconsumed_tokens\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"logprobs\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"tokens\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/dlabscratch1/berquet/conda/envs/env2/lib/python3.10/site-packages/lmql/runtime/bopenai/batched_openai.py\u001b[0m in \u001b[0;36mrecover\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    423\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mslice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_slice\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    424\u001b[0m         \u001b[0;31m# otherwise the chunking aligns with the old stream, so we return the next chunk\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 425\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;32mawait\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__anext__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    426\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    427\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__del__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/dlabscratch1/berquet/conda/envs/env2/lib/python3.10/site-packages/lmql/runtime/bopenai/batched_openai.py\u001b[0m in \u001b[0;36m__anext__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    514\u001b[0m                     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Cannot recover from stream error without a configured tokenizer\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflush\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    515\u001b[0m                     \u001b[0;32mraise\u001b[0m \u001b[0mattempt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 516\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mawait\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecover\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    517\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    518\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconsumed_tokens\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"logprobs\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"tokens\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/dlabscratch1/berquet/conda/envs/env2/lib/python3.10/site-packages/lmql/runtime/bopenai/batched_openai.py\u001b[0m in \u001b[0;36mrecover\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    423\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mslice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_slice\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    424\u001b[0m         \u001b[0;31m# otherwise the chunking aligns with the old stream, so we return the next chunk\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 425\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;32mawait\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__anext__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    426\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    427\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__del__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/dlabscratch1/berquet/conda/envs/env2/lib/python3.10/site-packages/lmql/runtime/bopenai/batched_openai.py\u001b[0m in \u001b[0;36m__anext__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    514\u001b[0m                     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Cannot recover from stream error without a configured tokenizer\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflush\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    515\u001b[0m                     \u001b[0;32mraise\u001b[0m \u001b[0mattempt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 516\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mawait\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecover\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    517\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    518\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconsumed_tokens\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"logprobs\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"tokens\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/dlabscratch1/berquet/conda/envs/env2/lib/python3.10/site-packages/lmql/runtime/bopenai/batched_openai.py\u001b[0m in \u001b[0;36mrecover\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    423\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mslice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_slice\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    424\u001b[0m         \u001b[0;31m# otherwise the chunking aligns with the old stream, so we return the next chunk\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 425\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;32mawait\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__anext__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    426\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    427\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__del__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/dlabscratch1/berquet/conda/envs/env2/lib/python3.10/site-packages/lmql/runtime/bopenai/batched_openai.py\u001b[0m in \u001b[0;36m__anext__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    514\u001b[0m                     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Cannot recover from stream error without a configured tokenizer\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflush\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    515\u001b[0m                     \u001b[0;32mraise\u001b[0m \u001b[0mattempt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 516\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mawait\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecover\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    517\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    518\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconsumed_tokens\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"logprobs\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"tokens\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/dlabscratch1/berquet/conda/envs/env2/lib/python3.10/site-packages/lmql/runtime/bopenai/batched_openai.py\u001b[0m in \u001b[0;36mrecover\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    423\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mslice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_slice\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    424\u001b[0m         \u001b[0;31m# otherwise the chunking aligns with the old stream, so we return the next chunk\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 425\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;32mawait\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__anext__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    426\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    427\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__del__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/dlabscratch1/berquet/conda/envs/env2/lib/python3.10/site-packages/lmql/runtime/bopenai/batched_openai.py\u001b[0m in \u001b[0;36m__anext__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    514\u001b[0m                     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Cannot recover from stream error without a configured tokenizer\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflush\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    515\u001b[0m                     \u001b[0;32mraise\u001b[0m \u001b[0mattempt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 516\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mawait\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecover\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    517\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    518\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconsumed_tokens\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"logprobs\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"tokens\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/dlabscratch1/berquet/conda/envs/env2/lib/python3.10/site-packages/lmql/runtime/bopenai/batched_openai.py\u001b[0m in \u001b[0;36mrecover\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    423\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mslice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_slice\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    424\u001b[0m         \u001b[0;31m# otherwise the chunking aligns with the old stream, so we return the next chunk\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 425\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;32mawait\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__anext__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    426\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    427\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__del__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/dlabscratch1/berquet/conda/envs/env2/lib/python3.10/site-packages/lmql/runtime/bopenai/batched_openai.py\u001b[0m in \u001b[0;36m__anext__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    514\u001b[0m                     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Cannot recover from stream error without a configured tokenizer\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflush\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    515\u001b[0m                     \u001b[0;32mraise\u001b[0m \u001b[0mattempt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 516\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mawait\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecover\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    517\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    518\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconsumed_tokens\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"logprobs\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"tokens\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/dlabscratch1/berquet/conda/envs/env2/lib/python3.10/site-packages/lmql/runtime/bopenai/batched_openai.py\u001b[0m in \u001b[0;36mrecover\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    423\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mslice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_slice\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    424\u001b[0m         \u001b[0;31m# otherwise the chunking aligns with the old stream, so we return the next chunk\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 425\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;32mawait\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__anext__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    426\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    427\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__del__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/dlabscratch1/berquet/conda/envs/env2/lib/python3.10/site-packages/lmql/runtime/bopenai/batched_openai.py\u001b[0m in \u001b[0;36m__anext__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    514\u001b[0m                     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Cannot recover from stream error without a configured tokenizer\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflush\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    515\u001b[0m                     \u001b[0;32mraise\u001b[0m \u001b[0mattempt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 516\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mawait\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecover\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    517\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    518\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconsumed_tokens\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"logprobs\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"tokens\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/dlabscratch1/berquet/conda/envs/env2/lib/python3.10/site-packages/lmql/runtime/bopenai/batched_openai.py\u001b[0m in \u001b[0;36mrecover\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    423\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mslice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_slice\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    424\u001b[0m         \u001b[0;31m# otherwise the chunking aligns with the old stream, so we return the next chunk\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 425\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;32mawait\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__anext__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    426\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    427\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__del__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/dlabscratch1/berquet/conda/envs/env2/lib/python3.10/site-packages/lmql/runtime/bopenai/batched_openai.py\u001b[0m in \u001b[0;36m__anext__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    514\u001b[0m                     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Cannot recover from stream error without a configured tokenizer\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflush\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    515\u001b[0m                     \u001b[0;32mraise\u001b[0m \u001b[0mattempt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 516\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mawait\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecover\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    517\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    518\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconsumed_tokens\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"logprobs\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"tokens\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/dlabscratch1/berquet/conda/envs/env2/lib/python3.10/site-packages/lmql/runtime/bopenai/batched_openai.py\u001b[0m in \u001b[0;36mrecover\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    423\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mslice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_slice\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    424\u001b[0m         \u001b[0;31m# otherwise the chunking aligns with the old stream, so we return the next chunk\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 425\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;32mawait\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__anext__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    426\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    427\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__del__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/dlabscratch1/berquet/conda/envs/env2/lib/python3.10/site-packages/lmql/runtime/bopenai/batched_openai.py\u001b[0m in \u001b[0;36m__anext__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    514\u001b[0m                     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Cannot recover from stream error without a configured tokenizer\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflush\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    515\u001b[0m                     \u001b[0;32mraise\u001b[0m \u001b[0mattempt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 516\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mawait\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecover\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    517\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    518\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconsumed_tokens\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"logprobs\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"tokens\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/dlabscratch1/berquet/conda/envs/env2/lib/python3.10/site-packages/lmql/runtime/bopenai/batched_openai.py\u001b[0m in \u001b[0;36mrecover\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    423\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mslice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_slice\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    424\u001b[0m         \u001b[0;31m# otherwise the chunking aligns with the old stream, so we return the next chunk\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 425\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;32mawait\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__anext__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    426\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    427\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__del__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/dlabscratch1/berquet/conda/envs/env2/lib/python3.10/site-packages/lmql/runtime/bopenai/batched_openai.py\u001b[0m in \u001b[0;36m__anext__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    514\u001b[0m                     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Cannot recover from stream error without a configured tokenizer\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflush\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    515\u001b[0m                     \u001b[0;32mraise\u001b[0m \u001b[0mattempt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 516\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mawait\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecover\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    517\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    518\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconsumed_tokens\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"logprobs\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"tokens\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/dlabscratch1/berquet/conda/envs/env2/lib/python3.10/site-packages/lmql/runtime/bopenai/batched_openai.py\u001b[0m in \u001b[0;36mrecover\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    423\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mslice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_slice\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    424\u001b[0m         \u001b[0;31m# otherwise the chunking aligns with the old stream, so we return the next chunk\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 425\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;32mawait\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__anext__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    426\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    427\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__del__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/dlabscratch1/berquet/conda/envs/env2/lib/python3.10/site-packages/lmql/runtime/bopenai/batched_openai.py\u001b[0m in \u001b[0;36m__anext__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    510\u001b[0m                 \u001b[0;31m# if we have exceeded the maximum number of retries, raise the error\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    511\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretries\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mattempt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmaximum_retries\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 512\u001b[0;31m                     \u001b[0;32mraise\u001b[0m \u001b[0mMaximumRetriesExceeded\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattempt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretries\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretries\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    513\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mslice\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscheduler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenizer\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    514\u001b[0m                     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Cannot recover from stream error without a configured tokenizer\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflush\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mMaximumRetriesExceeded\u001b[0m: Maximum retries exceeded (21) with error <class 'FileNotFoundError'>: To use openai/<models>, you have to configure your API credentials. To do so\nyou can either define the `OPENAI_API_KEY` environment variable or create a\nfile `api.env` in one of the following locations:\n\n - /dlabscratch1/berquet/conda/envs/env2/lib/python3.10/site-packages/api.env\n - /dlabscratch1/berquet/project/dlab_project/api.env\n - /dlabscratch1/berquet/home/.lmql/api.env\n\nTo use OpenAI models you need to create an api.env file with the following\ncontents:\n        \n        openai-secret: <your openai secret>\n        openai-org: <your openai org>\n        \nFor more info, check the related project docs:\nhttps://docs.lmql.ai/en/stable/language/openai.html#configuring-openai-api-credentials\n"
     ]
    }
   ],
   "source": [
    "import lmql\n",
    "import nest_asyncio\n",
    "\n",
    "nest_asyncio.apply()\n",
    "\n",
    "chain_of_thought = lmql.query(\"\"\"\n",
    "    \"Q: {question}\\\\n\"\n",
    "    \"A: Let's think step by step.\\\\n\"\n",
    "    \"[ANSWER]\"\n",
    "\"\"\", is_async=False)\n",
    "\n",
    "chain_of_thought(\"What is 2x3?\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3be21b8",
   "metadata": {},
   "source": [
    "### Build Prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "463584c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to format a row according to your fine-tuning requirements\n",
    "def format_row(row):\n",
    "    input_data = {\n",
    "        \"Source\": row['current_page'], \n",
    "        \"Candidates\": row['current_page_links'], \n",
    "        \"Target\": row['target']\n",
    "    }\n",
    "    \n",
    "    prompt = f\"\"\"You are a knowledge discovery expert familiar with the Wikipedia link structure and your objective is to play the game of Wikispeedia: https://dlab.epfl.ch/wikispeedia/play/.\n",
    "##Goal \n",
    "Given two Wikipedia articles, a source and a target, your goal is to reach the target article starting from the source article in as few clicks as possible. For the articles you are given this is always possible.\n",
    "\n",
    "##Constraint \n",
    "You should exclusively follow the links present in the articles that you encounter along the way.\n",
    "\n",
    "##Fine-grained instructions \n",
    "1. While the overall goal is to find a path from a source to a target article, you will proceed step by step.\n",
    "2. Given outgoing links from the source article as candidates, you should select the candidate that takes you closer to the target article. Use your knowledge of the \"expected\" Wikipedia link structure and relatedness between articles to identify the candidate that takes you closer to the target.\n",
    "3. Choose **only** from the provided candidates.\n",
    "4. Do not provide an algorithm, code to solve the task, or explanation just provide the link the choose among candidates.\n",
    "6. Even though the proposed links are not related to the target you should **always** choose a link.\n",
    "\n",
    "##Input \n",
    "{json.dumps(input_data, indent=4)}\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0dfe5cb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the formatting function to each row\n",
    "test_dataset = test_dataset.map(lambda x: {\"text\": format_row(x)})\n",
    "\n",
    "# You might want to remove the old columns and keep only 'text'\n",
    "test_dataset = test_dataset.remove_columns(['source', 'target', 'current_page', 'current_page_links', 'next_page', '__index_level_0__'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c532de69",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = train_dataset.map(lambda x: {\"text\": format_row(x)})\n",
    "\n",
    "# You might want to remove the old columns and keep only 'text'\n",
    "train_dataset = train_dataset.remove_columns(['source', 'target', 'current_page', 'current_page_links', 'next_page', '__index_level_0__'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16572fcc",
   "metadata": {},
   "source": [
    "### Import model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dde6135b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\n",
    "\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_use_double_quant=False,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=torch.bfloat16\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6c50e834",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_id = \"microsoft/phi-1_5\"\n",
    "model = AutoModelForCausalLM.from_pretrained(\"phi15_run1_optipaths/checkpoint-9000\", quantization_config=bnb_config, device_map=\"auto\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e08b487f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_id, add_bos_token=True, trust_remote_code=True, use_fast = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "67f1d043",
   "metadata": {},
   "outputs": [],
   "source": [
    "from peft import PeftModel\n",
    "\n",
    "ft_model = PeftModel.from_pretrained(model, \"phi15_run1_optipaths/checkpoint-9000\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "78f69b08",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_base = AutoModelForCausalLM.from_pretrained(model_id, quantization_config=bnb_config, device_map=\"auto\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4228a9d6",
   "metadata": {},
   "source": [
    "### Output extraction "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bbee4cfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_output_from_prompt(prompt):\n",
    "    # Look for the start of the JSON output block\n",
    "    start = prompt.find('##Output')\n",
    "    if start == -1:\n",
    "        return \"Output block not found.\"\n",
    "\n",
    "    # Extract the part of the prompt after the \"##Output\" marker\n",
    "    output_part = prompt[start:]\n",
    "\n",
    "    # Find the actual output value inside curly braces\n",
    "    output_start = output_part.find('{')\n",
    "    output_end = output_part.find('}')\n",
    "    if output_start == -1 or output_end == -1:\n",
    "        return \"Output not formatted correctly.\"\n",
    "\n",
    "    # Extract the string inside the curly braces\n",
    "    output_content = output_part[output_start+1:output_end]\n",
    "\n",
    "    # Look for the value after \"Output\":\n",
    "    marker = \"Output\\\": \"\n",
    "    value_start = output_content.find(marker)\n",
    "    if value_start == -1:\n",
    "        return \"Output key not found.\"\n",
    "\n",
    "    # Extract and clean the output value\n",
    "    output_value = output_content[value_start + len(marker):].strip(\"\\\" \")\n",
    "    \n",
    "    formatted_output = output_value.replace('_', ' ')\n",
    "    \n",
    "    return formatted_output[:-2] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0412a266",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_word_in_links(word, current_page_links_str):\n",
    "    # Handle escaped single quotes\n",
    "    if \"\\\\'\" in current_page_links_str:\n",
    "        current_page_links_str = current_page_links_str.replace(\"\\\\'\", \"'\") \n",
    "    \n",
    "    # Convert string representation of list to actual list\n",
    "    links_list = ast.literal_eval(current_page_links_str)\n",
    "\n",
    "    # Check if the word is in the list\n",
    "    return word in links_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7559b20f",
   "metadata": {},
   "source": [
    "### Random tests finetuned model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d845c2be",
   "metadata": {},
   "outputs": [],
   "source": [
    "index = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "23d9e1ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "input = test_dataset[index]\n",
    "input_tok = tokenizer([input['text']],return_tensors = \"pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f6b8998f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Arctic Ocean\n"
     ]
    }
   ],
   "source": [
    "ft_model.eval()\n",
    "with torch.no_grad():\n",
    "    out = (tokenizer.decode(ft_model.generate(**input_tok, max_new_tokens=150)[0], skip_special_tokens=True))\n",
    "    out_extracted = extract_output_from_prompt(out)\n",
    "    print(out_extracted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "699c42c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'You are a knowledge discovery expert familiar with the Wikipedia link structure and your objective is to play the game of Wikispeedia: https://dlab.epfl.ch/wikispeedia/play/.\\n##Goal \\nGiven two Wikipedia articles, a source and a target, your goal is to reach the target article starting from the source article in as few clicks as possible. For the articles you are given this is always possible.\\n\\n##Constraint \\nYou should exclusively follow the links present in the articles that you encounter along the way.\\n\\n##Fine-grained instructions \\n1. While the overall goal is to find a path from a source to a target article, you will proceed step by step.\\n2. Given outgoing links from the source article as candidates, you should select the candidate that takes you closer to the target article. Use your knowledge of the \"expected\" Wikipedia link structure and relatedness between articles to identify the candidate that takes you closer to the target.\\n3. Choose **only** from the provided candidates.\\n4. Do not provide an algorithm, code to solve the task, or explanation just provide the link the choose among candidates.\\n6. Even though the proposed links are not related to the target you should **always** choose a link.\\n\\n##Input \\n{\\n      \"Source\": \"Hudson_Bay\",\\n      \"Candidates\": \"[\\'Canada\\', \\'Minnesota\\', \\'Arctic Ocean\\', \\'Atlantic Ocean\\', \\'Greenland\\', \\'Montreal\\', \\'Canada\\', \\'Canada\\', \\'Glacier\\', \\'Cold War\\']\",\\n      \"Target\": \"Trout\"\\n}\\n\\n\\n##Output \\n{\\n      \"Output\": \"Arctic_Ocean\"\\n}\\n\\n\\n# Chapter: The use of Python Sets for Bioinformatician\\n\\n## Section: Applications of Remove Set Items for Bioinformatician\\n\\nIn this section, we will explore the various applications of removing items from sets in bioinformatics. We will cover the following subsections:\\n\\n1. Removing duplicates from a set\\n2. Removing specific elements from a set\\n3. Removing elements based on a condition\\n4. Removing elements based on a value in another set\\n\\n### 1. Removing duplicates from a set\\n\\nIn bioinformatics, it is common to work'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88440724",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_no_prompt[index]['current_page_links']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a684e8a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "is_word_in_links(out_extracted , test_no_prompt[index]['current_page_links'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa9eefda",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_no_prompt[index]['next_page']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19922c3b",
   "metadata": {},
   "source": [
    "### Tests : chosen link is among the proposed ones and chosen link is same as human"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "bd731053",
   "metadata": {},
   "outputs": [],
   "source": [
    "matching = 0\n",
    "non_matching = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "161f82b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "good_prediction = 0 \n",
    "bad_prediction = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "82f70424",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chosen link not in proposed on iter0\n",
      "Chosen link not in proposed on iter1\n",
      "Chosen link not in proposed on iter2\n",
      "Bad prediction on iter :3\n",
      "Chosen link not in proposed on iter4\n",
      "Chosen link not in proposed on iter5\n",
      "Bad prediction on iter :6\n",
      "Chosen link not in proposed on iter7\n",
      "Chosen link not in proposed on iter8\n",
      "Chosen link not in proposed on iter9\n",
      "Chosen link not in proposed on iter10\n",
      "Chosen link not in proposed on iter11\n",
      "Bad prediction on iter :12\n",
      "Chosen link not in proposed on iter13\n",
      "Chosen link not in proposed on iter14\n",
      "Chosen link not in proposed on iter15\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[182], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m input_tok \u001b[38;5;241m=\u001b[39m tokenizer([\u001b[38;5;28minput\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m'\u001b[39m]],return_tensors \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m----> 5\u001b[0m     out \u001b[38;5;241m=\u001b[39m (tokenizer\u001b[38;5;241m.\u001b[39mdecode(\u001b[43mft_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minput_tok\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_new_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m25\u001b[39;49m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m], skip_special_tokens\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m))\n\u001b[1;32m      6\u001b[0m     out_extracted \u001b[38;5;241m=\u001b[39m extract_output_from_prompt(out)\n\u001b[1;32m      7\u001b[0m links \u001b[38;5;241m=\u001b[39m  test_no_prompt[i][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcurrent_page_links\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "File \u001b[0;32m/dlabscratch1/berquet/conda/envs/env2/lib/python3.8/site-packages/peft/peft_model.py:1190\u001b[0m, in \u001b[0;36mPeftModelForCausalLM.generate\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1188\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_enable_peft_forward_hooks(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m   1189\u001b[0m         kwargs \u001b[38;5;241m=\u001b[39m {k: v \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m kwargs\u001b[38;5;241m.\u001b[39mitems() \u001b[38;5;28;01mif\u001b[39;00m k \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mspecial_peft_forward_args}\n\u001b[0;32m-> 1190\u001b[0m         outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbase_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1191\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1192\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbase_model\u001b[38;5;241m.\u001b[39mgenerate(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/dlabscratch1/berquet/conda/envs/env2/lib/python3.8/site-packages/torch/utils/_contextlib.py:115\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    114\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 115\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/dlabscratch1/berquet/conda/envs/env2/lib/python3.8/site-packages/transformers/generation/utils.py:1527\u001b[0m, in \u001b[0;36mGenerationMixin.generate\u001b[0;34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, negative_prompt_ids, negative_prompt_attention_mask, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39massisted_decoding(\n\u001b[1;32m   1510\u001b[0m         input_ids,\n\u001b[1;32m   1511\u001b[0m         candidate_generator\u001b[38;5;241m=\u001b[39mcandidate_generator,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1523\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_kwargs,\n\u001b[1;32m   1524\u001b[0m     )\n\u001b[1;32m   1525\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m generation_mode \u001b[38;5;241m==\u001b[39m GenerationMode\u001b[38;5;241m.\u001b[39mGREEDY_SEARCH:\n\u001b[1;32m   1526\u001b[0m     \u001b[38;5;66;03m# 11. run greedy search\u001b[39;00m\n\u001b[0;32m-> 1527\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_greedy_search\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1528\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlogits_processor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprepared_logits_processor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1530\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstopping_criteria\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprepared_stopping_criteria\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1531\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpad_token_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgeneration_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpad_token_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1532\u001b[0m \u001b[43m        \u001b[49m\u001b[43meos_token_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgeneration_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meos_token_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1533\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_scores\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgeneration_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moutput_scores\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1534\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_logits\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgeneration_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moutput_logits\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1535\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_dict_in_generate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgeneration_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreturn_dict_in_generate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1536\u001b[0m \u001b[43m        \u001b[49m\u001b[43msynced_gpus\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msynced_gpus\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1537\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstreamer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstreamer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1538\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1539\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1541\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m generation_mode \u001b[38;5;241m==\u001b[39m GenerationMode\u001b[38;5;241m.\u001b[39mCONTRASTIVE_SEARCH:\n\u001b[1;32m   1542\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m model_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muse_cache\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n",
      "File \u001b[0;32m/dlabscratch1/berquet/conda/envs/env2/lib/python3.8/site-packages/transformers/generation/utils.py:2411\u001b[0m, in \u001b[0;36mGenerationMixin._greedy_search\u001b[0;34m(self, input_ids, logits_processor, stopping_criteria, max_length, pad_token_id, eos_token_id, output_attentions, output_hidden_states, output_scores, output_logits, return_dict_in_generate, synced_gpus, streamer, **model_kwargs)\u001b[0m\n\u001b[1;32m   2408\u001b[0m model_inputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprepare_inputs_for_generation(input_ids, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_kwargs)\n\u001b[1;32m   2410\u001b[0m \u001b[38;5;66;03m# forward pass to get next token\u001b[39;00m\n\u001b[0;32m-> 2411\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2412\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2413\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   2414\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2415\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2416\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2418\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m synced_gpus \u001b[38;5;129;01mand\u001b[39;00m this_peer_finished:\n\u001b[1;32m   2419\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m  \u001b[38;5;66;03m# don't waste resources running the code we don't need\u001b[39;00m\n",
      "File \u001b[0;32m/dlabscratch1/berquet/conda/envs/env2/lib/python3.8/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/dlabscratch1/berquet/conda/envs/env2/lib/python3.8/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/dlabscratch1/berquet/conda/envs/env2/lib/python3.8/site-packages/accelerate/hooks.py:166\u001b[0m, in \u001b[0;36madd_hook_to_module.<locals>.new_forward\u001b[0;34m(module, *args, **kwargs)\u001b[0m\n\u001b[1;32m    164\u001b[0m         output \u001b[38;5;241m=\u001b[39m module\u001b[38;5;241m.\u001b[39m_old_forward(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    165\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 166\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_old_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    167\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m module\u001b[38;5;241m.\u001b[39m_hf_hook\u001b[38;5;241m.\u001b[39mpost_forward(module, output)\n",
      "File \u001b[0;32m/dlabscratch1/berquet/conda/envs/env2/lib/python3.8/site-packages/transformers/models/phi/modeling_phi.py:1173\u001b[0m, in \u001b[0;36mPhiForCausalLM.forward\u001b[0;34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1170\u001b[0m return_dict \u001b[38;5;241m=\u001b[39m return_dict \u001b[38;5;28;01mif\u001b[39;00m return_dict \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39muse_return_dict\n\u001b[1;32m   1172\u001b[0m \u001b[38;5;66;03m# decoder outputs consists of (dec_features, layer_state, dec_hidden, dec_attn)\u001b[39;00m\n\u001b[0;32m-> 1173\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1174\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1175\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1176\u001b[0m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1177\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1178\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1179\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1180\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1181\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1182\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1183\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1185\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m   1186\u001b[0m logits \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlm_head(hidden_states)\n",
      "File \u001b[0;32m/dlabscratch1/berquet/conda/envs/env2/lib/python3.8/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/dlabscratch1/berquet/conda/envs/env2/lib/python3.8/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/dlabscratch1/berquet/conda/envs/env2/lib/python3.8/site-packages/accelerate/hooks.py:166\u001b[0m, in \u001b[0;36madd_hook_to_module.<locals>.new_forward\u001b[0;34m(module, *args, **kwargs)\u001b[0m\n\u001b[1;32m    164\u001b[0m         output \u001b[38;5;241m=\u001b[39m module\u001b[38;5;241m.\u001b[39m_old_forward(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    165\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 166\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_old_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    167\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m module\u001b[38;5;241m.\u001b[39m_hf_hook\u001b[38;5;241m.\u001b[39mpost_forward(module, output)\n",
      "File \u001b[0;32m/dlabscratch1/berquet/conda/envs/env2/lib/python3.8/site-packages/transformers/models/phi/modeling_phi.py:1052\u001b[0m, in \u001b[0;36mPhiModel.forward\u001b[0;34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1043\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gradient_checkpointing_func(\n\u001b[1;32m   1044\u001b[0m         decoder_layer\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m,\n\u001b[1;32m   1045\u001b[0m         hidden_states,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         output_attentions,\n\u001b[1;32m   1050\u001b[0m     )\n\u001b[1;32m   1051\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1052\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mdecoder_layer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1053\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1054\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1055\u001b[0m \u001b[43m        \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1056\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1057\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1058\u001b[0m \u001b[43m        \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1059\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1061\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m layer_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m   1063\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m use_cache:\n",
      "File \u001b[0;32m/dlabscratch1/berquet/conda/envs/env2/lib/python3.8/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/dlabscratch1/berquet/conda/envs/env2/lib/python3.8/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/dlabscratch1/berquet/conda/envs/env2/lib/python3.8/site-packages/accelerate/hooks.py:166\u001b[0m, in \u001b[0;36madd_hook_to_module.<locals>.new_forward\u001b[0;34m(module, *args, **kwargs)\u001b[0m\n\u001b[1;32m    164\u001b[0m         output \u001b[38;5;241m=\u001b[39m module\u001b[38;5;241m.\u001b[39m_old_forward(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    165\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 166\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_old_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    167\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m module\u001b[38;5;241m.\u001b[39m_hf_hook\u001b[38;5;241m.\u001b[39mpost_forward(module, output)\n",
      "File \u001b[0;32m/dlabscratch1/berquet/conda/envs/env2/lib/python3.8/site-packages/transformers/models/phi/modeling_phi.py:783\u001b[0m, in \u001b[0;36mPhiDecoderLayer.forward\u001b[0;34m(self, hidden_states, attention_mask, position_ids, output_attentions, use_cache, past_key_value)\u001b[0m\n\u001b[1;32m    780\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_layernorm(hidden_states)\n\u001b[1;32m    782\u001b[0m \u001b[38;5;66;03m# Self Attention\u001b[39;00m\n\u001b[0;32m--> 783\u001b[0m attn_outputs, self_attn_weights, present_key_value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mself_attn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    784\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    785\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    786\u001b[0m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    787\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    788\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    789\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    790\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    791\u001b[0m attn_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresid_dropout(attn_outputs)\n\u001b[1;32m    793\u001b[0m feed_forward_hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresid_dropout(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmlp(hidden_states))\n",
      "File \u001b[0;32m/dlabscratch1/berquet/conda/envs/env2/lib/python3.8/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/dlabscratch1/berquet/conda/envs/env2/lib/python3.8/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/dlabscratch1/berquet/conda/envs/env2/lib/python3.8/site-packages/accelerate/hooks.py:166\u001b[0m, in \u001b[0;36madd_hook_to_module.<locals>.new_forward\u001b[0;34m(module, *args, **kwargs)\u001b[0m\n\u001b[1;32m    164\u001b[0m         output \u001b[38;5;241m=\u001b[39m module\u001b[38;5;241m.\u001b[39m_old_forward(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    165\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 166\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_old_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    167\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m module\u001b[38;5;241m.\u001b[39m_hf_hook\u001b[38;5;241m.\u001b[39mpost_forward(module, output)\n",
      "File \u001b[0;32m/dlabscratch1/berquet/conda/envs/env2/lib/python3.8/site-packages/transformers/models/phi/modeling_phi.py:666\u001b[0m, in \u001b[0;36mPhiSdpaAttention.forward\u001b[0;34m(self, hidden_states, attention_mask, position_ids, past_key_value, output_attentions, use_cache)\u001b[0m\n\u001b[1;32m    663\u001b[0m bsz, q_len, _ \u001b[38;5;241m=\u001b[39m hidden_states\u001b[38;5;241m.\u001b[39msize()\n\u001b[1;32m    665\u001b[0m query_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mq_proj(hidden_states)\n\u001b[0;32m--> 666\u001b[0m key_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mk_proj\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    667\u001b[0m value_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mv_proj(hidden_states)\n\u001b[1;32m    669\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mqk_layernorm:\n",
      "File \u001b[0;32m/dlabscratch1/berquet/conda/envs/env2/lib/python3.8/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/dlabscratch1/berquet/conda/envs/env2/lib/python3.8/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/dlabscratch1/berquet/conda/envs/env2/lib/python3.8/site-packages/peft/tuners/lora/bnb.py:478\u001b[0m, in \u001b[0;36mLinear4bit.forward\u001b[0;34m(self, x, *args, **kwargs)\u001b[0m\n\u001b[1;32m    476\u001b[0m             output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_apply_dora(x, lora_A, lora_B, scaling, active_adapter)\n\u001b[1;32m    477\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m requires_conversion:\n\u001b[0;32m--> 478\u001b[0m             output \u001b[38;5;241m=\u001b[39m \u001b[43moutput\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexpected_dtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    480\u001b[0m         result \u001b[38;5;241m=\u001b[39m result \u001b[38;5;241m+\u001b[39m output\n\u001b[1;32m    482\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for i in range(100) :\n",
    "    input = test_dataset[i + 232]\n",
    "    input_tok = tokenizer([input['text']],return_tensors = \"pt\").to(\"cuda\")\n",
    "    with torch.no_grad():\n",
    "        out = (tokenizer.decode(ft_model.generate(**input_tok, max_new_tokens=25)[0], skip_special_tokens=True))\n",
    "        out_extracted = extract_output_from_prompt(out)\n",
    "    links =  test_no_prompt[i]['current_page_links']\n",
    "    \n",
    "    #increase counter to get a sense of the proportion of wrong chosing\n",
    "    if (is_word_in_links(out_extracted ,links)) : \n",
    "        matching += 1    \n",
    "        true_target = test_no_prompt[i]['next_page'].replace('_', ' ')\n",
    "        if true_target == out_extracted :\n",
    "            good_prediction += 1\n",
    "        else : \n",
    "            print(f'Bad prediction on iter :{i}')\n",
    "            if not (true_target in bad_prediction) : \n",
    "                bad_prediction[true_target] = []\n",
    "            bad_prediction[true_target].append(out_extracted)\n",
    "            \n",
    "    else : \n",
    "        ## Keep track of the non matching chosen links and list of links to look for some patterns\n",
    "        if not(out_extracted in non_matching) :\n",
    "            non_matching[out_extracted] = []\n",
    "        print(f'Chosen link not in proposed on iter{i}')\n",
    "        non_matching[out_extracted].append(links)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de50d413",
   "metadata": {},
   "outputs": [],
   "source": [
    "good_prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "6c2a5af3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Coconut oil': [\"['History of the Internet', 'Clay', 'Abacus', 'Computers', 'Abacus', 'China', 'Abacus', 'Abacus', 'Johannes Kepler', 'Blaise Pascal', 'Gottfried Leibniz', 'Leibniz', 'Charles Babbage', 'Moon', 'Charles Babbage', 'United States Constitution', 'World War II', 'Computer programming', 'Charles Babbage', 'Richard Feynman', 'Integrated circuit', 'World War II', 'Computer programming', 'World War II', 'Electronics', 'Mercury (element)', 'Alan Turing', 'Alan Turing', 'Computer science', 'Algorithm', 'Germany', 'Charles Babbage', 'Programming language', 'World War II', 'World War II', 'World War II', 'Alan Turing', 'Boolean logic', 'John von Neumann', 'Electronics', 'University of Cambridge', 'Soviet Union', 'Ukraine', 'Programming language', 'Central processing unit', 'Integrated circuit']\"],\n",
       " 'List of essential oils': ['[\\'Battle of Normandy\\', \\'Nuclear weapon\\', \\'United States\\', \\'Soviet Union\\', \\'Europe\\', \\'Cold War\\', \\'United Kingdom\\', \\'United States\\', \\'Nazi Germany\\', \\'Joseph Stalin\\', \\'Winston Churchill\\', \\'Adolf Hitler\\', \\'Benito Mussolini\\', \\'War\\', \\'Adolf Hitler\\', \\'Nazi Germany\\', \\'Poland\\', \\'Soviet Union\\', \\'North Africa\\', \\'Royal Air Force\\', \\'Royal Navy\\', \\'Soviet Union\\', \\'Battle of Stalingrad\\', \\'Battle of Normandy\\', \\'Battle of the Bulge\\', \\'Jews\\', \\'The Holocaust\\', \\'Attack on Pearl Harbor\\', \\'Battle of Midway\\', \\'Battle of Leyte Gulf\\', \\'Benito Mussolini\\', \\'Adolf Hitler\\', \\'Nazi Germany\\', \\'China\\', \\'United States\\', \\'United Kingdom\\', \\'Treaty of Versailles\\', \\'Japan\\', \\'United States\\', \\'United Kingdom\\', \\'Republic of China\\', \\'Philippines\\', \\'Prime Minister of the United Kingdom\\', \\'Moscow\\', \\'Warsaw\\', \\'Soviet Union\\', \\'Romania\\', \\'Aircraft carrier\\', \\'Montevideo\\', \\'China\\', \\'Beijing\\', \\'Japanese war crimes\\', \\'League of Nations\\', \\'Latvia\\', \\'Lithuania\\', \\'Estonia\\', \\'Denmark\\', \\'Norway\\', \\'Luxembourg\\', \\'Belgium\\', \\'Netherlands\\', \\'France\\', \\'Flanders\\', \\'Blitzkrieg\\', \\'English Channel\\', \\'Paris\\', \\'Royal Air Force\\', \\'Battle of Britain\\', \\'Luftwaffe\\', \\'The Blitz\\', \\'Supermarine Spitfire\\', \\'Albania\\', \\'Gibraltar\\', \\'Malta\\', \\'Libya\\', \\'Egypt\\', \\'Suez Canal\\', \\'United Kingdom\\', \\'India\\', \\'New Zealand\\', \\'Erwin Rommel\\', \\'United Kingdom\\', \\'United States Congress\\', \\'Yugoslavia\\', \\'Battle of Moscow\\', \\'Winston Churchill\\', \\'Iraq\\', \\'Syria\\', \\'Lebanon\\', \\'Damascus\\', \\'Royal Navy\\', \\'Imperial Japanese Navy\\', \\'Saigon\\', \\'Winston Churchill\\', \\'Hong Kong\\', \\'British Empire\\', \\'Myanmar\\', \\'Singapore\\', \\'Battle of Normandy\\', \\'Suez Canal\\', \\'Tunisia\\', \\'Battle of Midway\\', \\'Naval Battle of Guadalcanal\\', \\'Benito Mussolini\\', \\'Rome\\', \\'Royal Navy\\', \\'Solomon Islands\\', \\'Mao Zedong\\', \\'Rome\\', \\'Hungary\\', \\'Romania\\', \\'Bulgaria\\', \\'Winston Churchill\\', \\'Bucharest\\', \\'Battle of Normandy\\', \\'United States\\', \\'United Kingdom\\', \\'Canada\\', \\'Battle of Normandy\\', \\'Paris\\', \\'Antwerp\\', \\'Battle of the Bulge\\', \\'Marshall Islands\\', \\'Guam\\', \\'Battle of Leyte Gulf\\', \\'Franklin D. Roosevelt\\', \\'Winston Churchill\\', \\'Joseph Stalin\\', \\'United Nations\\', \\'Election\\', \\'Rhine\\', \\'Baltic Sea\\', \\'Milan\\', \\'Great Britain\\', \\'Nuclear weapon\\', \\'Harry S. Truman\\', \\'Nuclear weapon\\', \\'Nuclear weapon\\', \\'North Korea\\', \\'Mao Zedong\\', \\'Hirohito\\', \\'The Holocaust\\', \\'Nazism\\', \\'League of Nations\\', \\'Japan\\', \\'Hirohito\\', \\'Slavery\\', \\'China\\', \\'Austria\\', \\'Lithuania\\', \\'Latvia\\', \\'Estonia\\', \\'Armia Krajowa\\', \\'Communism\\', \\'Enigma machine\\', \\'Nuclear weapon\\', \\'Radar\\', \\'Jet engine\\', \\'Aircraft\\', \\'Tank\\', \\'Finland\\', \\'United States of America\\', \\'United Nations\\', \\'San Francisco, California\\', \\'Philippines\\', \\'Cold War\\', \\'Korea\\', \"People\\'s Republic of China\", \\'Germany\\', \\'Austria\\', \\'Japan\\', \\'Korea\\', \\'Marshall Plan\\', \\'Estonia\\', \\'Latvia\\', \\'Lithuania\\', \\'Taiwan\\', \\'Philippines\\', \\'India\\', \\'Pakistan\\', \\'Vietnam\\', \\'League of Nations\\', \\'United Nations\\', \\'Israel\\']',\n",
       "  '[\\'French language\\', \\'London\\', \\'English language\\', \\'List of countries by system of government\\', \\'Constitutional monarchy\\', \\'British monarchy\\', \\'Elizabeth II of the United Kingdom\\', \\'Prime Minister of the United Kingdom\\', \\'Tony Blair\\', \\'Acts of Union 1707\\', \\'European Union\\', \\'Currency\\', \\'Pound sterling\\', \\'Time zone\\', \\'Scottish Gaelic language\\', \\'Scots language\\', \\'Latin\\', \\'English language\\', \\'Scottish Gaelic language\\', \\'Great Britain\\', \\'European Union\\', \\'Europe\\', \\'Great Britain\\', \\'Northern Ireland\\', \\'Ireland\\', \\'Atlantic Ocean\\', \\'North Sea\\', \\'English Channel\\', \\'Irish Sea\\', \\'France\\', \\'Republic of Ireland\\', \\'England\\', \\'Scotland\\', \\'Wales\\', \\'Northern Ireland\\', \\'Bermuda\\', \\'Gibraltar\\', \\'Montserrat\\', \\'Saint Helena\\', \\'Channel Islands\\', \\'Isle of Man\\', \\'Constitutional monarchy\\', \\'Elizabeth II of the United Kingdom\\', \\'United States dollar\\', \\'European Union\\', \\'NATO\\', \\'United Nations\\', \\'British Empire\\', \\'English language\\', \\'Northern Ireland\\', \\'Wales\\', \\'Laws in Wales Acts 1535-1542\\', \\'England\\', \\'Republic of Ireland\\', \\'Capitalism\\', \\'Parliamentary system\\', \\'British Empire\\', \\'Earth\\', \\'World War I\\', \\'World War II\\', \\'British Empire\\', \\'European Union\\', \\'Constitutional monarchy\\', \\'British monarchy\\', \\'Prime Minister of the United Kingdom\\', \\'Parliament of the United Kingdom\\', \\'British House of Commons\\', \\'House of Lords\\', \\'Tony Blair\\', \\'Buckingham Palace\\', \\'Anne of Great Britain\\', \\'Elizabeth II of the United Kingdom\\', \\'Parliament of the United Kingdom\\', \\'British House of Commons\\', \\'House of Lords\\', \\'Church of England\\', \\'Palace of Westminster\\', \\'River Thames\\', \\'London\\', \\'Parliament of the United Kingdom\\', \\'Republic of Ireland\\', \\'Belfast\\', \\'Scotland\\', \\'House of Lords\\', \\'England\\', \\'Wales\\', \\'Northern Ireland\\', \\'Scotland\\', \\'Lake District\\', \\'Peak District\\', \\'Cotswolds\\', \\'France\\', \\'England\\', \\'Lake District\\', \\'Scottish Highlands\\', \\'Ben Nevis\\', \\'Loch\\', \\'Hebrides\\', \\'Orkney Islands\\', \\'Edinburgh\\', \\'World Heritage Site\\', \\'Glasgow\\', \\'Cardiff\\', \\'Belfast\\', \"Giant\\'s Causeway\", \\'British Isles\\', \\'Northern Ireland\\', \\'England\\', \\'Wales\\', \\'Scotland\\', \\'Northern Ireland\\', \\'London\\', \\'Edinburgh\\', \\'Cardiff\\', \\'Belfast\\', \\'Trafalgar Square\\', \\'London\\', \\'European Union\\', \\'Germany\\', \\'France\\', \\'Europe\\', \\'British Empire\\', \\'Italy\\', \\'Spain\\', \\'English language\\', \\'British Isles\\', \\'Canada\\', \\'Argentina\\', \\'Scots language\\', \\'Hindi\\', \\'Hindi\\', \\'Canterbury Cathedral\\', \\'Roman Britain\\', \\'Church of England\\', \\'Henry VIII of England\\', \\'House of Lords\\', \\'Canterbury Cathedral\\', \\'Archbishop of Canterbury\\', \\'Westminster Abbey\\', \\'Church of England\\', \\'Anglican Communion\\', \\'Church of Ireland\\', \\'Hinduism\\', \\'Europe\\', \\'Christianity\\', \\'Islam\\', \\'Hinduism\\', \\'Sikhism\\', \\'Judaism\\', \\'Pakistan\\', \\'India\\', \\'Bangladesh\\', \\'Somalia\\', \\'India\\', \\'Hinduism\\', \\'Sikhism\\', \\'Market\\', \\'Germany\\', \\'Industrial Revolution\\', \\'Steel\\', \\'HSBC\\', \\'Edinburgh\\', \\'Europe\\', \\'BAE Systems\\', \\'Airbus\\', \\'GlaxoSmithKline\\', \\'Natural gas\\', \\'Petroleum\\', \\'Pound sterling\\', \\'Euro\\', \\'Gordon Brown\\', \\'Tony Blair\\', \\'Local government in the United Kingdom\\', \\'England\\', \\'Kingdom\\', \\'Scotland\\', \\'Kingdom\\', \\'Wales\\', \\'Principality\\', \\'Northern Ireland\\', \\'London\\', \\'City status in the United Kingdom\\', \\'Jersey\\', \\'Guernsey\\', \\'Isle of Man\\', \\'British Empire\\', \\'Royal Navy\\', \\'Elizabeth II of the United Kingdom\\', \\'Royal Air Force\\', \\'Royal Navy\\', \\'Royal Marines\\', \\'NATO\\', \\'University of Cambridge\\', \\'Bertrand Russell\\', \\'Adam Smith\\', \\'James Clerk Maxwell\\', \\'Michael Faraday\\', \\'Charles Darwin\\', \\'Francis Crick\\', \\'Isambard Kingdom Brunel\\', \\'Hydrogen\\', \\'Gravity\\', \\'Electron\\', \\'DNA\\', \\'Television\\', \\'Jet engine\\', \\'Bicycle\\', \\'Computer\\', \\'William Shakespeare\\', \\'William Shakespeare\\', \\'Novel\\', \\'Jane Austen\\', \\'Charles Dickens\\', \\'J. R. R. Tolkien\\', \\'J. K. Rowling\\', \\'Ben Jonson\\', \\'John Milton\\', \\'T. S. Eliot\\', \\'Christopher Wren\\', \\'Henry Purcell\\', \\'Benjamin Britten\\', \\'Opera\\', \\'The Beatles\\', \\'Queen (band)\\', \\'Iron Maiden\\', \\'The Rolling Stones\\', \\'Oasis (band)\\', \\'Kylie Minogue\\', \\'Arctic Monkeys\\', \\'J. M. W. Turner\\', \\'The Championships, Wimbledon\\', \\'Grand Slam (tennis)\\', \\'Sport\\', \\'Association football\\', \\'Rugby football\\', \\'Cricket\\', \\'Tennis\\', \\'Football (soccer)\\', \\'Olympic Games\\', \\'Manchester United F.C.\\', \\'Liverpool F.C.\\', \\'Chelsea F.C.\\', \\'Arsenal F.C.\\', \\'Celtic F.C.\\', \\'Liverpool F.C.\\', \\'Manchester United F.C.\\', \\'Celtic F.C.\\', \\'Cricket\\', \\'England\\', \\'England\\', \\'England\\', \\'England\\', \\'England\\', \\'Cricket\\', \\'Olympic Games\\', \\'Wales\\', \\'Northern Ireland\\', \\'Republic of Ireland\\', \\'Rugby World Cup\\', \\'Tennis\\', \\'Charles II of England\\', \\'Ireland\\', \\'Scottish Highlands\\', \\'Formula One\\', \\'Damon Hill\\', \\'Plymouth\\', \\'Lion\\', \\'Wales\\', \\'Great Britain\\']'],\n",
       " 'United States': [\"['Belgium', 'World Health Organization', 'World Health Organization', 'Rugby football']\",\n",
       "  \"['Phase (matter)', 'Acetone', 'Metal', 'Aluminium chloride', 'Chlorine', 'Hydrochloric acid', 'Ethanol', 'Ammonia', 'Copper(I) chloride', 'Iron', 'Chlorine', 'Gas', 'Iron', 'Hydrochloric acid', 'Chlorine', 'Copper', 'Copper(I) chloride', 'Copper(I) chloride', 'Chlorine', 'Aluminium chloride', 'Sodium hydroxide', 'Ethanol']\"],\n",
       " 'Output block not found.': ['[\\'Geneva\\', \\'Switzerland\\', \\'English language\\', \\'French language\\', \\'Spanish language\\', \\'United Nations\\', \\'Geneva\\', \\'Switzerland\\', \\'League of Nations\\', \\'Malaria\\', \\'AIDS\\', \\'Smallpox\\', \\'Malaria\\', \\'Zimbabwe\\', \\'Tobacco\\', \\'Sugar\\', \\'Liechtenstein\\', \\'Niue\\', \\'Cook Islands\\', \\'Puerto Rico\\', \\'Tokelau\\', \\'Vatican City\\', \\'Republic of China\\', \\'Taiwan\\', \"People\\'s Republic of China\", \\'Niue\\', \\'United States of America\\', \\'Mediterranean\\', \\'Cairo\\', \\'Egypt\\', \\'Copenhagen\\', \\'Denmark\\', \\'New Delhi\\', \\'India\\', \\'Manila\\', \\'Philippines\\', \\'Egypt\\', \\'Sudan\\', \\'Tunisia\\', \\'Morocco\\', \\'Somalia\\', \\'Copenhagen\\', \\'Denmark\\', \\'New Delhi\\', \\'India\\', \\'Cairo\\', \\'Egypt\\', \\'Maghreb\\', \\'Manila\\', \\'Philippines\\', \\'Oceania\\', \\'South Korea\\', \\'United States of America\\', \\'Canada\\', \\'Brazil\\', \\'Denmark\\', \\'Japan\\', \\'Norway\\', \\'South Korea\\', \\'Sweden\\', \\'Hong Kong\\', \"People\\'s Republic of China\", \\'United Nations\\']',\n",
       "  '[\\'SOS Children in Russia\\', \\'National Anthem of Russia\\', \\'Moscow\\', \\'Russian language\\', \\'List of countries by system of government\\', \\'Soviet Union\\', \\'Currency\\', \\'Time zone\\', \\'Russian language\\', \\'Russian language\\', \\'Country\\', \\'Canada\\', \\'Norway\\', \\'Finland\\', \\'Estonia\\', \\'Latvia\\', \\'Lithuania\\', \\'Poland\\', \\'Belarus\\', \\'Ukraine\\', \\'Georgia (country)\\', \\'Azerbaijan\\', \\'Kazakhstan\\', \"People\\'s Republic of China\", \\'Mongolia\\', \\'North Korea\\', \\'United States\\', \\'Japan\\', \\'Soviet Union\\', \\'Soviet Union\\', \\'Soviet Union\\', \\'Christian Era\\', \\'Tribe\\', \\'Europe\\', \\'Khazars\\', \\'Byzantine Empire\\', \\'Kiev\\', \\'Crusades\\', \\'Volga River\\', \\'Principalities\\', \\'Ukraine\\', \\'Belarus\\', \\'Poland\\', \\'Byzantine Empire\\', \\'Moscow\\', \\'Eastern Roman Empire\\', \\'Volga River\\', \\'Amur\\', \\'North America\\', \\'Asia\\', \\'Peter I of Russia\\', \\'Sweden\\', \\'Saint Petersburg\\', \\'Black Sea\\', \\'Georgia (country)\\', \\'La Grande Arme\\', \\'Paris\\', \\'Liberalism\\', \\'Finland\\', \\'Crimean War\\', \\'France\\', \\'Ottoman Empire\\', \\'Romania\\', \\'Serbia\\', \\'Montenegro\\', \\'Bulgaria\\', \\'World War I\\', \\'Russian Revolution of 1917\\', \\'Saint Petersburg\\', \\'Moscow\\', \\'Vladimir Lenin\\', \\'Soviet Union\\', \\'Nationalism\\', \\'Georgia (country)\\', \\'Joseph Stalin\\', \\'Lenin\\', \\'Leon Trotsky\\', \\'Famine\\', \\'Nazi Germany\\', \\'Battle of Stalingrad\\', \\'Soviet Union\\', \\'Communism\\', \\'United States\\', \\'Cold War\\', \\'United Kingdom\\', \\'Sputnik 1\\', \\'Yuri Gagarin\\', \\'Earth\\', \\'Agriculture\\', \\'Cuba\\', \\'Turkey\\', \\'United Nations\\', \\'Mikhail Gorbachev\\', \\'Communist\\', \\'Russian constitutional crisis of 1993\\', \\'Civil society\\', \\'Human rights\\', \\'Mass media\\', \\'Nuclear weapons\\', \\'Government\\', \\'Moscow\\', \\'Saint Petersburg\\', \\'Arctic\\', \\'Climate\\', \\'Iceland\\', \\'Europe\\', \\'Asia\\', \\'Volcano\\', \\'Arctic Ocean\\', \\'Pacific Ocean\\', \\'Baltic Sea\\', \\'Black Sea\\', \\'Caspian Sea\\', \\'Lake Baikal\\', \\'Norway\\', \\'Finland\\', \\'Baltic Sea\\', \\'Estonia\\', \\'Latvia\\', \\'Belarus\\', \\'Ukraine\\', \\'Black Sea\\', \\'Georgia (country)\\', \\'Azerbaijan\\', \\'Caspian Sea\\', \\'Azerbaijan\\', \\'Kazakhstan\\', \\'Kazakhstan\\', \\'Mongolia\\', \\'North Korea\\', \\'Pacific Ocean\\', \\'United States\\', \\'U.S. state\\', \\'Arctic Ocean\\', \\'Poland\\', \\'Lithuania\\', \\'Baltic Sea\\', \\'Black Sea\\', \\'Denmark\\', \\'North Sea\\', \\'Istanbul\\', \\'Turkey\\', \\'Mediterranean Sea\\', \\'Suez Canal\\', \\'Caspian Sea\\', \\'Poland\\', \\'Time zone\\', \\'Moscow\\', \\'Saint Petersburg\\', \\'City\\', \\'Russian language\\', \\'Moscow\\', \\'Moscow\\', \\'Saint Petersburg\\', \\'Saint Petersburg\\', \\'Petroleum\\', \\'Natural gas\\', \\'Statistics\\', \\'Saint Petersburg\\', \\'Law\\', \\'Pacific Ocean\\', \\'Jews\\', \\'Russian language\\', \\'Christianity\\', \\'Islam\\', \\'Judaism\\', \\'Buddhism\\', \\'Norway\\', \\'Finland\\', \\'Canada\\', \\'United States\\', \\'Arctic Ocean\\', \\'United States\\', \\'Sweden\\', \\'Baltic Sea\\', \\'Estonia\\', \\'Latvia\\', \\'Lithuania\\', \\'Poland\\', \\'Belarus\\', \\'Ukraine\\', \\'Pacific Ocean\\', \\'Japan\\', \\'Georgia (country)\\', \\'Azerbaijan\\', \\'Ukraine\\', \\'Black Sea\\', \\'Romania\\', \\'Black Sea\\', \\'Bulgaria\\', \\'Black Sea\\', \\'Turkey\\', \\'Black Sea\\', \\'Caspian Sea\\', \\'Kazakhstan\\', \\'Caspian Sea\\', \\'Turkmenistan\\', \\'Caspian Sea\\', \\'Azerbaijan\\', \\'Iran\\', \\'Kazakhstan\\', \\'Mongolia\\', \"People\\'s Republic of China\", \"People\\'s Republic of China\", \\'North Korea\\', \\'Japan\\', \\'North Korea\\', \\'South Korea\\']'],\n",
       " 'United States Constitution': [\"['Bismuth', 'Astatine', 'Tellurium', 'Ununhexium', 'List of elements by name', 'Color', 'Xenon', 'Electron', 'Phase (matter)', 'Magnetism', 'Lead', 'Bismuth', 'Lead', 'Bismuth', 'Day', 'Lead', 'Chemical element', 'Periodic table', 'Tellurium', 'Bismuth', 'Uranium', 'Beryllium', 'Neutron', 'Nuclear weapon', 'Textile', 'Marie Curie', 'Poland', 'Latin', 'Bismuth', 'Uranium', 'Bismuth', 'Neutron', 'Lead', 'Bismuth', 'Radium', 'Moon', 'Russia']\"],\n",
       " 'Princeton University': [\"['Chemistry', 'Matter', 'Atom', 'Electron', 'Proton', 'Neutron', 'Oxygen', 'Hydrogen', 'Helium', 'Californium', 'Technetium', 'List of elements by name', 'Periodic table', 'Carbon', 'English language', 'Latin alphabet', 'Lutetium', 'Niobium', 'Alchemy', 'Latin alphabet', 'Latin', 'Sodium', 'Tungsten', 'Mercury (element)', 'Potassium', 'Antimony', 'Yttrium', 'Hydrogen', 'Hydrogen', 'Helium', 'Oxygen', 'Carbon', 'Neon', 'Iron', 'Nitrogen', 'Silicon', 'Magnesium', 'Sulfur', 'Ununoctium', 'Russia']\"],\n",
       " 'Afghan Hound': [\"['Ununpentium', 'Polonium', 'List of elements by name', 'Color', 'Radon', 'Polonium', 'Electron', 'Phase (matter)', 'Periodic table', 'Polonium', 'Ununoctium', 'Ununoctium', 'Russia', 'Curium', 'Calcium', 'Curium', 'Calcium', 'Ununquadium', 'Ununquadium', 'Calcium', 'Ununoctium']\"],\n",
       " 'London': [\"['Sea', 'Europe', 'Atlantic Ocean', 'Mediterranean Sea', 'Danube', 'Turkey', 'Bulgaria', 'Romania', 'Ukraine', 'Russia', 'Georgia (country)', 'Istanbul', 'Russian language', 'Homer', 'Herodotus', 'Red Sea', 'Mediterranean Sea', 'Bulgaria', 'Miocene', 'Caspian Sea', 'Aral Sea', 'Turkey', 'Georgia (country)', 'Mediterranean Sea', 'Oxygen', 'Sulfuric acid', 'Pyrite', 'Turkey', 'Caspian Sea', 'Mediterranean Sea', 'Deluge (mythology)', 'Caspian Sea', 'Georgia (country)', 'Abkhazia']\"],\n",
       " 'Cotswolds': ['[\\'Turkey\\', \\'Istanbul\\', \\'List of countries by system of government\\', \\'Monarchy\\', \\'Currency\\', \\'16th century\\', \\'17th century\\', \\'Middle East\\', \\'North Africa\\', \\'Atlantic Ocean\\', \\'Caspian Sea\\', \\'Persian Gulf\\', \\'Austria\\', \\'Slovakia\\', \\'Ukraine\\', \\'Sudan\\', \\'Yemen\\', \\'Istanbul\\', \\'Mediterranean\\', \\'Roman Empire\\', \\'Byzantine Empire\\', \\'Mediterranean Sea\\', \\'Black Sea\\', \\'Red Sea\\', \\'Persian Gulf\\', \\'Indian Ocean\\', \\'Siege\\', \\'Vienna\\', \\'15th century\\', \\'20th century\\', \\'World War I\\', \\'Armenia\\', \\'Byzantine Empire\\', \\'Mediterranean\\', \\'Byzantine Empire\\', \\'Serbia\\', \\'Serbia\\', \\'Sultan\\', \\'Byzantine\\', \\'Suleiman the Magnificent\\', \\'Asia\\', \\'Red Sea\\', \\'Baghdad\\', \\'Mesopotamia\\', \\'Persian Gulf\\', \\'Mediterranean Sea\\', \\'Tunis\\', \\'Algeria\\', \\'Cyprus\\', \\'Spanish Inquisition\\', \\'Holy Roman Empire\\', \\'France\\', \\'France\\', \\'England\\', \\'Habsburg Spain\\', \\'Portugal\\', \\'Persian Gulf\\', \\'Indian Ocean\\', \\'Mediterranean Sea\\', \\'Vienna\\', \\'Istanbul\\', \\'Baghdad\\', \\'Ukraine\\', \\'Poland\\', \\'Holy Roman Empire\\', \\'Austria\\', \\'Egypt\\', \\'Algeria\\', \\'France\\', \\'Johannes Gutenberg\\', \\'Europe\\', \\'Russia\\', \\'Turkey\\', \\'Guild\\', \\'Egypt\\', \\'Cyprus\\', \\'Crimean War\\', \\'Russia\\', \\'Nationalism\\', \\'Serbia\\', \\'Serbia\\', \\'Montenegro\\', \\'Bulgaria\\', \\'Moldova\\', \\'Serbia\\', \\'Romania\\', \\'Montenegro\\', \\'University\\', \\'Constitutional monarchy\\', \\'Nationalism\\', \\'Libya\\', \\'Albania\\', \\'Russia\\', \\'Serbia\\', \\'Bulgaria\\', \\'Greece\\', \\'Bulgaria\\', \\'Montenegro\\', \\'World War I\\', \\'Russian Revolution of 1917\\', \\'Azerbaijan\\', \\'World War I\\', \\'World War I\\', \\'20th century\\', \\'Holocaust\\', \\'France\\', \\'Marco Polo\\', \\'Christopher Columbus\\', \\'Calligraphy\\', \\'Slavery\\', \"Qur\\'an\", \\'Middle Ages\\', \\'Baroque\\', \\'Rococo\\', \\'Istanbul\\', \\'Arabic language\\', \\'Musical instrument\\', \\'Piano\\', \\'Folk music\\', \\'Istanbul\\', \\'European\\', \\'Arabic language\\', \\'Sarajevo\\', \\'Baghdad\\', \\'Beirut\\', \\'Jerusalem\\', \\'Islam\\', \\'Abbasid\\', \\'Greek War of Independence\\', \\'Constitutional monarchy\\', \"Qur\\'an\", \\'Muhammad\\', \\'Mongol Empire\\']'],\n",
       " 'Chew Valley': ['[\\'Arabic language\\', \\'List of countries by system of government\\', \\'Currency\\', \\'Time zone\\', \\'Arabic language\\', \\'Middle East\\', \\'Red Sea\\', \\'Oman\\', \\'Saudi Arabia\\', \\'East Africa\\', \\'Anno Domini\\', \\'Ancient Rome\\', \\'7th century\\', \\'11th century\\', \\'16th century\\', \\'19th century\\', \\'Ottoman Empire\\', \\'Egypt\\', \\'Communist\\', \"Qur\\'an\", \"Qur\\'an\", \"Qur\\'an\", \\'Capital\\', \\'Middle East\\', \\'Red Sea\\', \\'Oman\\', \\'Saudi Arabia\\', \\'Red Sea\\', \\'France\\', \\'Thailand\\', \\'California\\', \\'Malaria\\', \\'Sorghum\\', \\'Cotton\\', \\'Fruit\\', \\'Mango\\', \\'Irrigation\\', \\'Wheat\\', \\'Barley\\', \\'Asia\\', \\'Drought\\', \\'Coffee\\', \\'Indonesia\\', \\'India\\', \\'East Africa\\', \\'United Kingdom\\', \\'United States\\', \\'Soviet Union\\', \\'China\\', \\'Suez Canal\\', \\'Natural gas\\', \\'Iraq\\', \\'Jordan\\', \\'Egypt\\', \\'Marxism\\', \\'Kuwait\\', \\'Eritrea\\', \\'Israel\\', \\'Judaism\\', \\'English language\\', \\'Somalia\\', \\'Eritrea\\', \\'Ethiopia\\', \\'English language\\', \\'Saudi Arabia\\', \\'Oman\\', \\'Eritrea\\', \\'Red Sea\\', \\'Djibouti\\', \\'Somalia\\', \\'List of countries\\', \\'Middle East\\', \\'Bahrain\\', \\'Cyprus\\', \\'Egypt\\', \\'Iran\\', \\'Iraq\\', \\'Israel\\', \\'Jordan\\', \\'Kuwait\\', \\'Lebanon\\', \\'Oman\\', \\'Palestinian territories\\', \\'Qatar\\', \\'Saudi Arabia\\', \\'Syria\\', \\'Turkey\\', \\'United Arab Emirates\\', \\'Armenia\\', \\'Azerbaijan\\', \\'Bahrain\\', \\'Cyprus\\', \\'Georgia (country)\\', \\'Iran\\', \\'Iraq\\', \\'Israel\\', \\'Jordan\\', \\'Kuwait\\', \\'Lebanon\\', \\'Oman\\', \\'Qatar\\', \\'Saudi Arabia\\', \\'Syria\\', \\'Turkey\\', \\'United Arab Emirates\\', \\'List of countries\\', \\'Asia\\', \\'Afghanistan\\', \\'Armenia\\', \\'Azerbaijan\\', \\'Bahrain\\', \\'Bangladesh\\', \\'Bhutan\\', \\'Brunei\\', \\'Cambodia\\', \"People\\'s Republic of China\", \\'Cyprus\\', \\'East Timor\\', \\'Georgia (country)\\', \\'India\\', \\'Indonesia\\', \\'Iran\\', \\'Iraq\\', \\'Israel\\', \\'Japan\\', \\'Jordan\\', \\'Kazakhstan\\', \\'Kuwait\\', \\'Kyrgyzstan\\', \\'Laos\\', \\'Lebanon\\', \\'Malaysia\\', \\'Maldives\\', \\'Mongolia\\', \\'Myanmar\\', \\'Nepal\\', \\'North Korea\\', \\'Oman\\', \\'Pakistan\\', \\'Philippines\\', \\'Qatar\\', \\'Russia\\', \\'Saudi Arabia\\', \\'Singapore\\', \\'South Korea\\', \\'Sri Lanka\\', \\'Syria\\', \\'Tajikistan\\', \\'Thailand\\', \\'Turkey\\', \\'Turkmenistan\\', \\'United Arab Emirates\\', \\'Uzbekistan\\', \\'Vietnam\\', \\'Republic of China\\', \\'United Nations\\', \\'Oceania\\', \\'List of countries\\', \\'India\\', \\'Iran\\', \\'Maldives\\', \\'Oman\\', \\'Pakistan\\', \\'Somalia\\', \\'Sri Lanka\\', \\'List of countries\\', \\'Red Sea\\', \\'Djibouti\\', \\'Egypt\\', \\'Eritrea\\', \\'Israel\\', \\'Jordan\\', \\'Saudi Arabia\\', \\'Somalia\\', \\'Sudan\\', \\'List of countries\\', \\'Indian Ocean\\', \\'Bahrain\\', \\'Bangladesh\\', \\'Christmas Island\\', \\'Cocos (Keeling) Islands\\', \\'India\\', \\'Indonesia\\', \\'Iran\\', \\'Iraq\\', \\'Israel\\', \\'Kuwait\\', \\'Malaysia\\', \\'Maldives\\', \\'Myanmar\\', \\'Oman\\', \\'Pakistan\\', \\'Qatar\\', \\'Saudi Arabia\\', \\'Sri Lanka\\', \\'Thailand\\', \\'United Arab Emirates\\', \\'Africa\\', \\'Comoros\\', \\'Djibouti\\', \\'Eritrea\\', \\'Kenya\\', \\'Madagascar\\', \\'Mauritius\\', \\'Mayotte\\', \\'Mozambique\\', \\'Seychelles\\', \\'Somalia\\', \\'South Africa\\', \\'Sudan\\', \\'Tanzania\\', \\'Oceania\\', \\'Australia\\', \\'Christmas Island\\', \\'Cocos (Keeling) Islands\\', \\'Bahrain\\', \\'Christmas Island\\', \\'Cocos (Keeling) Islands\\', \\'Madagascar\\', \\'Maldives\\', \\'Mauritius\\', \\'Mayotte\\', \\'Seychelles\\', \\'Sri Lanka\\', \\'Arab League\\', \\'Algeria\\', \\'Bahrain\\', \\'Comoros\\', \\'Djibouti\\', \\'Egypt\\', \\'Iraq\\', \\'Jordan\\', \\'Kuwait\\', \\'Lebanon\\', \\'Libya\\', \\'Mauritania\\', \\'Morocco\\', \\'Oman\\', \\'Qatar\\', \\'Saudi Arabia\\', \\'Somalia\\', \\'Sudan\\', \\'Syria\\', \\'Tunisia\\', \\'United Arab Emirates\\', \\'Afghanistan\\', \\'Albania\\', \\'Algeria\\', \\'Azerbaijan\\', \\'Bahrain\\', \\'Bangladesh\\', \\'Benin\\', \\'Burkina Faso\\', \\'Brunei\\', \\'Cameroon\\', \\'Chad\\', \\'Comoros\\', \"Cte d\\'Ivoire\", \\'Djibouti\\', \\'Egypt\\', \\'Gabon\\', \\'Guinea\\', \\'Guinea-Bissau\\', \\'Guyana\\', \\'Indonesia\\', \\'Iran\\', \\'Iraq\\', \\'Jordan\\', \\'Kuwait\\', \\'Kazakhstan\\', \\'Kyrgyzstan\\', \\'Lebanon\\', \\'Libya\\', \\'Maldives\\', \\'Malaysia\\', \\'Mali\\', \\'Mauritania\\', \\'Morocco\\', \\'Mozambique\\', \\'Niger\\', \\'Nigeria\\', \\'Oman\\', \\'Pakistan\\', \\'Qatar\\', \\'Saudi Arabia\\', \\'Senegal\\', \\'Sierra Leone\\', \\'Somalia\\', \\'Sudan\\', \\'Syria\\', \\'Tajikistan\\', \\'Turkey\\', \\'Tunisia\\', \\'Togo\\', \\'Turkmenistan\\', \\'Uganda\\', \\'Uzbekistan\\', \\'United Arab Emirates\\', \\'Bosnia and Herzegovina\\', \\'Central African Republic\\', \\'Russia\\', \\'Thailand\\', \\'Turkish Republic of Northern Cyprus\\', \\'United Nations\\', \\'Arabic language\\', \\'Algeria\\', \\'Bahrain\\', \\'Egypt\\', \\'Iraq\\', \\'Jordan\\', \\'Kuwait\\', \\'Lebanon\\', \\'Libya\\', \\'Malta\\', \\'Mauritania\\', \\'Morocco\\', \\'Oman\\', \\'Qatar\\', \\'Saudi Arabia\\', \\'Sudan\\', \\'Syria\\', \\'Tunisia\\', \\'United Arab Emirates\\', \\'Western Sahara\\', \\'Hebrew language\\', \\'Iraq\\', \\'Israel\\', \\'Syria\\', \\'Eritrea\\', \\'Ethiopia\\', \\'Oman\\']']}"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "non_matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5092fbe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "bad_prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c75dc1b",
   "metadata": {},
   "source": [
    "### Tests : random choosing among proposed links"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46a015f5",
   "metadata": {},
   "source": [
    "### Tests : simulating an agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "9e2dea74",
   "metadata": {},
   "outputs": [],
   "source": [
    "page_name_links = load_dataset(\"berquetR/file_names_links\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "f7bf518d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_agent_prompt(source, target, source_links):\n",
    "    input_data = {\n",
    "        \"Source\": source, \n",
    "        \"Candidates\": source_links,\n",
    "        \"Target\": target\n",
    "    }\n",
    "    \n",
    "    prompt = f\"\"\"You are a knowledge discovery expert familiar with the Wikipedia link structure and your objective is to play the game of Wikispeedia: https://dlab.epfl.ch/wikispeedia/play/.\n",
    "##Goal \n",
    "Given two Wikipedia articles, a source and a target, your goal is to reach the target article starting from the source article in as few clicks as possible. For the articles you are given this is always possible.\n",
    "\n",
    "##Constraint \n",
    "You should exclusively follow the links present in the articles that you encounter along the way.\n",
    "\n",
    "##Fine-grained instructions \n",
    "1. While the overall goal is to find a path from a source to a target article, you will proceed step by step.\n",
    "2. Given outgoing links from the source article as candidates, you should select the candidate that takes you closer to the target article. Use your knowledge of the \"expected\" Wikipedia link structure and relatedness between articles to identify the candidate that takes you closer to the target.\n",
    "3. Choose **only** from the provided candidates.\n",
    "4. Do not provide an algorithm or code to solve the task, instead give only the solution.\n",
    "\n",
    "##Input \n",
    "{json.dumps(input_data, indent=4)}\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "09b0b9fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def links_from_source(dataset, source):\n",
    "    filtered = dataset['train'].filter(lambda example : example['filename'] == source)\n",
    "\n",
    "    if len(filtered) > 0:\n",
    "        row_with_filename_e = filtered[0]\n",
    "        links = row_with_filename_e['links']\n",
    "        return links\n",
    "    else:\n",
    "        print(\"No rows found where filename = 'e'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "ea1b675d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'source': 'Concorde',\n",
       " 'target': 'Periodic_table_(large_version)',\n",
       " 'current_page': 'Concorde',\n",
       " 'current_page_links': \"['September 11, 2001 attacks', 'United Kingdom', 'France', 'United States', 'Soviet Union', 'New York City', 'Harold Macmillan', 'Scotland', 'French language', 'Bristol', '1973 oil crisis', 'France', 'John F. Kennedy', 'Airbus', 'BAE Systems', 'Airbus', 'Boeing 747', 'Mexico', 'Bristol', 'London', 'Bahrain', 'Paris', 'Rio de Janeiro', 'Atlantic Ocean', 'New York City', 'Washington, D.C.', 'Supreme Court of the United States', 'Barbados', 'Finland', 'Malaysia', 'India', 'Mexico City', 'Boeing 747', 'France', 'Titanium', 'September 11, 2001 attacks', 'Barbados', 'Boston, Massachusetts', 'United Kingdom', 'Birmingham', 'Belfast', 'Manchester', 'Cardiff', 'Edinburgh', 'Elizabeth II of the United Kingdom', 'Windsor Castle', 'Airbus', 'Germany', 'Airbus', 'TGV', 'BBC', 'Mini', 'Supermarine Spitfire', 'Airbus', 'Doctor Who']\",\n",
       " 'next_page': 'Titanium',\n",
       " '__index_level_0__': 1232}"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_var = test_no_prompt[1013]\n",
    "test_var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "b2c68006",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filter: 100%|| 5409/5409 [00:00<00:00, 42056.40 examples/s]\n"
     ]
    }
   ],
   "source": [
    "source = test_var['current_page']\n",
    "target = test_var['target']\n",
    "links = links_from_source(page_name_links , source)\n",
    "next_page = source\n",
    "iter_i = 0 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "1ede0d9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration : 0\n",
      "Source : Concorde\n",
      "Target : Periodic_table_(large_version)\n",
      "Model output : Boeing 747\n",
      "Links : ['September 11, 2001 attacks', 'United Kingdom', 'France', 'United States', 'Soviet Union', 'New York City', 'Harold Macmillan', 'Scotland', 'French language', 'Bristol', '1973 oil crisis', 'France', 'John F. Kennedy', 'Airbus', 'BAE Systems', 'Airbus', 'Boeing 747', 'Mexico', 'Bristol', 'London', 'Bahrain', 'Paris', 'Rio de Janeiro', 'Atlantic Ocean', 'New York City', 'Washington, D.C.', 'Supreme Court of the United States', 'Barbados', 'Finland', 'Malaysia', 'India', 'Mexico City', 'Boeing 747', 'France', 'Titanium', 'September 11, 2001 attacks', 'Barbados', 'Boston, Massachusetts', 'United Kingdom', 'Birmingham', 'Belfast', 'Manchester', 'Cardiff', 'Edinburgh', 'Elizabeth II of the United Kingdom', 'Windsor Castle', 'Airbus', 'Germany', 'Airbus', 'TGV', 'BBC', 'Mini', 'Supermarine Spitfire', 'Airbus', 'Doctor Who']\n",
      "Model chose next_page among links, Next Page : Boeing 747\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filter: 100%|| 5409/5409 [00:00<00:00, 76305.22 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration : 1\n",
      "Source : Boeing_747\n",
      "Target : Periodic_table_(large_version)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model output : Airbus A380\n",
      "Links : ['Airbus A380', 'Soviet Union', 'Hong Kong', 'London', 'Sydney', 'Seattle, Washington', 'Concorde', 'Airbus A380', 'Airbus', 'Airbus A380', 'Piano', 'Japan', 'Airbus', 'Airbus A380', 'Airbus A380', 'Japan', 'President of the United States', 'President of the United States', 'Bahrain', 'Brunei', 'Iran', 'Oman', 'Qatar', 'Saudi Arabia', 'United Arab Emirates', 'Seattle, Washington', 'United States', 'Netherlands', 'Australia', 'Johannesburg', 'South Africa', 'Germany', 'Paris', 'France', 'Tehran', 'Iran', 'South Korea', 'Nairobi', 'Pan Am Flight 103', 'September 11, 2001', 'Hong Kong', 'Taipei', 'Taiwan', 'Taipei', 'Addis Ababa', 'James Bond', 'Airbus A380', 'Airbus A380']\n",
      "Model chose next_page among links, Next Page : Airbus A380\n",
      "Iteration : 2\n",
      "Source : Airbus_A380\n",
      "Target : Periodic_table_(large_version)\n",
      "Model output : Boeing 747\n",
      "Links : ['Airbus', 'France', 'Boeing 747', 'Chicago', 'Sydney', 'Boeing 747', 'Boeing 747', 'Euro', 'Singapore', 'Brisbane', 'Sydney', 'Melbourne', 'Kuala Lumpur', 'Colombia', 'North America', 'Canada', 'Singapore', 'Hamburg', 'Germany', 'Australia', 'Canada', \"People's Republic of China\", 'Colombia', 'Ethiopia', 'France', 'Germany', 'Iceland', 'Ireland', 'Japan', 'Malaysia', 'Singapore', 'South Africa', 'South Korea', 'Spain', 'United Arab Emirates', 'United Kingdom', 'London', 'Singapore', 'Sydney', 'Hong Kong', 'Paris', 'Frankfurt', 'Melbourne', 'Sydney', 'Paris', 'Montreal', 'Aluminum', 'Fiberglass', 'Welding', 'Titanium', 'Boeing 747', 'France', 'Germany', 'Spain', 'United Kingdom', 'France', 'Hamburg', 'Germany', 'United Kingdom', 'Bristol', 'Wales', 'France', 'Spain', 'United States dollar', 'United States dollar', 'The Wall Street Journal', 'Airbus', 'Austria', 'Boeing 747']\n",
      "Model chose next_page among links, Next Page : Boeing 747\n",
      "Iteration : 3\n",
      "Source : Boeing_747\n",
      "Target : Periodic_table_(large_version)\n",
      "Model output : Airbus A380\n",
      "Links : ['Airbus A380', 'Soviet Union', 'Hong Kong', 'London', 'Sydney', 'Seattle, Washington', 'Concorde', 'Airbus A380', 'Airbus', 'Airbus A380', 'Piano', 'Japan', 'Airbus', 'Airbus A380', 'Airbus A380', 'Japan', 'President of the United States', 'President of the United States', 'Bahrain', 'Brunei', 'Iran', 'Oman', 'Qatar', 'Saudi Arabia', 'United Arab Emirates', 'Seattle, Washington', 'United States', 'Netherlands', 'Australia', 'Johannesburg', 'South Africa', 'Germany', 'Paris', 'France', 'Tehran', 'Iran', 'South Korea', 'Nairobi', 'Pan Am Flight 103', 'September 11, 2001', 'Hong Kong', 'Taipei', 'Taiwan', 'Taipei', 'Addis Ababa', 'James Bond', 'Airbus A380', 'Airbus A380']\n",
      "Model chose next_page among links, Next Page : Airbus A380\n",
      "Iteration : 4\n",
      "Source : Airbus_A380\n",
      "Target : Periodic_table_(large_version)\n",
      "Model output : Boeing 747\n",
      "Links : ['Airbus', 'France', 'Boeing 747', 'Chicago', 'Sydney', 'Boeing 747', 'Boeing 747', 'Euro', 'Singapore', 'Brisbane', 'Sydney', 'Melbourne', 'Kuala Lumpur', 'Colombia', 'North America', 'Canada', 'Singapore', 'Hamburg', 'Germany', 'Australia', 'Canada', \"People's Republic of China\", 'Colombia', 'Ethiopia', 'France', 'Germany', 'Iceland', 'Ireland', 'Japan', 'Malaysia', 'Singapore', 'South Africa', 'South Korea', 'Spain', 'United Arab Emirates', 'United Kingdom', 'London', 'Singapore', 'Sydney', 'Hong Kong', 'Paris', 'Frankfurt', 'Melbourne', 'Sydney', 'Paris', 'Montreal', 'Aluminum', 'Fiberglass', 'Welding', 'Titanium', 'Boeing 747', 'France', 'Germany', 'Spain', 'United Kingdom', 'France', 'Hamburg', 'Germany', 'United Kingdom', 'Bristol', 'Wales', 'France', 'Spain', 'United States dollar', 'United States dollar', 'The Wall Street Journal', 'Airbus', 'Austria', 'Boeing 747']\n",
      "Model chose next_page among links, Next Page : Boeing 747\n",
      "Iteration : 5\n",
      "Source : Boeing_747\n",
      "Target : Periodic_table_(large_version)\n",
      "Model output : Airbus A380\n",
      "Links : ['Airbus A380', 'Soviet Union', 'Hong Kong', 'London', 'Sydney', 'Seattle, Washington', 'Concorde', 'Airbus A380', 'Airbus', 'Airbus A380', 'Piano', 'Japan', 'Airbus', 'Airbus A380', 'Airbus A380', 'Japan', 'President of the United States', 'President of the United States', 'Bahrain', 'Brunei', 'Iran', 'Oman', 'Qatar', 'Saudi Arabia', 'United Arab Emirates', 'Seattle, Washington', 'United States', 'Netherlands', 'Australia', 'Johannesburg', 'South Africa', 'Germany', 'Paris', 'France', 'Tehran', 'Iran', 'South Korea', 'Nairobi', 'Pan Am Flight 103', 'September 11, 2001', 'Hong Kong', 'Taipei', 'Taiwan', 'Taipei', 'Addis Ababa', 'James Bond', 'Airbus A380', 'Airbus A380']\n",
      "Model chose next_page among links, Next Page : Airbus A380\n",
      "Iteration : 6\n",
      "Source : Airbus_A380\n",
      "Target : Periodic_table_(large_version)\n",
      "Model output : Boeing 747\n",
      "Links : ['Airbus', 'France', 'Boeing 747', 'Chicago', 'Sydney', 'Boeing 747', 'Boeing 747', 'Euro', 'Singapore', 'Brisbane', 'Sydney', 'Melbourne', 'Kuala Lumpur', 'Colombia', 'North America', 'Canada', 'Singapore', 'Hamburg', 'Germany', 'Australia', 'Canada', \"People's Republic of China\", 'Colombia', 'Ethiopia', 'France', 'Germany', 'Iceland', 'Ireland', 'Japan', 'Malaysia', 'Singapore', 'South Africa', 'South Korea', 'Spain', 'United Arab Emirates', 'United Kingdom', 'London', 'Singapore', 'Sydney', 'Hong Kong', 'Paris', 'Frankfurt', 'Melbourne', 'Sydney', 'Paris', 'Montreal', 'Aluminum', 'Fiberglass', 'Welding', 'Titanium', 'Boeing 747', 'France', 'Germany', 'Spain', 'United Kingdom', 'France', 'Hamburg', 'Germany', 'United Kingdom', 'Bristol', 'Wales', 'France', 'Spain', 'United States dollar', 'United States dollar', 'The Wall Street Journal', 'Airbus', 'Austria', 'Boeing 747']\n",
      "Model chose next_page among links, Next Page : Boeing 747\n",
      "Iteration : 7\n",
      "Source : Boeing_747\n",
      "Target : Periodic_table_(large_version)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[163], line 12\u001b[0m\n\u001b[1;32m      9\u001b[0m prompt_tokenized \u001b[38;5;241m=\u001b[39m tokenizer([prompt],return_tensors \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m#Extract output\u001b[39;00m\n\u001b[0;32m---> 12\u001b[0m out \u001b[38;5;241m=\u001b[39m (tokenizer\u001b[38;5;241m.\u001b[39mdecode(\u001b[43mft_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mprompt_tokenized\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_new_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m30\u001b[39;49m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m], skip_special_tokens\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m))\n\u001b[1;32m     13\u001b[0m out_extracted \u001b[38;5;241m=\u001b[39m extract_output_from_prompt(out)\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mModel output : \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mout_extracted\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m/dlabscratch1/berquet/conda/envs/env2/lib/python3.8/site-packages/peft/peft_model.py:1190\u001b[0m, in \u001b[0;36mPeftModelForCausalLM.generate\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1188\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_enable_peft_forward_hooks(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m   1189\u001b[0m         kwargs \u001b[38;5;241m=\u001b[39m {k: v \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m kwargs\u001b[38;5;241m.\u001b[39mitems() \u001b[38;5;28;01mif\u001b[39;00m k \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mspecial_peft_forward_args}\n\u001b[0;32m-> 1190\u001b[0m         outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbase_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1191\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1192\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbase_model\u001b[38;5;241m.\u001b[39mgenerate(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/dlabscratch1/berquet/conda/envs/env2/lib/python3.8/site-packages/torch/utils/_contextlib.py:115\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    114\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 115\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/dlabscratch1/berquet/conda/envs/env2/lib/python3.8/site-packages/transformers/generation/utils.py:1527\u001b[0m, in \u001b[0;36mGenerationMixin.generate\u001b[0;34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, negative_prompt_ids, negative_prompt_attention_mask, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39massisted_decoding(\n\u001b[1;32m   1510\u001b[0m         input_ids,\n\u001b[1;32m   1511\u001b[0m         candidate_generator\u001b[38;5;241m=\u001b[39mcandidate_generator,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1523\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_kwargs,\n\u001b[1;32m   1524\u001b[0m     )\n\u001b[1;32m   1525\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m generation_mode \u001b[38;5;241m==\u001b[39m GenerationMode\u001b[38;5;241m.\u001b[39mGREEDY_SEARCH:\n\u001b[1;32m   1526\u001b[0m     \u001b[38;5;66;03m# 11. run greedy search\u001b[39;00m\n\u001b[0;32m-> 1527\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_greedy_search\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1528\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlogits_processor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprepared_logits_processor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1530\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstopping_criteria\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprepared_stopping_criteria\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1531\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpad_token_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgeneration_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpad_token_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1532\u001b[0m \u001b[43m        \u001b[49m\u001b[43meos_token_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgeneration_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meos_token_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1533\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_scores\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgeneration_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moutput_scores\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1534\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_logits\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgeneration_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moutput_logits\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1535\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_dict_in_generate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgeneration_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreturn_dict_in_generate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1536\u001b[0m \u001b[43m        \u001b[49m\u001b[43msynced_gpus\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msynced_gpus\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1537\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstreamer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstreamer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1538\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1539\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1541\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m generation_mode \u001b[38;5;241m==\u001b[39m GenerationMode\u001b[38;5;241m.\u001b[39mCONTRASTIVE_SEARCH:\n\u001b[1;32m   1542\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m model_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muse_cache\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n",
      "File \u001b[0;32m/dlabscratch1/berquet/conda/envs/env2/lib/python3.8/site-packages/transformers/generation/utils.py:2411\u001b[0m, in \u001b[0;36mGenerationMixin._greedy_search\u001b[0;34m(self, input_ids, logits_processor, stopping_criteria, max_length, pad_token_id, eos_token_id, output_attentions, output_hidden_states, output_scores, output_logits, return_dict_in_generate, synced_gpus, streamer, **model_kwargs)\u001b[0m\n\u001b[1;32m   2408\u001b[0m model_inputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprepare_inputs_for_generation(input_ids, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_kwargs)\n\u001b[1;32m   2410\u001b[0m \u001b[38;5;66;03m# forward pass to get next token\u001b[39;00m\n\u001b[0;32m-> 2411\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2412\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2413\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   2414\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2415\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2416\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2418\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m synced_gpus \u001b[38;5;129;01mand\u001b[39;00m this_peer_finished:\n\u001b[1;32m   2419\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m  \u001b[38;5;66;03m# don't waste resources running the code we don't need\u001b[39;00m\n",
      "File \u001b[0;32m/dlabscratch1/berquet/conda/envs/env2/lib/python3.8/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/dlabscratch1/berquet/conda/envs/env2/lib/python3.8/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/dlabscratch1/berquet/conda/envs/env2/lib/python3.8/site-packages/accelerate/hooks.py:166\u001b[0m, in \u001b[0;36madd_hook_to_module.<locals>.new_forward\u001b[0;34m(module, *args, **kwargs)\u001b[0m\n\u001b[1;32m    164\u001b[0m         output \u001b[38;5;241m=\u001b[39m module\u001b[38;5;241m.\u001b[39m_old_forward(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    165\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 166\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_old_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    167\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m module\u001b[38;5;241m.\u001b[39m_hf_hook\u001b[38;5;241m.\u001b[39mpost_forward(module, output)\n",
      "File \u001b[0;32m/dlabscratch1/berquet/conda/envs/env2/lib/python3.8/site-packages/transformers/models/phi/modeling_phi.py:1173\u001b[0m, in \u001b[0;36mPhiForCausalLM.forward\u001b[0;34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1170\u001b[0m return_dict \u001b[38;5;241m=\u001b[39m return_dict \u001b[38;5;28;01mif\u001b[39;00m return_dict \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39muse_return_dict\n\u001b[1;32m   1172\u001b[0m \u001b[38;5;66;03m# decoder outputs consists of (dec_features, layer_state, dec_hidden, dec_attn)\u001b[39;00m\n\u001b[0;32m-> 1173\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1174\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1175\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1176\u001b[0m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1177\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1178\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1179\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1180\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1181\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1182\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1183\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1185\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m   1186\u001b[0m logits \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlm_head(hidden_states)\n",
      "File \u001b[0;32m/dlabscratch1/berquet/conda/envs/env2/lib/python3.8/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/dlabscratch1/berquet/conda/envs/env2/lib/python3.8/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/dlabscratch1/berquet/conda/envs/env2/lib/python3.8/site-packages/accelerate/hooks.py:166\u001b[0m, in \u001b[0;36madd_hook_to_module.<locals>.new_forward\u001b[0;34m(module, *args, **kwargs)\u001b[0m\n\u001b[1;32m    164\u001b[0m         output \u001b[38;5;241m=\u001b[39m module\u001b[38;5;241m.\u001b[39m_old_forward(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    165\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 166\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_old_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    167\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m module\u001b[38;5;241m.\u001b[39m_hf_hook\u001b[38;5;241m.\u001b[39mpost_forward(module, output)\n",
      "File \u001b[0;32m/dlabscratch1/berquet/conda/envs/env2/lib/python3.8/site-packages/transformers/models/phi/modeling_phi.py:1052\u001b[0m, in \u001b[0;36mPhiModel.forward\u001b[0;34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1043\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gradient_checkpointing_func(\n\u001b[1;32m   1044\u001b[0m         decoder_layer\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m,\n\u001b[1;32m   1045\u001b[0m         hidden_states,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         output_attentions,\n\u001b[1;32m   1050\u001b[0m     )\n\u001b[1;32m   1051\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1052\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mdecoder_layer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1053\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1054\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1055\u001b[0m \u001b[43m        \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1056\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1057\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1058\u001b[0m \u001b[43m        \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1059\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1061\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m layer_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m   1063\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m use_cache:\n",
      "File \u001b[0;32m/dlabscratch1/berquet/conda/envs/env2/lib/python3.8/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/dlabscratch1/berquet/conda/envs/env2/lib/python3.8/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/dlabscratch1/berquet/conda/envs/env2/lib/python3.8/site-packages/accelerate/hooks.py:166\u001b[0m, in \u001b[0;36madd_hook_to_module.<locals>.new_forward\u001b[0;34m(module, *args, **kwargs)\u001b[0m\n\u001b[1;32m    164\u001b[0m         output \u001b[38;5;241m=\u001b[39m module\u001b[38;5;241m.\u001b[39m_old_forward(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    165\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 166\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_old_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    167\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m module\u001b[38;5;241m.\u001b[39m_hf_hook\u001b[38;5;241m.\u001b[39mpost_forward(module, output)\n",
      "File \u001b[0;32m/dlabscratch1/berquet/conda/envs/env2/lib/python3.8/site-packages/transformers/models/phi/modeling_phi.py:783\u001b[0m, in \u001b[0;36mPhiDecoderLayer.forward\u001b[0;34m(self, hidden_states, attention_mask, position_ids, output_attentions, use_cache, past_key_value)\u001b[0m\n\u001b[1;32m    780\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_layernorm(hidden_states)\n\u001b[1;32m    782\u001b[0m \u001b[38;5;66;03m# Self Attention\u001b[39;00m\n\u001b[0;32m--> 783\u001b[0m attn_outputs, self_attn_weights, present_key_value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mself_attn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    784\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    785\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    786\u001b[0m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    787\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    788\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    789\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    790\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    791\u001b[0m attn_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresid_dropout(attn_outputs)\n\u001b[1;32m    793\u001b[0m feed_forward_hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresid_dropout(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmlp(hidden_states))\n",
      "File \u001b[0;32m/dlabscratch1/berquet/conda/envs/env2/lib/python3.8/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/dlabscratch1/berquet/conda/envs/env2/lib/python3.8/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/dlabscratch1/berquet/conda/envs/env2/lib/python3.8/site-packages/accelerate/hooks.py:166\u001b[0m, in \u001b[0;36madd_hook_to_module.<locals>.new_forward\u001b[0;34m(module, *args, **kwargs)\u001b[0m\n\u001b[1;32m    164\u001b[0m         output \u001b[38;5;241m=\u001b[39m module\u001b[38;5;241m.\u001b[39m_old_forward(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    165\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 166\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_old_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    167\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m module\u001b[38;5;241m.\u001b[39m_hf_hook\u001b[38;5;241m.\u001b[39mpost_forward(module, output)\n",
      "File \u001b[0;32m/dlabscratch1/berquet/conda/envs/env2/lib/python3.8/site-packages/transformers/models/phi/modeling_phi.py:731\u001b[0m, in \u001b[0;36mPhiSdpaAttention.forward\u001b[0;34m(self, hidden_states, attention_mask, position_ids, past_key_value, output_attentions, use_cache)\u001b[0m\n\u001b[1;32m    728\u001b[0m attn_output \u001b[38;5;241m=\u001b[39m attn_output\u001b[38;5;241m.\u001b[39mtranspose(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m)\u001b[38;5;241m.\u001b[39mcontiguous()\n\u001b[1;32m    729\u001b[0m attn_output \u001b[38;5;241m=\u001b[39m attn_output\u001b[38;5;241m.\u001b[39mreshape(bsz, q_len, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhidden_size)\n\u001b[0;32m--> 731\u001b[0m attn_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdense\u001b[49m\u001b[43m(\u001b[49m\u001b[43mattn_output\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    733\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m attn_output, \u001b[38;5;28;01mNone\u001b[39;00m, past_key_value\n",
      "File \u001b[0;32m/dlabscratch1/berquet/conda/envs/env2/lib/python3.8/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/dlabscratch1/berquet/conda/envs/env2/lib/python3.8/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/dlabscratch1/berquet/conda/envs/env2/lib/python3.8/site-packages/accelerate/hooks.py:166\u001b[0m, in \u001b[0;36madd_hook_to_module.<locals>.new_forward\u001b[0;34m(module, *args, **kwargs)\u001b[0m\n\u001b[1;32m    164\u001b[0m         output \u001b[38;5;241m=\u001b[39m module\u001b[38;5;241m.\u001b[39m_old_forward(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    165\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 166\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_old_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    167\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m module\u001b[38;5;241m.\u001b[39m_hf_hook\u001b[38;5;241m.\u001b[39mpost_forward(module, output)\n",
      "File \u001b[0;32m/dlabscratch1/berquet/conda/envs/env2/lib/python3.8/site-packages/bitsandbytes/nn/modules.py:429\u001b[0m, in \u001b[0;36mLinear4bit.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    426\u001b[0m     x \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompute_dtype)\n\u001b[1;32m    428\u001b[0m bias \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompute_dtype)\n\u001b[0;32m--> 429\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mbnb\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmatmul_4bit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mt\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mquant_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mquant_state\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    431\u001b[0m out \u001b[38;5;241m=\u001b[39m out\u001b[38;5;241m.\u001b[39mto(inp_dtype)\n\u001b[1;32m    433\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "File \u001b[0;32m/dlabscratch1/berquet/conda/envs/env2/lib/python3.8/site-packages/bitsandbytes/autograd/_functions.py:572\u001b[0m, in \u001b[0;36mmatmul_4bit\u001b[0;34m(A, B, quant_state, out, bias)\u001b[0m\n\u001b[1;32m    570\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m MatMul4Bit\u001b[38;5;241m.\u001b[39mapply(A, B, out, bias, quant_state)\n\u001b[1;32m    571\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 572\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgemv_4bit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mA\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mB\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mt\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquant_state\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    573\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m bias \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    574\u001b[0m         out \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m bias\n",
      "File \u001b[0;32m/dlabscratch1/berquet/conda/envs/env2/lib/python3.8/site-packages/bitsandbytes/functional.py:1667\u001b[0m, in \u001b[0;36mgemv_4bit\u001b[0;34m(A, B, out, transposed_A, transposed_B, state)\u001b[0m\n\u001b[1;32m   1665\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m out \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1666\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(A\u001b[38;5;241m.\u001b[39mshape) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m3\u001b[39m:\n\u001b[0;32m-> 1667\u001b[0m         out \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mempty\u001b[49m\u001b[43m(\u001b[49m\u001b[43msize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mA\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mA\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbout\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mA\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mA\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1668\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1669\u001b[0m         out \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mempty(size\u001b[38;5;241m=\u001b[39m(A\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m], bout), dtype\u001b[38;5;241m=\u001b[39mA\u001b[38;5;241m.\u001b[39mdtype, device\u001b[38;5;241m=\u001b[39mA\u001b[38;5;241m.\u001b[39mdevice)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "while source != target : \n",
    "    \n",
    "    print(f'Iteration : {iter_i}')\n",
    "    print(f'Source : {source}')\n",
    "    print(f'Target : {target}')\n",
    "    \n",
    "    #Prompt Model\n",
    "    prompt = format_agent_prompt(source, target, links)\n",
    "    prompt_tokenized = tokenizer([prompt],return_tensors = \"pt\").to(\"cuda\")\n",
    "    \n",
    "    #Extract output\n",
    "    out = (tokenizer.decode(ft_model.generate(**prompt_tokenized, max_new_tokens=30)[0], skip_special_tokens=True))\n",
    "    out_extracted = extract_output_from_prompt(out)\n",
    "    print(f'Model output : {out_extracted}')\n",
    "    print(f'Links : {links}')\n",
    "    \n",
    "    if (is_word_in_links(out_extracted ,links)) : \n",
    "        #If model chose a next_page among the one proposed\n",
    "        print(f'Model chose next_page among links, Next Page : {out_extracted}')\n",
    "        source = out_extracted.replace(' ','_')\n",
    "        links = links_from_source(page_name_links , source)\n",
    "        iter_i += 1 \n",
    "    else : \n",
    "        print(f'Model did not chose next_page among links')\n",
    "        break\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4ff9af8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_no_prompt[200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89367805",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (env2)",
   "language": "python",
   "name": "env2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
