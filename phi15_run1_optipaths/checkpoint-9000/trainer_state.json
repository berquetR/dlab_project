{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 1.8438844499078058,
  "eval_steps": 1000,
  "global_step": 9000,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.0,
      "grad_norm": 0.14801645278930664,
      "learning_rate": 4.000000000000001e-06,
      "loss": 2.1156,
      "step": 1
    },
    {
      "epoch": 0.0,
      "grad_norm": 0.13493788242340088,
      "learning_rate": 8.000000000000001e-06,
      "loss": 1.9722,
      "step": 2
    },
    {
      "epoch": 0.0,
      "grad_norm": 0.15431340038776398,
      "learning_rate": 1.2e-05,
      "loss": 1.9869,
      "step": 3
    },
    {
      "epoch": 0.0,
      "grad_norm": 0.16262447834014893,
      "learning_rate": 1.6000000000000003e-05,
      "loss": 2.1135,
      "step": 4
    },
    {
      "epoch": 0.0,
      "grad_norm": 0.17303526401519775,
      "learning_rate": 2e-05,
      "loss": 2.1664,
      "step": 5
    },
    {
      "epoch": 0.0,
      "grad_norm": 0.13639616966247559,
      "learning_rate": 1.9997950189607462e-05,
      "loss": 1.9903,
      "step": 6
    },
    {
      "epoch": 0.0,
      "grad_norm": 0.18173938989639282,
      "learning_rate": 1.9995900379214925e-05,
      "loss": 2.11,
      "step": 7
    },
    {
      "epoch": 0.0,
      "grad_norm": 0.14924438297748566,
      "learning_rate": 1.9993850568822386e-05,
      "loss": 2.0583,
      "step": 8
    },
    {
      "epoch": 0.0,
      "grad_norm": 0.13676227629184723,
      "learning_rate": 1.9991800758429846e-05,
      "loss": 2.0033,
      "step": 9
    },
    {
      "epoch": 0.0,
      "grad_norm": 0.16084697842597961,
      "learning_rate": 1.998975094803731e-05,
      "loss": 2.0674,
      "step": 10
    },
    {
      "epoch": 0.0,
      "grad_norm": 0.14938215911388397,
      "learning_rate": 1.998770113764477e-05,
      "loss": 2.1082,
      "step": 11
    },
    {
      "epoch": 0.0,
      "grad_norm": 0.17698830366134644,
      "learning_rate": 1.998565132725223e-05,
      "loss": 2.0683,
      "step": 12
    },
    {
      "epoch": 0.0,
      "grad_norm": 0.13263039290905,
      "learning_rate": 1.9983601516859693e-05,
      "loss": 1.9721,
      "step": 13
    },
    {
      "epoch": 0.0,
      "grad_norm": 0.16003204882144928,
      "learning_rate": 1.9981551706467153e-05,
      "loss": 2.0803,
      "step": 14
    },
    {
      "epoch": 0.0,
      "grad_norm": 0.17213737964630127,
      "learning_rate": 1.9979501896074617e-05,
      "loss": 2.1332,
      "step": 15
    },
    {
      "epoch": 0.0,
      "grad_norm": 0.16287054121494293,
      "learning_rate": 1.9977452085682077e-05,
      "loss": 2.0457,
      "step": 16
    },
    {
      "epoch": 0.0,
      "grad_norm": 0.15758869051933289,
      "learning_rate": 1.9975402275289537e-05,
      "loss": 2.0446,
      "step": 17
    },
    {
      "epoch": 0.0,
      "grad_norm": 0.1473529189825058,
      "learning_rate": 1.9973352464896997e-05,
      "loss": 2.027,
      "step": 18
    },
    {
      "epoch": 0.0,
      "grad_norm": 0.1683863401412964,
      "learning_rate": 1.997130265450446e-05,
      "loss": 2.0824,
      "step": 19
    },
    {
      "epoch": 0.0,
      "grad_norm": 0.1586163491010666,
      "learning_rate": 1.996925284411192e-05,
      "loss": 2.0198,
      "step": 20
    },
    {
      "epoch": 0.0,
      "grad_norm": 0.18549537658691406,
      "learning_rate": 1.996720303371938e-05,
      "loss": 2.1358,
      "step": 21
    },
    {
      "epoch": 0.0,
      "grad_norm": 0.14019063115119934,
      "learning_rate": 1.996515322332684e-05,
      "loss": 1.946,
      "step": 22
    },
    {
      "epoch": 0.0,
      "grad_norm": 0.1625114232301712,
      "learning_rate": 1.9963103412934305e-05,
      "loss": 2.0389,
      "step": 23
    },
    {
      "epoch": 0.0,
      "grad_norm": 0.1410573571920395,
      "learning_rate": 1.9961053602541765e-05,
      "loss": 1.8371,
      "step": 24
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.17715804278850555,
      "learning_rate": 1.995900379214923e-05,
      "loss": 2.0748,
      "step": 25
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.15705814957618713,
      "learning_rate": 1.995695398175669e-05,
      "loss": 1.9581,
      "step": 26
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.15306861698627472,
      "learning_rate": 1.9954904171364152e-05,
      "loss": 2.0346,
      "step": 27
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.16421838104724884,
      "learning_rate": 1.9952854360971612e-05,
      "loss": 1.9285,
      "step": 28
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.19836336374282837,
      "learning_rate": 1.9950804550579073e-05,
      "loss": 2.138,
      "step": 29
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.15860317647457123,
      "learning_rate": 1.9948754740186533e-05,
      "loss": 1.9731,
      "step": 30
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.13702386617660522,
      "learning_rate": 1.9946704929793996e-05,
      "loss": 1.8985,
      "step": 31
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.1636829376220703,
      "learning_rate": 1.9944655119401457e-05,
      "loss": 1.9295,
      "step": 32
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.1686127483844757,
      "learning_rate": 1.9942605309008917e-05,
      "loss": 1.9191,
      "step": 33
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.1804673671722412,
      "learning_rate": 1.9940555498616377e-05,
      "loss": 2.0491,
      "step": 34
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.16746807098388672,
      "learning_rate": 1.993850568822384e-05,
      "loss": 1.9798,
      "step": 35
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.16413995623588562,
      "learning_rate": 1.99364558778313e-05,
      "loss": 1.9326,
      "step": 36
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.1710110306739807,
      "learning_rate": 1.9934406067438764e-05,
      "loss": 1.8972,
      "step": 37
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.1396317183971405,
      "learning_rate": 1.9932356257046224e-05,
      "loss": 1.7885,
      "step": 38
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.1601867973804474,
      "learning_rate": 1.9930306446653688e-05,
      "loss": 1.9425,
      "step": 39
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.19330692291259766,
      "learning_rate": 1.9928256636261148e-05,
      "loss": 2.0239,
      "step": 40
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.16724620759487152,
      "learning_rate": 1.9926206825868608e-05,
      "loss": 1.9578,
      "step": 41
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.18211016058921814,
      "learning_rate": 1.992415701547607e-05,
      "loss": 2.0056,
      "step": 42
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.1630667746067047,
      "learning_rate": 1.9922107205083532e-05,
      "loss": 1.888,
      "step": 43
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.17010371387004852,
      "learning_rate": 1.9920057394690992e-05,
      "loss": 1.9167,
      "step": 44
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.18148313462734222,
      "learning_rate": 1.9918007584298452e-05,
      "loss": 1.9331,
      "step": 45
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.17127348482608795,
      "learning_rate": 1.9915957773905916e-05,
      "loss": 1.9477,
      "step": 46
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.19184516370296478,
      "learning_rate": 1.9913907963513376e-05,
      "loss": 1.9724,
      "step": 47
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.198837548494339,
      "learning_rate": 1.9911858153120836e-05,
      "loss": 2.0178,
      "step": 48
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.1623743772506714,
      "learning_rate": 1.99098083427283e-05,
      "loss": 1.8263,
      "step": 49
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.18465445935726166,
      "learning_rate": 1.990775853233576e-05,
      "loss": 1.9318,
      "step": 50
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.171209454536438,
      "learning_rate": 1.9905708721943223e-05,
      "loss": 1.7509,
      "step": 51
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.19016167521476746,
      "learning_rate": 1.9903658911550683e-05,
      "loss": 1.8727,
      "step": 52
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.18491792678833008,
      "learning_rate": 1.9901609101158144e-05,
      "loss": 1.8821,
      "step": 53
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.18468356132507324,
      "learning_rate": 1.9899559290765607e-05,
      "loss": 1.8937,
      "step": 54
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.21431516110897064,
      "learning_rate": 1.9897509480373067e-05,
      "loss": 1.9012,
      "step": 55
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.1696908175945282,
      "learning_rate": 1.9895459669980528e-05,
      "loss": 1.8271,
      "step": 56
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.18662254512310028,
      "learning_rate": 1.9893409859587988e-05,
      "loss": 1.8401,
      "step": 57
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.18320439755916595,
      "learning_rate": 1.989136004919545e-05,
      "loss": 1.861,
      "step": 58
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.18744365870952606,
      "learning_rate": 1.988931023880291e-05,
      "loss": 1.819,
      "step": 59
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.19097080826759338,
      "learning_rate": 1.988726042841037e-05,
      "loss": 1.8648,
      "step": 60
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.2096877545118332,
      "learning_rate": 1.9885210618017835e-05,
      "loss": 1.8725,
      "step": 61
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.1833464652299881,
      "learning_rate": 1.9883160807625295e-05,
      "loss": 1.8123,
      "step": 62
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.19815221428871155,
      "learning_rate": 1.988111099723276e-05,
      "loss": 1.8688,
      "step": 63
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.18720459938049316,
      "learning_rate": 1.987906118684022e-05,
      "loss": 1.7887,
      "step": 64
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.19058774411678314,
      "learning_rate": 1.9877011376447683e-05,
      "loss": 1.7693,
      "step": 65
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.2042541801929474,
      "learning_rate": 1.9874961566055143e-05,
      "loss": 1.7754,
      "step": 66
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.19555921852588654,
      "learning_rate": 1.9872911755662603e-05,
      "loss": 1.8329,
      "step": 67
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.23826687037944794,
      "learning_rate": 1.9870861945270063e-05,
      "loss": 1.8735,
      "step": 68
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.2317931056022644,
      "learning_rate": 1.9868812134877527e-05,
      "loss": 1.842,
      "step": 69
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.20384418964385986,
      "learning_rate": 1.9866762324484987e-05,
      "loss": 1.8198,
      "step": 70
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.1949259638786316,
      "learning_rate": 1.9864712514092447e-05,
      "loss": 1.7972,
      "step": 71
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.20163820683956146,
      "learning_rate": 1.9862662703699907e-05,
      "loss": 1.7857,
      "step": 72
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.21081550419330597,
      "learning_rate": 1.986061289330737e-05,
      "loss": 1.7535,
      "step": 73
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.21124212443828583,
      "learning_rate": 1.985856308291483e-05,
      "loss": 1.8161,
      "step": 74
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.2058476358652115,
      "learning_rate": 1.9856513272522294e-05,
      "loss": 1.755,
      "step": 75
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.18506187200546265,
      "learning_rate": 1.9854463462129754e-05,
      "loss": 1.7332,
      "step": 76
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.2168685644865036,
      "learning_rate": 1.9852413651737218e-05,
      "loss": 1.6861,
      "step": 77
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.21537922322750092,
      "learning_rate": 1.9850363841344678e-05,
      "loss": 1.7469,
      "step": 78
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.2310929298400879,
      "learning_rate": 1.984831403095214e-05,
      "loss": 1.7004,
      "step": 79
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.20755332708358765,
      "learning_rate": 1.98462642205596e-05,
      "loss": 1.6774,
      "step": 80
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.24066269397735596,
      "learning_rate": 1.9844214410167062e-05,
      "loss": 1.7278,
      "step": 81
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.28124022483825684,
      "learning_rate": 1.9842164599774522e-05,
      "loss": 1.77,
      "step": 82
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.24270261824131012,
      "learning_rate": 1.9840114789381982e-05,
      "loss": 1.7361,
      "step": 83
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.24854214489459991,
      "learning_rate": 1.9838064978989443e-05,
      "loss": 1.7097,
      "step": 84
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.22556163370609283,
      "learning_rate": 1.9836015168596906e-05,
      "loss": 1.6638,
      "step": 85
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.2117660939693451,
      "learning_rate": 1.9833965358204366e-05,
      "loss": 1.6118,
      "step": 86
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.20034928619861603,
      "learning_rate": 1.983191554781183e-05,
      "loss": 1.5845,
      "step": 87
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.2204093635082245,
      "learning_rate": 1.982986573741929e-05,
      "loss": 1.6252,
      "step": 88
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.20167583227157593,
      "learning_rate": 1.9827815927026754e-05,
      "loss": 1.6278,
      "step": 89
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.21437273919582367,
      "learning_rate": 1.9825766116634214e-05,
      "loss": 1.6432,
      "step": 90
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.2567161023616791,
      "learning_rate": 1.9823716306241674e-05,
      "loss": 1.6778,
      "step": 91
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.25239065289497375,
      "learning_rate": 1.9821666495849134e-05,
      "loss": 1.5851,
      "step": 92
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.25855380296707153,
      "learning_rate": 1.9819616685456598e-05,
      "loss": 1.5773,
      "step": 93
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.257782518863678,
      "learning_rate": 1.9817566875064058e-05,
      "loss": 1.6409,
      "step": 94
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.22905093431472778,
      "learning_rate": 1.9815517064671518e-05,
      "loss": 1.6085,
      "step": 95
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.2462063729763031,
      "learning_rate": 1.981346725427898e-05,
      "loss": 1.6255,
      "step": 96
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.26769962906837463,
      "learning_rate": 1.981141744388644e-05,
      "loss": 1.5624,
      "step": 97
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.2332739233970642,
      "learning_rate": 1.9809367633493902e-05,
      "loss": 1.5514,
      "step": 98
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.25260525941848755,
      "learning_rate": 1.9807317823101365e-05,
      "loss": 1.4679,
      "step": 99
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.29149627685546875,
      "learning_rate": 1.9805268012708825e-05,
      "loss": 1.5599,
      "step": 100
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.27089405059814453,
      "learning_rate": 1.980321820231629e-05,
      "loss": 1.6006,
      "step": 101
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.32050687074661255,
      "learning_rate": 1.980116839192375e-05,
      "loss": 1.5926,
      "step": 102
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.27958133816719055,
      "learning_rate": 1.979911858153121e-05,
      "loss": 1.5207,
      "step": 103
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.37188512086868286,
      "learning_rate": 1.9797068771138673e-05,
      "loss": 1.5203,
      "step": 104
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.32037055492401123,
      "learning_rate": 1.9795018960746133e-05,
      "loss": 1.4723,
      "step": 105
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.30734193325042725,
      "learning_rate": 1.9792969150353593e-05,
      "loss": 1.4439,
      "step": 106
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.3082571029663086,
      "learning_rate": 1.9790919339961053e-05,
      "loss": 1.5258,
      "step": 107
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.32039952278137207,
      "learning_rate": 1.9788869529568517e-05,
      "loss": 1.4197,
      "step": 108
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.4001242220401764,
      "learning_rate": 1.9786819719175977e-05,
      "loss": 1.4193,
      "step": 109
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.4055688977241516,
      "learning_rate": 1.9784769908783437e-05,
      "loss": 1.4226,
      "step": 110
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.33153218030929565,
      "learning_rate": 1.97827200983909e-05,
      "loss": 1.4295,
      "step": 111
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.35445675253868103,
      "learning_rate": 1.978067028799836e-05,
      "loss": 1.3796,
      "step": 112
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.40358075499534607,
      "learning_rate": 1.9778620477605825e-05,
      "loss": 1.4212,
      "step": 113
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.32602494955062866,
      "learning_rate": 1.9776570667213285e-05,
      "loss": 1.3807,
      "step": 114
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.3186560869216919,
      "learning_rate": 1.9774520856820745e-05,
      "loss": 1.3732,
      "step": 115
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.3246791958808899,
      "learning_rate": 1.977247104642821e-05,
      "loss": 1.4181,
      "step": 116
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.34996339678764343,
      "learning_rate": 1.977042123603567e-05,
      "loss": 1.2769,
      "step": 117
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.36430859565734863,
      "learning_rate": 1.976837142564313e-05,
      "loss": 1.3138,
      "step": 118
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.3703325092792511,
      "learning_rate": 1.976632161525059e-05,
      "loss": 1.258,
      "step": 119
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.32558107376098633,
      "learning_rate": 1.9764271804858052e-05,
      "loss": 1.3301,
      "step": 120
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.29304394125938416,
      "learning_rate": 1.9762221994465513e-05,
      "loss": 1.285,
      "step": 121
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.3146601915359497,
      "learning_rate": 1.9760172184072973e-05,
      "loss": 1.2781,
      "step": 122
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.32576581835746765,
      "learning_rate": 1.9758122373680436e-05,
      "loss": 1.332,
      "step": 123
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.3251970410346985,
      "learning_rate": 1.9756072563287896e-05,
      "loss": 1.204,
      "step": 124
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.2914409637451172,
      "learning_rate": 1.975402275289536e-05,
      "loss": 1.3544,
      "step": 125
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.28793925046920776,
      "learning_rate": 1.975197294250282e-05,
      "loss": 1.2734,
      "step": 126
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.34051278233528137,
      "learning_rate": 1.9749923132110284e-05,
      "loss": 1.1765,
      "step": 127
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.33435994386672974,
      "learning_rate": 1.9747873321717744e-05,
      "loss": 1.1906,
      "step": 128
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.2535462975502014,
      "learning_rate": 1.9745823511325204e-05,
      "loss": 1.2022,
      "step": 129
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.29028981924057007,
      "learning_rate": 1.9743773700932664e-05,
      "loss": 1.1626,
      "step": 130
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.3011995255947113,
      "learning_rate": 1.9741723890540128e-05,
      "loss": 1.1972,
      "step": 131
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.37259697914123535,
      "learning_rate": 1.9739674080147588e-05,
      "loss": 1.0717,
      "step": 132
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.2607201039791107,
      "learning_rate": 1.9737624269755048e-05,
      "loss": 1.1827,
      "step": 133
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.33192381262779236,
      "learning_rate": 1.9735574459362508e-05,
      "loss": 1.1224,
      "step": 134
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.3566271662712097,
      "learning_rate": 1.9733524648969972e-05,
      "loss": 1.0128,
      "step": 135
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.291311651468277,
      "learning_rate": 1.9731474838577432e-05,
      "loss": 1.1411,
      "step": 136
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.2526525557041168,
      "learning_rate": 1.9729425028184896e-05,
      "loss": 1.1177,
      "step": 137
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.26152029633522034,
      "learning_rate": 1.9727375217792356e-05,
      "loss": 1.1124,
      "step": 138
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.2161748707294464,
      "learning_rate": 1.972532540739982e-05,
      "loss": 1.2616,
      "step": 139
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.24315319955348969,
      "learning_rate": 1.972327559700728e-05,
      "loss": 1.0818,
      "step": 140
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.271156370639801,
      "learning_rate": 1.972122578661474e-05,
      "loss": 1.063,
      "step": 141
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.2510625123977661,
      "learning_rate": 1.97191759762222e-05,
      "loss": 0.989,
      "step": 142
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.22746270895004272,
      "learning_rate": 1.9717126165829663e-05,
      "loss": 1.0095,
      "step": 143
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.20309670269489288,
      "learning_rate": 1.9715076355437123e-05,
      "loss": 1.0417,
      "step": 144
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.1951362043619156,
      "learning_rate": 1.9713026545044584e-05,
      "loss": 1.0915,
      "step": 145
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.19874995946884155,
      "learning_rate": 1.9710976734652044e-05,
      "loss": 0.9936,
      "step": 146
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.20301520824432373,
      "learning_rate": 1.9708926924259507e-05,
      "loss": 0.9756,
      "step": 147
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.2011939138174057,
      "learning_rate": 1.9706877113866967e-05,
      "loss": 1.0198,
      "step": 148
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.18404176831245422,
      "learning_rate": 1.970482730347443e-05,
      "loss": 0.9893,
      "step": 149
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.17462767660617828,
      "learning_rate": 1.970277749308189e-05,
      "loss": 0.9749,
      "step": 150
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.20576846599578857,
      "learning_rate": 1.9700727682689355e-05,
      "loss": 0.8421,
      "step": 151
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.16285865008831024,
      "learning_rate": 1.9698677872296815e-05,
      "loss": 1.0332,
      "step": 152
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.14744864404201508,
      "learning_rate": 1.9696628061904275e-05,
      "loss": 1.0171,
      "step": 153
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.17768371105194092,
      "learning_rate": 1.969457825151174e-05,
      "loss": 0.9148,
      "step": 154
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.14266695082187653,
      "learning_rate": 1.96925284411192e-05,
      "loss": 0.9444,
      "step": 155
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.14746293425559998,
      "learning_rate": 1.969047863072666e-05,
      "loss": 0.9451,
      "step": 156
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.14510703086853027,
      "learning_rate": 1.968842882033412e-05,
      "loss": 0.9607,
      "step": 157
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.12286745011806488,
      "learning_rate": 1.9686379009941583e-05,
      "loss": 0.9804,
      "step": 158
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.15423738956451416,
      "learning_rate": 1.9684329199549043e-05,
      "loss": 0.9945,
      "step": 159
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.1409735530614853,
      "learning_rate": 1.9682279389156503e-05,
      "loss": 0.9481,
      "step": 160
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.12786269187927246,
      "learning_rate": 1.9680229578763967e-05,
      "loss": 1.0268,
      "step": 161
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.1277569830417633,
      "learning_rate": 1.9678179768371427e-05,
      "loss": 0.9584,
      "step": 162
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.1338379830121994,
      "learning_rate": 1.967612995797889e-05,
      "loss": 0.8752,
      "step": 163
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.1174040362238884,
      "learning_rate": 1.967408014758635e-05,
      "loss": 0.9657,
      "step": 164
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.11389858275651932,
      "learning_rate": 1.967203033719381e-05,
      "loss": 0.96,
      "step": 165
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.12520524859428406,
      "learning_rate": 1.9669980526801274e-05,
      "loss": 0.981,
      "step": 166
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.11895885318517685,
      "learning_rate": 1.9667930716408734e-05,
      "loss": 0.987,
      "step": 167
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.1287764608860016,
      "learning_rate": 1.9665880906016194e-05,
      "loss": 0.9839,
      "step": 168
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.1140211746096611,
      "learning_rate": 1.9663831095623655e-05,
      "loss": 0.9523,
      "step": 169
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.11723394691944122,
      "learning_rate": 1.9661781285231118e-05,
      "loss": 0.991,
      "step": 170
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.11477658897638321,
      "learning_rate": 1.965973147483858e-05,
      "loss": 0.9453,
      "step": 171
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.11470630764961243,
      "learning_rate": 1.965768166444604e-05,
      "loss": 0.9478,
      "step": 172
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.1085997223854065,
      "learning_rate": 1.9655631854053502e-05,
      "loss": 0.9989,
      "step": 173
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.11751675605773926,
      "learning_rate": 1.9653582043660962e-05,
      "loss": 0.9819,
      "step": 174
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.1253792643547058,
      "learning_rate": 1.9651532233268426e-05,
      "loss": 0.9512,
      "step": 175
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.1224038153886795,
      "learning_rate": 1.9649482422875886e-05,
      "loss": 0.8852,
      "step": 176
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.11550460755825043,
      "learning_rate": 1.9647432612483346e-05,
      "loss": 0.9893,
      "step": 177
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.11173273622989655,
      "learning_rate": 1.964538280209081e-05,
      "loss": 1.0019,
      "step": 178
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.11439226567745209,
      "learning_rate": 1.964333299169827e-05,
      "loss": 0.9285,
      "step": 179
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.12082788348197937,
      "learning_rate": 1.964128318130573e-05,
      "loss": 0.919,
      "step": 180
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.10875578224658966,
      "learning_rate": 1.963923337091319e-05,
      "loss": 1.0091,
      "step": 181
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.11381158977746964,
      "learning_rate": 1.9637183560520654e-05,
      "loss": 0.906,
      "step": 182
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.11693225055932999,
      "learning_rate": 1.9635133750128114e-05,
      "loss": 0.9262,
      "step": 183
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.11422082781791687,
      "learning_rate": 1.9633083939735574e-05,
      "loss": 0.9747,
      "step": 184
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.1133032888174057,
      "learning_rate": 1.9631034129343038e-05,
      "loss": 0.8995,
      "step": 185
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.11655422300100327,
      "learning_rate": 1.9628984318950498e-05,
      "loss": 0.9179,
      "step": 186
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.10629011690616608,
      "learning_rate": 1.962693450855796e-05,
      "loss": 1.0306,
      "step": 187
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.11696868389844894,
      "learning_rate": 1.962488469816542e-05,
      "loss": 0.915,
      "step": 188
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.1107262670993805,
      "learning_rate": 1.9622834887772885e-05,
      "loss": 0.9786,
      "step": 189
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.10548517107963562,
      "learning_rate": 1.9620785077380345e-05,
      "loss": 1.015,
      "step": 190
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.10317640751600266,
      "learning_rate": 1.9618735266987805e-05,
      "loss": 1.0508,
      "step": 191
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.11294328421354294,
      "learning_rate": 1.9616685456595265e-05,
      "loss": 0.9257,
      "step": 192
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.11201515793800354,
      "learning_rate": 1.961463564620273e-05,
      "loss": 0.9707,
      "step": 193
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.12294746190309525,
      "learning_rate": 1.961258583581019e-05,
      "loss": 0.8474,
      "step": 194
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.1048453152179718,
      "learning_rate": 1.961053602541765e-05,
      "loss": 0.9455,
      "step": 195
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.110934779047966,
      "learning_rate": 1.960848621502511e-05,
      "loss": 1.0264,
      "step": 196
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.10872286558151245,
      "learning_rate": 1.9606436404632573e-05,
      "loss": 0.9653,
      "step": 197
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.11702096462249756,
      "learning_rate": 1.9604386594240033e-05,
      "loss": 0.9578,
      "step": 198
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.11133939027786255,
      "learning_rate": 1.9602336783847497e-05,
      "loss": 0.9719,
      "step": 199
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.10960347205400467,
      "learning_rate": 1.9600286973454957e-05,
      "loss": 0.9638,
      "step": 200
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.12970641255378723,
      "learning_rate": 1.959823716306242e-05,
      "loss": 0.8593,
      "step": 201
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.11129017919301987,
      "learning_rate": 1.959618735266988e-05,
      "loss": 0.8625,
      "step": 202
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.12882918119430542,
      "learning_rate": 1.959413754227734e-05,
      "loss": 0.88,
      "step": 203
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.11775669455528259,
      "learning_rate": 1.95920877318848e-05,
      "loss": 0.88,
      "step": 204
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.11505789309740067,
      "learning_rate": 1.9590037921492264e-05,
      "loss": 0.9223,
      "step": 205
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.11349492520093918,
      "learning_rate": 1.9587988111099725e-05,
      "loss": 0.8141,
      "step": 206
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.10728686302900314,
      "learning_rate": 1.9585938300707185e-05,
      "loss": 0.9842,
      "step": 207
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.11916619539260864,
      "learning_rate": 1.9583888490314645e-05,
      "loss": 1.0015,
      "step": 208
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.11149190366268158,
      "learning_rate": 1.958183867992211e-05,
      "loss": 0.8548,
      "step": 209
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.1223873645067215,
      "learning_rate": 1.957978886952957e-05,
      "loss": 0.8721,
      "step": 210
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.10712231695652008,
      "learning_rate": 1.9577739059137032e-05,
      "loss": 0.9053,
      "step": 211
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.1161237582564354,
      "learning_rate": 1.9575689248744492e-05,
      "loss": 0.9305,
      "step": 212
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.10267391800880432,
      "learning_rate": 1.9573639438351956e-05,
      "loss": 0.9361,
      "step": 213
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.10983920097351074,
      "learning_rate": 1.9571589627959416e-05,
      "loss": 0.9442,
      "step": 214
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.12621043622493744,
      "learning_rate": 1.9569539817566876e-05,
      "loss": 0.8717,
      "step": 215
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.11078941076993942,
      "learning_rate": 1.956749000717434e-05,
      "loss": 0.9833,
      "step": 216
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.11060511320829391,
      "learning_rate": 1.95654401967818e-05,
      "loss": 0.975,
      "step": 217
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.11653444916009903,
      "learning_rate": 1.956339038638926e-05,
      "loss": 0.9077,
      "step": 218
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.1080295518040657,
      "learning_rate": 1.956134057599672e-05,
      "loss": 0.9326,
      "step": 219
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.12118266522884369,
      "learning_rate": 1.9559290765604184e-05,
      "loss": 0.8783,
      "step": 220
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.12586797773838043,
      "learning_rate": 1.9557240955211644e-05,
      "loss": 0.7879,
      "step": 221
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.1107342541217804,
      "learning_rate": 1.9555191144819104e-05,
      "loss": 0.9581,
      "step": 222
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.11808457970619202,
      "learning_rate": 1.9553141334426568e-05,
      "loss": 1.0065,
      "step": 223
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.11437413841485977,
      "learning_rate": 1.9551091524034028e-05,
      "loss": 1.0117,
      "step": 224
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.11293333768844604,
      "learning_rate": 1.954904171364149e-05,
      "loss": 0.9254,
      "step": 225
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.11271843314170837,
      "learning_rate": 1.954699190324895e-05,
      "loss": 0.9613,
      "step": 226
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.12039729952812195,
      "learning_rate": 1.9544942092856412e-05,
      "loss": 0.8398,
      "step": 227
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.12387534230947495,
      "learning_rate": 1.9542892282463875e-05,
      "loss": 0.9295,
      "step": 228
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.11054776608943939,
      "learning_rate": 1.9540842472071335e-05,
      "loss": 0.9387,
      "step": 229
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.11459952592849731,
      "learning_rate": 1.9538792661678796e-05,
      "loss": 0.9167,
      "step": 230
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.11788316816091537,
      "learning_rate": 1.9536742851286256e-05,
      "loss": 0.7641,
      "step": 231
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.11313901841640472,
      "learning_rate": 1.953469304089372e-05,
      "loss": 0.9054,
      "step": 232
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.10994742810726166,
      "learning_rate": 1.953264323050118e-05,
      "loss": 0.8754,
      "step": 233
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.10773077607154846,
      "learning_rate": 1.953059342010864e-05,
      "loss": 0.9426,
      "step": 234
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.10124799609184265,
      "learning_rate": 1.9528543609716103e-05,
      "loss": 0.9652,
      "step": 235
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.11278689652681351,
      "learning_rate": 1.9526493799323563e-05,
      "loss": 0.9142,
      "step": 236
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.1191551610827446,
      "learning_rate": 1.9524443988931027e-05,
      "loss": 0.886,
      "step": 237
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.12041749805212021,
      "learning_rate": 1.9522394178538487e-05,
      "loss": 0.9696,
      "step": 238
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.12373056262731552,
      "learning_rate": 1.9520344368145947e-05,
      "loss": 0.8643,
      "step": 239
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.10807184129953384,
      "learning_rate": 1.951829455775341e-05,
      "loss": 0.9088,
      "step": 240
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.10628893226385117,
      "learning_rate": 1.951624474736087e-05,
      "loss": 0.7853,
      "step": 241
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.10586827248334885,
      "learning_rate": 1.951419493696833e-05,
      "loss": 0.8618,
      "step": 242
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.10110622644424438,
      "learning_rate": 1.9512145126575795e-05,
      "loss": 1.0064,
      "step": 243
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.1106470599770546,
      "learning_rate": 1.9510095316183255e-05,
      "loss": 0.9826,
      "step": 244
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.10830700397491455,
      "learning_rate": 1.9508045505790715e-05,
      "loss": 0.7897,
      "step": 245
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.11630983650684357,
      "learning_rate": 1.9505995695398175e-05,
      "loss": 0.8729,
      "step": 246
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.10370375216007233,
      "learning_rate": 1.950394588500564e-05,
      "loss": 0.8206,
      "step": 247
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.10259199887514114,
      "learning_rate": 1.95018960746131e-05,
      "loss": 0.8949,
      "step": 248
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.1160779595375061,
      "learning_rate": 1.9499846264220562e-05,
      "loss": 0.9293,
      "step": 249
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.13695336878299713,
      "learning_rate": 1.9497796453828023e-05,
      "loss": 0.934,
      "step": 250
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.10347066819667816,
      "learning_rate": 1.9495746643435486e-05,
      "loss": 0.9335,
      "step": 251
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.1043834313750267,
      "learning_rate": 1.9493696833042946e-05,
      "loss": 0.8712,
      "step": 252
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.11564145237207413,
      "learning_rate": 1.9491647022650407e-05,
      "loss": 0.9823,
      "step": 253
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.11040244251489639,
      "learning_rate": 1.9489597212257867e-05,
      "loss": 0.9065,
      "step": 254
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.11539418250322342,
      "learning_rate": 1.948754740186533e-05,
      "loss": 0.8888,
      "step": 255
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.11019538342952728,
      "learning_rate": 1.948549759147279e-05,
      "loss": 0.9072,
      "step": 256
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.10494827479124069,
      "learning_rate": 1.948344778108025e-05,
      "loss": 0.9444,
      "step": 257
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.12025714665651321,
      "learning_rate": 1.948139797068771e-05,
      "loss": 0.8477,
      "step": 258
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.10517946630716324,
      "learning_rate": 1.9479348160295174e-05,
      "loss": 0.9468,
      "step": 259
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.10923108458518982,
      "learning_rate": 1.9477298349902634e-05,
      "loss": 0.9021,
      "step": 260
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.11453501880168915,
      "learning_rate": 1.9475248539510098e-05,
      "loss": 0.8489,
      "step": 261
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.11054644733667374,
      "learning_rate": 1.9473198729117558e-05,
      "loss": 1.0493,
      "step": 262
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.1404528021812439,
      "learning_rate": 1.947114891872502e-05,
      "loss": 0.7825,
      "step": 263
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.1030016839504242,
      "learning_rate": 1.9469099108332482e-05,
      "loss": 1.0164,
      "step": 264
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.1058816984295845,
      "learning_rate": 1.9467049297939942e-05,
      "loss": 0.8815,
      "step": 265
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.13101057708263397,
      "learning_rate": 1.9464999487547402e-05,
      "loss": 0.9684,
      "step": 266
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.11438069492578506,
      "learning_rate": 1.9462949677154866e-05,
      "loss": 0.829,
      "step": 267
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.12294495850801468,
      "learning_rate": 1.9460899866762326e-05,
      "loss": 0.9288,
      "step": 268
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.11855403333902359,
      "learning_rate": 1.9458850056369786e-05,
      "loss": 0.8787,
      "step": 269
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.12912406027317047,
      "learning_rate": 1.9456800245977246e-05,
      "loss": 0.873,
      "step": 270
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.10353491455316544,
      "learning_rate": 1.945475043558471e-05,
      "loss": 1.0211,
      "step": 271
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.10573985427618027,
      "learning_rate": 1.945270062519217e-05,
      "loss": 0.837,
      "step": 272
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.1281924545764923,
      "learning_rate": 1.9450650814799633e-05,
      "loss": 0.8037,
      "step": 273
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.12173116207122803,
      "learning_rate": 1.9448601004407094e-05,
      "loss": 0.8795,
      "step": 274
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.12658721208572388,
      "learning_rate": 1.9446551194014557e-05,
      "loss": 0.8383,
      "step": 275
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.11864066869020462,
      "learning_rate": 1.9444501383622017e-05,
      "loss": 0.9236,
      "step": 276
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.11576711386442184,
      "learning_rate": 1.9442451573229478e-05,
      "loss": 0.8528,
      "step": 277
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.10368352383375168,
      "learning_rate": 1.944040176283694e-05,
      "loss": 0.8491,
      "step": 278
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.11558093130588531,
      "learning_rate": 1.94383519524444e-05,
      "loss": 0.8999,
      "step": 279
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.12087540328502655,
      "learning_rate": 1.943630214205186e-05,
      "loss": 0.8675,
      "step": 280
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.10626393556594849,
      "learning_rate": 1.943425233165932e-05,
      "loss": 0.9382,
      "step": 281
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.10891518741846085,
      "learning_rate": 1.9432202521266785e-05,
      "loss": 0.8523,
      "step": 282
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.1174779161810875,
      "learning_rate": 1.9430152710874245e-05,
      "loss": 0.8653,
      "step": 283
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.1285378336906433,
      "learning_rate": 1.9428102900481705e-05,
      "loss": 0.8948,
      "step": 284
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.11372309178113937,
      "learning_rate": 1.942605309008917e-05,
      "loss": 0.8568,
      "step": 285
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.11427725106477737,
      "learning_rate": 1.942400327969663e-05,
      "loss": 0.8225,
      "step": 286
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.14900687336921692,
      "learning_rate": 1.9421953469304093e-05,
      "loss": 1.0323,
      "step": 287
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.11896420270204544,
      "learning_rate": 1.9419903658911553e-05,
      "loss": 0.8158,
      "step": 288
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.1303885281085968,
      "learning_rate": 1.9417853848519013e-05,
      "loss": 0.8579,
      "step": 289
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.12143409997224808,
      "learning_rate": 1.9415804038126477e-05,
      "loss": 0.8813,
      "step": 290
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.11280457675457001,
      "learning_rate": 1.9413754227733937e-05,
      "loss": 0.9227,
      "step": 291
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.11012837290763855,
      "learning_rate": 1.9411704417341397e-05,
      "loss": 0.9447,
      "step": 292
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.1120828315615654,
      "learning_rate": 1.9409654606948857e-05,
      "loss": 0.896,
      "step": 293
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.11666925251483917,
      "learning_rate": 1.940760479655632e-05,
      "loss": 0.7973,
      "step": 294
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.11904400587081909,
      "learning_rate": 1.940555498616378e-05,
      "loss": 0.8774,
      "step": 295
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.12668779492378235,
      "learning_rate": 1.940350517577124e-05,
      "loss": 0.8129,
      "step": 296
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.1139235869050026,
      "learning_rate": 1.9401455365378704e-05,
      "loss": 0.8645,
      "step": 297
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.12778016924858093,
      "learning_rate": 1.9399405554986165e-05,
      "loss": 0.8534,
      "step": 298
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.11882112175226212,
      "learning_rate": 1.9397355744593628e-05,
      "loss": 0.8941,
      "step": 299
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.12609803676605225,
      "learning_rate": 1.939530593420109e-05,
      "loss": 0.8019,
      "step": 300
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.13944514095783234,
      "learning_rate": 1.9393256123808552e-05,
      "loss": 0.8536,
      "step": 301
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.11209560185670853,
      "learning_rate": 1.9391206313416012e-05,
      "loss": 0.8875,
      "step": 302
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.1324322521686554,
      "learning_rate": 1.9389156503023472e-05,
      "loss": 0.7377,
      "step": 303
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.12412051111459732,
      "learning_rate": 1.9387106692630932e-05,
      "loss": 0.8199,
      "step": 304
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.11850414425134659,
      "learning_rate": 1.9385056882238396e-05,
      "loss": 0.8796,
      "step": 305
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.1256149560213089,
      "learning_rate": 1.9383007071845856e-05,
      "loss": 0.6658,
      "step": 306
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.11698953807353973,
      "learning_rate": 1.9380957261453316e-05,
      "loss": 0.7866,
      "step": 307
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.10981995612382889,
      "learning_rate": 1.9378907451060776e-05,
      "loss": 0.8674,
      "step": 308
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.12847840785980225,
      "learning_rate": 1.937685764066824e-05,
      "loss": 0.8973,
      "step": 309
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.13614852726459503,
      "learning_rate": 1.93748078302757e-05,
      "loss": 0.7349,
      "step": 310
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.12398331612348557,
      "learning_rate": 1.9372758019883164e-05,
      "loss": 0.8766,
      "step": 311
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.13640139997005463,
      "learning_rate": 1.9370708209490624e-05,
      "loss": 0.8962,
      "step": 312
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.11832497268915176,
      "learning_rate": 1.9368658399098087e-05,
      "loss": 0.9397,
      "step": 313
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.12573650479316711,
      "learning_rate": 1.9366608588705548e-05,
      "loss": 0.923,
      "step": 314
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.1262044608592987,
      "learning_rate": 1.9364558778313008e-05,
      "loss": 0.8252,
      "step": 315
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.1605004370212555,
      "learning_rate": 1.9362508967920468e-05,
      "loss": 0.8256,
      "step": 316
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.12002827972173691,
      "learning_rate": 1.936045915752793e-05,
      "loss": 0.743,
      "step": 317
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.12373246997594833,
      "learning_rate": 1.935840934713539e-05,
      "loss": 0.921,
      "step": 318
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.1096058115363121,
      "learning_rate": 1.9356359536742852e-05,
      "loss": 0.9311,
      "step": 319
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.12669838964939117,
      "learning_rate": 1.9354309726350312e-05,
      "loss": 0.9184,
      "step": 320
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.12685614824295044,
      "learning_rate": 1.9352259915957775e-05,
      "loss": 0.9086,
      "step": 321
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.15060833096504211,
      "learning_rate": 1.9350210105565236e-05,
      "loss": 0.8455,
      "step": 322
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.12823501229286194,
      "learning_rate": 1.93481602951727e-05,
      "loss": 0.8519,
      "step": 323
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.15130478143692017,
      "learning_rate": 1.934611048478016e-05,
      "loss": 0.7808,
      "step": 324
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.1281290203332901,
      "learning_rate": 1.9344060674387623e-05,
      "loss": 0.8036,
      "step": 325
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.11920052021741867,
      "learning_rate": 1.9342010863995083e-05,
      "loss": 0.9598,
      "step": 326
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.15807418525218964,
      "learning_rate": 1.9339961053602543e-05,
      "loss": 0.9132,
      "step": 327
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.13564768433570862,
      "learning_rate": 1.9337911243210003e-05,
      "loss": 0.9276,
      "step": 328
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.1396510750055313,
      "learning_rate": 1.9335861432817467e-05,
      "loss": 0.8934,
      "step": 329
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.13453885912895203,
      "learning_rate": 1.9333811622424927e-05,
      "loss": 0.8175,
      "step": 330
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.14032770693302155,
      "learning_rate": 1.9331761812032387e-05,
      "loss": 0.8741,
      "step": 331
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.14800895750522614,
      "learning_rate": 1.932971200163985e-05,
      "loss": 0.8674,
      "step": 332
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.1407247930765152,
      "learning_rate": 1.932766219124731e-05,
      "loss": 0.8784,
      "step": 333
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.1337730884552002,
      "learning_rate": 1.932561238085477e-05,
      "loss": 0.8722,
      "step": 334
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.14591968059539795,
      "learning_rate": 1.9323562570462235e-05,
      "loss": 0.8804,
      "step": 335
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.1397637575864792,
      "learning_rate": 1.9321512760069695e-05,
      "loss": 0.8626,
      "step": 336
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.1251293420791626,
      "learning_rate": 1.931946294967716e-05,
      "loss": 0.8343,
      "step": 337
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.14307206869125366,
      "learning_rate": 1.931741313928462e-05,
      "loss": 0.777,
      "step": 338
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.1107073500752449,
      "learning_rate": 1.931536332889208e-05,
      "loss": 0.894,
      "step": 339
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.12038864195346832,
      "learning_rate": 1.9313313518499542e-05,
      "loss": 0.8864,
      "step": 340
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.16119475662708282,
      "learning_rate": 1.9311263708107002e-05,
      "loss": 0.8488,
      "step": 341
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.14547263085842133,
      "learning_rate": 1.9309213897714463e-05,
      "loss": 0.9148,
      "step": 342
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.15499764680862427,
      "learning_rate": 1.9307164087321923e-05,
      "loss": 0.8858,
      "step": 343
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.121903195977211,
      "learning_rate": 1.9305114276929386e-05,
      "loss": 0.8409,
      "step": 344
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.13624075055122375,
      "learning_rate": 1.9303064466536846e-05,
      "loss": 0.8539,
      "step": 345
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.1289665848016739,
      "learning_rate": 1.9301014656144307e-05,
      "loss": 0.8972,
      "step": 346
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.14455804228782654,
      "learning_rate": 1.929896484575177e-05,
      "loss": 0.919,
      "step": 347
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.12730561196804047,
      "learning_rate": 1.929691503535923e-05,
      "loss": 0.9478,
      "step": 348
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.12746407091617584,
      "learning_rate": 1.9294865224966694e-05,
      "loss": 0.7405,
      "step": 349
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.1674691140651703,
      "learning_rate": 1.9292815414574154e-05,
      "loss": 0.8102,
      "step": 350
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.13995179533958435,
      "learning_rate": 1.9290765604181614e-05,
      "loss": 0.8215,
      "step": 351
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.14159509539604187,
      "learning_rate": 1.9288715793789078e-05,
      "loss": 0.8792,
      "step": 352
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.1344442367553711,
      "learning_rate": 1.9286665983396538e-05,
      "loss": 0.9716,
      "step": 353
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.15604564547538757,
      "learning_rate": 1.9284616173003998e-05,
      "loss": 0.8704,
      "step": 354
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.13720914721488953,
      "learning_rate": 1.9282566362611458e-05,
      "loss": 0.8326,
      "step": 355
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.14227120578289032,
      "learning_rate": 1.9280516552218922e-05,
      "loss": 0.8952,
      "step": 356
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.1455276608467102,
      "learning_rate": 1.9278466741826382e-05,
      "loss": 0.8903,
      "step": 357
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.13401660323143005,
      "learning_rate": 1.9276416931433842e-05,
      "loss": 0.8469,
      "step": 358
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.14276866614818573,
      "learning_rate": 1.9274367121041306e-05,
      "loss": 0.7735,
      "step": 359
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.13018949329853058,
      "learning_rate": 1.9272317310648766e-05,
      "loss": 0.9203,
      "step": 360
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.13455694913864136,
      "learning_rate": 1.927026750025623e-05,
      "loss": 0.8779,
      "step": 361
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.13384974002838135,
      "learning_rate": 1.926821768986369e-05,
      "loss": 0.8124,
      "step": 362
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.13184615969657898,
      "learning_rate": 1.9266167879471153e-05,
      "loss": 0.864,
      "step": 363
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.1454877406358719,
      "learning_rate": 1.9264118069078613e-05,
      "loss": 0.9136,
      "step": 364
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.14314337074756622,
      "learning_rate": 1.9262068258686073e-05,
      "loss": 0.8445,
      "step": 365
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.15504486858844757,
      "learning_rate": 1.9260018448293534e-05,
      "loss": 0.8873,
      "step": 366
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.1319129317998886,
      "learning_rate": 1.9257968637900997e-05,
      "loss": 0.8366,
      "step": 367
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.14638902246952057,
      "learning_rate": 1.9255918827508457e-05,
      "loss": 0.9188,
      "step": 368
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.1454022377729416,
      "learning_rate": 1.9253869017115917e-05,
      "loss": 0.8128,
      "step": 369
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.15703995525836945,
      "learning_rate": 1.9251819206723378e-05,
      "loss": 0.8067,
      "step": 370
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.14144857227802277,
      "learning_rate": 1.924976939633084e-05,
      "loss": 0.8696,
      "step": 371
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.17272283136844635,
      "learning_rate": 1.92477195859383e-05,
      "loss": 0.8252,
      "step": 372
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.1407836675643921,
      "learning_rate": 1.9245669775545765e-05,
      "loss": 0.8798,
      "step": 373
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.14374861121177673,
      "learning_rate": 1.9243619965153225e-05,
      "loss": 0.809,
      "step": 374
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.2178298681974411,
      "learning_rate": 1.924157015476069e-05,
      "loss": 0.8097,
      "step": 375
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.1452960968017578,
      "learning_rate": 1.923952034436815e-05,
      "loss": 0.8993,
      "step": 376
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.13822156190872192,
      "learning_rate": 1.923747053397561e-05,
      "loss": 0.8982,
      "step": 377
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.16437716782093048,
      "learning_rate": 1.923542072358307e-05,
      "loss": 0.7987,
      "step": 378
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.15675105154514313,
      "learning_rate": 1.9233370913190533e-05,
      "loss": 0.8576,
      "step": 379
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.1522854119539261,
      "learning_rate": 1.9231321102797993e-05,
      "loss": 0.8943,
      "step": 380
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.16838493943214417,
      "learning_rate": 1.9229271292405453e-05,
      "loss": 0.708,
      "step": 381
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.1511940211057663,
      "learning_rate": 1.9227221482012913e-05,
      "loss": 0.8517,
      "step": 382
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.16562093794345856,
      "learning_rate": 1.9225171671620377e-05,
      "loss": 0.7934,
      "step": 383
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.1492152363061905,
      "learning_rate": 1.9223121861227837e-05,
      "loss": 0.8708,
      "step": 384
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.1480678766965866,
      "learning_rate": 1.92210720508353e-05,
      "loss": 0.9034,
      "step": 385
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.1552446186542511,
      "learning_rate": 1.921902224044276e-05,
      "loss": 0.7942,
      "step": 386
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.14972244203090668,
      "learning_rate": 1.9216972430050224e-05,
      "loss": 0.855,
      "step": 387
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.1446336805820465,
      "learning_rate": 1.9214922619657684e-05,
      "loss": 0.8692,
      "step": 388
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.15611252188682556,
      "learning_rate": 1.9212872809265144e-05,
      "loss": 0.797,
      "step": 389
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.14483509957790375,
      "learning_rate": 1.9210822998872608e-05,
      "loss": 0.8415,
      "step": 390
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.14611844718456268,
      "learning_rate": 1.9208773188480068e-05,
      "loss": 0.8362,
      "step": 391
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.15801045298576355,
      "learning_rate": 1.920672337808753e-05,
      "loss": 0.8965,
      "step": 392
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.14152853190898895,
      "learning_rate": 1.920467356769499e-05,
      "loss": 0.8903,
      "step": 393
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.15904606878757477,
      "learning_rate": 1.9202623757302452e-05,
      "loss": 0.7721,
      "step": 394
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.1708311289548874,
      "learning_rate": 1.9200573946909912e-05,
      "loss": 0.7544,
      "step": 395
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.14611460268497467,
      "learning_rate": 1.9198524136517372e-05,
      "loss": 0.8079,
      "step": 396
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.13924139738082886,
      "learning_rate": 1.9196474326124836e-05,
      "loss": 0.8066,
      "step": 397
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.14339646697044373,
      "learning_rate": 1.9194424515732296e-05,
      "loss": 0.8984,
      "step": 398
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.19476652145385742,
      "learning_rate": 1.919237470533976e-05,
      "loss": 0.721,
      "step": 399
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.14827312529087067,
      "learning_rate": 1.919032489494722e-05,
      "loss": 0.7668,
      "step": 400
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.14345461130142212,
      "learning_rate": 1.918827508455468e-05,
      "loss": 0.8136,
      "step": 401
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.1758970022201538,
      "learning_rate": 1.9186225274162143e-05,
      "loss": 0.8317,
      "step": 402
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.15231788158416748,
      "learning_rate": 1.9184175463769604e-05,
      "loss": 0.8271,
      "step": 403
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.14136990904808044,
      "learning_rate": 1.9182125653377064e-05,
      "loss": 0.8636,
      "step": 404
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.1592167317867279,
      "learning_rate": 1.9180075842984524e-05,
      "loss": 0.8994,
      "step": 405
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.15409733355045319,
      "learning_rate": 1.9178026032591988e-05,
      "loss": 0.8645,
      "step": 406
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.1687871813774109,
      "learning_rate": 1.9175976222199448e-05,
      "loss": 0.7249,
      "step": 407
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.16160649061203003,
      "learning_rate": 1.9173926411806908e-05,
      "loss": 0.8686,
      "step": 408
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.1700599193572998,
      "learning_rate": 1.917187660141437e-05,
      "loss": 0.8008,
      "step": 409
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.17662590742111206,
      "learning_rate": 1.916982679102183e-05,
      "loss": 0.6727,
      "step": 410
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.17508365213871002,
      "learning_rate": 1.9167776980629295e-05,
      "loss": 0.807,
      "step": 411
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.18899306654930115,
      "learning_rate": 1.9165727170236755e-05,
      "loss": 0.7514,
      "step": 412
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.17519474029541016,
      "learning_rate": 1.9163677359844215e-05,
      "loss": 0.7937,
      "step": 413
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.17406079173088074,
      "learning_rate": 1.916162754945168e-05,
      "loss": 0.8598,
      "step": 414
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.1616392880678177,
      "learning_rate": 1.915957773905914e-05,
      "loss": 0.8522,
      "step": 415
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.17864663898944855,
      "learning_rate": 1.91575279286666e-05,
      "loss": 0.8591,
      "step": 416
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.16068516671657562,
      "learning_rate": 1.915547811827406e-05,
      "loss": 0.8761,
      "step": 417
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.16791556775569916,
      "learning_rate": 1.9153428307881523e-05,
      "loss": 0.747,
      "step": 418
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.17416690289974213,
      "learning_rate": 1.9151378497488983e-05,
      "loss": 0.8457,
      "step": 419
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.18067793548107147,
      "learning_rate": 1.9149328687096443e-05,
      "loss": 0.9268,
      "step": 420
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.14490729570388794,
      "learning_rate": 1.9147278876703907e-05,
      "loss": 0.8704,
      "step": 421
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.15132369101047516,
      "learning_rate": 1.9145229066311367e-05,
      "loss": 0.9143,
      "step": 422
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.2017907351255417,
      "learning_rate": 1.914317925591883e-05,
      "loss": 0.8814,
      "step": 423
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.1470775306224823,
      "learning_rate": 1.914112944552629e-05,
      "loss": 0.8234,
      "step": 424
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.19069324433803558,
      "learning_rate": 1.9139079635133754e-05,
      "loss": 0.816,
      "step": 425
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.1687970757484436,
      "learning_rate": 1.9137029824741214e-05,
      "loss": 0.7932,
      "step": 426
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.17496801912784576,
      "learning_rate": 1.9134980014348675e-05,
      "loss": 0.7629,
      "step": 427
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.16465221345424652,
      "learning_rate": 1.9132930203956135e-05,
      "loss": 0.7773,
      "step": 428
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.14980225265026093,
      "learning_rate": 1.91308803935636e-05,
      "loss": 0.9417,
      "step": 429
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.15588514506816864,
      "learning_rate": 1.912883058317106e-05,
      "loss": 0.8836,
      "step": 430
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.17013239860534668,
      "learning_rate": 1.912678077277852e-05,
      "loss": 0.8076,
      "step": 431
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.1522824466228485,
      "learning_rate": 1.912473096238598e-05,
      "loss": 0.8134,
      "step": 432
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.17980511486530304,
      "learning_rate": 1.9122681151993442e-05,
      "loss": 0.8953,
      "step": 433
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.18643483519554138,
      "learning_rate": 1.9120631341600903e-05,
      "loss": 0.7685,
      "step": 434
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.16374269127845764,
      "learning_rate": 1.9118581531208366e-05,
      "loss": 0.8073,
      "step": 435
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.17865963280200958,
      "learning_rate": 1.9116531720815826e-05,
      "loss": 0.8614,
      "step": 436
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.16780543327331543,
      "learning_rate": 1.911448191042329e-05,
      "loss": 0.78,
      "step": 437
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.16059668362140656,
      "learning_rate": 1.911243210003075e-05,
      "loss": 0.8635,
      "step": 438
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.16147461533546448,
      "learning_rate": 1.911038228963821e-05,
      "loss": 0.822,
      "step": 439
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.16893987357616425,
      "learning_rate": 1.910833247924567e-05,
      "loss": 0.8326,
      "step": 440
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.1762782484292984,
      "learning_rate": 1.9106282668853134e-05,
      "loss": 0.922,
      "step": 441
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.16019174456596375,
      "learning_rate": 1.9104232858460594e-05,
      "loss": 0.7339,
      "step": 442
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.22397136688232422,
      "learning_rate": 1.9102183048068054e-05,
      "loss": 0.8098,
      "step": 443
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.1708119511604309,
      "learning_rate": 1.9100133237675514e-05,
      "loss": 0.7452,
      "step": 444
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.16400514543056488,
      "learning_rate": 1.9098083427282978e-05,
      "loss": 0.8448,
      "step": 445
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.17854410409927368,
      "learning_rate": 1.9096033616890438e-05,
      "loss": 0.834,
      "step": 446
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.16905593872070312,
      "learning_rate": 1.90939838064979e-05,
      "loss": 0.8192,
      "step": 447
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.16718362271785736,
      "learning_rate": 1.9091933996105362e-05,
      "loss": 0.8364,
      "step": 448
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.15494103729724884,
      "learning_rate": 1.9089884185712825e-05,
      "loss": 0.9052,
      "step": 449
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.17324014008045197,
      "learning_rate": 1.9087834375320285e-05,
      "loss": 0.8398,
      "step": 450
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.16868022084236145,
      "learning_rate": 1.9085784564927746e-05,
      "loss": 0.8494,
      "step": 451
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.19692480564117432,
      "learning_rate": 1.908373475453521e-05,
      "loss": 0.8049,
      "step": 452
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.20679554343223572,
      "learning_rate": 1.908168494414267e-05,
      "loss": 0.8431,
      "step": 453
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.18304497003555298,
      "learning_rate": 1.907963513375013e-05,
      "loss": 0.7937,
      "step": 454
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.15351274609565735,
      "learning_rate": 1.907758532335759e-05,
      "loss": 0.7754,
      "step": 455
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.1994316279888153,
      "learning_rate": 1.9075535512965053e-05,
      "loss": 0.7174,
      "step": 456
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.2093765139579773,
      "learning_rate": 1.9073485702572513e-05,
      "loss": 0.7251,
      "step": 457
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.18247674405574799,
      "learning_rate": 1.9071435892179974e-05,
      "loss": 0.7514,
      "step": 458
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.20437216758728027,
      "learning_rate": 1.9069386081787437e-05,
      "loss": 0.7908,
      "step": 459
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.1926635354757309,
      "learning_rate": 1.9067336271394897e-05,
      "loss": 0.8769,
      "step": 460
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.1657874584197998,
      "learning_rate": 1.906528646100236e-05,
      "loss": 0.7522,
      "step": 461
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.1918681412935257,
      "learning_rate": 1.906323665060982e-05,
      "loss": 0.8902,
      "step": 462
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.16888751089572906,
      "learning_rate": 1.906118684021728e-05,
      "loss": 0.8086,
      "step": 463
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.18022564053535461,
      "learning_rate": 1.9059137029824745e-05,
      "loss": 0.7946,
      "step": 464
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.18103459477424622,
      "learning_rate": 1.9057087219432205e-05,
      "loss": 0.9281,
      "step": 465
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.17837344110012054,
      "learning_rate": 1.9055037409039665e-05,
      "loss": 0.8222,
      "step": 466
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.20301282405853271,
      "learning_rate": 1.9052987598647125e-05,
      "loss": 0.7211,
      "step": 467
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.18511620163917542,
      "learning_rate": 1.905093778825459e-05,
      "loss": 0.8539,
      "step": 468
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.17245325446128845,
      "learning_rate": 1.904888797786205e-05,
      "loss": 0.8117,
      "step": 469
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.17423871159553528,
      "learning_rate": 1.904683816746951e-05,
      "loss": 0.7473,
      "step": 470
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.19919812679290771,
      "learning_rate": 1.9044788357076973e-05,
      "loss": 0.8494,
      "step": 471
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.21152034401893616,
      "learning_rate": 1.9042738546684433e-05,
      "loss": 0.806,
      "step": 472
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.1872701197862625,
      "learning_rate": 1.9040688736291893e-05,
      "loss": 0.8033,
      "step": 473
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.2077201008796692,
      "learning_rate": 1.9038638925899356e-05,
      "loss": 0.777,
      "step": 474
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.1911279708147049,
      "learning_rate": 1.9036589115506817e-05,
      "loss": 0.8089,
      "step": 475
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.17532692849636078,
      "learning_rate": 1.903453930511428e-05,
      "loss": 0.8318,
      "step": 476
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.2234090119600296,
      "learning_rate": 1.903248949472174e-05,
      "loss": 0.9116,
      "step": 477
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.1920439749956131,
      "learning_rate": 1.90304396843292e-05,
      "loss": 0.8218,
      "step": 478
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.17685282230377197,
      "learning_rate": 1.9028389873936664e-05,
      "loss": 0.737,
      "step": 479
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.1973785012960434,
      "learning_rate": 1.9026340063544124e-05,
      "loss": 0.8184,
      "step": 480
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.21858394145965576,
      "learning_rate": 1.9024290253151584e-05,
      "loss": 0.7031,
      "step": 481
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.20711596310138702,
      "learning_rate": 1.9022240442759045e-05,
      "loss": 0.8233,
      "step": 482
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.19980688393115997,
      "learning_rate": 1.9020190632366508e-05,
      "loss": 0.8404,
      "step": 483
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.2554182708263397,
      "learning_rate": 1.9018140821973968e-05,
      "loss": 0.8242,
      "step": 484
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.2178659737110138,
      "learning_rate": 1.901609101158143e-05,
      "loss": 0.7831,
      "step": 485
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.19421729445457458,
      "learning_rate": 1.9014041201188892e-05,
      "loss": 0.9599,
      "step": 486
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.19006289541721344,
      "learning_rate": 1.9011991390796352e-05,
      "loss": 0.7554,
      "step": 487
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.20694541931152344,
      "learning_rate": 1.9009941580403816e-05,
      "loss": 0.798,
      "step": 488
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.20120131969451904,
      "learning_rate": 1.9007891770011276e-05,
      "loss": 0.8169,
      "step": 489
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.1653985232114792,
      "learning_rate": 1.9005841959618736e-05,
      "loss": 0.8662,
      "step": 490
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.19703707098960876,
      "learning_rate": 1.90037921492262e-05,
      "loss": 0.7897,
      "step": 491
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.2020362764596939,
      "learning_rate": 1.900174233883366e-05,
      "loss": 0.8957,
      "step": 492
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.18726219236850739,
      "learning_rate": 1.899969252844112e-05,
      "loss": 0.8154,
      "step": 493
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.20864568650722504,
      "learning_rate": 1.899764271804858e-05,
      "loss": 0.7117,
      "step": 494
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.1811826080083847,
      "learning_rate": 1.8995592907656044e-05,
      "loss": 0.8568,
      "step": 495
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.18101084232330322,
      "learning_rate": 1.8993543097263504e-05,
      "loss": 0.7961,
      "step": 496
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.21149250864982605,
      "learning_rate": 1.8991493286870964e-05,
      "loss": 0.7622,
      "step": 497
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.18719595670700073,
      "learning_rate": 1.8989443476478427e-05,
      "loss": 0.861,
      "step": 498
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.21494868397712708,
      "learning_rate": 1.8987393666085888e-05,
      "loss": 0.7725,
      "step": 499
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.19059619307518005,
      "learning_rate": 1.898534385569335e-05,
      "loss": 0.7189,
      "step": 500
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.19733569025993347,
      "learning_rate": 1.898329404530081e-05,
      "loss": 0.8581,
      "step": 501
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.18426968157291412,
      "learning_rate": 1.898124423490827e-05,
      "loss": 0.7409,
      "step": 502
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.19410546123981476,
      "learning_rate": 1.8979194424515735e-05,
      "loss": 0.7652,
      "step": 503
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.20012442767620087,
      "learning_rate": 1.8977144614123195e-05,
      "loss": 0.6592,
      "step": 504
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.21452948451042175,
      "learning_rate": 1.8975094803730655e-05,
      "loss": 0.7991,
      "step": 505
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.19325408339500427,
      "learning_rate": 1.8973044993338116e-05,
      "loss": 0.8303,
      "step": 506
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.20319633185863495,
      "learning_rate": 1.897099518294558e-05,
      "loss": 0.7804,
      "step": 507
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.20566116273403168,
      "learning_rate": 1.896894537255304e-05,
      "loss": 0.7449,
      "step": 508
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.20156601071357727,
      "learning_rate": 1.89668955621605e-05,
      "loss": 0.7583,
      "step": 509
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.20419004559516907,
      "learning_rate": 1.8964845751767963e-05,
      "loss": 0.8372,
      "step": 510
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.22958584129810333,
      "learning_rate": 1.8962795941375423e-05,
      "loss": 0.7746,
      "step": 511
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.216570183634758,
      "learning_rate": 1.8960746130982887e-05,
      "loss": 0.7997,
      "step": 512
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.20960162580013275,
      "learning_rate": 1.8958696320590347e-05,
      "loss": 0.8943,
      "step": 513
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.21094997227191925,
      "learning_rate": 1.895664651019781e-05,
      "loss": 0.8548,
      "step": 514
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.18289414048194885,
      "learning_rate": 1.895459669980527e-05,
      "loss": 0.8311,
      "step": 515
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.29864302277565,
      "learning_rate": 1.895254688941273e-05,
      "loss": 0.7515,
      "step": 516
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.25311973690986633,
      "learning_rate": 1.895049707902019e-05,
      "loss": 0.7582,
      "step": 517
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.262350857257843,
      "learning_rate": 1.8948447268627654e-05,
      "loss": 0.8844,
      "step": 518
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.23849861323833466,
      "learning_rate": 1.8946397458235115e-05,
      "loss": 0.6801,
      "step": 519
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.24991253018379211,
      "learning_rate": 1.8944347647842575e-05,
      "loss": 0.7709,
      "step": 520
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.21508775651454926,
      "learning_rate": 1.8942297837450035e-05,
      "loss": 0.865,
      "step": 521
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.22612547874450684,
      "learning_rate": 1.89402480270575e-05,
      "loss": 0.7808,
      "step": 522
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.23175758123397827,
      "learning_rate": 1.893819821666496e-05,
      "loss": 0.736,
      "step": 523
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.20399166643619537,
      "learning_rate": 1.8936148406272422e-05,
      "loss": 0.8919,
      "step": 524
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.23995094001293182,
      "learning_rate": 1.8934098595879882e-05,
      "loss": 0.7918,
      "step": 525
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.22864922881126404,
      "learning_rate": 1.8932048785487346e-05,
      "loss": 0.8403,
      "step": 526
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.22524893283843994,
      "learning_rate": 1.8929998975094806e-05,
      "loss": 0.8413,
      "step": 527
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.19651883840560913,
      "learning_rate": 1.8927949164702266e-05,
      "loss": 0.822,
      "step": 528
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.21977390348911285,
      "learning_rate": 1.8925899354309726e-05,
      "loss": 0.745,
      "step": 529
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.20708025991916656,
      "learning_rate": 1.892384954391719e-05,
      "loss": 0.758,
      "step": 530
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.2496166229248047,
      "learning_rate": 1.892179973352465e-05,
      "loss": 0.8371,
      "step": 531
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.24427592754364014,
      "learning_rate": 1.891974992313211e-05,
      "loss": 0.866,
      "step": 532
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.2351367473602295,
      "learning_rate": 1.891770011273957e-05,
      "loss": 0.7736,
      "step": 533
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.2400284856557846,
      "learning_rate": 1.8915650302347034e-05,
      "loss": 0.7418,
      "step": 534
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.21287386119365692,
      "learning_rate": 1.8913600491954494e-05,
      "loss": 0.7213,
      "step": 535
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.2319117784500122,
      "learning_rate": 1.8911550681561958e-05,
      "loss": 0.8659,
      "step": 536
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.21474748849868774,
      "learning_rate": 1.8909500871169418e-05,
      "loss": 0.7468,
      "step": 537
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.2480355054140091,
      "learning_rate": 1.890745106077688e-05,
      "loss": 0.7826,
      "step": 538
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.1993049830198288,
      "learning_rate": 1.890540125038434e-05,
      "loss": 0.8354,
      "step": 539
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.23135560750961304,
      "learning_rate": 1.8903351439991802e-05,
      "loss": 0.7514,
      "step": 540
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.23334814608097076,
      "learning_rate": 1.8901301629599265e-05,
      "loss": 0.7865,
      "step": 541
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.21762984991073608,
      "learning_rate": 1.8899251819206725e-05,
      "loss": 0.8809,
      "step": 542
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.2144210934638977,
      "learning_rate": 1.8897202008814186e-05,
      "loss": 0.7945,
      "step": 543
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.22259631752967834,
      "learning_rate": 1.8895152198421646e-05,
      "loss": 0.7325,
      "step": 544
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.21477104723453522,
      "learning_rate": 1.889310238802911e-05,
      "loss": 0.857,
      "step": 545
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.21294987201690674,
      "learning_rate": 1.889105257763657e-05,
      "loss": 0.799,
      "step": 546
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.25885850191116333,
      "learning_rate": 1.888900276724403e-05,
      "loss": 0.8143,
      "step": 547
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.21820950508117676,
      "learning_rate": 1.8886952956851493e-05,
      "loss": 0.832,
      "step": 548
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.2264004349708557,
      "learning_rate": 1.8884903146458953e-05,
      "loss": 0.8097,
      "step": 549
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.23316548764705658,
      "learning_rate": 1.8882853336066417e-05,
      "loss": 0.7515,
      "step": 550
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.20102547109127045,
      "learning_rate": 1.8880803525673877e-05,
      "loss": 0.8081,
      "step": 551
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.2040938436985016,
      "learning_rate": 1.8878753715281337e-05,
      "loss": 0.8534,
      "step": 552
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.236019566655159,
      "learning_rate": 1.88767039048888e-05,
      "loss": 0.7682,
      "step": 553
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.3004855811595917,
      "learning_rate": 1.887465409449626e-05,
      "loss": 0.7303,
      "step": 554
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.21686811745166779,
      "learning_rate": 1.887260428410372e-05,
      "loss": 0.8266,
      "step": 555
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.2634103298187256,
      "learning_rate": 1.887055447371118e-05,
      "loss": 0.7901,
      "step": 556
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.22976526618003845,
      "learning_rate": 1.8868504663318645e-05,
      "loss": 0.8512,
      "step": 557
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.296199768781662,
      "learning_rate": 1.8866454852926105e-05,
      "loss": 0.8566,
      "step": 558
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.24860918521881104,
      "learning_rate": 1.8864405042533565e-05,
      "loss": 0.8366,
      "step": 559
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.29074087738990784,
      "learning_rate": 1.886235523214103e-05,
      "loss": 0.7597,
      "step": 560
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.2821865975856781,
      "learning_rate": 1.886030542174849e-05,
      "loss": 0.7746,
      "step": 561
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.26934775710105896,
      "learning_rate": 1.8858255611355952e-05,
      "loss": 0.7584,
      "step": 562
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.2615976631641388,
      "learning_rate": 1.8856205800963413e-05,
      "loss": 0.7606,
      "step": 563
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.24356038868427277,
      "learning_rate": 1.8854155990570873e-05,
      "loss": 0.7066,
      "step": 564
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.2835129201412201,
      "learning_rate": 1.8852106180178336e-05,
      "loss": 0.7063,
      "step": 565
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.2627677321434021,
      "learning_rate": 1.8850056369785796e-05,
      "loss": 0.8881,
      "step": 566
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.2871919870376587,
      "learning_rate": 1.8848006559393257e-05,
      "loss": 0.8213,
      "step": 567
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.25961214303970337,
      "learning_rate": 1.884595674900072e-05,
      "loss": 0.9009,
      "step": 568
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.26552483439445496,
      "learning_rate": 1.884390693860818e-05,
      "loss": 0.834,
      "step": 569
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.24494673311710358,
      "learning_rate": 1.884185712821564e-05,
      "loss": 0.7715,
      "step": 570
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.2400072067975998,
      "learning_rate": 1.88398073178231e-05,
      "loss": 0.8085,
      "step": 571
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.23224161565303802,
      "learning_rate": 1.8837757507430564e-05,
      "loss": 0.7976,
      "step": 572
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.2596319615840912,
      "learning_rate": 1.8835707697038024e-05,
      "loss": 0.7869,
      "step": 573
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.285260409116745,
      "learning_rate": 1.8833657886645488e-05,
      "loss": 0.7651,
      "step": 574
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.26859959959983826,
      "learning_rate": 1.8831608076252948e-05,
      "loss": 0.7573,
      "step": 575
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.25955668091773987,
      "learning_rate": 1.882955826586041e-05,
      "loss": 0.7789,
      "step": 576
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.25042223930358887,
      "learning_rate": 1.8827508455467872e-05,
      "loss": 0.7996,
      "step": 577
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.2487245500087738,
      "learning_rate": 1.8825458645075332e-05,
      "loss": 0.718,
      "step": 578
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.22486095130443573,
      "learning_rate": 1.8823408834682792e-05,
      "loss": 0.7956,
      "step": 579
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.2707049548625946,
      "learning_rate": 1.8821359024290256e-05,
      "loss": 0.6772,
      "step": 580
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.24360224604606628,
      "learning_rate": 1.8819309213897716e-05,
      "loss": 0.806,
      "step": 581
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.26013419032096863,
      "learning_rate": 1.8817259403505176e-05,
      "loss": 0.776,
      "step": 582
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.26571816205978394,
      "learning_rate": 1.8815209593112636e-05,
      "loss": 0.7599,
      "step": 583
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.26651903986930847,
      "learning_rate": 1.88131597827201e-05,
      "loss": 0.8334,
      "step": 584
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.3071249723434448,
      "learning_rate": 1.881110997232756e-05,
      "loss": 0.7747,
      "step": 585
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.30715256929397583,
      "learning_rate": 1.8809060161935023e-05,
      "loss": 0.6903,
      "step": 586
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.23905496299266815,
      "learning_rate": 1.8807010351542484e-05,
      "loss": 0.7866,
      "step": 587
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.24115152657032013,
      "learning_rate": 1.8804960541149947e-05,
      "loss": 0.748,
      "step": 588
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.22978830337524414,
      "learning_rate": 1.8802910730757407e-05,
      "loss": 0.6972,
      "step": 589
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.22623153030872345,
      "learning_rate": 1.8800860920364867e-05,
      "loss": 0.8043,
      "step": 590
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.2673869729042053,
      "learning_rate": 1.8798811109972328e-05,
      "loss": 0.8982,
      "step": 591
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.2301866114139557,
      "learning_rate": 1.879676129957979e-05,
      "loss": 0.7844,
      "step": 592
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.24445998668670654,
      "learning_rate": 1.879471148918725e-05,
      "loss": 0.7336,
      "step": 593
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.23602020740509033,
      "learning_rate": 1.879266167879471e-05,
      "loss": 0.7118,
      "step": 594
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.25433769822120667,
      "learning_rate": 1.8790611868402175e-05,
      "loss": 0.7902,
      "step": 595
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.2582925856113434,
      "learning_rate": 1.8788562058009635e-05,
      "loss": 0.7455,
      "step": 596
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.2507253587245941,
      "learning_rate": 1.8786512247617095e-05,
      "loss": 0.7269,
      "step": 597
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.24637457728385925,
      "learning_rate": 1.878446243722456e-05,
      "loss": 0.7391,
      "step": 598
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.24102479219436646,
      "learning_rate": 1.878241262683202e-05,
      "loss": 0.8535,
      "step": 599
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.30762001872062683,
      "learning_rate": 1.8780362816439483e-05,
      "loss": 0.7081,
      "step": 600
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.2617662847042084,
      "learning_rate": 1.8778313006046943e-05,
      "loss": 0.7538,
      "step": 601
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.2924197018146515,
      "learning_rate": 1.8776263195654403e-05,
      "loss": 0.7402,
      "step": 602
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.25363895297050476,
      "learning_rate": 1.8774213385261867e-05,
      "loss": 0.7425,
      "step": 603
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.26895347237586975,
      "learning_rate": 1.8772163574869327e-05,
      "loss": 0.7969,
      "step": 604
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.28718337416648865,
      "learning_rate": 1.8770113764476787e-05,
      "loss": 0.7708,
      "step": 605
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.2528524100780487,
      "learning_rate": 1.8768063954084247e-05,
      "loss": 0.7702,
      "step": 606
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.2677992582321167,
      "learning_rate": 1.876601414369171e-05,
      "loss": 0.7172,
      "step": 607
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.31523728370666504,
      "learning_rate": 1.876396433329917e-05,
      "loss": 0.7547,
      "step": 608
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.22344838082790375,
      "learning_rate": 1.876191452290663e-05,
      "loss": 0.7414,
      "step": 609
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.26969507336616516,
      "learning_rate": 1.8759864712514094e-05,
      "loss": 0.7992,
      "step": 610
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.39049336314201355,
      "learning_rate": 1.8757814902121555e-05,
      "loss": 0.7956,
      "step": 611
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.26343175768852234,
      "learning_rate": 1.8755765091729018e-05,
      "loss": 0.8465,
      "step": 612
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.2986372113227844,
      "learning_rate": 1.8753715281336478e-05,
      "loss": 0.7476,
      "step": 613
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.26255324482917786,
      "learning_rate": 1.875166547094394e-05,
      "loss": 0.6618,
      "step": 614
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.2755093276500702,
      "learning_rate": 1.8749615660551402e-05,
      "loss": 0.8586,
      "step": 615
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.27989357709884644,
      "learning_rate": 1.8747565850158862e-05,
      "loss": 0.7771,
      "step": 616
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.3005853295326233,
      "learning_rate": 1.8745516039766322e-05,
      "loss": 0.7872,
      "step": 617
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.3140900433063507,
      "learning_rate": 1.8743466229373782e-05,
      "loss": 0.811,
      "step": 618
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.3815363943576813,
      "learning_rate": 1.8741416418981246e-05,
      "loss": 0.7254,
      "step": 619
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.28141000866889954,
      "learning_rate": 1.8739366608588706e-05,
      "loss": 0.6784,
      "step": 620
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.3459838628768921,
      "learning_rate": 1.8737316798196166e-05,
      "loss": 0.7484,
      "step": 621
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.26786547899246216,
      "learning_rate": 1.873526698780363e-05,
      "loss": 0.8363,
      "step": 622
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.33138319849967957,
      "learning_rate": 1.873321717741109e-05,
      "loss": 0.7766,
      "step": 623
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.27499139308929443,
      "learning_rate": 1.8731167367018554e-05,
      "loss": 0.8174,
      "step": 624
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.2671065628528595,
      "learning_rate": 1.8729117556626014e-05,
      "loss": 0.703,
      "step": 625
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.24237236380577087,
      "learning_rate": 1.8727067746233477e-05,
      "loss": 0.7344,
      "step": 626
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.26603057980537415,
      "learning_rate": 1.8725017935840938e-05,
      "loss": 0.6984,
      "step": 627
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.4455318748950958,
      "learning_rate": 1.8722968125448398e-05,
      "loss": 0.7154,
      "step": 628
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.35970625281333923,
      "learning_rate": 1.8720918315055858e-05,
      "loss": 0.6792,
      "step": 629
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.24973182380199432,
      "learning_rate": 1.871886850466332e-05,
      "loss": 0.7959,
      "step": 630
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.3197944164276123,
      "learning_rate": 1.871681869427078e-05,
      "loss": 0.823,
      "step": 631
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.3085663616657257,
      "learning_rate": 1.8714768883878242e-05,
      "loss": 0.7818,
      "step": 632
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.5861884951591492,
      "learning_rate": 1.8712719073485702e-05,
      "loss": 0.736,
      "step": 633
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.31729575991630554,
      "learning_rate": 1.8710669263093165e-05,
      "loss": 0.7858,
      "step": 634
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.24467049539089203,
      "learning_rate": 1.8708619452700626e-05,
      "loss": 0.7231,
      "step": 635
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.3214152157306671,
      "learning_rate": 1.870656964230809e-05,
      "loss": 0.6832,
      "step": 636
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.29062697291374207,
      "learning_rate": 1.870451983191555e-05,
      "loss": 0.7585,
      "step": 637
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.2639349102973938,
      "learning_rate": 1.8702470021523013e-05,
      "loss": 0.8305,
      "step": 638
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.2599736750125885,
      "learning_rate": 1.8700420211130473e-05,
      "loss": 0.741,
      "step": 639
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.28552183508872986,
      "learning_rate": 1.8698370400737933e-05,
      "loss": 0.8023,
      "step": 640
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.30511707067489624,
      "learning_rate": 1.8696320590345393e-05,
      "loss": 0.7845,
      "step": 641
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.28802749514579773,
      "learning_rate": 1.8694270779952857e-05,
      "loss": 0.7299,
      "step": 642
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.2700783610343933,
      "learning_rate": 1.8692220969560317e-05,
      "loss": 0.7752,
      "step": 643
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.357479989528656,
      "learning_rate": 1.8690171159167777e-05,
      "loss": 0.7619,
      "step": 644
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.26713383197784424,
      "learning_rate": 1.8688121348775237e-05,
      "loss": 0.7588,
      "step": 645
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.26902085542678833,
      "learning_rate": 1.86860715383827e-05,
      "loss": 0.8006,
      "step": 646
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.3053898811340332,
      "learning_rate": 1.868402172799016e-05,
      "loss": 0.7074,
      "step": 647
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.30651965737342834,
      "learning_rate": 1.8681971917597625e-05,
      "loss": 0.6776,
      "step": 648
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.30364400148391724,
      "learning_rate": 1.8679922107205085e-05,
      "loss": 0.7094,
      "step": 649
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.45219185948371887,
      "learning_rate": 1.867787229681255e-05,
      "loss": 0.7414,
      "step": 650
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.33632686734199524,
      "learning_rate": 1.867582248642001e-05,
      "loss": 0.8247,
      "step": 651
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.27378049492836,
      "learning_rate": 1.867377267602747e-05,
      "loss": 0.7217,
      "step": 652
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.32606759667396545,
      "learning_rate": 1.867172286563493e-05,
      "loss": 0.9137,
      "step": 653
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.4139516353607178,
      "learning_rate": 1.8669673055242392e-05,
      "loss": 0.6719,
      "step": 654
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.407975971698761,
      "learning_rate": 1.8667623244849853e-05,
      "loss": 0.7217,
      "step": 655
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.31235629320144653,
      "learning_rate": 1.8665573434457313e-05,
      "loss": 0.7938,
      "step": 656
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.306678831577301,
      "learning_rate": 1.8663523624064776e-05,
      "loss": 0.7975,
      "step": 657
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.3054419457912445,
      "learning_rate": 1.8661473813672236e-05,
      "loss": 0.7549,
      "step": 658
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.2784799337387085,
      "learning_rate": 1.8659424003279697e-05,
      "loss": 0.7744,
      "step": 659
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.31096217036247253,
      "learning_rate": 1.865737419288716e-05,
      "loss": 0.8372,
      "step": 660
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.3108414113521576,
      "learning_rate": 1.865532438249462e-05,
      "loss": 0.7821,
      "step": 661
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.3422684073448181,
      "learning_rate": 1.8653274572102084e-05,
      "loss": 0.6332,
      "step": 662
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.27207282185554504,
      "learning_rate": 1.8651224761709544e-05,
      "loss": 0.8161,
      "step": 663
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.32756397128105164,
      "learning_rate": 1.8649174951317004e-05,
      "loss": 0.6827,
      "step": 664
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.35011640191078186,
      "learning_rate": 1.8647125140924468e-05,
      "loss": 0.6699,
      "step": 665
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.33124545216560364,
      "learning_rate": 1.8645075330531928e-05,
      "loss": 0.6844,
      "step": 666
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.3036869466304779,
      "learning_rate": 1.8643025520139388e-05,
      "loss": 0.7202,
      "step": 667
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.4293011724948883,
      "learning_rate": 1.8640975709746848e-05,
      "loss": 0.7756,
      "step": 668
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.4789758324623108,
      "learning_rate": 1.8638925899354312e-05,
      "loss": 0.7574,
      "step": 669
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.33938974142074585,
      "learning_rate": 1.8636876088961772e-05,
      "loss": 0.7449,
      "step": 670
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.2775660753250122,
      "learning_rate": 1.8634826278569232e-05,
      "loss": 0.7933,
      "step": 671
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.28979596495628357,
      "learning_rate": 1.8632776468176696e-05,
      "loss": 0.8205,
      "step": 672
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.2685103118419647,
      "learning_rate": 1.8630726657784156e-05,
      "loss": 0.7204,
      "step": 673
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.4604327380657196,
      "learning_rate": 1.862867684739162e-05,
      "loss": 0.7665,
      "step": 674
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.3960510790348053,
      "learning_rate": 1.862662703699908e-05,
      "loss": 0.8591,
      "step": 675
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.3221500813961029,
      "learning_rate": 1.862457722660654e-05,
      "loss": 0.7863,
      "step": 676
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.29200273752212524,
      "learning_rate": 1.8622527416214003e-05,
      "loss": 0.8267,
      "step": 677
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.3674166798591614,
      "learning_rate": 1.8620477605821463e-05,
      "loss": 0.729,
      "step": 678
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.3679443299770355,
      "learning_rate": 1.8618427795428924e-05,
      "loss": 0.7954,
      "step": 679
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.28557607531547546,
      "learning_rate": 1.8616377985036384e-05,
      "loss": 0.6353,
      "step": 680
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.330252468585968,
      "learning_rate": 1.8614328174643847e-05,
      "loss": 0.765,
      "step": 681
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.33303672075271606,
      "learning_rate": 1.8612278364251307e-05,
      "loss": 0.626,
      "step": 682
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.27430498600006104,
      "learning_rate": 1.8610228553858768e-05,
      "loss": 0.7415,
      "step": 683
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.2744219899177551,
      "learning_rate": 1.860817874346623e-05,
      "loss": 0.7709,
      "step": 684
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.30445465445518494,
      "learning_rate": 1.860612893307369e-05,
      "loss": 0.7008,
      "step": 685
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.2783001959323883,
      "learning_rate": 1.8604079122681155e-05,
      "loss": 0.7687,
      "step": 686
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.3679037094116211,
      "learning_rate": 1.8602029312288615e-05,
      "loss": 0.81,
      "step": 687
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.37763097882270813,
      "learning_rate": 1.859997950189608e-05,
      "loss": 0.6983,
      "step": 688
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.4544643759727478,
      "learning_rate": 1.859792969150354e-05,
      "loss": 0.7667,
      "step": 689
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.2900504171848297,
      "learning_rate": 1.8595879881111e-05,
      "loss": 0.8443,
      "step": 690
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.32240623235702515,
      "learning_rate": 1.859383007071846e-05,
      "loss": 0.7483,
      "step": 691
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.32900500297546387,
      "learning_rate": 1.8591780260325923e-05,
      "loss": 0.6492,
      "step": 692
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.3703707754611969,
      "learning_rate": 1.8589730449933383e-05,
      "loss": 0.7254,
      "step": 693
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.4254625141620636,
      "learning_rate": 1.8587680639540843e-05,
      "loss": 0.6392,
      "step": 694
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.29394441843032837,
      "learning_rate": 1.8585630829148303e-05,
      "loss": 0.7379,
      "step": 695
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.4378385841846466,
      "learning_rate": 1.8583581018755767e-05,
      "loss": 0.7827,
      "step": 696
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.48359277844429016,
      "learning_rate": 1.8581531208363227e-05,
      "loss": 0.6433,
      "step": 697
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.3416093587875366,
      "learning_rate": 1.857948139797069e-05,
      "loss": 0.7242,
      "step": 698
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.30828067660331726,
      "learning_rate": 1.857743158757815e-05,
      "loss": 0.7609,
      "step": 699
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.517676055431366,
      "learning_rate": 1.8575381777185614e-05,
      "loss": 0.7249,
      "step": 700
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.3971892297267914,
      "learning_rate": 1.8573331966793074e-05,
      "loss": 0.7275,
      "step": 701
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.33746176958084106,
      "learning_rate": 1.8571282156400534e-05,
      "loss": 0.7576,
      "step": 702
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.32515254616737366,
      "learning_rate": 1.8569232346007995e-05,
      "loss": 0.8303,
      "step": 703
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.3975939452648163,
      "learning_rate": 1.8567182535615458e-05,
      "loss": 0.7686,
      "step": 704
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.37193068861961365,
      "learning_rate": 1.8565132725222918e-05,
      "loss": 0.6498,
      "step": 705
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.46627968549728394,
      "learning_rate": 1.856308291483038e-05,
      "loss": 0.6542,
      "step": 706
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.32185736298561096,
      "learning_rate": 1.856103310443784e-05,
      "loss": 0.7644,
      "step": 707
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.3419387638568878,
      "learning_rate": 1.8558983294045302e-05,
      "loss": 0.8139,
      "step": 708
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.34390830993652344,
      "learning_rate": 1.8556933483652762e-05,
      "loss": 0.6869,
      "step": 709
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.30676236748695374,
      "learning_rate": 1.8554883673260226e-05,
      "loss": 0.7712,
      "step": 710
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.38774573802948,
      "learning_rate": 1.8552833862867686e-05,
      "loss": 0.6645,
      "step": 711
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.3417278230190277,
      "learning_rate": 1.855078405247515e-05,
      "loss": 0.7311,
      "step": 712
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.31306809186935425,
      "learning_rate": 1.854873424208261e-05,
      "loss": 0.8923,
      "step": 713
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.3018990159034729,
      "learning_rate": 1.854668443169007e-05,
      "loss": 0.8087,
      "step": 714
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.27663567662239075,
      "learning_rate": 1.8544634621297533e-05,
      "loss": 0.8361,
      "step": 715
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.5003049373626709,
      "learning_rate": 1.8542584810904994e-05,
      "loss": 0.6641,
      "step": 716
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.3594311773777008,
      "learning_rate": 1.8540535000512454e-05,
      "loss": 0.6216,
      "step": 717
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.3374612331390381,
      "learning_rate": 1.8538485190119914e-05,
      "loss": 0.7658,
      "step": 718
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.3757317364215851,
      "learning_rate": 1.8536435379727377e-05,
      "loss": 0.7006,
      "step": 719
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.4909655451774597,
      "learning_rate": 1.8534385569334838e-05,
      "loss": 0.7254,
      "step": 720
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.4365713596343994,
      "learning_rate": 1.8532335758942298e-05,
      "loss": 0.7363,
      "step": 721
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.3125793933868408,
      "learning_rate": 1.853028594854976e-05,
      "loss": 0.7207,
      "step": 722
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.4891459047794342,
      "learning_rate": 1.852823613815722e-05,
      "loss": 0.7067,
      "step": 723
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.3163311779499054,
      "learning_rate": 1.8526186327764685e-05,
      "loss": 0.6401,
      "step": 724
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.31483927369117737,
      "learning_rate": 1.8524136517372145e-05,
      "loss": 0.7027,
      "step": 725
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.35486382246017456,
      "learning_rate": 1.8522086706979605e-05,
      "loss": 0.6556,
      "step": 726
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.3418521285057068,
      "learning_rate": 1.852003689658707e-05,
      "loss": 0.7576,
      "step": 727
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.2981542646884918,
      "learning_rate": 1.851798708619453e-05,
      "loss": 0.8013,
      "step": 728
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.3128420412540436,
      "learning_rate": 1.851593727580199e-05,
      "loss": 0.7103,
      "step": 729
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.3254688084125519,
      "learning_rate": 1.851388746540945e-05,
      "loss": 0.728,
      "step": 730
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.31213757395744324,
      "learning_rate": 1.8511837655016913e-05,
      "loss": 0.728,
      "step": 731
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.28854265809059143,
      "learning_rate": 1.8509787844624373e-05,
      "loss": 0.7557,
      "step": 732
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.3398171365261078,
      "learning_rate": 1.8507738034231833e-05,
      "loss": 0.6799,
      "step": 733
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.34003064036369324,
      "learning_rate": 1.8505688223839297e-05,
      "loss": 0.7119,
      "step": 734
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.39870837330818176,
      "learning_rate": 1.8503638413446757e-05,
      "loss": 0.8255,
      "step": 735
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.31319308280944824,
      "learning_rate": 1.850158860305422e-05,
      "loss": 0.8004,
      "step": 736
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.29807278513908386,
      "learning_rate": 1.849953879266168e-05,
      "loss": 0.8058,
      "step": 737
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.4358442425727844,
      "learning_rate": 1.849748898226914e-05,
      "loss": 0.7133,
      "step": 738
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.37343865633010864,
      "learning_rate": 1.8495439171876604e-05,
      "loss": 0.6576,
      "step": 739
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.34897083044052124,
      "learning_rate": 1.8493389361484065e-05,
      "loss": 0.7354,
      "step": 740
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.38121914863586426,
      "learning_rate": 1.8491339551091525e-05,
      "loss": 0.8388,
      "step": 741
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.4444100558757782,
      "learning_rate": 1.848928974069899e-05,
      "loss": 0.6765,
      "step": 742
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.3391948938369751,
      "learning_rate": 1.848723993030645e-05,
      "loss": 0.8228,
      "step": 743
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.3986491858959198,
      "learning_rate": 1.848519011991391e-05,
      "loss": 0.7897,
      "step": 744
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.37333256006240845,
      "learning_rate": 1.848314030952137e-05,
      "loss": 0.7476,
      "step": 745
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.43750837445259094,
      "learning_rate": 1.8481090499128832e-05,
      "loss": 0.7887,
      "step": 746
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.3638215959072113,
      "learning_rate": 1.8479040688736293e-05,
      "loss": 0.7321,
      "step": 747
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.32453709840774536,
      "learning_rate": 1.8476990878343756e-05,
      "loss": 0.6265,
      "step": 748
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.4802641272544861,
      "learning_rate": 1.8474941067951216e-05,
      "loss": 0.7587,
      "step": 749
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.43956223130226135,
      "learning_rate": 1.847289125755868e-05,
      "loss": 0.6881,
      "step": 750
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.32497453689575195,
      "learning_rate": 1.847084144716614e-05,
      "loss": 0.7811,
      "step": 751
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.4412628710269928,
      "learning_rate": 1.84687916367736e-05,
      "loss": 0.6482,
      "step": 752
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.40573760867118835,
      "learning_rate": 1.846674182638106e-05,
      "loss": 0.6994,
      "step": 753
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.5959574580192566,
      "learning_rate": 1.8464692015988524e-05,
      "loss": 0.5326,
      "step": 754
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.3822227418422699,
      "learning_rate": 1.8462642205595984e-05,
      "loss": 0.6461,
      "step": 755
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.3202332854270935,
      "learning_rate": 1.8460592395203444e-05,
      "loss": 0.7033,
      "step": 756
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.5029582381248474,
      "learning_rate": 1.8458542584810904e-05,
      "loss": 0.8372,
      "step": 757
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.35861167311668396,
      "learning_rate": 1.8456492774418368e-05,
      "loss": 0.8276,
      "step": 758
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.5442591905593872,
      "learning_rate": 1.8454442964025828e-05,
      "loss": 0.6844,
      "step": 759
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.3382883071899414,
      "learning_rate": 1.845239315363329e-05,
      "loss": 0.7545,
      "step": 760
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.3822135031223297,
      "learning_rate": 1.8450343343240752e-05,
      "loss": 0.6785,
      "step": 761
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.3524187207221985,
      "learning_rate": 1.8448293532848215e-05,
      "loss": 0.7035,
      "step": 762
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.5718131065368652,
      "learning_rate": 1.8446243722455675e-05,
      "loss": 0.6628,
      "step": 763
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.5670221447944641,
      "learning_rate": 1.8444193912063136e-05,
      "loss": 0.7467,
      "step": 764
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.6257759928703308,
      "learning_rate": 1.8442144101670596e-05,
      "loss": 0.5425,
      "step": 765
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.3476133644580841,
      "learning_rate": 1.844009429127806e-05,
      "loss": 0.7651,
      "step": 766
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.3382849395275116,
      "learning_rate": 1.843804448088552e-05,
      "loss": 0.666,
      "step": 767
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.35760655999183655,
      "learning_rate": 1.843599467049298e-05,
      "loss": 0.7683,
      "step": 768
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.345113068819046,
      "learning_rate": 1.843394486010044e-05,
      "loss": 0.8237,
      "step": 769
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.3445224165916443,
      "learning_rate": 1.8431895049707903e-05,
      "loss": 0.7544,
      "step": 770
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.34835100173950195,
      "learning_rate": 1.8429845239315364e-05,
      "loss": 0.7118,
      "step": 771
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.3312264680862427,
      "learning_rate": 1.8427795428922827e-05,
      "loss": 0.5742,
      "step": 772
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.32391804456710815,
      "learning_rate": 1.8425745618530287e-05,
      "loss": 0.8163,
      "step": 773
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.3408675193786621,
      "learning_rate": 1.842369580813775e-05,
      "loss": 0.7516,
      "step": 774
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.31878426671028137,
      "learning_rate": 1.842164599774521e-05,
      "loss": 0.7788,
      "step": 775
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.35067152976989746,
      "learning_rate": 1.841959618735267e-05,
      "loss": 0.7482,
      "step": 776
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.3820863664150238,
      "learning_rate": 1.8417546376960135e-05,
      "loss": 0.6476,
      "step": 777
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.3818586468696594,
      "learning_rate": 1.8415496566567595e-05,
      "loss": 0.6988,
      "step": 778
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.37748727202415466,
      "learning_rate": 1.8413446756175055e-05,
      "loss": 0.6549,
      "step": 779
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.3882914185523987,
      "learning_rate": 1.8411396945782515e-05,
      "loss": 0.7389,
      "step": 780
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.3661918640136719,
      "learning_rate": 1.840934713538998e-05,
      "loss": 0.7472,
      "step": 781
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.38381168246269226,
      "learning_rate": 1.840729732499744e-05,
      "loss": 0.8291,
      "step": 782
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.38169392943382263,
      "learning_rate": 1.84052475146049e-05,
      "loss": 0.6882,
      "step": 783
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.36396491527557373,
      "learning_rate": 1.8403197704212363e-05,
      "loss": 0.7248,
      "step": 784
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.32172074913978577,
      "learning_rate": 1.8401147893819823e-05,
      "loss": 0.7095,
      "step": 785
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.38077113032341003,
      "learning_rate": 1.8399098083427286e-05,
      "loss": 0.7364,
      "step": 786
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.3368634581565857,
      "learning_rate": 1.8397048273034746e-05,
      "loss": 0.7344,
      "step": 787
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.3104882538318634,
      "learning_rate": 1.8394998462642207e-05,
      "loss": 0.7972,
      "step": 788
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.39613014459609985,
      "learning_rate": 1.839294865224967e-05,
      "loss": 0.6937,
      "step": 789
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.4015425741672516,
      "learning_rate": 1.839089884185713e-05,
      "loss": 0.6905,
      "step": 790
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.4483844041824341,
      "learning_rate": 1.838884903146459e-05,
      "loss": 0.741,
      "step": 791
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.4784570634365082,
      "learning_rate": 1.838679922107205e-05,
      "loss": 0.6994,
      "step": 792
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.38381892442703247,
      "learning_rate": 1.8384749410679514e-05,
      "loss": 0.7228,
      "step": 793
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.5806990265846252,
      "learning_rate": 1.8382699600286974e-05,
      "loss": 0.7639,
      "step": 794
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.4452645778656006,
      "learning_rate": 1.8380649789894435e-05,
      "loss": 0.6363,
      "step": 795
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.38077521324157715,
      "learning_rate": 1.8378599979501898e-05,
      "loss": 0.6264,
      "step": 796
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.6829047799110413,
      "learning_rate": 1.8376550169109358e-05,
      "loss": 0.4541,
      "step": 797
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.3296494781970978,
      "learning_rate": 1.8374500358716822e-05,
      "loss": 0.803,
      "step": 798
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.45602652430534363,
      "learning_rate": 1.8372450548324282e-05,
      "loss": 0.7552,
      "step": 799
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.31666791439056396,
      "learning_rate": 1.8370400737931742e-05,
      "loss": 0.6335,
      "step": 800
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.44298651814460754,
      "learning_rate": 1.8368350927539206e-05,
      "loss": 0.6915,
      "step": 801
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.47092998027801514,
      "learning_rate": 1.8366301117146666e-05,
      "loss": 0.7799,
      "step": 802
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.7840266823768616,
      "learning_rate": 1.8364251306754126e-05,
      "loss": 0.7154,
      "step": 803
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.38121023774147034,
      "learning_rate": 1.836220149636159e-05,
      "loss": 0.7159,
      "step": 804
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.767606794834137,
      "learning_rate": 1.836015168596905e-05,
      "loss": 0.7212,
      "step": 805
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.8547561168670654,
      "learning_rate": 1.835810187557651e-05,
      "loss": 0.7215,
      "step": 806
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.37105560302734375,
      "learning_rate": 1.835605206518397e-05,
      "loss": 0.7077,
      "step": 807
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.49927404522895813,
      "learning_rate": 1.8354002254791434e-05,
      "loss": 0.7616,
      "step": 808
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.7632033228874207,
      "learning_rate": 1.8351952444398894e-05,
      "loss": 0.6147,
      "step": 809
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.6649359464645386,
      "learning_rate": 1.8349902634006357e-05,
      "loss": 0.7497,
      "step": 810
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.5113076567649841,
      "learning_rate": 1.8347852823613817e-05,
      "loss": 0.665,
      "step": 811
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.43120482563972473,
      "learning_rate": 1.834580301322128e-05,
      "loss": 0.5366,
      "step": 812
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.6887221932411194,
      "learning_rate": 1.834375320282874e-05,
      "loss": 0.7336,
      "step": 813
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.5085777640342712,
      "learning_rate": 1.83417033924362e-05,
      "loss": 0.7838,
      "step": 814
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.6687688827514648,
      "learning_rate": 1.833965358204366e-05,
      "loss": 0.6043,
      "step": 815
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.4470117688179016,
      "learning_rate": 1.8337603771651125e-05,
      "loss": 0.7853,
      "step": 816
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.6082642674446106,
      "learning_rate": 1.8335553961258585e-05,
      "loss": 0.6707,
      "step": 817
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.556739091873169,
      "learning_rate": 1.8333504150866045e-05,
      "loss": 0.6384,
      "step": 818
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.593297004699707,
      "learning_rate": 1.8331454340473506e-05,
      "loss": 0.7156,
      "step": 819
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.4088369309902191,
      "learning_rate": 1.832940453008097e-05,
      "loss": 0.6469,
      "step": 820
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.5740868449211121,
      "learning_rate": 1.832735471968843e-05,
      "loss": 0.6262,
      "step": 821
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.4739842414855957,
      "learning_rate": 1.8325304909295893e-05,
      "loss": 0.7095,
      "step": 822
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.5292513966560364,
      "learning_rate": 1.8323255098903353e-05,
      "loss": 0.6413,
      "step": 823
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.3731658458709717,
      "learning_rate": 1.8321205288510816e-05,
      "loss": 0.7914,
      "step": 824
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.39712899923324585,
      "learning_rate": 1.8319155478118277e-05,
      "loss": 0.6274,
      "step": 825
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.4137084484100342,
      "learning_rate": 1.8317105667725737e-05,
      "loss": 0.895,
      "step": 826
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.5887430906295776,
      "learning_rate": 1.8315055857333197e-05,
      "loss": 0.7754,
      "step": 827
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.4509851336479187,
      "learning_rate": 1.831300604694066e-05,
      "loss": 0.7488,
      "step": 828
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.35678544640541077,
      "learning_rate": 1.831095623654812e-05,
      "loss": 0.732,
      "step": 829
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.39582085609436035,
      "learning_rate": 1.830890642615558e-05,
      "loss": 0.7189,
      "step": 830
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.3869258165359497,
      "learning_rate": 1.8306856615763044e-05,
      "loss": 0.8149,
      "step": 831
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.8728341460227966,
      "learning_rate": 1.8304806805370505e-05,
      "loss": 0.719,
      "step": 832
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.39453545212745667,
      "learning_rate": 1.8302756994977965e-05,
      "loss": 0.6269,
      "step": 833
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.39652642607688904,
      "learning_rate": 1.8300707184585428e-05,
      "loss": 0.6767,
      "step": 834
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.5281271934509277,
      "learning_rate": 1.829865737419289e-05,
      "loss": 0.7747,
      "step": 835
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.4026881158351898,
      "learning_rate": 1.8296607563800352e-05,
      "loss": 0.7466,
      "step": 836
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.38571298122406006,
      "learning_rate": 1.8294557753407812e-05,
      "loss": 0.755,
      "step": 837
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.393897145986557,
      "learning_rate": 1.8292507943015272e-05,
      "loss": 0.6925,
      "step": 838
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.3204295337200165,
      "learning_rate": 1.8290458132622736e-05,
      "loss": 0.6842,
      "step": 839
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.6132552623748779,
      "learning_rate": 1.8288408322230196e-05,
      "loss": 0.6335,
      "step": 840
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.4217650592327118,
      "learning_rate": 1.8286358511837656e-05,
      "loss": 0.697,
      "step": 841
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.423797607421875,
      "learning_rate": 1.8284308701445116e-05,
      "loss": 0.7175,
      "step": 842
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.4340386986732483,
      "learning_rate": 1.828225889105258e-05,
      "loss": 0.5318,
      "step": 843
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.5517090559005737,
      "learning_rate": 1.828020908066004e-05,
      "loss": 0.5481,
      "step": 844
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.48700082302093506,
      "learning_rate": 1.82781592702675e-05,
      "loss": 0.6788,
      "step": 845
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.34000372886657715,
      "learning_rate": 1.8276109459874964e-05,
      "loss": 0.7436,
      "step": 846
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.38510167598724365,
      "learning_rate": 1.8274059649482424e-05,
      "loss": 0.6562,
      "step": 847
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.43188080191612244,
      "learning_rate": 1.8272009839089887e-05,
      "loss": 0.7289,
      "step": 848
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.42137399315834045,
      "learning_rate": 1.8269960028697348e-05,
      "loss": 0.7173,
      "step": 849
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.38572052121162415,
      "learning_rate": 1.8267910218304808e-05,
      "loss": 0.7576,
      "step": 850
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.40080949664115906,
      "learning_rate": 1.826586040791227e-05,
      "loss": 0.6614,
      "step": 851
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.3580224812030792,
      "learning_rate": 1.826381059751973e-05,
      "loss": 0.6294,
      "step": 852
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.46862682700157166,
      "learning_rate": 1.8261760787127192e-05,
      "loss": 0.7558,
      "step": 853
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.40485680103302,
      "learning_rate": 1.8259710976734652e-05,
      "loss": 0.7162,
      "step": 854
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.39934080839157104,
      "learning_rate": 1.8257661166342115e-05,
      "loss": 0.7318,
      "step": 855
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.42829325795173645,
      "learning_rate": 1.8255611355949576e-05,
      "loss": 0.7367,
      "step": 856
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.500968337059021,
      "learning_rate": 1.8253561545557036e-05,
      "loss": 0.7091,
      "step": 857
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.3849359452724457,
      "learning_rate": 1.82515117351645e-05,
      "loss": 0.6623,
      "step": 858
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.40085428953170776,
      "learning_rate": 1.824946192477196e-05,
      "loss": 0.6305,
      "step": 859
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.3848453164100647,
      "learning_rate": 1.8247412114379423e-05,
      "loss": 0.6868,
      "step": 860
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.41218090057373047,
      "learning_rate": 1.8245362303986883e-05,
      "loss": 0.6544,
      "step": 861
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.3708559274673462,
      "learning_rate": 1.8243312493594347e-05,
      "loss": 0.6551,
      "step": 862
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.4281514883041382,
      "learning_rate": 1.8241262683201807e-05,
      "loss": 0.5519,
      "step": 863
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.5886114835739136,
      "learning_rate": 1.8239212872809267e-05,
      "loss": 0.4795,
      "step": 864
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.5138920545578003,
      "learning_rate": 1.8237163062416727e-05,
      "loss": 0.7296,
      "step": 865
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.3646332323551178,
      "learning_rate": 1.823511325202419e-05,
      "loss": 0.7963,
      "step": 866
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.34660905599594116,
      "learning_rate": 1.823306344163165e-05,
      "loss": 0.7459,
      "step": 867
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.7398350238800049,
      "learning_rate": 1.823101363123911e-05,
      "loss": 0.6053,
      "step": 868
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.34717774391174316,
      "learning_rate": 1.822896382084657e-05,
      "loss": 0.6942,
      "step": 869
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.4412369728088379,
      "learning_rate": 1.8226914010454035e-05,
      "loss": 0.6657,
      "step": 870
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.44629335403442383,
      "learning_rate": 1.8224864200061495e-05,
      "loss": 0.777,
      "step": 871
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.42369726300239563,
      "learning_rate": 1.822281438966896e-05,
      "loss": 0.745,
      "step": 872
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.3678620755672455,
      "learning_rate": 1.822076457927642e-05,
      "loss": 0.552,
      "step": 873
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.4654993414878845,
      "learning_rate": 1.8218714768883882e-05,
      "loss": 0.6133,
      "step": 874
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.43903836607933044,
      "learning_rate": 1.8216664958491342e-05,
      "loss": 0.6503,
      "step": 875
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.4525679051876068,
      "learning_rate": 1.8214615148098803e-05,
      "loss": 0.6991,
      "step": 876
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.40005528926849365,
      "learning_rate": 1.8212565337706263e-05,
      "loss": 0.6968,
      "step": 877
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.6973149180412292,
      "learning_rate": 1.8210515527313726e-05,
      "loss": 0.6795,
      "step": 878
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.39223435521125793,
      "learning_rate": 1.8208465716921186e-05,
      "loss": 0.5328,
      "step": 879
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.7147462964057922,
      "learning_rate": 1.8206415906528647e-05,
      "loss": 0.6555,
      "step": 880
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.3760982155799866,
      "learning_rate": 1.8204366096136107e-05,
      "loss": 0.7856,
      "step": 881
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.6709074378013611,
      "learning_rate": 1.820231628574357e-05,
      "loss": 0.5288,
      "step": 882
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.3951513171195984,
      "learning_rate": 1.820026647535103e-05,
      "loss": 0.6501,
      "step": 883
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.9724901914596558,
      "learning_rate": 1.8198216664958494e-05,
      "loss": 0.5904,
      "step": 884
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.3793524503707886,
      "learning_rate": 1.8196166854565954e-05,
      "loss": 0.6266,
      "step": 885
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.5935982465744019,
      "learning_rate": 1.8194117044173418e-05,
      "loss": 0.6587,
      "step": 886
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.452092707157135,
      "learning_rate": 1.8192067233780878e-05,
      "loss": 0.7845,
      "step": 887
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.4551563858985901,
      "learning_rate": 1.8190017423388338e-05,
      "loss": 0.6162,
      "step": 888
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.43898817896842957,
      "learning_rate": 1.8187967612995798e-05,
      "loss": 0.5888,
      "step": 889
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.394233375787735,
      "learning_rate": 1.8185917802603262e-05,
      "loss": 0.6493,
      "step": 890
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.4864000678062439,
      "learning_rate": 1.8183867992210722e-05,
      "loss": 0.6861,
      "step": 891
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.5025405883789062,
      "learning_rate": 1.8181818181818182e-05,
      "loss": 0.6503,
      "step": 892
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.4941229522228241,
      "learning_rate": 1.8179768371425646e-05,
      "loss": 0.5629,
      "step": 893
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.40720701217651367,
      "learning_rate": 1.8177718561033106e-05,
      "loss": 0.8052,
      "step": 894
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.42570561170578003,
      "learning_rate": 1.8175668750640566e-05,
      "loss": 0.7186,
      "step": 895
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.43226298689842224,
      "learning_rate": 1.817361894024803e-05,
      "loss": 0.757,
      "step": 896
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.7076277136802673,
      "learning_rate": 1.817156912985549e-05,
      "loss": 0.712,
      "step": 897
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.440159410238266,
      "learning_rate": 1.8169519319462953e-05,
      "loss": 0.7014,
      "step": 898
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.39494553208351135,
      "learning_rate": 1.8167469509070413e-05,
      "loss": 0.7205,
      "step": 899
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.3951118588447571,
      "learning_rate": 1.8165419698677874e-05,
      "loss": 0.6503,
      "step": 900
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.5288782119750977,
      "learning_rate": 1.8163369888285337e-05,
      "loss": 0.6108,
      "step": 901
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.6907683610916138,
      "learning_rate": 1.8161320077892797e-05,
      "loss": 0.6007,
      "step": 902
    },
    {
      "epoch": 0.19,
      "grad_norm": 0.3930463194847107,
      "learning_rate": 1.8159270267500257e-05,
      "loss": 0.6818,
      "step": 903
    },
    {
      "epoch": 0.19,
      "grad_norm": 0.4185275435447693,
      "learning_rate": 1.8157220457107718e-05,
      "loss": 0.7209,
      "step": 904
    },
    {
      "epoch": 0.19,
      "grad_norm": 0.7686632871627808,
      "learning_rate": 1.815517064671518e-05,
      "loss": 0.7527,
      "step": 905
    },
    {
      "epoch": 0.19,
      "grad_norm": 0.5023302435874939,
      "learning_rate": 1.815312083632264e-05,
      "loss": 0.7128,
      "step": 906
    },
    {
      "epoch": 0.19,
      "grad_norm": 0.5007780194282532,
      "learning_rate": 1.81510710259301e-05,
      "loss": 0.608,
      "step": 907
    },
    {
      "epoch": 0.19,
      "grad_norm": 0.6725736856460571,
      "learning_rate": 1.8149021215537565e-05,
      "loss": 0.7584,
      "step": 908
    },
    {
      "epoch": 0.19,
      "grad_norm": 0.931692361831665,
      "learning_rate": 1.8146971405145025e-05,
      "loss": 0.7622,
      "step": 909
    },
    {
      "epoch": 0.19,
      "grad_norm": 0.39940518140792847,
      "learning_rate": 1.814492159475249e-05,
      "loss": 0.7644,
      "step": 910
    },
    {
      "epoch": 0.19,
      "grad_norm": 0.4073428213596344,
      "learning_rate": 1.814287178435995e-05,
      "loss": 0.7916,
      "step": 911
    },
    {
      "epoch": 0.19,
      "grad_norm": 0.7836171388626099,
      "learning_rate": 1.814082197396741e-05,
      "loss": 0.589,
      "step": 912
    },
    {
      "epoch": 0.19,
      "grad_norm": 0.4967021644115448,
      "learning_rate": 1.8138772163574873e-05,
      "loss": 0.6699,
      "step": 913
    },
    {
      "epoch": 0.19,
      "grad_norm": 0.685780942440033,
      "learning_rate": 1.8136722353182333e-05,
      "loss": 0.6944,
      "step": 914
    },
    {
      "epoch": 0.19,
      "grad_norm": 0.45136794447898865,
      "learning_rate": 1.8134672542789793e-05,
      "loss": 0.5489,
      "step": 915
    },
    {
      "epoch": 0.19,
      "grad_norm": 0.47103267908096313,
      "learning_rate": 1.8132622732397253e-05,
      "loss": 0.7089,
      "step": 916
    },
    {
      "epoch": 0.19,
      "grad_norm": 1.4208459854125977,
      "learning_rate": 1.8130572922004717e-05,
      "loss": 0.672,
      "step": 917
    },
    {
      "epoch": 0.19,
      "grad_norm": 0.9348700046539307,
      "learning_rate": 1.8128523111612177e-05,
      "loss": 0.6471,
      "step": 918
    },
    {
      "epoch": 0.19,
      "grad_norm": 0.3924078047275543,
      "learning_rate": 1.8126473301219637e-05,
      "loss": 0.7447,
      "step": 919
    },
    {
      "epoch": 0.19,
      "grad_norm": 0.9750374555587769,
      "learning_rate": 1.81244234908271e-05,
      "loss": 0.7087,
      "step": 920
    },
    {
      "epoch": 0.19,
      "grad_norm": 1.7007211446762085,
      "learning_rate": 1.812237368043456e-05,
      "loss": 0.5351,
      "step": 921
    },
    {
      "epoch": 0.19,
      "grad_norm": 0.442564457654953,
      "learning_rate": 1.8120323870042024e-05,
      "loss": 0.6833,
      "step": 922
    },
    {
      "epoch": 0.19,
      "grad_norm": 0.45591282844543457,
      "learning_rate": 1.8118274059649484e-05,
      "loss": 0.5787,
      "step": 923
    },
    {
      "epoch": 0.19,
      "grad_norm": 1.5567580461502075,
      "learning_rate": 1.8116224249256945e-05,
      "loss": 0.7134,
      "step": 924
    },
    {
      "epoch": 0.19,
      "grad_norm": 1.2040061950683594,
      "learning_rate": 1.8114174438864408e-05,
      "loss": 0.6736,
      "step": 925
    },
    {
      "epoch": 0.19,
      "grad_norm": 0.45492762327194214,
      "learning_rate": 1.8112124628471868e-05,
      "loss": 0.554,
      "step": 926
    },
    {
      "epoch": 0.19,
      "grad_norm": 0.5635227560997009,
      "learning_rate": 1.811007481807933e-05,
      "loss": 0.6058,
      "step": 927
    },
    {
      "epoch": 0.19,
      "grad_norm": 0.49082639813423157,
      "learning_rate": 1.8108025007686792e-05,
      "loss": 0.7288,
      "step": 928
    },
    {
      "epoch": 0.19,
      "grad_norm": 0.4423486888408661,
      "learning_rate": 1.8105975197294252e-05,
      "loss": 0.6226,
      "step": 929
    },
    {
      "epoch": 0.19,
      "grad_norm": 0.4169524610042572,
      "learning_rate": 1.8103925386901712e-05,
      "loss": 0.6772,
      "step": 930
    },
    {
      "epoch": 0.19,
      "grad_norm": 0.5752652287483215,
      "learning_rate": 1.8101875576509172e-05,
      "loss": 0.7031,
      "step": 931
    },
    {
      "epoch": 0.19,
      "grad_norm": 0.5587458610534668,
      "learning_rate": 1.8099825766116636e-05,
      "loss": 0.6021,
      "step": 932
    },
    {
      "epoch": 0.19,
      "grad_norm": 0.45150548219680786,
      "learning_rate": 1.8097775955724096e-05,
      "loss": 0.7215,
      "step": 933
    },
    {
      "epoch": 0.19,
      "grad_norm": 0.867041826248169,
      "learning_rate": 1.809572614533156e-05,
      "loss": 0.6352,
      "step": 934
    },
    {
      "epoch": 0.19,
      "grad_norm": 0.6960977911949158,
      "learning_rate": 1.809367633493902e-05,
      "loss": 0.5963,
      "step": 935
    },
    {
      "epoch": 0.19,
      "grad_norm": 0.44052258133888245,
      "learning_rate": 1.809162652454648e-05,
      "loss": 0.6084,
      "step": 936
    },
    {
      "epoch": 0.19,
      "grad_norm": 0.42431822419166565,
      "learning_rate": 1.8089576714153944e-05,
      "loss": 0.7031,
      "step": 937
    },
    {
      "epoch": 0.19,
      "grad_norm": 0.5878831148147583,
      "learning_rate": 1.8087526903761404e-05,
      "loss": 0.663,
      "step": 938
    },
    {
      "epoch": 0.19,
      "grad_norm": 0.7023143172264099,
      "learning_rate": 1.8085477093368864e-05,
      "loss": 0.7178,
      "step": 939
    },
    {
      "epoch": 0.19,
      "grad_norm": 1.051466703414917,
      "learning_rate": 1.8083427282976327e-05,
      "loss": 0.7182,
      "step": 940
    },
    {
      "epoch": 0.19,
      "grad_norm": 0.44801533222198486,
      "learning_rate": 1.8081377472583788e-05,
      "loss": 0.623,
      "step": 941
    },
    {
      "epoch": 0.19,
      "grad_norm": 0.7694495916366577,
      "learning_rate": 1.8079327662191248e-05,
      "loss": 0.6695,
      "step": 942
    },
    {
      "epoch": 0.19,
      "grad_norm": 1.1408681869506836,
      "learning_rate": 1.8077277851798708e-05,
      "loss": 0.531,
      "step": 943
    },
    {
      "epoch": 0.19,
      "grad_norm": 0.7007236480712891,
      "learning_rate": 1.807522804140617e-05,
      "loss": 0.6049,
      "step": 944
    },
    {
      "epoch": 0.19,
      "grad_norm": 0.49812501668930054,
      "learning_rate": 1.807317823101363e-05,
      "loss": 0.7247,
      "step": 945
    },
    {
      "epoch": 0.19,
      "grad_norm": 0.47634437680244446,
      "learning_rate": 1.8071128420621092e-05,
      "loss": 0.6715,
      "step": 946
    },
    {
      "epoch": 0.19,
      "grad_norm": 0.703545331954956,
      "learning_rate": 1.8069078610228555e-05,
      "loss": 0.6589,
      "step": 947
    },
    {
      "epoch": 0.19,
      "grad_norm": 0.5607951283454895,
      "learning_rate": 1.8067028799836016e-05,
      "loss": 0.7381,
      "step": 948
    },
    {
      "epoch": 0.19,
      "grad_norm": 0.623207688331604,
      "learning_rate": 1.806497898944348e-05,
      "loss": 0.7697,
      "step": 949
    },
    {
      "epoch": 0.19,
      "grad_norm": 0.5086536407470703,
      "learning_rate": 1.806292917905094e-05,
      "loss": 0.6564,
      "step": 950
    },
    {
      "epoch": 0.19,
      "grad_norm": 0.5248609781265259,
      "learning_rate": 1.8060879368658403e-05,
      "loss": 0.6345,
      "step": 951
    },
    {
      "epoch": 0.2,
      "grad_norm": 0.615601658821106,
      "learning_rate": 1.8058829558265863e-05,
      "loss": 0.7065,
      "step": 952
    },
    {
      "epoch": 0.2,
      "grad_norm": 0.6393739581108093,
      "learning_rate": 1.8056779747873323e-05,
      "loss": 0.7671,
      "step": 953
    },
    {
      "epoch": 0.2,
      "grad_norm": 0.5130853056907654,
      "learning_rate": 1.8054729937480783e-05,
      "loss": 0.7325,
      "step": 954
    },
    {
      "epoch": 0.2,
      "grad_norm": 0.43274986743927,
      "learning_rate": 1.8052680127088247e-05,
      "loss": 0.6656,
      "step": 955
    },
    {
      "epoch": 0.2,
      "grad_norm": 0.4293273687362671,
      "learning_rate": 1.8050630316695707e-05,
      "loss": 0.6029,
      "step": 956
    },
    {
      "epoch": 0.2,
      "grad_norm": 0.5159664154052734,
      "learning_rate": 1.8048580506303167e-05,
      "loss": 0.686,
      "step": 957
    },
    {
      "epoch": 0.2,
      "grad_norm": 0.5480853319168091,
      "learning_rate": 1.8046530695910627e-05,
      "loss": 0.6321,
      "step": 958
    },
    {
      "epoch": 0.2,
      "grad_norm": 0.6391343474388123,
      "learning_rate": 1.804448088551809e-05,
      "loss": 0.6256,
      "step": 959
    },
    {
      "epoch": 0.2,
      "grad_norm": 0.4127422869205475,
      "learning_rate": 1.804243107512555e-05,
      "loss": 0.7422,
      "step": 960
    },
    {
      "epoch": 0.2,
      "grad_norm": 0.5759455561637878,
      "learning_rate": 1.8040381264733015e-05,
      "loss": 0.7446,
      "step": 961
    },
    {
      "epoch": 0.2,
      "grad_norm": 1.721444010734558,
      "learning_rate": 1.8038331454340475e-05,
      "loss": 0.6502,
      "step": 962
    },
    {
      "epoch": 0.2,
      "grad_norm": 0.7205697298049927,
      "learning_rate": 1.8036281643947938e-05,
      "loss": 0.6732,
      "step": 963
    },
    {
      "epoch": 0.2,
      "grad_norm": 0.47355058789253235,
      "learning_rate": 1.80342318335554e-05,
      "loss": 0.6802,
      "step": 964
    },
    {
      "epoch": 0.2,
      "grad_norm": 0.42176657915115356,
      "learning_rate": 1.803218202316286e-05,
      "loss": 0.4875,
      "step": 965
    },
    {
      "epoch": 0.2,
      "grad_norm": 0.8192176222801208,
      "learning_rate": 1.803013221277032e-05,
      "loss": 0.6398,
      "step": 966
    },
    {
      "epoch": 0.2,
      "grad_norm": 1.2861359119415283,
      "learning_rate": 1.8028082402377782e-05,
      "loss": 0.5773,
      "step": 967
    },
    {
      "epoch": 0.2,
      "grad_norm": 0.4470946192741394,
      "learning_rate": 1.8026032591985243e-05,
      "loss": 0.5842,
      "step": 968
    },
    {
      "epoch": 0.2,
      "grad_norm": 0.44402486085891724,
      "learning_rate": 1.8023982781592703e-05,
      "loss": 0.665,
      "step": 969
    },
    {
      "epoch": 0.2,
      "grad_norm": 1.1630643606185913,
      "learning_rate": 1.8021932971200163e-05,
      "loss": 0.6535,
      "step": 970
    },
    {
      "epoch": 0.2,
      "grad_norm": 0.7565960884094238,
      "learning_rate": 1.8019883160807626e-05,
      "loss": 0.7613,
      "step": 971
    },
    {
      "epoch": 0.2,
      "grad_norm": 0.6709368228912354,
      "learning_rate": 1.8017833350415087e-05,
      "loss": 0.6905,
      "step": 972
    },
    {
      "epoch": 0.2,
      "grad_norm": 0.5808483958244324,
      "learning_rate": 1.801578354002255e-05,
      "loss": 0.6128,
      "step": 973
    },
    {
      "epoch": 0.2,
      "grad_norm": 0.6312974691390991,
      "learning_rate": 1.801373372963001e-05,
      "loss": 0.479,
      "step": 974
    },
    {
      "epoch": 0.2,
      "grad_norm": 0.8591532111167908,
      "learning_rate": 1.8011683919237474e-05,
      "loss": 0.5951,
      "step": 975
    },
    {
      "epoch": 0.2,
      "grad_norm": 0.9757481217384338,
      "learning_rate": 1.8009634108844934e-05,
      "loss": 0.666,
      "step": 976
    },
    {
      "epoch": 0.2,
      "grad_norm": 0.6285104155540466,
      "learning_rate": 1.8007584298452394e-05,
      "loss": 0.6446,
      "step": 977
    },
    {
      "epoch": 0.2,
      "grad_norm": 0.9877322316169739,
      "learning_rate": 1.8005534488059858e-05,
      "loss": 0.7462,
      "step": 978
    },
    {
      "epoch": 0.2,
      "grad_norm": 1.3466852903366089,
      "learning_rate": 1.8003484677667318e-05,
      "loss": 0.651,
      "step": 979
    },
    {
      "epoch": 0.2,
      "grad_norm": 1.0339725017547607,
      "learning_rate": 1.8001434867274778e-05,
      "loss": 0.6854,
      "step": 980
    },
    {
      "epoch": 0.2,
      "grad_norm": 0.48022592067718506,
      "learning_rate": 1.7999385056882238e-05,
      "loss": 0.6729,
      "step": 981
    },
    {
      "epoch": 0.2,
      "grad_norm": 0.37813159823417664,
      "learning_rate": 1.7997335246489702e-05,
      "loss": 0.5687,
      "step": 982
    },
    {
      "epoch": 0.2,
      "grad_norm": 0.694395124912262,
      "learning_rate": 1.7995285436097162e-05,
      "loss": 0.6738,
      "step": 983
    },
    {
      "epoch": 0.2,
      "grad_norm": 1.1972506046295166,
      "learning_rate": 1.7993235625704622e-05,
      "loss": 0.6039,
      "step": 984
    },
    {
      "epoch": 0.2,
      "grad_norm": 0.6524549126625061,
      "learning_rate": 1.7991185815312086e-05,
      "loss": 0.6084,
      "step": 985
    },
    {
      "epoch": 0.2,
      "grad_norm": 0.46900734305381775,
      "learning_rate": 1.7989136004919546e-05,
      "loss": 0.6232,
      "step": 986
    },
    {
      "epoch": 0.2,
      "grad_norm": 0.4189130663871765,
      "learning_rate": 1.798708619452701e-05,
      "loss": 0.5284,
      "step": 987
    },
    {
      "epoch": 0.2,
      "grad_norm": 0.8869667649269104,
      "learning_rate": 1.798503638413447e-05,
      "loss": 0.7361,
      "step": 988
    },
    {
      "epoch": 0.2,
      "grad_norm": 1.0329676866531372,
      "learning_rate": 1.798298657374193e-05,
      "loss": 0.6531,
      "step": 989
    },
    {
      "epoch": 0.2,
      "grad_norm": 0.5591780543327332,
      "learning_rate": 1.7980936763349393e-05,
      "loss": 0.8548,
      "step": 990
    },
    {
      "epoch": 0.2,
      "grad_norm": 0.5431678891181946,
      "learning_rate": 1.7978886952956853e-05,
      "loss": 0.7422,
      "step": 991
    },
    {
      "epoch": 0.2,
      "grad_norm": 1.1330517530441284,
      "learning_rate": 1.7976837142564314e-05,
      "loss": 0.5918,
      "step": 992
    },
    {
      "epoch": 0.2,
      "grad_norm": 1.392986536026001,
      "learning_rate": 1.7974787332171774e-05,
      "loss": 0.5775,
      "step": 993
    },
    {
      "epoch": 0.2,
      "grad_norm": 0.8402047157287598,
      "learning_rate": 1.7972737521779237e-05,
      "loss": 0.6291,
      "step": 994
    },
    {
      "epoch": 0.2,
      "grad_norm": 1.5754432678222656,
      "learning_rate": 1.7970687711386697e-05,
      "loss": 0.5104,
      "step": 995
    },
    {
      "epoch": 0.2,
      "grad_norm": 1.6208248138427734,
      "learning_rate": 1.7968637900994158e-05,
      "loss": 0.6114,
      "step": 996
    },
    {
      "epoch": 0.2,
      "grad_norm": 1.2679451704025269,
      "learning_rate": 1.796658809060162e-05,
      "loss": 0.602,
      "step": 997
    },
    {
      "epoch": 0.2,
      "grad_norm": 0.7579483389854431,
      "learning_rate": 1.796453828020908e-05,
      "loss": 0.5588,
      "step": 998
    },
    {
      "epoch": 0.2,
      "grad_norm": 0.7470415234565735,
      "learning_rate": 1.7962488469816545e-05,
      "loss": 0.6047,
      "step": 999
    },
    {
      "epoch": 0.2,
      "grad_norm": 2.1790597438812256,
      "learning_rate": 1.7960438659424005e-05,
      "loss": 0.5289,
      "step": 1000
    },
    {
      "epoch": 0.2,
      "eval_loss": 0.6467469334602356,
      "eval_runtime": 657.5713,
      "eval_samples_per_second": 15.207,
      "eval_steps_per_second": 1.901,
      "step": 1000
    },
    {
      "epoch": 0.21,
      "grad_norm": 0.42002877593040466,
      "learning_rate": 1.7958388849031465e-05,
      "loss": 0.5012,
      "step": 1001
    },
    {
      "epoch": 0.21,
      "grad_norm": 0.4813898503780365,
      "learning_rate": 1.795633903863893e-05,
      "loss": 0.7273,
      "step": 1002
    },
    {
      "epoch": 0.21,
      "grad_norm": 0.6547921895980835,
      "learning_rate": 1.795428922824639e-05,
      "loss": 0.6174,
      "step": 1003
    },
    {
      "epoch": 0.21,
      "grad_norm": 0.6431492567062378,
      "learning_rate": 1.795223941785385e-05,
      "loss": 0.6467,
      "step": 1004
    },
    {
      "epoch": 0.21,
      "grad_norm": 0.7573054432868958,
      "learning_rate": 1.795018960746131e-05,
      "loss": 0.6014,
      "step": 1005
    },
    {
      "epoch": 0.21,
      "grad_norm": 1.2148357629776,
      "learning_rate": 1.7948139797068773e-05,
      "loss": 0.5762,
      "step": 1006
    },
    {
      "epoch": 0.21,
      "grad_norm": 0.5631579160690308,
      "learning_rate": 1.7946089986676233e-05,
      "loss": 0.5204,
      "step": 1007
    },
    {
      "epoch": 0.21,
      "grad_norm": 0.6227715611457825,
      "learning_rate": 1.7944040176283693e-05,
      "loss": 0.5605,
      "step": 1008
    },
    {
      "epoch": 0.21,
      "grad_norm": 0.4981236159801483,
      "learning_rate": 1.7941990365891157e-05,
      "loss": 0.6531,
      "step": 1009
    },
    {
      "epoch": 0.21,
      "grad_norm": 0.6654307246208191,
      "learning_rate": 1.7939940555498617e-05,
      "loss": 0.6811,
      "step": 1010
    },
    {
      "epoch": 0.21,
      "grad_norm": 0.8461410999298096,
      "learning_rate": 1.793789074510608e-05,
      "loss": 0.6932,
      "step": 1011
    },
    {
      "epoch": 0.21,
      "grad_norm": 0.48229798674583435,
      "learning_rate": 1.793584093471354e-05,
      "loss": 0.6167,
      "step": 1012
    },
    {
      "epoch": 0.21,
      "grad_norm": 0.7804051637649536,
      "learning_rate": 1.7933791124321004e-05,
      "loss": 0.5082,
      "step": 1013
    },
    {
      "epoch": 0.21,
      "grad_norm": 0.7780382037162781,
      "learning_rate": 1.7931741313928464e-05,
      "loss": 0.6339,
      "step": 1014
    },
    {
      "epoch": 0.21,
      "grad_norm": 0.5596080422401428,
      "learning_rate": 1.7929691503535924e-05,
      "loss": 0.5981,
      "step": 1015
    },
    {
      "epoch": 0.21,
      "grad_norm": 0.42181873321533203,
      "learning_rate": 1.7927641693143385e-05,
      "loss": 0.6039,
      "step": 1016
    },
    {
      "epoch": 0.21,
      "grad_norm": 0.5295882821083069,
      "learning_rate": 1.7925591882750848e-05,
      "loss": 0.7102,
      "step": 1017
    },
    {
      "epoch": 0.21,
      "grad_norm": 0.6372422575950623,
      "learning_rate": 1.7923542072358308e-05,
      "loss": 0.6709,
      "step": 1018
    },
    {
      "epoch": 0.21,
      "grad_norm": 1.286965250968933,
      "learning_rate": 1.792149226196577e-05,
      "loss": 0.6444,
      "step": 1019
    },
    {
      "epoch": 0.21,
      "grad_norm": 0.8342341780662537,
      "learning_rate": 1.791944245157323e-05,
      "loss": 0.5853,
      "step": 1020
    },
    {
      "epoch": 0.21,
      "grad_norm": 0.6796934008598328,
      "learning_rate": 1.7917392641180692e-05,
      "loss": 0.5991,
      "step": 1021
    },
    {
      "epoch": 0.21,
      "grad_norm": 0.9070333242416382,
      "learning_rate": 1.7915342830788152e-05,
      "loss": 0.7144,
      "step": 1022
    },
    {
      "epoch": 0.21,
      "grad_norm": 1.031298279762268,
      "learning_rate": 1.7913293020395616e-05,
      "loss": 0.509,
      "step": 1023
    },
    {
      "epoch": 0.21,
      "grad_norm": 0.49184975028038025,
      "learning_rate": 1.7911243210003076e-05,
      "loss": 0.7379,
      "step": 1024
    },
    {
      "epoch": 0.21,
      "grad_norm": 0.5917986035346985,
      "learning_rate": 1.790919339961054e-05,
      "loss": 0.6084,
      "step": 1025
    },
    {
      "epoch": 0.21,
      "grad_norm": 0.6080788373947144,
      "learning_rate": 1.7907143589218e-05,
      "loss": 0.7608,
      "step": 1026
    },
    {
      "epoch": 0.21,
      "grad_norm": 0.5376918911933899,
      "learning_rate": 1.790509377882546e-05,
      "loss": 0.7219,
      "step": 1027
    },
    {
      "epoch": 0.21,
      "grad_norm": 0.3781145513057709,
      "learning_rate": 1.790304396843292e-05,
      "loss": 0.6268,
      "step": 1028
    },
    {
      "epoch": 0.21,
      "grad_norm": 0.570962131023407,
      "learning_rate": 1.7900994158040384e-05,
      "loss": 0.7588,
      "step": 1029
    },
    {
      "epoch": 0.21,
      "grad_norm": 0.4713650941848755,
      "learning_rate": 1.7898944347647844e-05,
      "loss": 0.7512,
      "step": 1030
    },
    {
      "epoch": 0.21,
      "grad_norm": 0.6689375638961792,
      "learning_rate": 1.7896894537255304e-05,
      "loss": 0.7048,
      "step": 1031
    },
    {
      "epoch": 0.21,
      "grad_norm": 0.5006043910980225,
      "learning_rate": 1.7894844726862764e-05,
      "loss": 0.7886,
      "step": 1032
    },
    {
      "epoch": 0.21,
      "grad_norm": 0.6762322187423706,
      "learning_rate": 1.7892794916470228e-05,
      "loss": 0.5614,
      "step": 1033
    },
    {
      "epoch": 0.21,
      "grad_norm": 0.9265605807304382,
      "learning_rate": 1.7890745106077688e-05,
      "loss": 0.6386,
      "step": 1034
    },
    {
      "epoch": 0.21,
      "grad_norm": 0.500510036945343,
      "learning_rate": 1.788869529568515e-05,
      "loss": 0.7471,
      "step": 1035
    },
    {
      "epoch": 0.21,
      "grad_norm": 0.6887156963348389,
      "learning_rate": 1.788664548529261e-05,
      "loss": 0.6121,
      "step": 1036
    },
    {
      "epoch": 0.21,
      "grad_norm": 0.5280219316482544,
      "learning_rate": 1.7884595674900075e-05,
      "loss": 0.6562,
      "step": 1037
    },
    {
      "epoch": 0.21,
      "grad_norm": 0.5333704352378845,
      "learning_rate": 1.7882545864507535e-05,
      "loss": 0.633,
      "step": 1038
    },
    {
      "epoch": 0.21,
      "grad_norm": 0.6351872086524963,
      "learning_rate": 1.7880496054114995e-05,
      "loss": 0.6034,
      "step": 1039
    },
    {
      "epoch": 0.21,
      "grad_norm": 0.5258100628852844,
      "learning_rate": 1.787844624372246e-05,
      "loss": 0.7377,
      "step": 1040
    },
    {
      "epoch": 0.21,
      "grad_norm": 0.5118831396102905,
      "learning_rate": 1.787639643332992e-05,
      "loss": 0.6968,
      "step": 1041
    },
    {
      "epoch": 0.21,
      "grad_norm": 0.46586892008781433,
      "learning_rate": 1.787434662293738e-05,
      "loss": 0.6446,
      "step": 1042
    },
    {
      "epoch": 0.21,
      "grad_norm": 0.5072208046913147,
      "learning_rate": 1.787229681254484e-05,
      "loss": 0.6794,
      "step": 1043
    },
    {
      "epoch": 0.21,
      "grad_norm": 0.48136383295059204,
      "learning_rate": 1.7870247002152303e-05,
      "loss": 0.61,
      "step": 1044
    },
    {
      "epoch": 0.21,
      "grad_norm": 0.519041121006012,
      "learning_rate": 1.7868197191759763e-05,
      "loss": 0.6546,
      "step": 1045
    },
    {
      "epoch": 0.21,
      "grad_norm": 0.49152839183807373,
      "learning_rate": 1.7866147381367223e-05,
      "loss": 0.8335,
      "step": 1046
    },
    {
      "epoch": 0.21,
      "grad_norm": 0.6290562152862549,
      "learning_rate": 1.7864097570974687e-05,
      "loss": 0.6569,
      "step": 1047
    },
    {
      "epoch": 0.21,
      "grad_norm": 0.49904173612594604,
      "learning_rate": 1.7862047760582147e-05,
      "loss": 0.7013,
      "step": 1048
    },
    {
      "epoch": 0.21,
      "grad_norm": 0.5064246654510498,
      "learning_rate": 1.785999795018961e-05,
      "loss": 0.5707,
      "step": 1049
    },
    {
      "epoch": 0.22,
      "grad_norm": 0.5274969339370728,
      "learning_rate": 1.785794813979707e-05,
      "loss": 0.7593,
      "step": 1050
    },
    {
      "epoch": 0.22,
      "grad_norm": 1.1150273084640503,
      "learning_rate": 1.785589832940453e-05,
      "loss": 0.6176,
      "step": 1051
    },
    {
      "epoch": 0.22,
      "grad_norm": 0.5808218121528625,
      "learning_rate": 1.7853848519011994e-05,
      "loss": 0.6808,
      "step": 1052
    },
    {
      "epoch": 0.22,
      "grad_norm": 0.4814855754375458,
      "learning_rate": 1.7851798708619455e-05,
      "loss": 0.6334,
      "step": 1053
    },
    {
      "epoch": 0.22,
      "grad_norm": 0.5612244009971619,
      "learning_rate": 1.7849748898226915e-05,
      "loss": 0.6628,
      "step": 1054
    },
    {
      "epoch": 0.22,
      "grad_norm": 0.4210192561149597,
      "learning_rate": 1.7847699087834375e-05,
      "loss": 0.6957,
      "step": 1055
    },
    {
      "epoch": 0.22,
      "grad_norm": 1.1374484300613403,
      "learning_rate": 1.784564927744184e-05,
      "loss": 0.509,
      "step": 1056
    },
    {
      "epoch": 0.22,
      "grad_norm": 1.1307541131973267,
      "learning_rate": 1.78435994670493e-05,
      "loss": 0.488,
      "step": 1057
    },
    {
      "epoch": 0.22,
      "grad_norm": 0.5591580271720886,
      "learning_rate": 1.784154965665676e-05,
      "loss": 0.5233,
      "step": 1058
    },
    {
      "epoch": 0.22,
      "grad_norm": 0.8043792843818665,
      "learning_rate": 1.7839499846264222e-05,
      "loss": 0.5894,
      "step": 1059
    },
    {
      "epoch": 0.22,
      "grad_norm": 1.3598605394363403,
      "learning_rate": 1.7837450035871682e-05,
      "loss": 0.6209,
      "step": 1060
    },
    {
      "epoch": 0.22,
      "grad_norm": 1.4004344940185547,
      "learning_rate": 1.7835400225479146e-05,
      "loss": 0.7198,
      "step": 1061
    },
    {
      "epoch": 0.22,
      "grad_norm": 0.5764651298522949,
      "learning_rate": 1.7833350415086606e-05,
      "loss": 0.5837,
      "step": 1062
    },
    {
      "epoch": 0.22,
      "grad_norm": 0.6001191735267639,
      "learning_rate": 1.7831300604694066e-05,
      "loss": 0.6216,
      "step": 1063
    },
    {
      "epoch": 0.22,
      "grad_norm": 1.2760859727859497,
      "learning_rate": 1.782925079430153e-05,
      "loss": 0.5497,
      "step": 1064
    },
    {
      "epoch": 0.22,
      "grad_norm": 0.4327603876590729,
      "learning_rate": 1.782720098390899e-05,
      "loss": 0.6073,
      "step": 1065
    },
    {
      "epoch": 0.22,
      "grad_norm": 0.4884154796600342,
      "learning_rate": 1.782515117351645e-05,
      "loss": 0.7028,
      "step": 1066
    },
    {
      "epoch": 0.22,
      "grad_norm": 0.5117096304893494,
      "learning_rate": 1.7823101363123914e-05,
      "loss": 0.5987,
      "step": 1067
    },
    {
      "epoch": 0.22,
      "grad_norm": 0.5070714354515076,
      "learning_rate": 1.7821051552731374e-05,
      "loss": 0.7491,
      "step": 1068
    },
    {
      "epoch": 0.22,
      "grad_norm": 0.5581636428833008,
      "learning_rate": 1.7819001742338834e-05,
      "loss": 0.5163,
      "step": 1069
    },
    {
      "epoch": 0.22,
      "grad_norm": 0.39593252539634705,
      "learning_rate": 1.7816951931946294e-05,
      "loss": 0.6099,
      "step": 1070
    },
    {
      "epoch": 0.22,
      "grad_norm": 0.4532753527164459,
      "learning_rate": 1.7814902121553758e-05,
      "loss": 0.7579,
      "step": 1071
    },
    {
      "epoch": 0.22,
      "grad_norm": 0.5392829775810242,
      "learning_rate": 1.7812852311161218e-05,
      "loss": 0.6156,
      "step": 1072
    },
    {
      "epoch": 0.22,
      "grad_norm": 0.5357301235198975,
      "learning_rate": 1.781080250076868e-05,
      "loss": 0.6186,
      "step": 1073
    },
    {
      "epoch": 0.22,
      "grad_norm": 0.6499019265174866,
      "learning_rate": 1.780875269037614e-05,
      "loss": 0.6484,
      "step": 1074
    },
    {
      "epoch": 0.22,
      "grad_norm": 0.42030245065689087,
      "learning_rate": 1.7806702879983605e-05,
      "loss": 0.5592,
      "step": 1075
    },
    {
      "epoch": 0.22,
      "grad_norm": 0.9310789704322815,
      "learning_rate": 1.7804653069591065e-05,
      "loss": 0.7621,
      "step": 1076
    },
    {
      "epoch": 0.22,
      "grad_norm": 0.518587589263916,
      "learning_rate": 1.7802603259198526e-05,
      "loss": 0.7298,
      "step": 1077
    },
    {
      "epoch": 0.22,
      "grad_norm": 0.43559005856513977,
      "learning_rate": 1.7800553448805986e-05,
      "loss": 0.6679,
      "step": 1078
    },
    {
      "epoch": 0.22,
      "grad_norm": 0.45356976985931396,
      "learning_rate": 1.779850363841345e-05,
      "loss": 0.595,
      "step": 1079
    },
    {
      "epoch": 0.22,
      "grad_norm": 0.4643285870552063,
      "learning_rate": 1.779645382802091e-05,
      "loss": 0.7068,
      "step": 1080
    },
    {
      "epoch": 0.22,
      "grad_norm": 0.6644536852836609,
      "learning_rate": 1.779440401762837e-05,
      "loss": 0.5833,
      "step": 1081
    },
    {
      "epoch": 0.22,
      "grad_norm": 0.5286713242530823,
      "learning_rate": 1.779235420723583e-05,
      "loss": 0.639,
      "step": 1082
    },
    {
      "epoch": 0.22,
      "grad_norm": 0.4805488884449005,
      "learning_rate": 1.7790304396843293e-05,
      "loss": 0.6311,
      "step": 1083
    },
    {
      "epoch": 0.22,
      "grad_norm": 0.47322118282318115,
      "learning_rate": 1.7788254586450753e-05,
      "loss": 0.6293,
      "step": 1084
    },
    {
      "epoch": 0.22,
      "grad_norm": 1.289350152015686,
      "learning_rate": 1.7786204776058217e-05,
      "loss": 0.6284,
      "step": 1085
    },
    {
      "epoch": 0.22,
      "grad_norm": 0.5768840312957764,
      "learning_rate": 1.7784154965665677e-05,
      "loss": 0.6176,
      "step": 1086
    },
    {
      "epoch": 0.22,
      "grad_norm": 0.6374141573905945,
      "learning_rate": 1.778210515527314e-05,
      "loss": 0.5522,
      "step": 1087
    },
    {
      "epoch": 0.22,
      "grad_norm": 0.4552421569824219,
      "learning_rate": 1.77800553448806e-05,
      "loss": 0.6573,
      "step": 1088
    },
    {
      "epoch": 0.22,
      "grad_norm": 0.45592695474624634,
      "learning_rate": 1.777800553448806e-05,
      "loss": 0.662,
      "step": 1089
    },
    {
      "epoch": 0.22,
      "grad_norm": 0.4886457324028015,
      "learning_rate": 1.777595572409552e-05,
      "loss": 0.7197,
      "step": 1090
    },
    {
      "epoch": 0.22,
      "grad_norm": 0.5786242485046387,
      "learning_rate": 1.7773905913702985e-05,
      "loss": 0.7013,
      "step": 1091
    },
    {
      "epoch": 0.22,
      "grad_norm": 0.5519167184829712,
      "learning_rate": 1.7771856103310445e-05,
      "loss": 0.6272,
      "step": 1092
    },
    {
      "epoch": 0.22,
      "grad_norm": 0.49884307384490967,
      "learning_rate": 1.7769806292917905e-05,
      "loss": 0.7361,
      "step": 1093
    },
    {
      "epoch": 0.22,
      "grad_norm": 0.4425940215587616,
      "learning_rate": 1.7767756482525365e-05,
      "loss": 0.6966,
      "step": 1094
    },
    {
      "epoch": 0.22,
      "grad_norm": 0.6257272958755493,
      "learning_rate": 1.776570667213283e-05,
      "loss": 0.7197,
      "step": 1095
    },
    {
      "epoch": 0.22,
      "grad_norm": 0.5074118375778198,
      "learning_rate": 1.776365686174029e-05,
      "loss": 0.7551,
      "step": 1096
    },
    {
      "epoch": 0.22,
      "grad_norm": 0.6735489964485168,
      "learning_rate": 1.7761607051347753e-05,
      "loss": 0.5977,
      "step": 1097
    },
    {
      "epoch": 0.22,
      "grad_norm": 0.5653809905052185,
      "learning_rate": 1.7759557240955213e-05,
      "loss": 0.7174,
      "step": 1098
    },
    {
      "epoch": 0.23,
      "grad_norm": 0.7311569452285767,
      "learning_rate": 1.7757507430562676e-05,
      "loss": 0.4501,
      "step": 1099
    },
    {
      "epoch": 0.23,
      "grad_norm": 0.5048385858535767,
      "learning_rate": 1.7755457620170136e-05,
      "loss": 0.6728,
      "step": 1100
    },
    {
      "epoch": 0.23,
      "grad_norm": 0.5197431445121765,
      "learning_rate": 1.7753407809777597e-05,
      "loss": 0.6546,
      "step": 1101
    },
    {
      "epoch": 0.23,
      "grad_norm": 0.5409545302391052,
      "learning_rate": 1.775135799938506e-05,
      "loss": 0.5069,
      "step": 1102
    },
    {
      "epoch": 0.23,
      "grad_norm": 0.4540907144546509,
      "learning_rate": 1.774930818899252e-05,
      "loss": 0.58,
      "step": 1103
    },
    {
      "epoch": 0.23,
      "grad_norm": 0.832853376865387,
      "learning_rate": 1.774725837859998e-05,
      "loss": 0.6522,
      "step": 1104
    },
    {
      "epoch": 0.23,
      "grad_norm": 0.6383385062217712,
      "learning_rate": 1.774520856820744e-05,
      "loss": 0.7191,
      "step": 1105
    },
    {
      "epoch": 0.23,
      "grad_norm": 0.6006247401237488,
      "learning_rate": 1.7743158757814904e-05,
      "loss": 0.602,
      "step": 1106
    },
    {
      "epoch": 0.23,
      "grad_norm": 0.4427940845489502,
      "learning_rate": 1.7741108947422364e-05,
      "loss": 0.5593,
      "step": 1107
    },
    {
      "epoch": 0.23,
      "grad_norm": 0.7780283093452454,
      "learning_rate": 1.7739059137029824e-05,
      "loss": 0.5441,
      "step": 1108
    },
    {
      "epoch": 0.23,
      "grad_norm": 0.5359314680099487,
      "learning_rate": 1.7737009326637288e-05,
      "loss": 0.7519,
      "step": 1109
    },
    {
      "epoch": 0.23,
      "grad_norm": 0.8805988430976868,
      "learning_rate": 1.7734959516244748e-05,
      "loss": 0.5218,
      "step": 1110
    },
    {
      "epoch": 0.23,
      "grad_norm": 0.7450745701789856,
      "learning_rate": 1.7732909705852212e-05,
      "loss": 0.665,
      "step": 1111
    },
    {
      "epoch": 0.23,
      "grad_norm": 0.5611605644226074,
      "learning_rate": 1.7730859895459672e-05,
      "loss": 0.6437,
      "step": 1112
    },
    {
      "epoch": 0.23,
      "grad_norm": 0.549916684627533,
      "learning_rate": 1.7728810085067132e-05,
      "loss": 0.5752,
      "step": 1113
    },
    {
      "epoch": 0.23,
      "grad_norm": 0.4365618824958801,
      "learning_rate": 1.7726760274674596e-05,
      "loss": 0.6927,
      "step": 1114
    },
    {
      "epoch": 0.23,
      "grad_norm": 0.4919431209564209,
      "learning_rate": 1.7724710464282056e-05,
      "loss": 0.6337,
      "step": 1115
    },
    {
      "epoch": 0.23,
      "grad_norm": 1.2152966260910034,
      "learning_rate": 1.7722660653889516e-05,
      "loss": 0.4437,
      "step": 1116
    },
    {
      "epoch": 0.23,
      "grad_norm": 0.764674961566925,
      "learning_rate": 1.7720610843496976e-05,
      "loss": 0.6675,
      "step": 1117
    },
    {
      "epoch": 0.23,
      "grad_norm": 0.7382251024246216,
      "learning_rate": 1.771856103310444e-05,
      "loss": 0.6164,
      "step": 1118
    },
    {
      "epoch": 0.23,
      "grad_norm": 1.108991026878357,
      "learning_rate": 1.77165112227119e-05,
      "loss": 0.7364,
      "step": 1119
    },
    {
      "epoch": 0.23,
      "grad_norm": 0.7315986752510071,
      "learning_rate": 1.771446141231936e-05,
      "loss": 0.7506,
      "step": 1120
    },
    {
      "epoch": 0.23,
      "grad_norm": 0.7580021619796753,
      "learning_rate": 1.7712411601926824e-05,
      "loss": 0.7275,
      "step": 1121
    },
    {
      "epoch": 0.23,
      "grad_norm": 0.868184506893158,
      "learning_rate": 1.7710361791534284e-05,
      "loss": 0.4705,
      "step": 1122
    },
    {
      "epoch": 0.23,
      "grad_norm": 0.8013703227043152,
      "learning_rate": 1.7708311981141747e-05,
      "loss": 0.6409,
      "step": 1123
    },
    {
      "epoch": 0.23,
      "grad_norm": 0.618884801864624,
      "learning_rate": 1.7706262170749207e-05,
      "loss": 0.6448,
      "step": 1124
    },
    {
      "epoch": 0.23,
      "grad_norm": 0.5663954019546509,
      "learning_rate": 1.7704212360356668e-05,
      "loss": 0.6924,
      "step": 1125
    },
    {
      "epoch": 0.23,
      "grad_norm": 0.5992571115493774,
      "learning_rate": 1.770216254996413e-05,
      "loss": 0.5531,
      "step": 1126
    },
    {
      "epoch": 0.23,
      "grad_norm": 0.582062840461731,
      "learning_rate": 1.770011273957159e-05,
      "loss": 0.6581,
      "step": 1127
    },
    {
      "epoch": 0.23,
      "grad_norm": 0.6871599555015564,
      "learning_rate": 1.769806292917905e-05,
      "loss": 0.4786,
      "step": 1128
    },
    {
      "epoch": 0.23,
      "grad_norm": 0.7100038528442383,
      "learning_rate": 1.7696013118786515e-05,
      "loss": 0.6612,
      "step": 1129
    },
    {
      "epoch": 0.23,
      "grad_norm": 0.49328848719596863,
      "learning_rate": 1.7693963308393975e-05,
      "loss": 0.663,
      "step": 1130
    },
    {
      "epoch": 0.23,
      "grad_norm": 0.5469598174095154,
      "learning_rate": 1.7691913498001435e-05,
      "loss": 0.7229,
      "step": 1131
    },
    {
      "epoch": 0.23,
      "grad_norm": 0.7034865021705627,
      "learning_rate": 1.7689863687608895e-05,
      "loss": 0.7516,
      "step": 1132
    },
    {
      "epoch": 0.23,
      "grad_norm": 0.4514857828617096,
      "learning_rate": 1.768781387721636e-05,
      "loss": 0.6842,
      "step": 1133
    },
    {
      "epoch": 0.23,
      "grad_norm": 0.5806258916854858,
      "learning_rate": 1.768576406682382e-05,
      "loss": 0.5096,
      "step": 1134
    },
    {
      "epoch": 0.23,
      "grad_norm": 0.7432615756988525,
      "learning_rate": 1.7683714256431283e-05,
      "loss": 0.7362,
      "step": 1135
    },
    {
      "epoch": 0.23,
      "grad_norm": 0.6105364561080933,
      "learning_rate": 1.7681664446038743e-05,
      "loss": 0.6937,
      "step": 1136
    },
    {
      "epoch": 0.23,
      "grad_norm": 0.7446211576461792,
      "learning_rate": 1.7679614635646206e-05,
      "loss": 0.595,
      "step": 1137
    },
    {
      "epoch": 0.23,
      "grad_norm": 0.6685088276863098,
      "learning_rate": 1.7677564825253667e-05,
      "loss": 0.5781,
      "step": 1138
    },
    {
      "epoch": 0.23,
      "grad_norm": 0.4935617744922638,
      "learning_rate": 1.7675515014861127e-05,
      "loss": 0.6285,
      "step": 1139
    },
    {
      "epoch": 0.23,
      "grad_norm": 0.994918704032898,
      "learning_rate": 1.7673465204468587e-05,
      "loss": 0.6371,
      "step": 1140
    },
    {
      "epoch": 0.23,
      "grad_norm": 0.6353073120117188,
      "learning_rate": 1.767141539407605e-05,
      "loss": 0.5372,
      "step": 1141
    },
    {
      "epoch": 0.23,
      "grad_norm": 0.9206259846687317,
      "learning_rate": 1.766936558368351e-05,
      "loss": 0.5845,
      "step": 1142
    },
    {
      "epoch": 0.23,
      "grad_norm": 0.497967004776001,
      "learning_rate": 1.766731577329097e-05,
      "loss": 0.655,
      "step": 1143
    },
    {
      "epoch": 0.23,
      "grad_norm": 0.564018726348877,
      "learning_rate": 1.766526596289843e-05,
      "loss": 0.7714,
      "step": 1144
    },
    {
      "epoch": 0.23,
      "grad_norm": 0.6296719312667847,
      "learning_rate": 1.7663216152505895e-05,
      "loss": 0.4534,
      "step": 1145
    },
    {
      "epoch": 0.23,
      "grad_norm": 0.7142187356948853,
      "learning_rate": 1.7661166342113355e-05,
      "loss": 0.7196,
      "step": 1146
    },
    {
      "epoch": 0.23,
      "grad_norm": 0.4753344655036926,
      "learning_rate": 1.7659116531720818e-05,
      "loss": 0.5333,
      "step": 1147
    },
    {
      "epoch": 0.24,
      "grad_norm": 0.9475431442260742,
      "learning_rate": 1.765706672132828e-05,
      "loss": 0.605,
      "step": 1148
    },
    {
      "epoch": 0.24,
      "grad_norm": 0.8282219171524048,
      "learning_rate": 1.7655016910935742e-05,
      "loss": 0.5701,
      "step": 1149
    },
    {
      "epoch": 0.24,
      "grad_norm": 0.7965812087059021,
      "learning_rate": 1.7652967100543202e-05,
      "loss": 0.6933,
      "step": 1150
    },
    {
      "epoch": 0.24,
      "grad_norm": 0.6973093748092651,
      "learning_rate": 1.7650917290150662e-05,
      "loss": 0.5671,
      "step": 1151
    },
    {
      "epoch": 0.24,
      "grad_norm": 0.5563529133796692,
      "learning_rate": 1.7648867479758122e-05,
      "loss": 0.6358,
      "step": 1152
    },
    {
      "epoch": 0.24,
      "grad_norm": 0.6388635635375977,
      "learning_rate": 1.7646817669365586e-05,
      "loss": 0.582,
      "step": 1153
    },
    {
      "epoch": 0.24,
      "grad_norm": 0.7026799917221069,
      "learning_rate": 1.7644767858973046e-05,
      "loss": 0.7009,
      "step": 1154
    },
    {
      "epoch": 0.24,
      "grad_norm": 0.5650050640106201,
      "learning_rate": 1.7642718048580506e-05,
      "loss": 0.675,
      "step": 1155
    },
    {
      "epoch": 0.24,
      "grad_norm": 0.5653408169746399,
      "learning_rate": 1.764066823818797e-05,
      "loss": 0.5029,
      "step": 1156
    },
    {
      "epoch": 0.24,
      "grad_norm": 0.9293228387832642,
      "learning_rate": 1.763861842779543e-05,
      "loss": 0.6487,
      "step": 1157
    },
    {
      "epoch": 0.24,
      "grad_norm": 0.6766716837882996,
      "learning_rate": 1.763656861740289e-05,
      "loss": 0.3998,
      "step": 1158
    },
    {
      "epoch": 0.24,
      "grad_norm": 0.6453434824943542,
      "learning_rate": 1.7634518807010354e-05,
      "loss": 0.6182,
      "step": 1159
    },
    {
      "epoch": 0.24,
      "grad_norm": 0.4668368995189667,
      "learning_rate": 1.7632468996617814e-05,
      "loss": 0.6068,
      "step": 1160
    },
    {
      "epoch": 0.24,
      "grad_norm": 0.7772189378738403,
      "learning_rate": 1.7630419186225277e-05,
      "loss": 0.5639,
      "step": 1161
    },
    {
      "epoch": 0.24,
      "grad_norm": 0.6868874430656433,
      "learning_rate": 1.7628369375832738e-05,
      "loss": 0.7497,
      "step": 1162
    },
    {
      "epoch": 0.24,
      "grad_norm": 0.4974821209907532,
      "learning_rate": 1.7626319565440198e-05,
      "loss": 0.6703,
      "step": 1163
    },
    {
      "epoch": 0.24,
      "grad_norm": 0.5436607599258423,
      "learning_rate": 1.762426975504766e-05,
      "loss": 0.6124,
      "step": 1164
    },
    {
      "epoch": 0.24,
      "grad_norm": 1.0344246625900269,
      "learning_rate": 1.762221994465512e-05,
      "loss": 0.5872,
      "step": 1165
    },
    {
      "epoch": 0.24,
      "grad_norm": 0.6962998509407043,
      "learning_rate": 1.762017013426258e-05,
      "loss": 0.5906,
      "step": 1166
    },
    {
      "epoch": 0.24,
      "grad_norm": 0.49682262539863586,
      "learning_rate": 1.7618120323870042e-05,
      "loss": 0.5938,
      "step": 1167
    },
    {
      "epoch": 0.24,
      "grad_norm": 1.625410795211792,
      "learning_rate": 1.7616070513477505e-05,
      "loss": 0.5879,
      "step": 1168
    },
    {
      "epoch": 0.24,
      "grad_norm": 0.9015966653823853,
      "learning_rate": 1.7614020703084966e-05,
      "loss": 0.5237,
      "step": 1169
    },
    {
      "epoch": 0.24,
      "grad_norm": 0.5719929337501526,
      "learning_rate": 1.7611970892692426e-05,
      "loss": 0.7133,
      "step": 1170
    },
    {
      "epoch": 0.24,
      "grad_norm": 0.6736540198326111,
      "learning_rate": 1.760992108229989e-05,
      "loss": 0.6938,
      "step": 1171
    },
    {
      "epoch": 0.24,
      "grad_norm": 0.9676467776298523,
      "learning_rate": 1.760787127190735e-05,
      "loss": 0.577,
      "step": 1172
    },
    {
      "epoch": 0.24,
      "grad_norm": 0.6553153395652771,
      "learning_rate": 1.7605821461514813e-05,
      "loss": 0.7868,
      "step": 1173
    },
    {
      "epoch": 0.24,
      "grad_norm": 0.9029708504676819,
      "learning_rate": 1.7603771651122273e-05,
      "loss": 0.4906,
      "step": 1174
    },
    {
      "epoch": 0.24,
      "grad_norm": 0.5279548764228821,
      "learning_rate": 1.7601721840729733e-05,
      "loss": 0.6871,
      "step": 1175
    },
    {
      "epoch": 0.24,
      "grad_norm": 0.5926553010940552,
      "learning_rate": 1.7599672030337197e-05,
      "loss": 0.6428,
      "step": 1176
    },
    {
      "epoch": 0.24,
      "grad_norm": 0.6619328856468201,
      "learning_rate": 1.7597622219944657e-05,
      "loss": 0.6775,
      "step": 1177
    },
    {
      "epoch": 0.24,
      "grad_norm": 0.4637937843799591,
      "learning_rate": 1.7595572409552117e-05,
      "loss": 0.6805,
      "step": 1178
    },
    {
      "epoch": 0.24,
      "grad_norm": 0.6112285256385803,
      "learning_rate": 1.7593522599159577e-05,
      "loss": 0.6687,
      "step": 1179
    },
    {
      "epoch": 0.24,
      "grad_norm": 0.5603399276733398,
      "learning_rate": 1.759147278876704e-05,
      "loss": 0.535,
      "step": 1180
    },
    {
      "epoch": 0.24,
      "grad_norm": 0.4937492311000824,
      "learning_rate": 1.75894229783745e-05,
      "loss": 0.5859,
      "step": 1181
    },
    {
      "epoch": 0.24,
      "grad_norm": 0.623779833316803,
      "learning_rate": 1.758737316798196e-05,
      "loss": 0.6738,
      "step": 1182
    },
    {
      "epoch": 0.24,
      "grad_norm": 0.49456706643104553,
      "learning_rate": 1.7585323357589425e-05,
      "loss": 0.781,
      "step": 1183
    },
    {
      "epoch": 0.24,
      "grad_norm": 0.5548242926597595,
      "learning_rate": 1.7583273547196885e-05,
      "loss": 0.565,
      "step": 1184
    },
    {
      "epoch": 0.24,
      "grad_norm": 0.4921729564666748,
      "learning_rate": 1.758122373680435e-05,
      "loss": 0.6478,
      "step": 1185
    },
    {
      "epoch": 0.24,
      "grad_norm": 0.5167906284332275,
      "learning_rate": 1.757917392641181e-05,
      "loss": 0.5413,
      "step": 1186
    },
    {
      "epoch": 0.24,
      "grad_norm": 0.592338502407074,
      "learning_rate": 1.7577124116019272e-05,
      "loss": 0.6345,
      "step": 1187
    },
    {
      "epoch": 0.24,
      "grad_norm": 0.5014265775680542,
      "learning_rate": 1.7575074305626732e-05,
      "loss": 0.7301,
      "step": 1188
    },
    {
      "epoch": 0.24,
      "grad_norm": 0.49040499329566956,
      "learning_rate": 1.7573024495234192e-05,
      "loss": 0.6678,
      "step": 1189
    },
    {
      "epoch": 0.24,
      "grad_norm": 0.5287253856658936,
      "learning_rate": 1.7570974684841653e-05,
      "loss": 0.5551,
      "step": 1190
    },
    {
      "epoch": 0.24,
      "grad_norm": 0.6246576905250549,
      "learning_rate": 1.7568924874449116e-05,
      "loss": 0.5386,
      "step": 1191
    },
    {
      "epoch": 0.24,
      "grad_norm": 0.6587978601455688,
      "learning_rate": 1.7566875064056576e-05,
      "loss": 0.5882,
      "step": 1192
    },
    {
      "epoch": 0.24,
      "grad_norm": 0.8012040853500366,
      "learning_rate": 1.7564825253664037e-05,
      "loss": 0.4495,
      "step": 1193
    },
    {
      "epoch": 0.24,
      "grad_norm": 0.5975950956344604,
      "learning_rate": 1.7562775443271497e-05,
      "loss": 0.5681,
      "step": 1194
    },
    {
      "epoch": 0.24,
      "grad_norm": 0.43407756090164185,
      "learning_rate": 1.756072563287896e-05,
      "loss": 0.5514,
      "step": 1195
    },
    {
      "epoch": 0.25,
      "grad_norm": 0.5094166994094849,
      "learning_rate": 1.755867582248642e-05,
      "loss": 0.5389,
      "step": 1196
    },
    {
      "epoch": 0.25,
      "grad_norm": 1.4423408508300781,
      "learning_rate": 1.7556626012093884e-05,
      "loss": 0.4065,
      "step": 1197
    },
    {
      "epoch": 0.25,
      "grad_norm": 0.43579912185668945,
      "learning_rate": 1.7554576201701344e-05,
      "loss": 0.6334,
      "step": 1198
    },
    {
      "epoch": 0.25,
      "grad_norm": 0.48554420471191406,
      "learning_rate": 1.7552526391308808e-05,
      "loss": 0.6792,
      "step": 1199
    },
    {
      "epoch": 0.25,
      "grad_norm": 0.682624101638794,
      "learning_rate": 1.7550476580916268e-05,
      "loss": 0.7151,
      "step": 1200
    },
    {
      "epoch": 0.25,
      "grad_norm": 0.7826636433601379,
      "learning_rate": 1.7548426770523728e-05,
      "loss": 0.5521,
      "step": 1201
    },
    {
      "epoch": 0.25,
      "grad_norm": 0.8360652923583984,
      "learning_rate": 1.7546376960131188e-05,
      "loss": 0.6696,
      "step": 1202
    },
    {
      "epoch": 0.25,
      "grad_norm": 0.6668421030044556,
      "learning_rate": 1.7544327149738652e-05,
      "loss": 0.6729,
      "step": 1203
    },
    {
      "epoch": 0.25,
      "grad_norm": 1.8270697593688965,
      "learning_rate": 1.7542277339346112e-05,
      "loss": 0.5935,
      "step": 1204
    },
    {
      "epoch": 0.25,
      "grad_norm": 1.2444489002227783,
      "learning_rate": 1.7540227528953572e-05,
      "loss": 0.6095,
      "step": 1205
    },
    {
      "epoch": 0.25,
      "grad_norm": 0.562905490398407,
      "learning_rate": 1.7538177718561032e-05,
      "loss": 0.6064,
      "step": 1206
    },
    {
      "epoch": 0.25,
      "grad_norm": 0.6046627759933472,
      "learning_rate": 1.7536127908168496e-05,
      "loss": 0.723,
      "step": 1207
    },
    {
      "epoch": 0.25,
      "grad_norm": 0.6848174929618835,
      "learning_rate": 1.7534078097775956e-05,
      "loss": 0.4676,
      "step": 1208
    },
    {
      "epoch": 0.25,
      "grad_norm": 1.1879228353500366,
      "learning_rate": 1.753202828738342e-05,
      "loss": 0.6452,
      "step": 1209
    },
    {
      "epoch": 0.25,
      "grad_norm": 0.7811193466186523,
      "learning_rate": 1.752997847699088e-05,
      "loss": 0.6171,
      "step": 1210
    },
    {
      "epoch": 0.25,
      "grad_norm": 0.5042272806167603,
      "learning_rate": 1.7527928666598343e-05,
      "loss": 0.6431,
      "step": 1211
    },
    {
      "epoch": 0.25,
      "grad_norm": 0.6257587671279907,
      "learning_rate": 1.7525878856205803e-05,
      "loss": 0.6536,
      "step": 1212
    },
    {
      "epoch": 0.25,
      "grad_norm": 0.6641731262207031,
      "learning_rate": 1.7523829045813263e-05,
      "loss": 0.6753,
      "step": 1213
    },
    {
      "epoch": 0.25,
      "grad_norm": 1.0651649236679077,
      "learning_rate": 1.7521779235420727e-05,
      "loss": 0.6342,
      "step": 1214
    },
    {
      "epoch": 0.25,
      "grad_norm": 0.7764202356338501,
      "learning_rate": 1.7519729425028187e-05,
      "loss": 0.6633,
      "step": 1215
    },
    {
      "epoch": 0.25,
      "grad_norm": 0.9624457955360413,
      "learning_rate": 1.7517679614635647e-05,
      "loss": 0.7358,
      "step": 1216
    },
    {
      "epoch": 0.25,
      "grad_norm": 0.5283332467079163,
      "learning_rate": 1.7515629804243108e-05,
      "loss": 0.6908,
      "step": 1217
    },
    {
      "epoch": 0.25,
      "grad_norm": 0.5153570175170898,
      "learning_rate": 1.751357999385057e-05,
      "loss": 0.585,
      "step": 1218
    },
    {
      "epoch": 0.25,
      "grad_norm": 0.6519194841384888,
      "learning_rate": 1.751153018345803e-05,
      "loss": 0.649,
      "step": 1219
    },
    {
      "epoch": 0.25,
      "grad_norm": 0.47771838307380676,
      "learning_rate": 1.750948037306549e-05,
      "loss": 0.6286,
      "step": 1220
    },
    {
      "epoch": 0.25,
      "grad_norm": 0.5576452016830444,
      "learning_rate": 1.7507430562672955e-05,
      "loss": 0.5257,
      "step": 1221
    },
    {
      "epoch": 0.25,
      "grad_norm": 0.716991662979126,
      "learning_rate": 1.7505380752280415e-05,
      "loss": 0.5534,
      "step": 1222
    },
    {
      "epoch": 0.25,
      "grad_norm": 0.8128733038902283,
      "learning_rate": 1.750333094188788e-05,
      "loss": 0.5357,
      "step": 1223
    },
    {
      "epoch": 0.25,
      "grad_norm": 0.5437614917755127,
      "learning_rate": 1.750128113149534e-05,
      "loss": 0.6359,
      "step": 1224
    },
    {
      "epoch": 0.25,
      "grad_norm": 0.817213237285614,
      "learning_rate": 1.74992313211028e-05,
      "loss": 0.5783,
      "step": 1225
    },
    {
      "epoch": 0.25,
      "grad_norm": 0.5535455942153931,
      "learning_rate": 1.7497181510710263e-05,
      "loss": 0.6514,
      "step": 1226
    },
    {
      "epoch": 0.25,
      "grad_norm": 0.5330238938331604,
      "learning_rate": 1.7495131700317723e-05,
      "loss": 0.5674,
      "step": 1227
    },
    {
      "epoch": 0.25,
      "grad_norm": 0.7151432633399963,
      "learning_rate": 1.7493081889925183e-05,
      "loss": 0.5621,
      "step": 1228
    },
    {
      "epoch": 0.25,
      "grad_norm": 0.9249876737594604,
      "learning_rate": 1.7491032079532643e-05,
      "loss": 0.5792,
      "step": 1229
    },
    {
      "epoch": 0.25,
      "grad_norm": 0.9597374200820923,
      "learning_rate": 1.7488982269140107e-05,
      "loss": 0.5447,
      "step": 1230
    },
    {
      "epoch": 0.25,
      "grad_norm": 0.9935823678970337,
      "learning_rate": 1.7486932458747567e-05,
      "loss": 0.4137,
      "step": 1231
    },
    {
      "epoch": 0.25,
      "grad_norm": 1.9906649589538574,
      "learning_rate": 1.7484882648355027e-05,
      "loss": 0.5083,
      "step": 1232
    },
    {
      "epoch": 0.25,
      "grad_norm": 1.097550392150879,
      "learning_rate": 1.748283283796249e-05,
      "loss": 0.5595,
      "step": 1233
    },
    {
      "epoch": 0.25,
      "grad_norm": 1.2494250535964966,
      "learning_rate": 1.748078302756995e-05,
      "loss": 0.5369,
      "step": 1234
    },
    {
      "epoch": 0.25,
      "grad_norm": 1.420657753944397,
      "learning_rate": 1.7478733217177414e-05,
      "loss": 0.5994,
      "step": 1235
    },
    {
      "epoch": 0.25,
      "grad_norm": 1.0253506898880005,
      "learning_rate": 1.7476683406784874e-05,
      "loss": 0.5298,
      "step": 1236
    },
    {
      "epoch": 0.25,
      "grad_norm": 0.7914808988571167,
      "learning_rate": 1.7474633596392334e-05,
      "loss": 0.5656,
      "step": 1237
    },
    {
      "epoch": 0.25,
      "grad_norm": 1.186343789100647,
      "learning_rate": 1.7472583785999798e-05,
      "loss": 0.6013,
      "step": 1238
    },
    {
      "epoch": 0.25,
      "grad_norm": 0.6077494621276855,
      "learning_rate": 1.7470533975607258e-05,
      "loss": 0.5578,
      "step": 1239
    },
    {
      "epoch": 0.25,
      "grad_norm": 0.8309895396232605,
      "learning_rate": 1.746848416521472e-05,
      "loss": 0.4539,
      "step": 1240
    },
    {
      "epoch": 0.25,
      "grad_norm": 0.576911449432373,
      "learning_rate": 1.746643435482218e-05,
      "loss": 0.6049,
      "step": 1241
    },
    {
      "epoch": 0.25,
      "grad_norm": 1.2421222925186157,
      "learning_rate": 1.7464384544429642e-05,
      "loss": 0.5462,
      "step": 1242
    },
    {
      "epoch": 0.25,
      "grad_norm": 0.9654963612556458,
      "learning_rate": 1.7462334734037102e-05,
      "loss": 0.6103,
      "step": 1243
    },
    {
      "epoch": 0.25,
      "grad_norm": 0.7224642038345337,
      "learning_rate": 1.7460284923644562e-05,
      "loss": 0.6585,
      "step": 1244
    },
    {
      "epoch": 0.26,
      "grad_norm": 0.675377368927002,
      "learning_rate": 1.7458235113252026e-05,
      "loss": 0.5041,
      "step": 1245
    },
    {
      "epoch": 0.26,
      "grad_norm": 1.0871708393096924,
      "learning_rate": 1.7456185302859486e-05,
      "loss": 0.7147,
      "step": 1246
    },
    {
      "epoch": 0.26,
      "grad_norm": 0.6525322198867798,
      "learning_rate": 1.745413549246695e-05,
      "loss": 0.6151,
      "step": 1247
    },
    {
      "epoch": 0.26,
      "grad_norm": 0.7375141978263855,
      "learning_rate": 1.745208568207441e-05,
      "loss": 0.7667,
      "step": 1248
    },
    {
      "epoch": 0.26,
      "grad_norm": 1.3710753917694092,
      "learning_rate": 1.7450035871681873e-05,
      "loss": 0.5764,
      "step": 1249
    },
    {
      "epoch": 0.26,
      "grad_norm": 1.0423709154129028,
      "learning_rate": 1.7447986061289334e-05,
      "loss": 0.6341,
      "step": 1250
    },
    {
      "epoch": 0.26,
      "grad_norm": 0.5409685373306274,
      "learning_rate": 1.7445936250896794e-05,
      "loss": 0.61,
      "step": 1251
    },
    {
      "epoch": 0.26,
      "grad_norm": 0.5220358967781067,
      "learning_rate": 1.7443886440504254e-05,
      "loss": 0.599,
      "step": 1252
    },
    {
      "epoch": 0.26,
      "grad_norm": 0.6013790965080261,
      "learning_rate": 1.7441836630111717e-05,
      "loss": 0.7315,
      "step": 1253
    },
    {
      "epoch": 0.26,
      "grad_norm": 1.0610342025756836,
      "learning_rate": 1.7439786819719178e-05,
      "loss": 0.5756,
      "step": 1254
    },
    {
      "epoch": 0.26,
      "grad_norm": 0.5908238887786865,
      "learning_rate": 1.7437737009326638e-05,
      "loss": 0.6636,
      "step": 1255
    },
    {
      "epoch": 0.26,
      "grad_norm": 0.46380212903022766,
      "learning_rate": 1.7435687198934098e-05,
      "loss": 0.6421,
      "step": 1256
    },
    {
      "epoch": 0.26,
      "grad_norm": 0.7393020987510681,
      "learning_rate": 1.743363738854156e-05,
      "loss": 0.5376,
      "step": 1257
    },
    {
      "epoch": 0.26,
      "grad_norm": 0.5628510117530823,
      "learning_rate": 1.743158757814902e-05,
      "loss": 0.7419,
      "step": 1258
    },
    {
      "epoch": 0.26,
      "grad_norm": 0.7560034990310669,
      "learning_rate": 1.7429537767756485e-05,
      "loss": 0.406,
      "step": 1259
    },
    {
      "epoch": 0.26,
      "grad_norm": 0.46630698442459106,
      "learning_rate": 1.7427487957363945e-05,
      "loss": 0.6182,
      "step": 1260
    },
    {
      "epoch": 0.26,
      "grad_norm": 0.6307033896446228,
      "learning_rate": 1.742543814697141e-05,
      "loss": 0.7052,
      "step": 1261
    },
    {
      "epoch": 0.26,
      "grad_norm": 0.8670955896377563,
      "learning_rate": 1.742338833657887e-05,
      "loss": 0.6231,
      "step": 1262
    },
    {
      "epoch": 0.26,
      "grad_norm": 1.2910807132720947,
      "learning_rate": 1.742133852618633e-05,
      "loss": 0.6682,
      "step": 1263
    },
    {
      "epoch": 0.26,
      "grad_norm": 0.5520555377006531,
      "learning_rate": 1.741928871579379e-05,
      "loss": 0.6828,
      "step": 1264
    },
    {
      "epoch": 0.26,
      "grad_norm": 0.6187029480934143,
      "learning_rate": 1.7417238905401253e-05,
      "loss": 0.6368,
      "step": 1265
    },
    {
      "epoch": 0.26,
      "grad_norm": 0.42395201325416565,
      "learning_rate": 1.7415189095008713e-05,
      "loss": 0.5362,
      "step": 1266
    },
    {
      "epoch": 0.26,
      "grad_norm": 1.5858186483383179,
      "learning_rate": 1.7413139284616173e-05,
      "loss": 0.6481,
      "step": 1267
    },
    {
      "epoch": 0.26,
      "grad_norm": 0.47290000319480896,
      "learning_rate": 1.7411089474223633e-05,
      "loss": 0.6537,
      "step": 1268
    },
    {
      "epoch": 0.26,
      "grad_norm": 0.48223891854286194,
      "learning_rate": 1.7409039663831097e-05,
      "loss": 0.6492,
      "step": 1269
    },
    {
      "epoch": 0.26,
      "grad_norm": 0.8610141277313232,
      "learning_rate": 1.7406989853438557e-05,
      "loss": 0.6712,
      "step": 1270
    },
    {
      "epoch": 0.26,
      "grad_norm": 0.8060125708580017,
      "learning_rate": 1.740494004304602e-05,
      "loss": 0.5635,
      "step": 1271
    },
    {
      "epoch": 0.26,
      "grad_norm": 1.4236938953399658,
      "learning_rate": 1.740289023265348e-05,
      "loss": 0.4436,
      "step": 1272
    },
    {
      "epoch": 0.26,
      "grad_norm": 1.0551825761795044,
      "learning_rate": 1.7400840422260944e-05,
      "loss": 0.582,
      "step": 1273
    },
    {
      "epoch": 0.26,
      "grad_norm": 0.6193097233772278,
      "learning_rate": 1.7398790611868405e-05,
      "loss": 0.6832,
      "step": 1274
    },
    {
      "epoch": 0.26,
      "grad_norm": 1.457351565361023,
      "learning_rate": 1.7396740801475865e-05,
      "loss": 0.6419,
      "step": 1275
    },
    {
      "epoch": 0.26,
      "grad_norm": 1.2290664911270142,
      "learning_rate": 1.7394690991083328e-05,
      "loss": 0.4854,
      "step": 1276
    },
    {
      "epoch": 0.26,
      "grad_norm": 0.4882279932498932,
      "learning_rate": 1.739264118069079e-05,
      "loss": 0.503,
      "step": 1277
    },
    {
      "epoch": 0.26,
      "grad_norm": 0.6402392387390137,
      "learning_rate": 1.739059137029825e-05,
      "loss": 0.6236,
      "step": 1278
    },
    {
      "epoch": 0.26,
      "grad_norm": 0.6971977353096008,
      "learning_rate": 1.738854155990571e-05,
      "loss": 0.635,
      "step": 1279
    },
    {
      "epoch": 0.26,
      "grad_norm": 0.6399807929992676,
      "learning_rate": 1.7386491749513172e-05,
      "loss": 0.6546,
      "step": 1280
    },
    {
      "epoch": 0.26,
      "grad_norm": 0.813946545124054,
      "learning_rate": 1.7384441939120632e-05,
      "loss": 0.5274,
      "step": 1281
    },
    {
      "epoch": 0.26,
      "grad_norm": 0.42689958214759827,
      "learning_rate": 1.7382392128728093e-05,
      "loss": 0.5901,
      "step": 1282
    },
    {
      "epoch": 0.26,
      "grad_norm": 0.8480196595191956,
      "learning_rate": 1.7380342318335556e-05,
      "loss": 0.6392,
      "step": 1283
    },
    {
      "epoch": 0.26,
      "grad_norm": 0.7374138832092285,
      "learning_rate": 1.7378292507943016e-05,
      "loss": 0.6052,
      "step": 1284
    },
    {
      "epoch": 0.26,
      "grad_norm": 0.9796348214149475,
      "learning_rate": 1.737624269755048e-05,
      "loss": 0.5608,
      "step": 1285
    },
    {
      "epoch": 0.26,
      "grad_norm": 0.6670116782188416,
      "learning_rate": 1.737419288715794e-05,
      "loss": 0.6468,
      "step": 1286
    },
    {
      "epoch": 0.26,
      "grad_norm": 0.6450726389884949,
      "learning_rate": 1.73721430767654e-05,
      "loss": 0.5499,
      "step": 1287
    },
    {
      "epoch": 0.26,
      "grad_norm": 0.8312482237815857,
      "learning_rate": 1.7370093266372864e-05,
      "loss": 0.5497,
      "step": 1288
    },
    {
      "epoch": 0.26,
      "grad_norm": 1.1720871925354004,
      "learning_rate": 1.7368043455980324e-05,
      "loss": 0.5508,
      "step": 1289
    },
    {
      "epoch": 0.26,
      "grad_norm": 1.3014636039733887,
      "learning_rate": 1.7365993645587784e-05,
      "loss": 0.6684,
      "step": 1290
    },
    {
      "epoch": 0.26,
      "grad_norm": 0.8216764330863953,
      "learning_rate": 1.7363943835195244e-05,
      "loss": 0.6121,
      "step": 1291
    },
    {
      "epoch": 0.26,
      "grad_norm": 1.1059082746505737,
      "learning_rate": 1.7361894024802708e-05,
      "loss": 0.6192,
      "step": 1292
    },
    {
      "epoch": 0.26,
      "grad_norm": 2.552563190460205,
      "learning_rate": 1.7359844214410168e-05,
      "loss": 0.5093,
      "step": 1293
    },
    {
      "epoch": 0.27,
      "grad_norm": 0.7190911769866943,
      "learning_rate": 1.7357794404017628e-05,
      "loss": 0.6871,
      "step": 1294
    },
    {
      "epoch": 0.27,
      "grad_norm": 0.8770358562469482,
      "learning_rate": 1.735574459362509e-05,
      "loss": 0.5514,
      "step": 1295
    },
    {
      "epoch": 0.27,
      "grad_norm": 0.49405840039253235,
      "learning_rate": 1.7353694783232552e-05,
      "loss": 0.6177,
      "step": 1296
    },
    {
      "epoch": 0.27,
      "grad_norm": 0.7957446575164795,
      "learning_rate": 1.7351644972840015e-05,
      "loss": 0.56,
      "step": 1297
    },
    {
      "epoch": 0.27,
      "grad_norm": 0.9183294177055359,
      "learning_rate": 1.7349595162447476e-05,
      "loss": 0.6501,
      "step": 1298
    },
    {
      "epoch": 0.27,
      "grad_norm": 0.4979005753993988,
      "learning_rate": 1.7347545352054936e-05,
      "loss": 0.7014,
      "step": 1299
    },
    {
      "epoch": 0.27,
      "grad_norm": 0.9874870181083679,
      "learning_rate": 1.73454955416624e-05,
      "loss": 0.6821,
      "step": 1300
    },
    {
      "epoch": 0.27,
      "grad_norm": 0.849424421787262,
      "learning_rate": 1.734344573126986e-05,
      "loss": 0.5099,
      "step": 1301
    },
    {
      "epoch": 0.27,
      "grad_norm": 0.5670831799507141,
      "learning_rate": 1.734139592087732e-05,
      "loss": 0.5551,
      "step": 1302
    },
    {
      "epoch": 0.27,
      "grad_norm": 0.4800548255443573,
      "learning_rate": 1.7339346110484783e-05,
      "loss": 0.4894,
      "step": 1303
    },
    {
      "epoch": 0.27,
      "grad_norm": 0.8625893592834473,
      "learning_rate": 1.7337296300092243e-05,
      "loss": 0.5462,
      "step": 1304
    },
    {
      "epoch": 0.27,
      "grad_norm": 0.4950539469718933,
      "learning_rate": 1.7335246489699703e-05,
      "loss": 0.6645,
      "step": 1305
    },
    {
      "epoch": 0.27,
      "grad_norm": 0.9899898171424866,
      "learning_rate": 1.7333196679307164e-05,
      "loss": 0.6763,
      "step": 1306
    },
    {
      "epoch": 0.27,
      "grad_norm": 0.5954983234405518,
      "learning_rate": 1.7331146868914627e-05,
      "loss": 0.558,
      "step": 1307
    },
    {
      "epoch": 0.27,
      "grad_norm": 1.6844900846481323,
      "learning_rate": 1.7329097058522087e-05,
      "loss": 0.6854,
      "step": 1308
    },
    {
      "epoch": 0.27,
      "grad_norm": 0.8620871305465698,
      "learning_rate": 1.732704724812955e-05,
      "loss": 0.5239,
      "step": 1309
    },
    {
      "epoch": 0.27,
      "grad_norm": 0.5192792415618896,
      "learning_rate": 1.732499743773701e-05,
      "loss": 0.5803,
      "step": 1310
    },
    {
      "epoch": 0.27,
      "grad_norm": 0.559499979019165,
      "learning_rate": 1.7322947627344475e-05,
      "loss": 0.7055,
      "step": 1311
    },
    {
      "epoch": 0.27,
      "grad_norm": 0.7967908382415771,
      "learning_rate": 1.7320897816951935e-05,
      "loss": 0.5723,
      "step": 1312
    },
    {
      "epoch": 0.27,
      "grad_norm": 0.6358000040054321,
      "learning_rate": 1.7318848006559395e-05,
      "loss": 0.8349,
      "step": 1313
    },
    {
      "epoch": 0.27,
      "grad_norm": 1.5847203731536865,
      "learning_rate": 1.7316798196166855e-05,
      "loss": 0.5253,
      "step": 1314
    },
    {
      "epoch": 0.27,
      "grad_norm": 0.8105005025863647,
      "learning_rate": 1.731474838577432e-05,
      "loss": 0.6233,
      "step": 1315
    },
    {
      "epoch": 0.27,
      "grad_norm": 0.8942078948020935,
      "learning_rate": 1.731269857538178e-05,
      "loss": 0.5104,
      "step": 1316
    },
    {
      "epoch": 0.27,
      "grad_norm": 1.0169129371643066,
      "learning_rate": 1.731064876498924e-05,
      "loss": 0.5001,
      "step": 1317
    },
    {
      "epoch": 0.27,
      "grad_norm": 1.0042988061904907,
      "learning_rate": 1.73085989545967e-05,
      "loss": 0.6946,
      "step": 1318
    },
    {
      "epoch": 0.27,
      "grad_norm": 0.4564298987388611,
      "learning_rate": 1.7306549144204163e-05,
      "loss": 0.4646,
      "step": 1319
    },
    {
      "epoch": 0.27,
      "grad_norm": 0.7254770398139954,
      "learning_rate": 1.7304499333811623e-05,
      "loss": 0.5447,
      "step": 1320
    },
    {
      "epoch": 0.27,
      "grad_norm": 0.7515467405319214,
      "learning_rate": 1.7302449523419086e-05,
      "loss": 0.5167,
      "step": 1321
    },
    {
      "epoch": 0.27,
      "grad_norm": 0.9003231525421143,
      "learning_rate": 1.7300399713026547e-05,
      "loss": 0.5885,
      "step": 1322
    },
    {
      "epoch": 0.27,
      "grad_norm": 0.5775757431983948,
      "learning_rate": 1.729834990263401e-05,
      "loss": 0.6925,
      "step": 1323
    },
    {
      "epoch": 0.27,
      "grad_norm": 0.7794371843338013,
      "learning_rate": 1.729630009224147e-05,
      "loss": 0.5429,
      "step": 1324
    },
    {
      "epoch": 0.27,
      "grad_norm": 0.6868864893913269,
      "learning_rate": 1.729425028184893e-05,
      "loss": 0.5533,
      "step": 1325
    },
    {
      "epoch": 0.27,
      "grad_norm": 0.6691756844520569,
      "learning_rate": 1.729220047145639e-05,
      "loss": 0.5467,
      "step": 1326
    },
    {
      "epoch": 0.27,
      "grad_norm": 0.7495008111000061,
      "learning_rate": 1.7290150661063854e-05,
      "loss": 0.4301,
      "step": 1327
    },
    {
      "epoch": 0.27,
      "grad_norm": 0.8433192372322083,
      "learning_rate": 1.7288100850671314e-05,
      "loss": 0.4446,
      "step": 1328
    },
    {
      "epoch": 0.27,
      "grad_norm": 0.594143271446228,
      "learning_rate": 1.7286051040278774e-05,
      "loss": 0.6312,
      "step": 1329
    },
    {
      "epoch": 0.27,
      "grad_norm": 0.7274181246757507,
      "learning_rate": 1.7284001229886235e-05,
      "loss": 0.5859,
      "step": 1330
    },
    {
      "epoch": 0.27,
      "grad_norm": 0.5783569812774658,
      "learning_rate": 1.7281951419493698e-05,
      "loss": 0.585,
      "step": 1331
    },
    {
      "epoch": 0.27,
      "grad_norm": 0.9179807901382446,
      "learning_rate": 1.727990160910116e-05,
      "loss": 0.7114,
      "step": 1332
    },
    {
      "epoch": 0.27,
      "grad_norm": 0.8959589004516602,
      "learning_rate": 1.7277851798708622e-05,
      "loss": 0.4676,
      "step": 1333
    },
    {
      "epoch": 0.27,
      "grad_norm": 0.5941171050071716,
      "learning_rate": 1.7275801988316082e-05,
      "loss": 0.6903,
      "step": 1334
    },
    {
      "epoch": 0.27,
      "grad_norm": 0.7084178328514099,
      "learning_rate": 1.7273752177923546e-05,
      "loss": 0.5575,
      "step": 1335
    },
    {
      "epoch": 0.27,
      "grad_norm": 1.504014015197754,
      "learning_rate": 1.7271702367531006e-05,
      "loss": 0.5184,
      "step": 1336
    },
    {
      "epoch": 0.27,
      "grad_norm": 1.418208122253418,
      "learning_rate": 1.7269652557138466e-05,
      "loss": 0.5118,
      "step": 1337
    },
    {
      "epoch": 0.27,
      "grad_norm": 1.716120958328247,
      "learning_rate": 1.726760274674593e-05,
      "loss": 0.6689,
      "step": 1338
    },
    {
      "epoch": 0.27,
      "grad_norm": 0.7110560536384583,
      "learning_rate": 1.726555293635339e-05,
      "loss": 0.5904,
      "step": 1339
    },
    {
      "epoch": 0.27,
      "grad_norm": 1.3866881132125854,
      "learning_rate": 1.726350312596085e-05,
      "loss": 0.5162,
      "step": 1340
    },
    {
      "epoch": 0.27,
      "grad_norm": 0.9098381400108337,
      "learning_rate": 1.726145331556831e-05,
      "loss": 0.56,
      "step": 1341
    },
    {
      "epoch": 0.27,
      "grad_norm": 0.5066974759101868,
      "learning_rate": 1.7259403505175774e-05,
      "loss": 0.5477,
      "step": 1342
    },
    {
      "epoch": 0.28,
      "grad_norm": 0.6656247973442078,
      "learning_rate": 1.7257353694783234e-05,
      "loss": 0.4928,
      "step": 1343
    },
    {
      "epoch": 0.28,
      "grad_norm": 0.9470134377479553,
      "learning_rate": 1.7255303884390694e-05,
      "loss": 0.5837,
      "step": 1344
    },
    {
      "epoch": 0.28,
      "grad_norm": 0.943960964679718,
      "learning_rate": 1.7253254073998157e-05,
      "loss": 0.6133,
      "step": 1345
    },
    {
      "epoch": 0.28,
      "grad_norm": 0.783374547958374,
      "learning_rate": 1.7251204263605618e-05,
      "loss": 0.6248,
      "step": 1346
    },
    {
      "epoch": 0.28,
      "grad_norm": 0.5556337833404541,
      "learning_rate": 1.724915445321308e-05,
      "loss": 0.7219,
      "step": 1347
    },
    {
      "epoch": 0.28,
      "grad_norm": 0.6029803156852722,
      "learning_rate": 1.724710464282054e-05,
      "loss": 0.7305,
      "step": 1348
    },
    {
      "epoch": 0.28,
      "grad_norm": 2.738595724105835,
      "learning_rate": 1.7245054832428e-05,
      "loss": 0.5767,
      "step": 1349
    },
    {
      "epoch": 0.28,
      "grad_norm": 1.022717833518982,
      "learning_rate": 1.7243005022035465e-05,
      "loss": 0.5905,
      "step": 1350
    },
    {
      "epoch": 0.28,
      "grad_norm": 0.9153075814247131,
      "learning_rate": 1.7240955211642925e-05,
      "loss": 0.6065,
      "step": 1351
    },
    {
      "epoch": 0.28,
      "grad_norm": 1.0359997749328613,
      "learning_rate": 1.7238905401250385e-05,
      "loss": 0.4186,
      "step": 1352
    },
    {
      "epoch": 0.28,
      "grad_norm": 1.7910019159317017,
      "learning_rate": 1.7236855590857845e-05,
      "loss": 0.3992,
      "step": 1353
    },
    {
      "epoch": 0.28,
      "grad_norm": 2.396782159805298,
      "learning_rate": 1.723480578046531e-05,
      "loss": 0.4343,
      "step": 1354
    },
    {
      "epoch": 0.28,
      "grad_norm": 0.6984423398971558,
      "learning_rate": 1.723275597007277e-05,
      "loss": 0.5979,
      "step": 1355
    },
    {
      "epoch": 0.28,
      "grad_norm": 0.9322121143341064,
      "learning_rate": 1.723070615968023e-05,
      "loss": 0.6311,
      "step": 1356
    },
    {
      "epoch": 0.28,
      "grad_norm": 1.6208263635635376,
      "learning_rate": 1.7228656349287693e-05,
      "loss": 0.6298,
      "step": 1357
    },
    {
      "epoch": 0.28,
      "grad_norm": 0.5827040672302246,
      "learning_rate": 1.7226606538895153e-05,
      "loss": 0.5999,
      "step": 1358
    },
    {
      "epoch": 0.28,
      "grad_norm": 0.6434630751609802,
      "learning_rate": 1.7224556728502617e-05,
      "loss": 0.7326,
      "step": 1359
    },
    {
      "epoch": 0.28,
      "grad_norm": 0.8688753247261047,
      "learning_rate": 1.7222506918110077e-05,
      "loss": 0.4122,
      "step": 1360
    },
    {
      "epoch": 0.28,
      "grad_norm": 0.46684080362319946,
      "learning_rate": 1.722045710771754e-05,
      "loss": 0.4971,
      "step": 1361
    },
    {
      "epoch": 0.28,
      "grad_norm": 0.7450120449066162,
      "learning_rate": 1.7218407297325e-05,
      "loss": 0.4587,
      "step": 1362
    },
    {
      "epoch": 0.28,
      "grad_norm": 0.7038478255271912,
      "learning_rate": 1.721635748693246e-05,
      "loss": 0.6304,
      "step": 1363
    },
    {
      "epoch": 0.28,
      "grad_norm": 0.5928561091423035,
      "learning_rate": 1.721430767653992e-05,
      "loss": 0.7084,
      "step": 1364
    },
    {
      "epoch": 0.28,
      "grad_norm": 0.5818875432014465,
      "learning_rate": 1.7212257866147384e-05,
      "loss": 0.6343,
      "step": 1365
    },
    {
      "epoch": 0.28,
      "grad_norm": 0.6166658401489258,
      "learning_rate": 1.7210208055754845e-05,
      "loss": 0.6913,
      "step": 1366
    },
    {
      "epoch": 0.28,
      "grad_norm": 0.5697566866874695,
      "learning_rate": 1.7208158245362305e-05,
      "loss": 0.5785,
      "step": 1367
    },
    {
      "epoch": 0.28,
      "grad_norm": 0.5647256374359131,
      "learning_rate": 1.7206108434969765e-05,
      "loss": 0.6255,
      "step": 1368
    },
    {
      "epoch": 0.28,
      "grad_norm": 0.6793409585952759,
      "learning_rate": 1.720405862457723e-05,
      "loss": 0.653,
      "step": 1369
    },
    {
      "epoch": 0.28,
      "grad_norm": 0.7150396108627319,
      "learning_rate": 1.720200881418469e-05,
      "loss": 0.5208,
      "step": 1370
    },
    {
      "epoch": 0.28,
      "grad_norm": 0.5542529225349426,
      "learning_rate": 1.7199959003792152e-05,
      "loss": 0.6703,
      "step": 1371
    },
    {
      "epoch": 0.28,
      "grad_norm": 0.8696192502975464,
      "learning_rate": 1.7197909193399612e-05,
      "loss": 0.7167,
      "step": 1372
    },
    {
      "epoch": 0.28,
      "grad_norm": 0.5688415765762329,
      "learning_rate": 1.7195859383007076e-05,
      "loss": 0.6346,
      "step": 1373
    },
    {
      "epoch": 0.28,
      "grad_norm": 0.7920488119125366,
      "learning_rate": 1.7193809572614536e-05,
      "loss": 0.6222,
      "step": 1374
    },
    {
      "epoch": 0.28,
      "grad_norm": 0.5886764526367188,
      "learning_rate": 1.7191759762221996e-05,
      "loss": 0.5465,
      "step": 1375
    },
    {
      "epoch": 0.28,
      "grad_norm": 0.7526588439941406,
      "learning_rate": 1.7189709951829456e-05,
      "loss": 0.5713,
      "step": 1376
    },
    {
      "epoch": 0.28,
      "grad_norm": 2.046948194503784,
      "learning_rate": 1.718766014143692e-05,
      "loss": 0.5921,
      "step": 1377
    },
    {
      "epoch": 0.28,
      "grad_norm": 0.6655771136283875,
      "learning_rate": 1.718561033104438e-05,
      "loss": 0.563,
      "step": 1378
    },
    {
      "epoch": 0.28,
      "grad_norm": 0.7634278535842896,
      "learning_rate": 1.718356052065184e-05,
      "loss": 0.7264,
      "step": 1379
    },
    {
      "epoch": 0.28,
      "grad_norm": 0.7288808226585388,
      "learning_rate": 1.71815107102593e-05,
      "loss": 0.6639,
      "step": 1380
    },
    {
      "epoch": 0.28,
      "grad_norm": 0.9291777014732361,
      "learning_rate": 1.7179460899866764e-05,
      "loss": 0.5569,
      "step": 1381
    },
    {
      "epoch": 0.28,
      "grad_norm": 0.4469766616821289,
      "learning_rate": 1.7177411089474224e-05,
      "loss": 0.5521,
      "step": 1382
    },
    {
      "epoch": 0.28,
      "grad_norm": 1.082310438156128,
      "learning_rate": 1.7175361279081688e-05,
      "loss": 0.5672,
      "step": 1383
    },
    {
      "epoch": 0.28,
      "grad_norm": 0.7469315528869629,
      "learning_rate": 1.7173311468689148e-05,
      "loss": 0.456,
      "step": 1384
    },
    {
      "epoch": 0.28,
      "grad_norm": 0.6076864004135132,
      "learning_rate": 1.717126165829661e-05,
      "loss": 0.6126,
      "step": 1385
    },
    {
      "epoch": 0.28,
      "grad_norm": 0.584158718585968,
      "learning_rate": 1.716921184790407e-05,
      "loss": 0.6319,
      "step": 1386
    },
    {
      "epoch": 0.28,
      "grad_norm": 1.8670910596847534,
      "learning_rate": 1.716716203751153e-05,
      "loss": 0.5504,
      "step": 1387
    },
    {
      "epoch": 0.28,
      "grad_norm": 1.7230768203735352,
      "learning_rate": 1.7165112227118992e-05,
      "loss": 0.5475,
      "step": 1388
    },
    {
      "epoch": 0.28,
      "grad_norm": 0.7818484306335449,
      "learning_rate": 1.7163062416726455e-05,
      "loss": 0.5027,
      "step": 1389
    },
    {
      "epoch": 0.28,
      "grad_norm": 1.2336845397949219,
      "learning_rate": 1.7161012606333916e-05,
      "loss": 0.5861,
      "step": 1390
    },
    {
      "epoch": 0.28,
      "grad_norm": 0.9788059592247009,
      "learning_rate": 1.7158962795941376e-05,
      "loss": 0.6317,
      "step": 1391
    },
    {
      "epoch": 0.29,
      "grad_norm": 0.9500896334648132,
      "learning_rate": 1.715691298554884e-05,
      "loss": 0.6632,
      "step": 1392
    },
    {
      "epoch": 0.29,
      "grad_norm": 0.825229823589325,
      "learning_rate": 1.71548631751563e-05,
      "loss": 0.6084,
      "step": 1393
    },
    {
      "epoch": 0.29,
      "grad_norm": 0.9803351163864136,
      "learning_rate": 1.715281336476376e-05,
      "loss": 0.623,
      "step": 1394
    },
    {
      "epoch": 0.29,
      "grad_norm": 1.4575011730194092,
      "learning_rate": 1.7150763554371223e-05,
      "loss": 0.4005,
      "step": 1395
    },
    {
      "epoch": 0.29,
      "grad_norm": 0.661566436290741,
      "learning_rate": 1.7148713743978683e-05,
      "loss": 0.6975,
      "step": 1396
    },
    {
      "epoch": 0.29,
      "grad_norm": 0.629935085773468,
      "learning_rate": 1.7146663933586143e-05,
      "loss": 0.44,
      "step": 1397
    },
    {
      "epoch": 0.29,
      "grad_norm": 1.5279983282089233,
      "learning_rate": 1.7144614123193607e-05,
      "loss": 0.6019,
      "step": 1398
    },
    {
      "epoch": 0.29,
      "grad_norm": 1.064817190170288,
      "learning_rate": 1.7142564312801067e-05,
      "loss": 0.4714,
      "step": 1399
    },
    {
      "epoch": 0.29,
      "grad_norm": 0.6565262079238892,
      "learning_rate": 1.714051450240853e-05,
      "loss": 0.5966,
      "step": 1400
    },
    {
      "epoch": 0.29,
      "grad_norm": 0.4982617497444153,
      "learning_rate": 1.713846469201599e-05,
      "loss": 0.5633,
      "step": 1401
    },
    {
      "epoch": 0.29,
      "grad_norm": 0.6325174570083618,
      "learning_rate": 1.713641488162345e-05,
      "loss": 0.6572,
      "step": 1402
    },
    {
      "epoch": 0.29,
      "grad_norm": 0.8662752509117126,
      "learning_rate": 1.713436507123091e-05,
      "loss": 0.5832,
      "step": 1403
    },
    {
      "epoch": 0.29,
      "grad_norm": 0.4819878935813904,
      "learning_rate": 1.7132315260838375e-05,
      "loss": 0.6313,
      "step": 1404
    },
    {
      "epoch": 0.29,
      "grad_norm": 1.2553871870040894,
      "learning_rate": 1.7130265450445835e-05,
      "loss": 0.6069,
      "step": 1405
    },
    {
      "epoch": 0.29,
      "grad_norm": 0.9323967695236206,
      "learning_rate": 1.7128215640053295e-05,
      "loss": 0.7102,
      "step": 1406
    },
    {
      "epoch": 0.29,
      "grad_norm": 0.9684056639671326,
      "learning_rate": 1.712616582966076e-05,
      "loss": 0.5316,
      "step": 1407
    },
    {
      "epoch": 0.29,
      "grad_norm": 1.0790321826934814,
      "learning_rate": 1.712411601926822e-05,
      "loss": 0.6567,
      "step": 1408
    },
    {
      "epoch": 0.29,
      "grad_norm": 0.6630308032035828,
      "learning_rate": 1.712206620887568e-05,
      "loss": 0.5939,
      "step": 1409
    },
    {
      "epoch": 0.29,
      "grad_norm": 1.3190712928771973,
      "learning_rate": 1.7120016398483142e-05,
      "loss": 0.4952,
      "step": 1410
    },
    {
      "epoch": 0.29,
      "grad_norm": 0.5137133598327637,
      "learning_rate": 1.7117966588090603e-05,
      "loss": 0.6424,
      "step": 1411
    },
    {
      "epoch": 0.29,
      "grad_norm": 1.7487090826034546,
      "learning_rate": 1.7115916777698066e-05,
      "loss": 0.6568,
      "step": 1412
    },
    {
      "epoch": 0.29,
      "grad_norm": 0.7576638460159302,
      "learning_rate": 1.7113866967305526e-05,
      "loss": 0.6346,
      "step": 1413
    },
    {
      "epoch": 0.29,
      "grad_norm": 1.0828721523284912,
      "learning_rate": 1.7111817156912987e-05,
      "loss": 0.6546,
      "step": 1414
    },
    {
      "epoch": 0.29,
      "grad_norm": 1.0380789041519165,
      "learning_rate": 1.7109767346520447e-05,
      "loss": 0.6259,
      "step": 1415
    },
    {
      "epoch": 0.29,
      "grad_norm": 0.5895111560821533,
      "learning_rate": 1.710771753612791e-05,
      "loss": 0.507,
      "step": 1416
    },
    {
      "epoch": 0.29,
      "grad_norm": 0.937354564666748,
      "learning_rate": 1.710566772573537e-05,
      "loss": 0.6204,
      "step": 1417
    },
    {
      "epoch": 0.29,
      "grad_norm": 0.7062352299690247,
      "learning_rate": 1.710361791534283e-05,
      "loss": 0.5871,
      "step": 1418
    },
    {
      "epoch": 0.29,
      "grad_norm": 0.7047114372253418,
      "learning_rate": 1.710156810495029e-05,
      "loss": 0.5725,
      "step": 1419
    },
    {
      "epoch": 0.29,
      "grad_norm": 0.621817409992218,
      "learning_rate": 1.7099518294557754e-05,
      "loss": 0.5957,
      "step": 1420
    },
    {
      "epoch": 0.29,
      "grad_norm": 1.098771572113037,
      "learning_rate": 1.7097468484165214e-05,
      "loss": 0.4786,
      "step": 1421
    },
    {
      "epoch": 0.29,
      "grad_norm": 1.1970704793930054,
      "learning_rate": 1.7095418673772678e-05,
      "loss": 0.7416,
      "step": 1422
    },
    {
      "epoch": 0.29,
      "grad_norm": 1.3364408016204834,
      "learning_rate": 1.7093368863380138e-05,
      "loss": 0.4247,
      "step": 1423
    },
    {
      "epoch": 0.29,
      "grad_norm": 1.279963731765747,
      "learning_rate": 1.70913190529876e-05,
      "loss": 0.4571,
      "step": 1424
    },
    {
      "epoch": 0.29,
      "grad_norm": 0.5891528725624084,
      "learning_rate": 1.7089269242595062e-05,
      "loss": 0.5407,
      "step": 1425
    },
    {
      "epoch": 0.29,
      "grad_norm": 0.7491536736488342,
      "learning_rate": 1.7087219432202522e-05,
      "loss": 0.5862,
      "step": 1426
    },
    {
      "epoch": 0.29,
      "grad_norm": 1.2696936130523682,
      "learning_rate": 1.7085169621809986e-05,
      "loss": 0.5804,
      "step": 1427
    },
    {
      "epoch": 0.29,
      "grad_norm": 0.5655589699745178,
      "learning_rate": 1.7083119811417446e-05,
      "loss": 0.5982,
      "step": 1428
    },
    {
      "epoch": 0.29,
      "grad_norm": 0.5247395038604736,
      "learning_rate": 1.7081070001024906e-05,
      "loss": 0.5325,
      "step": 1429
    },
    {
      "epoch": 0.29,
      "grad_norm": 1.3931312561035156,
      "learning_rate": 1.7079020190632366e-05,
      "loss": 0.5372,
      "step": 1430
    },
    {
      "epoch": 0.29,
      "grad_norm": 0.8308396935462952,
      "learning_rate": 1.707697038023983e-05,
      "loss": 0.6615,
      "step": 1431
    },
    {
      "epoch": 0.29,
      "grad_norm": 0.8648917078971863,
      "learning_rate": 1.707492056984729e-05,
      "loss": 0.5802,
      "step": 1432
    },
    {
      "epoch": 0.29,
      "grad_norm": 0.9745562672615051,
      "learning_rate": 1.707287075945475e-05,
      "loss": 0.7514,
      "step": 1433
    },
    {
      "epoch": 0.29,
      "grad_norm": 0.832360565662384,
      "learning_rate": 1.7070820949062213e-05,
      "loss": 0.6537,
      "step": 1434
    },
    {
      "epoch": 0.29,
      "grad_norm": 0.6694221496582031,
      "learning_rate": 1.7068771138669674e-05,
      "loss": 0.6226,
      "step": 1435
    },
    {
      "epoch": 0.29,
      "grad_norm": 1.7840303182601929,
      "learning_rate": 1.7066721328277137e-05,
      "loss": 0.5511,
      "step": 1436
    },
    {
      "epoch": 0.29,
      "grad_norm": 1.2845746278762817,
      "learning_rate": 1.7064671517884597e-05,
      "loss": 0.6477,
      "step": 1437
    },
    {
      "epoch": 0.29,
      "grad_norm": 0.6077301502227783,
      "learning_rate": 1.7062621707492058e-05,
      "loss": 0.6782,
      "step": 1438
    },
    {
      "epoch": 0.29,
      "grad_norm": 0.9102367758750916,
      "learning_rate": 1.706057189709952e-05,
      "loss": 0.6017,
      "step": 1439
    },
    {
      "epoch": 0.3,
      "grad_norm": 1.9552899599075317,
      "learning_rate": 1.705852208670698e-05,
      "loss": 0.4982,
      "step": 1440
    },
    {
      "epoch": 0.3,
      "grad_norm": 0.5201340913772583,
      "learning_rate": 1.705647227631444e-05,
      "loss": 0.5969,
      "step": 1441
    },
    {
      "epoch": 0.3,
      "grad_norm": 0.6341315507888794,
      "learning_rate": 1.70544224659219e-05,
      "loss": 0.5802,
      "step": 1442
    },
    {
      "epoch": 0.3,
      "grad_norm": 1.1000854969024658,
      "learning_rate": 1.7052372655529365e-05,
      "loss": 0.6037,
      "step": 1443
    },
    {
      "epoch": 0.3,
      "grad_norm": 1.4496369361877441,
      "learning_rate": 1.7050322845136825e-05,
      "loss": 0.5334,
      "step": 1444
    },
    {
      "epoch": 0.3,
      "grad_norm": 0.7560088038444519,
      "learning_rate": 1.7048273034744285e-05,
      "loss": 0.6263,
      "step": 1445
    },
    {
      "epoch": 0.3,
      "grad_norm": 0.7439632415771484,
      "learning_rate": 1.704622322435175e-05,
      "loss": 0.5332,
      "step": 1446
    },
    {
      "epoch": 0.3,
      "grad_norm": 1.8394124507904053,
      "learning_rate": 1.704417341395921e-05,
      "loss": 0.508,
      "step": 1447
    },
    {
      "epoch": 0.3,
      "grad_norm": 0.8087986707687378,
      "learning_rate": 1.7042123603566673e-05,
      "loss": 0.6001,
      "step": 1448
    },
    {
      "epoch": 0.3,
      "grad_norm": 0.5912961363792419,
      "learning_rate": 1.7040073793174133e-05,
      "loss": 0.5569,
      "step": 1449
    },
    {
      "epoch": 0.3,
      "grad_norm": 0.9719750285148621,
      "learning_rate": 1.7038023982781596e-05,
      "loss": 0.5767,
      "step": 1450
    },
    {
      "epoch": 0.3,
      "grad_norm": 1.3580797910690308,
      "learning_rate": 1.7035974172389057e-05,
      "loss": 0.454,
      "step": 1451
    },
    {
      "epoch": 0.3,
      "grad_norm": 0.6963120698928833,
      "learning_rate": 1.7033924361996517e-05,
      "loss": 0.5627,
      "step": 1452
    },
    {
      "epoch": 0.3,
      "grad_norm": 0.8004229068756104,
      "learning_rate": 1.7031874551603977e-05,
      "loss": 0.604,
      "step": 1453
    },
    {
      "epoch": 0.3,
      "grad_norm": 0.9804049134254456,
      "learning_rate": 1.702982474121144e-05,
      "loss": 0.6262,
      "step": 1454
    },
    {
      "epoch": 0.3,
      "grad_norm": 1.089925765991211,
      "learning_rate": 1.70277749308189e-05,
      "loss": 0.5578,
      "step": 1455
    },
    {
      "epoch": 0.3,
      "grad_norm": 0.487109899520874,
      "learning_rate": 1.702572512042636e-05,
      "loss": 0.5234,
      "step": 1456
    },
    {
      "epoch": 0.3,
      "grad_norm": 1.5724406242370605,
      "learning_rate": 1.702367531003382e-05,
      "loss": 0.5297,
      "step": 1457
    },
    {
      "epoch": 0.3,
      "grad_norm": 0.8694827556610107,
      "learning_rate": 1.7021625499641284e-05,
      "loss": 0.7011,
      "step": 1458
    },
    {
      "epoch": 0.3,
      "grad_norm": 0.617782711982727,
      "learning_rate": 1.7019575689248745e-05,
      "loss": 0.5845,
      "step": 1459
    },
    {
      "epoch": 0.3,
      "grad_norm": 0.6813617944717407,
      "learning_rate": 1.7017525878856208e-05,
      "loss": 0.5388,
      "step": 1460
    },
    {
      "epoch": 0.3,
      "grad_norm": 0.6345847249031067,
      "learning_rate": 1.701547606846367e-05,
      "loss": 0.5642,
      "step": 1461
    },
    {
      "epoch": 0.3,
      "grad_norm": 1.7785016298294067,
      "learning_rate": 1.7013426258071132e-05,
      "loss": 0.4805,
      "step": 1462
    },
    {
      "epoch": 0.3,
      "grad_norm": 0.772957444190979,
      "learning_rate": 1.7011376447678592e-05,
      "loss": 0.5653,
      "step": 1463
    },
    {
      "epoch": 0.3,
      "grad_norm": 0.7011449337005615,
      "learning_rate": 1.7009326637286052e-05,
      "loss": 0.5573,
      "step": 1464
    },
    {
      "epoch": 0.3,
      "grad_norm": 0.5118207335472107,
      "learning_rate": 1.7007276826893512e-05,
      "loss": 0.6026,
      "step": 1465
    },
    {
      "epoch": 0.3,
      "grad_norm": 0.5007657408714294,
      "learning_rate": 1.7005227016500976e-05,
      "loss": 0.5984,
      "step": 1466
    },
    {
      "epoch": 0.3,
      "grad_norm": 1.5030301809310913,
      "learning_rate": 1.7003177206108436e-05,
      "loss": 0.557,
      "step": 1467
    },
    {
      "epoch": 0.3,
      "grad_norm": 1.7471920251846313,
      "learning_rate": 1.7001127395715896e-05,
      "loss": 0.6265,
      "step": 1468
    },
    {
      "epoch": 0.3,
      "grad_norm": 0.5552562475204468,
      "learning_rate": 1.6999077585323356e-05,
      "loss": 0.5419,
      "step": 1469
    },
    {
      "epoch": 0.3,
      "grad_norm": 1.137403964996338,
      "learning_rate": 1.699702777493082e-05,
      "loss": 0.5575,
      "step": 1470
    },
    {
      "epoch": 0.3,
      "grad_norm": 1.2026865482330322,
      "learning_rate": 1.699497796453828e-05,
      "loss": 0.3949,
      "step": 1471
    },
    {
      "epoch": 0.3,
      "grad_norm": 0.6103307604789734,
      "learning_rate": 1.6992928154145744e-05,
      "loss": 0.6562,
      "step": 1472
    },
    {
      "epoch": 0.3,
      "grad_norm": 1.0148427486419678,
      "learning_rate": 1.6990878343753204e-05,
      "loss": 0.4657,
      "step": 1473
    },
    {
      "epoch": 0.3,
      "grad_norm": 0.6005374789237976,
      "learning_rate": 1.6988828533360667e-05,
      "loss": 0.6424,
      "step": 1474
    },
    {
      "epoch": 0.3,
      "grad_norm": 0.9151141047477722,
      "learning_rate": 1.6986778722968128e-05,
      "loss": 0.5099,
      "step": 1475
    },
    {
      "epoch": 0.3,
      "grad_norm": 0.7667863965034485,
      "learning_rate": 1.6984728912575588e-05,
      "loss": 0.6164,
      "step": 1476
    },
    {
      "epoch": 0.3,
      "grad_norm": 0.543389618396759,
      "learning_rate": 1.6982679102183048e-05,
      "loss": 0.5598,
      "step": 1477
    },
    {
      "epoch": 0.3,
      "grad_norm": 1.1728570461273193,
      "learning_rate": 1.698062929179051e-05,
      "loss": 0.4666,
      "step": 1478
    },
    {
      "epoch": 0.3,
      "grad_norm": 0.7646595239639282,
      "learning_rate": 1.697857948139797e-05,
      "loss": 0.4802,
      "step": 1479
    },
    {
      "epoch": 0.3,
      "grad_norm": 1.0102994441986084,
      "learning_rate": 1.6976529671005432e-05,
      "loss": 0.6536,
      "step": 1480
    },
    {
      "epoch": 0.3,
      "grad_norm": 3.0033040046691895,
      "learning_rate": 1.6974479860612895e-05,
      "loss": 0.4624,
      "step": 1481
    },
    {
      "epoch": 0.3,
      "grad_norm": 0.6125076413154602,
      "learning_rate": 1.6972430050220355e-05,
      "loss": 0.64,
      "step": 1482
    },
    {
      "epoch": 0.3,
      "grad_norm": 1.301892638206482,
      "learning_rate": 1.6970380239827816e-05,
      "loss": 0.5854,
      "step": 1483
    },
    {
      "epoch": 0.3,
      "grad_norm": 0.7615789175033569,
      "learning_rate": 1.696833042943528e-05,
      "loss": 0.5246,
      "step": 1484
    },
    {
      "epoch": 0.3,
      "grad_norm": 0.5869591236114502,
      "learning_rate": 1.696628061904274e-05,
      "loss": 0.5647,
      "step": 1485
    },
    {
      "epoch": 0.3,
      "grad_norm": 0.8340713977813721,
      "learning_rate": 1.6964230808650203e-05,
      "loss": 0.6261,
      "step": 1486
    },
    {
      "epoch": 0.3,
      "grad_norm": 0.9458353519439697,
      "learning_rate": 1.6962180998257663e-05,
      "loss": 0.5456,
      "step": 1487
    },
    {
      "epoch": 0.3,
      "grad_norm": 0.717164933681488,
      "learning_rate": 1.6960131187865123e-05,
      "loss": 0.504,
      "step": 1488
    },
    {
      "epoch": 0.31,
      "grad_norm": 0.6338264346122742,
      "learning_rate": 1.6958081377472587e-05,
      "loss": 0.5698,
      "step": 1489
    },
    {
      "epoch": 0.31,
      "grad_norm": 0.4884253740310669,
      "learning_rate": 1.6956031567080047e-05,
      "loss": 0.5746,
      "step": 1490
    },
    {
      "epoch": 0.31,
      "grad_norm": 0.6519578695297241,
      "learning_rate": 1.6953981756687507e-05,
      "loss": 0.5983,
      "step": 1491
    },
    {
      "epoch": 0.31,
      "grad_norm": 1.0662013292312622,
      "learning_rate": 1.6951931946294967e-05,
      "loss": 0.4923,
      "step": 1492
    },
    {
      "epoch": 0.31,
      "grad_norm": 0.840713381767273,
      "learning_rate": 1.694988213590243e-05,
      "loss": 0.5304,
      "step": 1493
    },
    {
      "epoch": 0.31,
      "grad_norm": 0.7370150685310364,
      "learning_rate": 1.694783232550989e-05,
      "loss": 0.6106,
      "step": 1494
    },
    {
      "epoch": 0.31,
      "grad_norm": 0.9337832927703857,
      "learning_rate": 1.694578251511735e-05,
      "loss": 0.5662,
      "step": 1495
    },
    {
      "epoch": 0.31,
      "grad_norm": 0.8361760377883911,
      "learning_rate": 1.6943732704724815e-05,
      "loss": 0.5535,
      "step": 1496
    },
    {
      "epoch": 0.31,
      "grad_norm": 0.5842688083648682,
      "learning_rate": 1.6941682894332275e-05,
      "loss": 0.5508,
      "step": 1497
    },
    {
      "epoch": 0.31,
      "grad_norm": 0.5847613215446472,
      "learning_rate": 1.693963308393974e-05,
      "loss": 0.5337,
      "step": 1498
    },
    {
      "epoch": 0.31,
      "grad_norm": 0.47780507802963257,
      "learning_rate": 1.69375832735472e-05,
      "loss": 0.5818,
      "step": 1499
    },
    {
      "epoch": 0.31,
      "grad_norm": 0.6132011413574219,
      "learning_rate": 1.693553346315466e-05,
      "loss": 0.532,
      "step": 1500
    },
    {
      "epoch": 0.31,
      "grad_norm": 0.9175974130630493,
      "learning_rate": 1.6933483652762122e-05,
      "loss": 0.5113,
      "step": 1501
    },
    {
      "epoch": 0.31,
      "grad_norm": 0.7772498726844788,
      "learning_rate": 1.6931433842369582e-05,
      "loss": 0.555,
      "step": 1502
    },
    {
      "epoch": 0.31,
      "grad_norm": 0.7180939316749573,
      "learning_rate": 1.6929384031977043e-05,
      "loss": 0.5541,
      "step": 1503
    },
    {
      "epoch": 0.31,
      "grad_norm": 0.6109021306037903,
      "learning_rate": 1.6927334221584503e-05,
      "loss": 0.5627,
      "step": 1504
    },
    {
      "epoch": 0.31,
      "grad_norm": 1.1009056568145752,
      "learning_rate": 1.6925284411191966e-05,
      "loss": 0.3326,
      "step": 1505
    },
    {
      "epoch": 0.31,
      "grad_norm": 0.7030218839645386,
      "learning_rate": 1.6923234600799426e-05,
      "loss": 0.5502,
      "step": 1506
    },
    {
      "epoch": 0.31,
      "grad_norm": 0.9219755530357361,
      "learning_rate": 1.6921184790406887e-05,
      "loss": 0.6754,
      "step": 1507
    },
    {
      "epoch": 0.31,
      "grad_norm": 0.6740766763687134,
      "learning_rate": 1.691913498001435e-05,
      "loss": 0.693,
      "step": 1508
    },
    {
      "epoch": 0.31,
      "grad_norm": 1.3233534097671509,
      "learning_rate": 1.691708516962181e-05,
      "loss": 0.4936,
      "step": 1509
    },
    {
      "epoch": 0.31,
      "grad_norm": 1.0513663291931152,
      "learning_rate": 1.6915035359229274e-05,
      "loss": 0.4653,
      "step": 1510
    },
    {
      "epoch": 0.31,
      "grad_norm": 1.5166627168655396,
      "learning_rate": 1.6912985548836734e-05,
      "loss": 0.6222,
      "step": 1511
    },
    {
      "epoch": 0.31,
      "grad_norm": 1.509883999824524,
      "learning_rate": 1.6910935738444198e-05,
      "loss": 0.6359,
      "step": 1512
    },
    {
      "epoch": 0.31,
      "grad_norm": 0.6630398631095886,
      "learning_rate": 1.6908885928051658e-05,
      "loss": 0.47,
      "step": 1513
    },
    {
      "epoch": 0.31,
      "grad_norm": 0.7672303915023804,
      "learning_rate": 1.6906836117659118e-05,
      "loss": 0.5428,
      "step": 1514
    },
    {
      "epoch": 0.31,
      "grad_norm": 0.5605847239494324,
      "learning_rate": 1.6904786307266578e-05,
      "loss": 0.6106,
      "step": 1515
    },
    {
      "epoch": 0.31,
      "grad_norm": 1.0969082117080688,
      "learning_rate": 1.690273649687404e-05,
      "loss": 0.4492,
      "step": 1516
    },
    {
      "epoch": 0.31,
      "grad_norm": 0.9377955198287964,
      "learning_rate": 1.6900686686481502e-05,
      "loss": 0.6142,
      "step": 1517
    },
    {
      "epoch": 0.31,
      "grad_norm": 0.6595229506492615,
      "learning_rate": 1.6898636876088962e-05,
      "loss": 0.3696,
      "step": 1518
    },
    {
      "epoch": 0.31,
      "grad_norm": 2.0674126148223877,
      "learning_rate": 1.6896587065696422e-05,
      "loss": 0.5345,
      "step": 1519
    },
    {
      "epoch": 0.31,
      "grad_norm": 1.127084493637085,
      "learning_rate": 1.6894537255303886e-05,
      "loss": 0.5773,
      "step": 1520
    },
    {
      "epoch": 0.31,
      "grad_norm": 0.6802537441253662,
      "learning_rate": 1.6892487444911346e-05,
      "loss": 0.3413,
      "step": 1521
    },
    {
      "epoch": 0.31,
      "grad_norm": 0.9587801098823547,
      "learning_rate": 1.689043763451881e-05,
      "loss": 0.4494,
      "step": 1522
    },
    {
      "epoch": 0.31,
      "grad_norm": 2.118302822113037,
      "learning_rate": 1.688838782412627e-05,
      "loss": 0.6831,
      "step": 1523
    },
    {
      "epoch": 0.31,
      "grad_norm": 0.5462909936904907,
      "learning_rate": 1.6886338013733733e-05,
      "loss": 0.557,
      "step": 1524
    },
    {
      "epoch": 0.31,
      "grad_norm": 1.0800049304962158,
      "learning_rate": 1.6884288203341193e-05,
      "loss": 0.468,
      "step": 1525
    },
    {
      "epoch": 0.31,
      "grad_norm": 1.020974040031433,
      "learning_rate": 1.6882238392948653e-05,
      "loss": 0.4571,
      "step": 1526
    },
    {
      "epoch": 0.31,
      "grad_norm": 1.4176539182662964,
      "learning_rate": 1.6880188582556114e-05,
      "loss": 0.5163,
      "step": 1527
    },
    {
      "epoch": 0.31,
      "grad_norm": 0.5489646792411804,
      "learning_rate": 1.6878138772163577e-05,
      "loss": 0.4671,
      "step": 1528
    },
    {
      "epoch": 0.31,
      "grad_norm": 0.5310382843017578,
      "learning_rate": 1.6876088961771037e-05,
      "loss": 0.3942,
      "step": 1529
    },
    {
      "epoch": 0.31,
      "grad_norm": 0.6502390503883362,
      "learning_rate": 1.6874039151378497e-05,
      "loss": 0.4922,
      "step": 1530
    },
    {
      "epoch": 0.31,
      "grad_norm": 0.7650313377380371,
      "learning_rate": 1.6871989340985958e-05,
      "loss": 0.5552,
      "step": 1531
    },
    {
      "epoch": 0.31,
      "grad_norm": 0.7155864834785461,
      "learning_rate": 1.686993953059342e-05,
      "loss": 0.5556,
      "step": 1532
    },
    {
      "epoch": 0.31,
      "grad_norm": 0.5932578444480896,
      "learning_rate": 1.686788972020088e-05,
      "loss": 0.54,
      "step": 1533
    },
    {
      "epoch": 0.31,
      "grad_norm": 0.69143146276474,
      "learning_rate": 1.6865839909808345e-05,
      "loss": 0.6523,
      "step": 1534
    },
    {
      "epoch": 0.31,
      "grad_norm": 0.7920687794685364,
      "learning_rate": 1.6863790099415805e-05,
      "loss": 0.4822,
      "step": 1535
    },
    {
      "epoch": 0.31,
      "grad_norm": 1.4263103008270264,
      "learning_rate": 1.686174028902327e-05,
      "loss": 0.5719,
      "step": 1536
    },
    {
      "epoch": 0.31,
      "grad_norm": 0.7654801607131958,
      "learning_rate": 1.685969047863073e-05,
      "loss": 0.6066,
      "step": 1537
    },
    {
      "epoch": 0.32,
      "grad_norm": 0.6867973804473877,
      "learning_rate": 1.685764066823819e-05,
      "loss": 0.6341,
      "step": 1538
    },
    {
      "epoch": 0.32,
      "grad_norm": 0.7788054347038269,
      "learning_rate": 1.6855590857845652e-05,
      "loss": 0.4859,
      "step": 1539
    },
    {
      "epoch": 0.32,
      "grad_norm": 1.417726993560791,
      "learning_rate": 1.6853541047453113e-05,
      "loss": 0.4527,
      "step": 1540
    },
    {
      "epoch": 0.32,
      "grad_norm": 0.7047397494316101,
      "learning_rate": 1.6851491237060573e-05,
      "loss": 0.3923,
      "step": 1541
    },
    {
      "epoch": 0.32,
      "grad_norm": 1.5901713371276855,
      "learning_rate": 1.6849441426668033e-05,
      "loss": 0.5369,
      "step": 1542
    },
    {
      "epoch": 0.32,
      "grad_norm": 1.273614525794983,
      "learning_rate": 1.6847391616275497e-05,
      "loss": 0.5141,
      "step": 1543
    },
    {
      "epoch": 0.32,
      "grad_norm": 0.773471474647522,
      "learning_rate": 1.6845341805882957e-05,
      "loss": 0.4232,
      "step": 1544
    },
    {
      "epoch": 0.32,
      "grad_norm": 1.2924140691757202,
      "learning_rate": 1.6843291995490417e-05,
      "loss": 0.6005,
      "step": 1545
    },
    {
      "epoch": 0.32,
      "grad_norm": 1.4871313571929932,
      "learning_rate": 1.684124218509788e-05,
      "loss": 0.4522,
      "step": 1546
    },
    {
      "epoch": 0.32,
      "grad_norm": 0.6525979042053223,
      "learning_rate": 1.683919237470534e-05,
      "loss": 0.5887,
      "step": 1547
    },
    {
      "epoch": 0.32,
      "grad_norm": 0.918015718460083,
      "learning_rate": 1.6837142564312804e-05,
      "loss": 0.4125,
      "step": 1548
    },
    {
      "epoch": 0.32,
      "grad_norm": 0.8145923614501953,
      "learning_rate": 1.6835092753920264e-05,
      "loss": 0.3762,
      "step": 1549
    },
    {
      "epoch": 0.32,
      "grad_norm": 0.9384548664093018,
      "learning_rate": 1.6833042943527724e-05,
      "loss": 0.6433,
      "step": 1550
    },
    {
      "epoch": 0.32,
      "grad_norm": 0.6503298282623291,
      "learning_rate": 1.6830993133135188e-05,
      "loss": 0.6429,
      "step": 1551
    },
    {
      "epoch": 0.32,
      "grad_norm": 0.5051053166389465,
      "learning_rate": 1.6828943322742648e-05,
      "loss": 0.5902,
      "step": 1552
    },
    {
      "epoch": 0.32,
      "grad_norm": 1.0084500312805176,
      "learning_rate": 1.682689351235011e-05,
      "loss": 0.6327,
      "step": 1553
    },
    {
      "epoch": 0.32,
      "grad_norm": 1.7875511646270752,
      "learning_rate": 1.682484370195757e-05,
      "loss": 0.4058,
      "step": 1554
    },
    {
      "epoch": 0.32,
      "grad_norm": 0.6473841071128845,
      "learning_rate": 1.6822793891565032e-05,
      "loss": 0.6579,
      "step": 1555
    },
    {
      "epoch": 0.32,
      "grad_norm": 1.017788052558899,
      "learning_rate": 1.6820744081172492e-05,
      "loss": 0.5829,
      "step": 1556
    },
    {
      "epoch": 0.32,
      "grad_norm": 0.8418326377868652,
      "learning_rate": 1.6818694270779952e-05,
      "loss": 0.6113,
      "step": 1557
    },
    {
      "epoch": 0.32,
      "grad_norm": 0.6439622640609741,
      "learning_rate": 1.6816644460387416e-05,
      "loss": 0.5375,
      "step": 1558
    },
    {
      "epoch": 0.32,
      "grad_norm": 0.7161807417869568,
      "learning_rate": 1.6814594649994876e-05,
      "loss": 0.553,
      "step": 1559
    },
    {
      "epoch": 0.32,
      "grad_norm": 1.3178541660308838,
      "learning_rate": 1.681254483960234e-05,
      "loss": 0.5501,
      "step": 1560
    },
    {
      "epoch": 0.32,
      "grad_norm": 0.6014881134033203,
      "learning_rate": 1.68104950292098e-05,
      "loss": 0.6748,
      "step": 1561
    },
    {
      "epoch": 0.32,
      "grad_norm": 1.308899998664856,
      "learning_rate": 1.680844521881726e-05,
      "loss": 0.4865,
      "step": 1562
    },
    {
      "epoch": 0.32,
      "grad_norm": 0.7048689126968384,
      "learning_rate": 1.6806395408424723e-05,
      "loss": 0.5135,
      "step": 1563
    },
    {
      "epoch": 0.32,
      "grad_norm": 0.605164110660553,
      "learning_rate": 1.6804345598032184e-05,
      "loss": 0.4471,
      "step": 1564
    },
    {
      "epoch": 0.32,
      "grad_norm": 0.65097576379776,
      "learning_rate": 1.6802295787639644e-05,
      "loss": 0.5559,
      "step": 1565
    },
    {
      "epoch": 0.32,
      "grad_norm": 0.92476487159729,
      "learning_rate": 1.6800245977247104e-05,
      "loss": 0.5153,
      "step": 1566
    },
    {
      "epoch": 0.32,
      "grad_norm": 0.6292250156402588,
      "learning_rate": 1.6798196166854568e-05,
      "loss": 0.6564,
      "step": 1567
    },
    {
      "epoch": 0.32,
      "grad_norm": 0.8735501766204834,
      "learning_rate": 1.6796146356462028e-05,
      "loss": 0.5219,
      "step": 1568
    },
    {
      "epoch": 0.32,
      "grad_norm": 0.8162030577659607,
      "learning_rate": 1.6794096546069488e-05,
      "loss": 0.6731,
      "step": 1569
    },
    {
      "epoch": 0.32,
      "grad_norm": 0.8076343536376953,
      "learning_rate": 1.679204673567695e-05,
      "loss": 0.628,
      "step": 1570
    },
    {
      "epoch": 0.32,
      "grad_norm": 0.7750017642974854,
      "learning_rate": 1.678999692528441e-05,
      "loss": 0.3997,
      "step": 1571
    },
    {
      "epoch": 0.32,
      "grad_norm": 0.9600683450698853,
      "learning_rate": 1.6787947114891875e-05,
      "loss": 0.4788,
      "step": 1572
    },
    {
      "epoch": 0.32,
      "grad_norm": 0.8635596632957458,
      "learning_rate": 1.6785897304499335e-05,
      "loss": 0.5364,
      "step": 1573
    },
    {
      "epoch": 0.32,
      "grad_norm": 0.9805151224136353,
      "learning_rate": 1.67838474941068e-05,
      "loss": 0.4467,
      "step": 1574
    },
    {
      "epoch": 0.32,
      "grad_norm": 0.5613981485366821,
      "learning_rate": 1.678179768371426e-05,
      "loss": 0.461,
      "step": 1575
    },
    {
      "epoch": 0.32,
      "grad_norm": 1.4984632730484009,
      "learning_rate": 1.677974787332172e-05,
      "loss": 0.5997,
      "step": 1576
    },
    {
      "epoch": 0.32,
      "grad_norm": 0.5582991242408752,
      "learning_rate": 1.677769806292918e-05,
      "loss": 0.5505,
      "step": 1577
    },
    {
      "epoch": 0.32,
      "grad_norm": 0.4967726469039917,
      "learning_rate": 1.6775648252536643e-05,
      "loss": 0.5486,
      "step": 1578
    },
    {
      "epoch": 0.32,
      "grad_norm": 1.079211950302124,
      "learning_rate": 1.6773598442144103e-05,
      "loss": 0.5489,
      "step": 1579
    },
    {
      "epoch": 0.32,
      "grad_norm": 0.6911900639533997,
      "learning_rate": 1.6771548631751563e-05,
      "loss": 0.4548,
      "step": 1580
    },
    {
      "epoch": 0.32,
      "grad_norm": 0.9111732244491577,
      "learning_rate": 1.6769498821359023e-05,
      "loss": 0.6227,
      "step": 1581
    },
    {
      "epoch": 0.32,
      "grad_norm": 1.0069379806518555,
      "learning_rate": 1.6767449010966487e-05,
      "loss": 0.6447,
      "step": 1582
    },
    {
      "epoch": 0.32,
      "grad_norm": 0.7539737224578857,
      "learning_rate": 1.6765399200573947e-05,
      "loss": 0.6143,
      "step": 1583
    },
    {
      "epoch": 0.32,
      "grad_norm": 1.0207445621490479,
      "learning_rate": 1.676334939018141e-05,
      "loss": 0.7162,
      "step": 1584
    },
    {
      "epoch": 0.32,
      "grad_norm": 1.5684609413146973,
      "learning_rate": 1.676129957978887e-05,
      "loss": 0.5684,
      "step": 1585
    },
    {
      "epoch": 0.32,
      "grad_norm": 0.6547241806983948,
      "learning_rate": 1.6759249769396334e-05,
      "loss": 0.6583,
      "step": 1586
    },
    {
      "epoch": 0.33,
      "grad_norm": 1.2669625282287598,
      "learning_rate": 1.6757199959003795e-05,
      "loss": 0.5428,
      "step": 1587
    },
    {
      "epoch": 0.33,
      "grad_norm": 0.9062367081642151,
      "learning_rate": 1.6755150148611255e-05,
      "loss": 0.5876,
      "step": 1588
    },
    {
      "epoch": 0.33,
      "grad_norm": 0.8227617144584656,
      "learning_rate": 1.6753100338218715e-05,
      "loss": 0.6101,
      "step": 1589
    },
    {
      "epoch": 0.33,
      "grad_norm": 0.719382107257843,
      "learning_rate": 1.675105052782618e-05,
      "loss": 0.4038,
      "step": 1590
    },
    {
      "epoch": 0.33,
      "grad_norm": 0.7560623288154602,
      "learning_rate": 1.674900071743364e-05,
      "loss": 0.5992,
      "step": 1591
    },
    {
      "epoch": 0.33,
      "grad_norm": 0.6458967924118042,
      "learning_rate": 1.67469509070411e-05,
      "loss": 0.6339,
      "step": 1592
    },
    {
      "epoch": 0.33,
      "grad_norm": 0.589109480381012,
      "learning_rate": 1.674490109664856e-05,
      "loss": 0.6272,
      "step": 1593
    },
    {
      "epoch": 0.33,
      "grad_norm": 0.6215763688087463,
      "learning_rate": 1.6742851286256022e-05,
      "loss": 0.6867,
      "step": 1594
    },
    {
      "epoch": 0.33,
      "grad_norm": 1.2961788177490234,
      "learning_rate": 1.6740801475863483e-05,
      "loss": 0.5545,
      "step": 1595
    },
    {
      "epoch": 0.33,
      "grad_norm": 0.6495617032051086,
      "learning_rate": 1.6738751665470946e-05,
      "loss": 0.5528,
      "step": 1596
    },
    {
      "epoch": 0.33,
      "grad_norm": 1.4851375818252563,
      "learning_rate": 1.6736701855078406e-05,
      "loss": 0.6529,
      "step": 1597
    },
    {
      "epoch": 0.33,
      "grad_norm": 0.9725810289382935,
      "learning_rate": 1.673465204468587e-05,
      "loss": 0.5396,
      "step": 1598
    },
    {
      "epoch": 0.33,
      "grad_norm": 0.8164690136909485,
      "learning_rate": 1.673260223429333e-05,
      "loss": 0.3536,
      "step": 1599
    },
    {
      "epoch": 0.33,
      "grad_norm": 0.6524404287338257,
      "learning_rate": 1.673055242390079e-05,
      "loss": 0.5773,
      "step": 1600
    },
    {
      "epoch": 0.33,
      "grad_norm": 1.538584589958191,
      "learning_rate": 1.6728502613508254e-05,
      "loss": 0.3966,
      "step": 1601
    },
    {
      "epoch": 0.33,
      "grad_norm": 0.8188105821609497,
      "learning_rate": 1.6726452803115714e-05,
      "loss": 0.5193,
      "step": 1602
    },
    {
      "epoch": 0.33,
      "grad_norm": 0.8420895338058472,
      "learning_rate": 1.6724402992723174e-05,
      "loss": 0.6119,
      "step": 1603
    },
    {
      "epoch": 0.33,
      "grad_norm": 0.5460177659988403,
      "learning_rate": 1.6722353182330634e-05,
      "loss": 0.5087,
      "step": 1604
    },
    {
      "epoch": 0.33,
      "grad_norm": 0.6797110438346863,
      "learning_rate": 1.6720303371938098e-05,
      "loss": 0.6371,
      "step": 1605
    },
    {
      "epoch": 0.33,
      "grad_norm": 0.6304404735565186,
      "learning_rate": 1.6718253561545558e-05,
      "loss": 0.4963,
      "step": 1606
    },
    {
      "epoch": 0.33,
      "grad_norm": 0.6235561966896057,
      "learning_rate": 1.6716203751153018e-05,
      "loss": 0.5718,
      "step": 1607
    },
    {
      "epoch": 0.33,
      "grad_norm": 0.6099548935890198,
      "learning_rate": 1.671415394076048e-05,
      "loss": 0.6333,
      "step": 1608
    },
    {
      "epoch": 0.33,
      "grad_norm": 0.5240814685821533,
      "learning_rate": 1.6712104130367942e-05,
      "loss": 0.5645,
      "step": 1609
    },
    {
      "epoch": 0.33,
      "grad_norm": 0.836094856262207,
      "learning_rate": 1.6710054319975405e-05,
      "loss": 0.6606,
      "step": 1610
    },
    {
      "epoch": 0.33,
      "grad_norm": 0.5074852108955383,
      "learning_rate": 1.6708004509582866e-05,
      "loss": 0.6367,
      "step": 1611
    },
    {
      "epoch": 0.33,
      "grad_norm": 0.8348028659820557,
      "learning_rate": 1.6705954699190326e-05,
      "loss": 0.6072,
      "step": 1612
    },
    {
      "epoch": 0.33,
      "grad_norm": 0.7837212681770325,
      "learning_rate": 1.670390488879779e-05,
      "loss": 0.5409,
      "step": 1613
    },
    {
      "epoch": 0.33,
      "grad_norm": 0.6535000801086426,
      "learning_rate": 1.670185507840525e-05,
      "loss": 0.4004,
      "step": 1614
    },
    {
      "epoch": 0.33,
      "grad_norm": 0.5407872200012207,
      "learning_rate": 1.669980526801271e-05,
      "loss": 0.6772,
      "step": 1615
    },
    {
      "epoch": 0.33,
      "grad_norm": 0.8759889602661133,
      "learning_rate": 1.669775545762017e-05,
      "loss": 0.5427,
      "step": 1616
    },
    {
      "epoch": 0.33,
      "grad_norm": 1.086737871170044,
      "learning_rate": 1.6695705647227633e-05,
      "loss": 0.5253,
      "step": 1617
    },
    {
      "epoch": 0.33,
      "grad_norm": 0.6656686663627625,
      "learning_rate": 1.6693655836835093e-05,
      "loss": 0.5971,
      "step": 1618
    },
    {
      "epoch": 0.33,
      "grad_norm": 1.1970149278640747,
      "learning_rate": 1.6691606026442554e-05,
      "loss": 0.5226,
      "step": 1619
    },
    {
      "epoch": 0.33,
      "grad_norm": 0.6927193999290466,
      "learning_rate": 1.6689556216050017e-05,
      "loss": 0.6014,
      "step": 1620
    },
    {
      "epoch": 0.33,
      "grad_norm": 0.5922743678092957,
      "learning_rate": 1.6687506405657477e-05,
      "loss": 0.6434,
      "step": 1621
    },
    {
      "epoch": 0.33,
      "grad_norm": 2.1439175605773926,
      "learning_rate": 1.668545659526494e-05,
      "loss": 0.6076,
      "step": 1622
    },
    {
      "epoch": 0.33,
      "grad_norm": 0.7486517429351807,
      "learning_rate": 1.66834067848724e-05,
      "loss": 0.5157,
      "step": 1623
    },
    {
      "epoch": 0.33,
      "grad_norm": 0.9766629934310913,
      "learning_rate": 1.668135697447986e-05,
      "loss": 0.5318,
      "step": 1624
    },
    {
      "epoch": 0.33,
      "grad_norm": 0.6418522000312805,
      "learning_rate": 1.6679307164087325e-05,
      "loss": 0.3738,
      "step": 1625
    },
    {
      "epoch": 0.33,
      "grad_norm": 0.8160764575004578,
      "learning_rate": 1.6677257353694785e-05,
      "loss": 0.4865,
      "step": 1626
    },
    {
      "epoch": 0.33,
      "grad_norm": 1.8831959962844849,
      "learning_rate": 1.6675207543302245e-05,
      "loss": 0.298,
      "step": 1627
    },
    {
      "epoch": 0.33,
      "grad_norm": 0.8921478986740112,
      "learning_rate": 1.667315773290971e-05,
      "loss": 0.5996,
      "step": 1628
    },
    {
      "epoch": 0.33,
      "grad_norm": 1.0129103660583496,
      "learning_rate": 1.667110792251717e-05,
      "loss": 0.5359,
      "step": 1629
    },
    {
      "epoch": 0.33,
      "grad_norm": 0.9133020639419556,
      "learning_rate": 1.666905811212463e-05,
      "loss": 0.5565,
      "step": 1630
    },
    {
      "epoch": 0.33,
      "grad_norm": 0.575829803943634,
      "learning_rate": 1.666700830173209e-05,
      "loss": 0.4754,
      "step": 1631
    },
    {
      "epoch": 0.33,
      "grad_norm": 0.666926383972168,
      "learning_rate": 1.6664958491339553e-05,
      "loss": 0.6027,
      "step": 1632
    },
    {
      "epoch": 0.33,
      "grad_norm": 0.698796808719635,
      "learning_rate": 1.6662908680947013e-05,
      "loss": 0.6369,
      "step": 1633
    },
    {
      "epoch": 0.33,
      "grad_norm": 0.6598007678985596,
      "learning_rate": 1.6660858870554476e-05,
      "loss": 0.5087,
      "step": 1634
    },
    {
      "epoch": 0.33,
      "grad_norm": 0.9681737422943115,
      "learning_rate": 1.6658809060161937e-05,
      "loss": 0.4789,
      "step": 1635
    },
    {
      "epoch": 0.34,
      "grad_norm": 0.806402325630188,
      "learning_rate": 1.66567592497694e-05,
      "loss": 0.4405,
      "step": 1636
    },
    {
      "epoch": 0.34,
      "grad_norm": 1.0229896306991577,
      "learning_rate": 1.665470943937686e-05,
      "loss": 0.3663,
      "step": 1637
    },
    {
      "epoch": 0.34,
      "grad_norm": 0.6109407544136047,
      "learning_rate": 1.665265962898432e-05,
      "loss": 0.4549,
      "step": 1638
    },
    {
      "epoch": 0.34,
      "grad_norm": 0.6958716511726379,
      "learning_rate": 1.665060981859178e-05,
      "loss": 0.5656,
      "step": 1639
    },
    {
      "epoch": 0.34,
      "grad_norm": 0.7062833905220032,
      "learning_rate": 1.6648560008199244e-05,
      "loss": 0.6249,
      "step": 1640
    },
    {
      "epoch": 0.34,
      "grad_norm": 0.8163561224937439,
      "learning_rate": 1.6646510197806704e-05,
      "loss": 0.5388,
      "step": 1641
    },
    {
      "epoch": 0.34,
      "grad_norm": 0.7839031219482422,
      "learning_rate": 1.6644460387414164e-05,
      "loss": 0.5456,
      "step": 1642
    },
    {
      "epoch": 0.34,
      "grad_norm": 0.6093508005142212,
      "learning_rate": 1.6642410577021625e-05,
      "loss": 0.5709,
      "step": 1643
    },
    {
      "epoch": 0.34,
      "grad_norm": 0.9317324757575989,
      "learning_rate": 1.6640360766629088e-05,
      "loss": 0.5416,
      "step": 1644
    },
    {
      "epoch": 0.34,
      "grad_norm": 0.6349551677703857,
      "learning_rate": 1.6638310956236548e-05,
      "loss": 0.5502,
      "step": 1645
    },
    {
      "epoch": 0.34,
      "grad_norm": 0.6896551251411438,
      "learning_rate": 1.6636261145844012e-05,
      "loss": 0.4841,
      "step": 1646
    },
    {
      "epoch": 0.34,
      "grad_norm": 0.78227299451828,
      "learning_rate": 1.6634211335451472e-05,
      "loss": 0.5105,
      "step": 1647
    },
    {
      "epoch": 0.34,
      "grad_norm": 0.820128858089447,
      "learning_rate": 1.6632161525058936e-05,
      "loss": 0.4895,
      "step": 1648
    },
    {
      "epoch": 0.34,
      "grad_norm": 1.0504214763641357,
      "learning_rate": 1.6630111714666396e-05,
      "loss": 0.5454,
      "step": 1649
    },
    {
      "epoch": 0.34,
      "grad_norm": 0.7073389887809753,
      "learning_rate": 1.6628061904273856e-05,
      "loss": 0.5665,
      "step": 1650
    },
    {
      "epoch": 0.34,
      "grad_norm": 0.8695961833000183,
      "learning_rate": 1.6626012093881316e-05,
      "loss": 0.6182,
      "step": 1651
    },
    {
      "epoch": 0.34,
      "grad_norm": 0.7897429466247559,
      "learning_rate": 1.662396228348878e-05,
      "loss": 0.5106,
      "step": 1652
    },
    {
      "epoch": 0.34,
      "grad_norm": 0.8207104802131653,
      "learning_rate": 1.662191247309624e-05,
      "loss": 0.6192,
      "step": 1653
    },
    {
      "epoch": 0.34,
      "grad_norm": 0.6068262457847595,
      "learning_rate": 1.66198626627037e-05,
      "loss": 0.5257,
      "step": 1654
    },
    {
      "epoch": 0.34,
      "grad_norm": 0.7998161911964417,
      "learning_rate": 1.661781285231116e-05,
      "loss": 0.5245,
      "step": 1655
    },
    {
      "epoch": 0.34,
      "grad_norm": 1.0210458040237427,
      "learning_rate": 1.6615763041918624e-05,
      "loss": 0.6293,
      "step": 1656
    },
    {
      "epoch": 0.34,
      "grad_norm": 0.6606007814407349,
      "learning_rate": 1.6613713231526084e-05,
      "loss": 0.5746,
      "step": 1657
    },
    {
      "epoch": 0.34,
      "grad_norm": 1.3725398778915405,
      "learning_rate": 1.6611663421133547e-05,
      "loss": 0.3794,
      "step": 1658
    },
    {
      "epoch": 0.34,
      "grad_norm": 0.6189135313034058,
      "learning_rate": 1.6609613610741008e-05,
      "loss": 0.6407,
      "step": 1659
    },
    {
      "epoch": 0.34,
      "grad_norm": 0.70970618724823,
      "learning_rate": 1.660756380034847e-05,
      "loss": 0.4705,
      "step": 1660
    },
    {
      "epoch": 0.34,
      "grad_norm": 0.8332765698432922,
      "learning_rate": 1.660551398995593e-05,
      "loss": 0.5846,
      "step": 1661
    },
    {
      "epoch": 0.34,
      "grad_norm": 0.5797868371009827,
      "learning_rate": 1.660346417956339e-05,
      "loss": 0.545,
      "step": 1662
    },
    {
      "epoch": 0.34,
      "grad_norm": 0.7079054713249207,
      "learning_rate": 1.6601414369170855e-05,
      "loss": 0.571,
      "step": 1663
    },
    {
      "epoch": 0.34,
      "grad_norm": 0.664544939994812,
      "learning_rate": 1.6599364558778315e-05,
      "loss": 0.6125,
      "step": 1664
    },
    {
      "epoch": 0.34,
      "grad_norm": 0.5466228127479553,
      "learning_rate": 1.6597314748385775e-05,
      "loss": 0.4227,
      "step": 1665
    },
    {
      "epoch": 0.34,
      "grad_norm": 0.762506902217865,
      "learning_rate": 1.6595264937993235e-05,
      "loss": 0.619,
      "step": 1666
    },
    {
      "epoch": 0.34,
      "grad_norm": 0.5641332864761353,
      "learning_rate": 1.65932151276007e-05,
      "loss": 0.537,
      "step": 1667
    },
    {
      "epoch": 0.34,
      "grad_norm": 0.5996009111404419,
      "learning_rate": 1.659116531720816e-05,
      "loss": 0.5328,
      "step": 1668
    },
    {
      "epoch": 0.34,
      "grad_norm": 0.8274356126785278,
      "learning_rate": 1.658911550681562e-05,
      "loss": 0.6091,
      "step": 1669
    },
    {
      "epoch": 0.34,
      "grad_norm": 0.8642942309379578,
      "learning_rate": 1.6587065696423083e-05,
      "loss": 0.6053,
      "step": 1670
    },
    {
      "epoch": 0.34,
      "grad_norm": 0.5083860754966736,
      "learning_rate": 1.6585015886030543e-05,
      "loss": 0.5229,
      "step": 1671
    },
    {
      "epoch": 0.34,
      "grad_norm": 0.713253378868103,
      "learning_rate": 1.6582966075638007e-05,
      "loss": 0.4541,
      "step": 1672
    },
    {
      "epoch": 0.34,
      "grad_norm": 0.6308371424674988,
      "learning_rate": 1.6580916265245467e-05,
      "loss": 0.4812,
      "step": 1673
    },
    {
      "epoch": 0.34,
      "grad_norm": 1.0377955436706543,
      "learning_rate": 1.6578866454852927e-05,
      "loss": 0.6655,
      "step": 1674
    },
    {
      "epoch": 0.34,
      "grad_norm": 0.7203810811042786,
      "learning_rate": 1.657681664446039e-05,
      "loss": 0.6282,
      "step": 1675
    },
    {
      "epoch": 0.34,
      "grad_norm": 0.6377701163291931,
      "learning_rate": 1.657476683406785e-05,
      "loss": 0.5904,
      "step": 1676
    },
    {
      "epoch": 0.34,
      "grad_norm": 0.8347584009170532,
      "learning_rate": 1.657271702367531e-05,
      "loss": 0.4628,
      "step": 1677
    },
    {
      "epoch": 0.34,
      "grad_norm": 1.0739927291870117,
      "learning_rate": 1.657066721328277e-05,
      "loss": 0.6038,
      "step": 1678
    },
    {
      "epoch": 0.34,
      "grad_norm": 0.7787837386131287,
      "learning_rate": 1.6568617402890234e-05,
      "loss": 0.5809,
      "step": 1679
    },
    {
      "epoch": 0.34,
      "grad_norm": 0.9990854263305664,
      "learning_rate": 1.6566567592497695e-05,
      "loss": 0.6401,
      "step": 1680
    },
    {
      "epoch": 0.34,
      "grad_norm": 1.3269387483596802,
      "learning_rate": 1.6564517782105155e-05,
      "loss": 0.5009,
      "step": 1681
    },
    {
      "epoch": 0.34,
      "grad_norm": 0.6945544481277466,
      "learning_rate": 1.656246797171262e-05,
      "loss": 0.6429,
      "step": 1682
    },
    {
      "epoch": 0.34,
      "grad_norm": 0.7990537881851196,
      "learning_rate": 1.656041816132008e-05,
      "loss": 0.5566,
      "step": 1683
    },
    {
      "epoch": 0.35,
      "grad_norm": 1.02051842212677,
      "learning_rate": 1.6558368350927542e-05,
      "loss": 0.4815,
      "step": 1684
    },
    {
      "epoch": 0.35,
      "grad_norm": 0.9262992739677429,
      "learning_rate": 1.6556318540535002e-05,
      "loss": 0.5998,
      "step": 1685
    },
    {
      "epoch": 0.35,
      "grad_norm": 0.8053572773933411,
      "learning_rate": 1.6554268730142466e-05,
      "loss": 0.4784,
      "step": 1686
    },
    {
      "epoch": 0.35,
      "grad_norm": 0.9887570738792419,
      "learning_rate": 1.6552218919749926e-05,
      "loss": 0.5836,
      "step": 1687
    },
    {
      "epoch": 0.35,
      "grad_norm": 1.5343080759048462,
      "learning_rate": 1.6550169109357386e-05,
      "loss": 0.4562,
      "step": 1688
    },
    {
      "epoch": 0.35,
      "grad_norm": 1.0085954666137695,
      "learning_rate": 1.6548119298964846e-05,
      "loss": 0.6224,
      "step": 1689
    },
    {
      "epoch": 0.35,
      "grad_norm": 0.6530793309211731,
      "learning_rate": 1.654606948857231e-05,
      "loss": 0.5585,
      "step": 1690
    },
    {
      "epoch": 0.35,
      "grad_norm": 0.6923734545707703,
      "learning_rate": 1.654401967817977e-05,
      "loss": 0.5019,
      "step": 1691
    },
    {
      "epoch": 0.35,
      "grad_norm": 0.673252284526825,
      "learning_rate": 1.654196986778723e-05,
      "loss": 0.5753,
      "step": 1692
    },
    {
      "epoch": 0.35,
      "grad_norm": 1.3941680192947388,
      "learning_rate": 1.653992005739469e-05,
      "loss": 0.4145,
      "step": 1693
    },
    {
      "epoch": 0.35,
      "grad_norm": 1.571424961090088,
      "learning_rate": 1.6537870247002154e-05,
      "loss": 0.7142,
      "step": 1694
    },
    {
      "epoch": 0.35,
      "grad_norm": 0.8749324679374695,
      "learning_rate": 1.6535820436609614e-05,
      "loss": 0.6025,
      "step": 1695
    },
    {
      "epoch": 0.35,
      "grad_norm": 0.7746242880821228,
      "learning_rate": 1.6533770626217078e-05,
      "loss": 0.5249,
      "step": 1696
    },
    {
      "epoch": 0.35,
      "grad_norm": 0.724499523639679,
      "learning_rate": 1.6531720815824538e-05,
      "loss": 0.487,
      "step": 1697
    },
    {
      "epoch": 0.35,
      "grad_norm": 1.410477876663208,
      "learning_rate": 1.6529671005432e-05,
      "loss": 0.5037,
      "step": 1698
    },
    {
      "epoch": 0.35,
      "grad_norm": 0.6430262923240662,
      "learning_rate": 1.652762119503946e-05,
      "loss": 0.48,
      "step": 1699
    },
    {
      "epoch": 0.35,
      "grad_norm": 0.691510796546936,
      "learning_rate": 1.652557138464692e-05,
      "loss": 0.485,
      "step": 1700
    },
    {
      "epoch": 0.35,
      "grad_norm": 1.0568979978561401,
      "learning_rate": 1.6523521574254382e-05,
      "loss": 0.4806,
      "step": 1701
    },
    {
      "epoch": 0.35,
      "grad_norm": 0.7854495644569397,
      "learning_rate": 1.6521471763861845e-05,
      "loss": 0.6492,
      "step": 1702
    },
    {
      "epoch": 0.35,
      "grad_norm": 1.1062934398651123,
      "learning_rate": 1.6519421953469305e-05,
      "loss": 0.4463,
      "step": 1703
    },
    {
      "epoch": 0.35,
      "grad_norm": 1.651571273803711,
      "learning_rate": 1.6517372143076766e-05,
      "loss": 0.3926,
      "step": 1704
    },
    {
      "epoch": 0.35,
      "grad_norm": 0.7464438080787659,
      "learning_rate": 1.6515322332684226e-05,
      "loss": 0.4862,
      "step": 1705
    },
    {
      "epoch": 0.35,
      "grad_norm": 1.1824626922607422,
      "learning_rate": 1.651327252229169e-05,
      "loss": 0.4709,
      "step": 1706
    },
    {
      "epoch": 0.35,
      "grad_norm": 1.5713123083114624,
      "learning_rate": 1.651122271189915e-05,
      "loss": 0.5474,
      "step": 1707
    },
    {
      "epoch": 0.35,
      "grad_norm": 1.0059823989868164,
      "learning_rate": 1.6509172901506613e-05,
      "loss": 0.539,
      "step": 1708
    },
    {
      "epoch": 0.35,
      "grad_norm": 2.53924298286438,
      "learning_rate": 1.6507123091114073e-05,
      "loss": 0.6516,
      "step": 1709
    },
    {
      "epoch": 0.35,
      "grad_norm": 1.0818371772766113,
      "learning_rate": 1.6505073280721537e-05,
      "loss": 0.6082,
      "step": 1710
    },
    {
      "epoch": 0.35,
      "grad_norm": 0.4960727393627167,
      "learning_rate": 1.6503023470328997e-05,
      "loss": 0.4626,
      "step": 1711
    },
    {
      "epoch": 0.35,
      "grad_norm": 0.7706207036972046,
      "learning_rate": 1.6500973659936457e-05,
      "loss": 0.532,
      "step": 1712
    },
    {
      "epoch": 0.35,
      "grad_norm": 1.0712274312973022,
      "learning_rate": 1.6498923849543917e-05,
      "loss": 0.4756,
      "step": 1713
    },
    {
      "epoch": 0.35,
      "grad_norm": 0.566230297088623,
      "learning_rate": 1.649687403915138e-05,
      "loss": 0.5744,
      "step": 1714
    },
    {
      "epoch": 0.35,
      "grad_norm": 0.7589687705039978,
      "learning_rate": 1.649482422875884e-05,
      "loss": 0.5695,
      "step": 1715
    },
    {
      "epoch": 0.35,
      "grad_norm": 1.0569597482681274,
      "learning_rate": 1.64927744183663e-05,
      "loss": 0.6213,
      "step": 1716
    },
    {
      "epoch": 0.35,
      "grad_norm": 0.8063945770263672,
      "learning_rate": 1.6490724607973765e-05,
      "loss": 0.6187,
      "step": 1717
    },
    {
      "epoch": 0.35,
      "grad_norm": 0.6678124666213989,
      "learning_rate": 1.6488674797581225e-05,
      "loss": 0.5937,
      "step": 1718
    },
    {
      "epoch": 0.35,
      "grad_norm": 0.937566339969635,
      "learning_rate": 1.6486624987188685e-05,
      "loss": 0.5034,
      "step": 1719
    },
    {
      "epoch": 0.35,
      "grad_norm": 1.5419297218322754,
      "learning_rate": 1.648457517679615e-05,
      "loss": 0.5691,
      "step": 1720
    },
    {
      "epoch": 0.35,
      "grad_norm": 0.9014100432395935,
      "learning_rate": 1.648252536640361e-05,
      "loss": 0.5447,
      "step": 1721
    },
    {
      "epoch": 0.35,
      "grad_norm": 0.723760724067688,
      "learning_rate": 1.6480475556011072e-05,
      "loss": 0.6474,
      "step": 1722
    },
    {
      "epoch": 0.35,
      "grad_norm": 1.2647135257720947,
      "learning_rate": 1.6478425745618532e-05,
      "loss": 0.4251,
      "step": 1723
    },
    {
      "epoch": 0.35,
      "grad_norm": 0.7779359817504883,
      "learning_rate": 1.6476375935225993e-05,
      "loss": 0.5783,
      "step": 1724
    },
    {
      "epoch": 0.35,
      "grad_norm": 0.8091672658920288,
      "learning_rate": 1.6474326124833456e-05,
      "loss": 0.5762,
      "step": 1725
    },
    {
      "epoch": 0.35,
      "grad_norm": 0.9744724035263062,
      "learning_rate": 1.6472276314440916e-05,
      "loss": 0.6086,
      "step": 1726
    },
    {
      "epoch": 0.35,
      "grad_norm": 0.6156354546546936,
      "learning_rate": 1.6470226504048376e-05,
      "loss": 0.6525,
      "step": 1727
    },
    {
      "epoch": 0.35,
      "grad_norm": 0.9169564247131348,
      "learning_rate": 1.6468176693655837e-05,
      "loss": 0.5122,
      "step": 1728
    },
    {
      "epoch": 0.35,
      "grad_norm": 0.9139271974563599,
      "learning_rate": 1.64661268832633e-05,
      "loss": 0.4411,
      "step": 1729
    },
    {
      "epoch": 0.35,
      "grad_norm": 0.9163761734962463,
      "learning_rate": 1.646407707287076e-05,
      "loss": 0.6305,
      "step": 1730
    },
    {
      "epoch": 0.35,
      "grad_norm": 0.9971905946731567,
      "learning_rate": 1.646202726247822e-05,
      "loss": 0.6537,
      "step": 1731
    },
    {
      "epoch": 0.35,
      "grad_norm": 0.6504819989204407,
      "learning_rate": 1.6459977452085684e-05,
      "loss": 0.4371,
      "step": 1732
    },
    {
      "epoch": 0.36,
      "grad_norm": 0.6784805655479431,
      "learning_rate": 1.6457927641693144e-05,
      "loss": 0.6097,
      "step": 1733
    },
    {
      "epoch": 0.36,
      "grad_norm": 1.0255955457687378,
      "learning_rate": 1.6455877831300608e-05,
      "loss": 0.5838,
      "step": 1734
    },
    {
      "epoch": 0.36,
      "grad_norm": 0.669596254825592,
      "learning_rate": 1.6453828020908068e-05,
      "loss": 0.4716,
      "step": 1735
    },
    {
      "epoch": 0.36,
      "grad_norm": 0.9596995711326599,
      "learning_rate": 1.6451778210515528e-05,
      "loss": 0.4052,
      "step": 1736
    },
    {
      "epoch": 0.36,
      "grad_norm": 0.7337960600852966,
      "learning_rate": 1.644972840012299e-05,
      "loss": 0.6152,
      "step": 1737
    },
    {
      "epoch": 0.36,
      "grad_norm": 0.7096208333969116,
      "learning_rate": 1.6447678589730452e-05,
      "loss": 0.6757,
      "step": 1738
    },
    {
      "epoch": 0.36,
      "grad_norm": 0.5587864518165588,
      "learning_rate": 1.6445628779337912e-05,
      "loss": 0.4912,
      "step": 1739
    },
    {
      "epoch": 0.36,
      "grad_norm": 1.0918282270431519,
      "learning_rate": 1.6443578968945372e-05,
      "loss": 0.4128,
      "step": 1740
    },
    {
      "epoch": 0.36,
      "grad_norm": 0.6577172875404358,
      "learning_rate": 1.6441529158552836e-05,
      "loss": 0.5033,
      "step": 1741
    },
    {
      "epoch": 0.36,
      "grad_norm": 0.60053950548172,
      "learning_rate": 1.6439479348160296e-05,
      "loss": 0.4097,
      "step": 1742
    },
    {
      "epoch": 0.36,
      "grad_norm": 0.8454326391220093,
      "learning_rate": 1.6437429537767756e-05,
      "loss": 0.5428,
      "step": 1743
    },
    {
      "epoch": 0.36,
      "grad_norm": 0.5733681321144104,
      "learning_rate": 1.643537972737522e-05,
      "loss": 0.584,
      "step": 1744
    },
    {
      "epoch": 0.36,
      "grad_norm": 0.8706533312797546,
      "learning_rate": 1.643332991698268e-05,
      "loss": 0.7455,
      "step": 1745
    },
    {
      "epoch": 0.36,
      "grad_norm": 0.8650305867195129,
      "learning_rate": 1.6431280106590143e-05,
      "loss": 0.5723,
      "step": 1746
    },
    {
      "epoch": 0.36,
      "grad_norm": 0.7256678938865662,
      "learning_rate": 1.6429230296197603e-05,
      "loss": 0.5207,
      "step": 1747
    },
    {
      "epoch": 0.36,
      "grad_norm": 0.8742494583129883,
      "learning_rate": 1.6427180485805067e-05,
      "loss": 0.4523,
      "step": 1748
    },
    {
      "epoch": 0.36,
      "grad_norm": 0.8901025056838989,
      "learning_rate": 1.6425130675412527e-05,
      "loss": 0.5735,
      "step": 1749
    },
    {
      "epoch": 0.36,
      "grad_norm": 0.5982896089553833,
      "learning_rate": 1.6423080865019987e-05,
      "loss": 0.4503,
      "step": 1750
    },
    {
      "epoch": 0.36,
      "grad_norm": 0.5671358704566956,
      "learning_rate": 1.6421031054627447e-05,
      "loss": 0.6029,
      "step": 1751
    },
    {
      "epoch": 0.36,
      "grad_norm": 0.8294201493263245,
      "learning_rate": 1.641898124423491e-05,
      "loss": 0.6741,
      "step": 1752
    },
    {
      "epoch": 0.36,
      "grad_norm": 0.7592639327049255,
      "learning_rate": 1.641693143384237e-05,
      "loss": 0.7029,
      "step": 1753
    },
    {
      "epoch": 0.36,
      "grad_norm": 0.7658393979072571,
      "learning_rate": 1.641488162344983e-05,
      "loss": 0.5865,
      "step": 1754
    },
    {
      "epoch": 0.36,
      "grad_norm": 1.1112017631530762,
      "learning_rate": 1.641283181305729e-05,
      "loss": 0.5799,
      "step": 1755
    },
    {
      "epoch": 0.36,
      "grad_norm": 0.4702620208263397,
      "learning_rate": 1.6410782002664755e-05,
      "loss": 0.4455,
      "step": 1756
    },
    {
      "epoch": 0.36,
      "grad_norm": 0.7721081376075745,
      "learning_rate": 1.6408732192272215e-05,
      "loss": 0.3479,
      "step": 1757
    },
    {
      "epoch": 0.36,
      "grad_norm": 0.7274115085601807,
      "learning_rate": 1.640668238187968e-05,
      "loss": 0.6206,
      "step": 1758
    },
    {
      "epoch": 0.36,
      "grad_norm": 0.7792503833770752,
      "learning_rate": 1.640463257148714e-05,
      "loss": 0.4652,
      "step": 1759
    },
    {
      "epoch": 0.36,
      "grad_norm": 0.7404916882514954,
      "learning_rate": 1.6402582761094602e-05,
      "loss": 0.5636,
      "step": 1760
    },
    {
      "epoch": 0.36,
      "grad_norm": 0.6527920365333557,
      "learning_rate": 1.6400532950702063e-05,
      "loss": 0.5022,
      "step": 1761
    },
    {
      "epoch": 0.36,
      "grad_norm": 0.7590650320053101,
      "learning_rate": 1.6398483140309523e-05,
      "loss": 0.6434,
      "step": 1762
    },
    {
      "epoch": 0.36,
      "grad_norm": 1.2435353994369507,
      "learning_rate": 1.6396433329916983e-05,
      "loss": 0.5252,
      "step": 1763
    },
    {
      "epoch": 0.36,
      "grad_norm": 1.1452568769454956,
      "learning_rate": 1.6394383519524447e-05,
      "loss": 0.4953,
      "step": 1764
    },
    {
      "epoch": 0.36,
      "grad_norm": 1.0317296981811523,
      "learning_rate": 1.6392333709131907e-05,
      "loss": 0.5464,
      "step": 1765
    },
    {
      "epoch": 0.36,
      "grad_norm": 0.853760838508606,
      "learning_rate": 1.6390283898739367e-05,
      "loss": 0.4517,
      "step": 1766
    },
    {
      "epoch": 0.36,
      "grad_norm": 0.9589062929153442,
      "learning_rate": 1.6388234088346827e-05,
      "loss": 0.4961,
      "step": 1767
    },
    {
      "epoch": 0.36,
      "grad_norm": 1.1364142894744873,
      "learning_rate": 1.638618427795429e-05,
      "loss": 0.558,
      "step": 1768
    },
    {
      "epoch": 0.36,
      "grad_norm": 1.2899494171142578,
      "learning_rate": 1.638413446756175e-05,
      "loss": 0.5359,
      "step": 1769
    },
    {
      "epoch": 0.36,
      "grad_norm": 0.936962366104126,
      "learning_rate": 1.6382084657169214e-05,
      "loss": 0.5198,
      "step": 1770
    },
    {
      "epoch": 0.36,
      "grad_norm": 0.7122761011123657,
      "learning_rate": 1.6380034846776674e-05,
      "loss": 0.5117,
      "step": 1771
    },
    {
      "epoch": 0.36,
      "grad_norm": 0.6951327323913574,
      "learning_rate": 1.6377985036384138e-05,
      "loss": 0.5001,
      "step": 1772
    },
    {
      "epoch": 0.36,
      "grad_norm": 0.9122344255447388,
      "learning_rate": 1.6375935225991598e-05,
      "loss": 0.6082,
      "step": 1773
    },
    {
      "epoch": 0.36,
      "grad_norm": 0.7351672053337097,
      "learning_rate": 1.637388541559906e-05,
      "loss": 0.5729,
      "step": 1774
    },
    {
      "epoch": 0.36,
      "grad_norm": 0.5665810704231262,
      "learning_rate": 1.6371835605206522e-05,
      "loss": 0.5326,
      "step": 1775
    },
    {
      "epoch": 0.36,
      "grad_norm": 0.6811888813972473,
      "learning_rate": 1.6369785794813982e-05,
      "loss": 0.6175,
      "step": 1776
    },
    {
      "epoch": 0.36,
      "grad_norm": 0.7995415925979614,
      "learning_rate": 1.6367735984421442e-05,
      "loss": 0.3996,
      "step": 1777
    },
    {
      "epoch": 0.36,
      "grad_norm": 0.8535711169242859,
      "learning_rate": 1.6365686174028902e-05,
      "loss": 0.5201,
      "step": 1778
    },
    {
      "epoch": 0.36,
      "grad_norm": 0.8587885499000549,
      "learning_rate": 1.6363636363636366e-05,
      "loss": 0.4917,
      "step": 1779
    },
    {
      "epoch": 0.36,
      "grad_norm": 0.9613382816314697,
      "learning_rate": 1.6361586553243826e-05,
      "loss": 0.466,
      "step": 1780
    },
    {
      "epoch": 0.36,
      "grad_norm": 1.1176598072052002,
      "learning_rate": 1.6359536742851286e-05,
      "loss": 0.4979,
      "step": 1781
    },
    {
      "epoch": 0.37,
      "grad_norm": 1.0687156915664673,
      "learning_rate": 1.635748693245875e-05,
      "loss": 0.433,
      "step": 1782
    },
    {
      "epoch": 0.37,
      "grad_norm": 0.7605177760124207,
      "learning_rate": 1.635543712206621e-05,
      "loss": 0.626,
      "step": 1783
    },
    {
      "epoch": 0.37,
      "grad_norm": 0.7528932690620422,
      "learning_rate": 1.6353387311673673e-05,
      "loss": 0.5544,
      "step": 1784
    },
    {
      "epoch": 0.37,
      "grad_norm": 0.8325492143630981,
      "learning_rate": 1.6351337501281134e-05,
      "loss": 0.565,
      "step": 1785
    },
    {
      "epoch": 0.37,
      "grad_norm": 1.3361061811447144,
      "learning_rate": 1.6349287690888594e-05,
      "loss": 0.511,
      "step": 1786
    },
    {
      "epoch": 0.37,
      "grad_norm": 0.7821720838546753,
      "learning_rate": 1.6347237880496057e-05,
      "loss": 0.4711,
      "step": 1787
    },
    {
      "epoch": 0.37,
      "grad_norm": 0.7568750977516174,
      "learning_rate": 1.6345188070103518e-05,
      "loss": 0.4873,
      "step": 1788
    },
    {
      "epoch": 0.37,
      "grad_norm": 0.9346373677253723,
      "learning_rate": 1.6343138259710978e-05,
      "loss": 0.5265,
      "step": 1789
    },
    {
      "epoch": 0.37,
      "grad_norm": 1.083690881729126,
      "learning_rate": 1.6341088449318438e-05,
      "loss": 0.4331,
      "step": 1790
    },
    {
      "epoch": 0.37,
      "grad_norm": 0.7392241954803467,
      "learning_rate": 1.63390386389259e-05,
      "loss": 0.6272,
      "step": 1791
    },
    {
      "epoch": 0.37,
      "grad_norm": 1.565379023551941,
      "learning_rate": 1.633698882853336e-05,
      "loss": 0.4219,
      "step": 1792
    },
    {
      "epoch": 0.37,
      "grad_norm": 0.9405615329742432,
      "learning_rate": 1.6334939018140822e-05,
      "loss": 0.6011,
      "step": 1793
    },
    {
      "epoch": 0.37,
      "grad_norm": 0.8895688652992249,
      "learning_rate": 1.6332889207748285e-05,
      "loss": 0.6283,
      "step": 1794
    },
    {
      "epoch": 0.37,
      "grad_norm": 1.1552518606185913,
      "learning_rate": 1.6330839397355745e-05,
      "loss": 0.6605,
      "step": 1795
    },
    {
      "epoch": 0.37,
      "grad_norm": 0.7866799831390381,
      "learning_rate": 1.632878958696321e-05,
      "loss": 0.5681,
      "step": 1796
    },
    {
      "epoch": 0.37,
      "grad_norm": 1.2385625839233398,
      "learning_rate": 1.632673977657067e-05,
      "loss": 0.575,
      "step": 1797
    },
    {
      "epoch": 0.37,
      "grad_norm": 1.0655198097229004,
      "learning_rate": 1.632468996617813e-05,
      "loss": 0.5542,
      "step": 1798
    },
    {
      "epoch": 0.37,
      "grad_norm": 1.1506502628326416,
      "learning_rate": 1.6322640155785593e-05,
      "loss": 0.5013,
      "step": 1799
    },
    {
      "epoch": 0.37,
      "grad_norm": 0.8383618593215942,
      "learning_rate": 1.6320590345393053e-05,
      "loss": 0.6746,
      "step": 1800
    },
    {
      "epoch": 0.37,
      "grad_norm": 0.7998085021972656,
      "learning_rate": 1.6318540535000513e-05,
      "loss": 0.4128,
      "step": 1801
    },
    {
      "epoch": 0.37,
      "grad_norm": 0.681084156036377,
      "learning_rate": 1.6316490724607973e-05,
      "loss": 0.3886,
      "step": 1802
    },
    {
      "epoch": 0.37,
      "grad_norm": 1.5224143266677856,
      "learning_rate": 1.6314440914215437e-05,
      "loss": 0.5066,
      "step": 1803
    },
    {
      "epoch": 0.37,
      "grad_norm": 0.7128422260284424,
      "learning_rate": 1.6312391103822897e-05,
      "loss": 0.556,
      "step": 1804
    },
    {
      "epoch": 0.37,
      "grad_norm": 0.9637089371681213,
      "learning_rate": 1.6310341293430357e-05,
      "loss": 0.457,
      "step": 1805
    },
    {
      "epoch": 0.37,
      "grad_norm": 1.552146553993225,
      "learning_rate": 1.630829148303782e-05,
      "loss": 0.4887,
      "step": 1806
    },
    {
      "epoch": 0.37,
      "grad_norm": 1.0228488445281982,
      "learning_rate": 1.630624167264528e-05,
      "loss": 0.6414,
      "step": 1807
    },
    {
      "epoch": 0.37,
      "grad_norm": 0.8008121848106384,
      "learning_rate": 1.6304191862252744e-05,
      "loss": 0.5989,
      "step": 1808
    },
    {
      "epoch": 0.37,
      "grad_norm": 1.4317861795425415,
      "learning_rate": 1.6302142051860205e-05,
      "loss": 0.613,
      "step": 1809
    },
    {
      "epoch": 0.37,
      "grad_norm": 0.8892465829849243,
      "learning_rate": 1.6300092241467668e-05,
      "loss": 0.587,
      "step": 1810
    },
    {
      "epoch": 0.37,
      "grad_norm": 0.806516706943512,
      "learning_rate": 1.629804243107513e-05,
      "loss": 0.6501,
      "step": 1811
    },
    {
      "epoch": 0.37,
      "grad_norm": 1.1655118465423584,
      "learning_rate": 1.629599262068259e-05,
      "loss": 0.5005,
      "step": 1812
    },
    {
      "epoch": 0.37,
      "grad_norm": 1.0679457187652588,
      "learning_rate": 1.629394281029005e-05,
      "loss": 0.3544,
      "step": 1813
    },
    {
      "epoch": 0.37,
      "grad_norm": 0.8231015205383301,
      "learning_rate": 1.6291892999897512e-05,
      "loss": 0.7401,
      "step": 1814
    },
    {
      "epoch": 0.37,
      "grad_norm": 0.9781939387321472,
      "learning_rate": 1.6289843189504972e-05,
      "loss": 0.5392,
      "step": 1815
    },
    {
      "epoch": 0.37,
      "grad_norm": 0.9638791680335999,
      "learning_rate": 1.6287793379112433e-05,
      "loss": 0.3669,
      "step": 1816
    },
    {
      "epoch": 0.37,
      "grad_norm": 0.7631210088729858,
      "learning_rate": 1.6285743568719893e-05,
      "loss": 0.5698,
      "step": 1817
    },
    {
      "epoch": 0.37,
      "grad_norm": 1.021750807762146,
      "learning_rate": 1.6283693758327356e-05,
      "loss": 0.4493,
      "step": 1818
    },
    {
      "epoch": 0.37,
      "grad_norm": 0.985220193862915,
      "learning_rate": 1.6281643947934816e-05,
      "loss": 0.4917,
      "step": 1819
    },
    {
      "epoch": 0.37,
      "grad_norm": 1.0531057119369507,
      "learning_rate": 1.627959413754228e-05,
      "loss": 0.7009,
      "step": 1820
    },
    {
      "epoch": 0.37,
      "grad_norm": 0.7230086922645569,
      "learning_rate": 1.627754432714974e-05,
      "loss": 0.4405,
      "step": 1821
    },
    {
      "epoch": 0.37,
      "grad_norm": 0.9590867757797241,
      "learning_rate": 1.6275494516757204e-05,
      "loss": 0.5393,
      "step": 1822
    },
    {
      "epoch": 0.37,
      "grad_norm": 1.0839567184448242,
      "learning_rate": 1.6273444706364664e-05,
      "loss": 0.5792,
      "step": 1823
    },
    {
      "epoch": 0.37,
      "grad_norm": 0.7548925280570984,
      "learning_rate": 1.6271394895972124e-05,
      "loss": 0.4772,
      "step": 1824
    },
    {
      "epoch": 0.37,
      "grad_norm": 0.7321885824203491,
      "learning_rate": 1.6269345085579584e-05,
      "loss": 0.5052,
      "step": 1825
    },
    {
      "epoch": 0.37,
      "grad_norm": 0.8312947154045105,
      "learning_rate": 1.6267295275187048e-05,
      "loss": 0.5053,
      "step": 1826
    },
    {
      "epoch": 0.37,
      "grad_norm": 2.0956263542175293,
      "learning_rate": 1.6265245464794508e-05,
      "loss": 0.6268,
      "step": 1827
    },
    {
      "epoch": 0.37,
      "grad_norm": 1.7219163179397583,
      "learning_rate": 1.6263195654401968e-05,
      "loss": 0.461,
      "step": 1828
    },
    {
      "epoch": 0.37,
      "grad_norm": 0.7334265112876892,
      "learning_rate": 1.6261145844009428e-05,
      "loss": 0.7091,
      "step": 1829
    },
    {
      "epoch": 0.37,
      "grad_norm": 2.7158217430114746,
      "learning_rate": 1.6259096033616892e-05,
      "loss": 0.5342,
      "step": 1830
    },
    {
      "epoch": 0.38,
      "grad_norm": 1.1312446594238281,
      "learning_rate": 1.6257046223224352e-05,
      "loss": 0.4802,
      "step": 1831
    },
    {
      "epoch": 0.38,
      "grad_norm": 0.7706102132797241,
      "learning_rate": 1.6254996412831815e-05,
      "loss": 0.389,
      "step": 1832
    },
    {
      "epoch": 0.38,
      "grad_norm": 1.0940450429916382,
      "learning_rate": 1.6252946602439276e-05,
      "loss": 0.5471,
      "step": 1833
    },
    {
      "epoch": 0.38,
      "grad_norm": 1.4126124382019043,
      "learning_rate": 1.625089679204674e-05,
      "loss": 0.6299,
      "step": 1834
    },
    {
      "epoch": 0.38,
      "grad_norm": 2.114290714263916,
      "learning_rate": 1.62488469816542e-05,
      "loss": 0.5142,
      "step": 1835
    },
    {
      "epoch": 0.38,
      "grad_norm": 1.3817329406738281,
      "learning_rate": 1.624679717126166e-05,
      "loss": 0.4982,
      "step": 1836
    },
    {
      "epoch": 0.38,
      "grad_norm": 0.80378258228302,
      "learning_rate": 1.6244747360869123e-05,
      "loss": 0.5266,
      "step": 1837
    },
    {
      "epoch": 0.38,
      "grad_norm": 0.535494863986969,
      "learning_rate": 1.6242697550476583e-05,
      "loss": 0.5688,
      "step": 1838
    },
    {
      "epoch": 0.38,
      "grad_norm": 0.539146363735199,
      "learning_rate": 1.6240647740084043e-05,
      "loss": 0.4302,
      "step": 1839
    },
    {
      "epoch": 0.38,
      "grad_norm": 0.8844977021217346,
      "learning_rate": 1.6238597929691504e-05,
      "loss": 0.4791,
      "step": 1840
    },
    {
      "epoch": 0.38,
      "grad_norm": 0.8257958292961121,
      "learning_rate": 1.6236548119298967e-05,
      "loss": 0.4668,
      "step": 1841
    },
    {
      "epoch": 0.38,
      "grad_norm": 0.6533525586128235,
      "learning_rate": 1.6234498308906427e-05,
      "loss": 0.6052,
      "step": 1842
    },
    {
      "epoch": 0.38,
      "grad_norm": 0.9134606122970581,
      "learning_rate": 1.6232448498513887e-05,
      "loss": 0.6246,
      "step": 1843
    },
    {
      "epoch": 0.38,
      "grad_norm": 0.9806819558143616,
      "learning_rate": 1.623039868812135e-05,
      "loss": 0.3446,
      "step": 1844
    },
    {
      "epoch": 0.38,
      "grad_norm": 0.7158230543136597,
      "learning_rate": 1.622834887772881e-05,
      "loss": 0.6019,
      "step": 1845
    },
    {
      "epoch": 0.38,
      "grad_norm": 1.6202775239944458,
      "learning_rate": 1.6226299067336275e-05,
      "loss": 0.4761,
      "step": 1846
    },
    {
      "epoch": 0.38,
      "grad_norm": 1.0592659711837769,
      "learning_rate": 1.6224249256943735e-05,
      "loss": 0.5584,
      "step": 1847
    },
    {
      "epoch": 0.38,
      "grad_norm": 1.1659718751907349,
      "learning_rate": 1.6222199446551195e-05,
      "loss": 0.3965,
      "step": 1848
    },
    {
      "epoch": 0.38,
      "grad_norm": 0.7322186231613159,
      "learning_rate": 1.622014963615866e-05,
      "loss": 0.4739,
      "step": 1849
    },
    {
      "epoch": 0.38,
      "grad_norm": 0.8118440508842468,
      "learning_rate": 1.621809982576612e-05,
      "loss": 0.5372,
      "step": 1850
    },
    {
      "epoch": 0.38,
      "grad_norm": 0.9065337777137756,
      "learning_rate": 1.621605001537358e-05,
      "loss": 0.6717,
      "step": 1851
    },
    {
      "epoch": 0.38,
      "grad_norm": 0.989113986492157,
      "learning_rate": 1.621400020498104e-05,
      "loss": 0.6394,
      "step": 1852
    },
    {
      "epoch": 0.38,
      "grad_norm": 0.7326028943061829,
      "learning_rate": 1.6211950394588503e-05,
      "loss": 0.6234,
      "step": 1853
    },
    {
      "epoch": 0.38,
      "grad_norm": 0.5873129367828369,
      "learning_rate": 1.6209900584195963e-05,
      "loss": 0.4346,
      "step": 1854
    },
    {
      "epoch": 0.38,
      "grad_norm": 0.80805504322052,
      "learning_rate": 1.6207850773803423e-05,
      "loss": 0.5857,
      "step": 1855
    },
    {
      "epoch": 0.38,
      "grad_norm": 0.6762176752090454,
      "learning_rate": 1.6205800963410886e-05,
      "loss": 0.5811,
      "step": 1856
    },
    {
      "epoch": 0.38,
      "grad_norm": 1.009477138519287,
      "learning_rate": 1.6203751153018347e-05,
      "loss": 0.5771,
      "step": 1857
    },
    {
      "epoch": 0.38,
      "grad_norm": 0.8809904456138611,
      "learning_rate": 1.620170134262581e-05,
      "loss": 0.5654,
      "step": 1858
    },
    {
      "epoch": 0.38,
      "grad_norm": 0.8402704000473022,
      "learning_rate": 1.619965153223327e-05,
      "loss": 0.6524,
      "step": 1859
    },
    {
      "epoch": 0.38,
      "grad_norm": 0.8765560984611511,
      "learning_rate": 1.619760172184073e-05,
      "loss": 0.5984,
      "step": 1860
    },
    {
      "epoch": 0.38,
      "grad_norm": 0.6236980557441711,
      "learning_rate": 1.6195551911448194e-05,
      "loss": 0.3448,
      "step": 1861
    },
    {
      "epoch": 0.38,
      "grad_norm": 1.015946388244629,
      "learning_rate": 1.6193502101055654e-05,
      "loss": 0.7054,
      "step": 1862
    },
    {
      "epoch": 0.38,
      "grad_norm": 0.8126426935195923,
      "learning_rate": 1.6191452290663114e-05,
      "loss": 0.476,
      "step": 1863
    },
    {
      "epoch": 0.38,
      "grad_norm": 1.5977702140808105,
      "learning_rate": 1.6189402480270578e-05,
      "loss": 0.5324,
      "step": 1864
    },
    {
      "epoch": 0.38,
      "grad_norm": 1.014351725578308,
      "learning_rate": 1.6187352669878038e-05,
      "loss": 0.452,
      "step": 1865
    },
    {
      "epoch": 0.38,
      "grad_norm": 1.010711669921875,
      "learning_rate": 1.6185302859485498e-05,
      "loss": 0.4908,
      "step": 1866
    },
    {
      "epoch": 0.38,
      "grad_norm": 0.7154874205589294,
      "learning_rate": 1.618325304909296e-05,
      "loss": 0.5691,
      "step": 1867
    },
    {
      "epoch": 0.38,
      "grad_norm": 0.927644670009613,
      "learning_rate": 1.6181203238700422e-05,
      "loss": 0.5942,
      "step": 1868
    },
    {
      "epoch": 0.38,
      "grad_norm": 1.2856179475784302,
      "learning_rate": 1.6179153428307882e-05,
      "loss": 0.4865,
      "step": 1869
    },
    {
      "epoch": 0.38,
      "grad_norm": 0.6747699975967407,
      "learning_rate": 1.6177103617915342e-05,
      "loss": 0.5558,
      "step": 1870
    },
    {
      "epoch": 0.38,
      "grad_norm": 1.757285237312317,
      "learning_rate": 1.6175053807522806e-05,
      "loss": 0.441,
      "step": 1871
    },
    {
      "epoch": 0.38,
      "grad_norm": 1.16260826587677,
      "learning_rate": 1.6173003997130266e-05,
      "loss": 0.5079,
      "step": 1872
    },
    {
      "epoch": 0.38,
      "grad_norm": 0.6538863778114319,
      "learning_rate": 1.617095418673773e-05,
      "loss": 0.5127,
      "step": 1873
    },
    {
      "epoch": 0.38,
      "grad_norm": 0.9432892203330994,
      "learning_rate": 1.616890437634519e-05,
      "loss": 0.5144,
      "step": 1874
    },
    {
      "epoch": 0.38,
      "grad_norm": 1.3529345989227295,
      "learning_rate": 1.616685456595265e-05,
      "loss": 0.4702,
      "step": 1875
    },
    {
      "epoch": 0.38,
      "grad_norm": 0.842808723449707,
      "learning_rate": 1.6164804755560113e-05,
      "loss": 0.5476,
      "step": 1876
    },
    {
      "epoch": 0.38,
      "grad_norm": 0.876764178276062,
      "learning_rate": 1.6162754945167574e-05,
      "loss": 0.5355,
      "step": 1877
    },
    {
      "epoch": 0.38,
      "grad_norm": 0.945828378200531,
      "learning_rate": 1.6160705134775034e-05,
      "loss": 0.511,
      "step": 1878
    },
    {
      "epoch": 0.38,
      "grad_norm": 1.6328983306884766,
      "learning_rate": 1.6158655324382494e-05,
      "loss": 0.5792,
      "step": 1879
    },
    {
      "epoch": 0.39,
      "grad_norm": 0.8263119459152222,
      "learning_rate": 1.6156605513989957e-05,
      "loss": 0.6121,
      "step": 1880
    },
    {
      "epoch": 0.39,
      "grad_norm": 3.108476400375366,
      "learning_rate": 1.6154555703597418e-05,
      "loss": 0.5811,
      "step": 1881
    },
    {
      "epoch": 0.39,
      "grad_norm": 1.7786668539047241,
      "learning_rate": 1.6152505893204878e-05,
      "loss": 0.3413,
      "step": 1882
    },
    {
      "epoch": 0.39,
      "grad_norm": 1.329643964767456,
      "learning_rate": 1.615045608281234e-05,
      "loss": 0.5355,
      "step": 1883
    },
    {
      "epoch": 0.39,
      "grad_norm": 0.6837608814239502,
      "learning_rate": 1.61484062724198e-05,
      "loss": 0.5086,
      "step": 1884
    },
    {
      "epoch": 0.39,
      "grad_norm": 2.845874786376953,
      "learning_rate": 1.6146356462027265e-05,
      "loss": 0.4876,
      "step": 1885
    },
    {
      "epoch": 0.39,
      "grad_norm": 2.7094132900238037,
      "learning_rate": 1.6144306651634725e-05,
      "loss": 0.4881,
      "step": 1886
    },
    {
      "epoch": 0.39,
      "grad_norm": 0.8725818991661072,
      "learning_rate": 1.6142256841242185e-05,
      "loss": 0.4805,
      "step": 1887
    },
    {
      "epoch": 0.39,
      "grad_norm": 0.709153950214386,
      "learning_rate": 1.614020703084965e-05,
      "loss": 0.4684,
      "step": 1888
    },
    {
      "epoch": 0.39,
      "grad_norm": 1.2845865488052368,
      "learning_rate": 1.613815722045711e-05,
      "loss": 0.5387,
      "step": 1889
    },
    {
      "epoch": 0.39,
      "grad_norm": 1.346280574798584,
      "learning_rate": 1.613610741006457e-05,
      "loss": 0.3592,
      "step": 1890
    },
    {
      "epoch": 0.39,
      "grad_norm": 1.2246894836425781,
      "learning_rate": 1.613405759967203e-05,
      "loss": 0.5332,
      "step": 1891
    },
    {
      "epoch": 0.39,
      "grad_norm": 1.3073663711547852,
      "learning_rate": 1.6132007789279493e-05,
      "loss": 0.5786,
      "step": 1892
    },
    {
      "epoch": 0.39,
      "grad_norm": 0.9273183345794678,
      "learning_rate": 1.6129957978886953e-05,
      "loss": 0.4921,
      "step": 1893
    },
    {
      "epoch": 0.39,
      "grad_norm": 1.666253924369812,
      "learning_rate": 1.6127908168494413e-05,
      "loss": 0.4494,
      "step": 1894
    },
    {
      "epoch": 0.39,
      "grad_norm": 0.803300142288208,
      "learning_rate": 1.6125858358101877e-05,
      "loss": 0.5101,
      "step": 1895
    },
    {
      "epoch": 0.39,
      "grad_norm": 1.0473747253417969,
      "learning_rate": 1.6123808547709337e-05,
      "loss": 0.4957,
      "step": 1896
    },
    {
      "epoch": 0.39,
      "grad_norm": 1.2779556512832642,
      "learning_rate": 1.61217587373168e-05,
      "loss": 0.5706,
      "step": 1897
    },
    {
      "epoch": 0.39,
      "grad_norm": 1.2126528024673462,
      "learning_rate": 1.611970892692426e-05,
      "loss": 0.4773,
      "step": 1898
    },
    {
      "epoch": 0.39,
      "grad_norm": 0.6767532825469971,
      "learning_rate": 1.6117659116531724e-05,
      "loss": 0.567,
      "step": 1899
    },
    {
      "epoch": 0.39,
      "grad_norm": 0.8770017623901367,
      "learning_rate": 1.6115609306139184e-05,
      "loss": 0.5268,
      "step": 1900
    },
    {
      "epoch": 0.39,
      "grad_norm": 1.2005833387374878,
      "learning_rate": 1.6113559495746645e-05,
      "loss": 0.4581,
      "step": 1901
    },
    {
      "epoch": 0.39,
      "grad_norm": 1.0016186237335205,
      "learning_rate": 1.6111509685354105e-05,
      "loss": 0.3167,
      "step": 1902
    },
    {
      "epoch": 0.39,
      "grad_norm": 0.5536693334579468,
      "learning_rate": 1.610945987496157e-05,
      "loss": 0.5203,
      "step": 1903
    },
    {
      "epoch": 0.39,
      "grad_norm": 1.312339186668396,
      "learning_rate": 1.610741006456903e-05,
      "loss": 0.4991,
      "step": 1904
    },
    {
      "epoch": 0.39,
      "grad_norm": 0.6890427470207214,
      "learning_rate": 1.610536025417649e-05,
      "loss": 0.5735,
      "step": 1905
    },
    {
      "epoch": 0.39,
      "grad_norm": 1.0607852935791016,
      "learning_rate": 1.610331044378395e-05,
      "loss": 0.4487,
      "step": 1906
    },
    {
      "epoch": 0.39,
      "grad_norm": 0.6535047888755798,
      "learning_rate": 1.6101260633391412e-05,
      "loss": 0.4265,
      "step": 1907
    },
    {
      "epoch": 0.39,
      "grad_norm": 1.1923779249191284,
      "learning_rate": 1.6099210822998873e-05,
      "loss": 0.4508,
      "step": 1908
    },
    {
      "epoch": 0.39,
      "grad_norm": 1.1591089963912964,
      "learning_rate": 1.6097161012606336e-05,
      "loss": 0.6562,
      "step": 1909
    },
    {
      "epoch": 0.39,
      "grad_norm": 1.0155657529830933,
      "learning_rate": 1.6095111202213796e-05,
      "loss": 0.4196,
      "step": 1910
    },
    {
      "epoch": 0.39,
      "grad_norm": 0.7368214130401611,
      "learning_rate": 1.609306139182126e-05,
      "loss": 0.5529,
      "step": 1911
    },
    {
      "epoch": 0.39,
      "grad_norm": 0.5949654579162598,
      "learning_rate": 1.609101158142872e-05,
      "loss": 0.5759,
      "step": 1912
    },
    {
      "epoch": 0.39,
      "grad_norm": 0.9912669658660889,
      "learning_rate": 1.608896177103618e-05,
      "loss": 0.4611,
      "step": 1913
    },
    {
      "epoch": 0.39,
      "grad_norm": 0.8306072950363159,
      "learning_rate": 1.608691196064364e-05,
      "loss": 0.5767,
      "step": 1914
    },
    {
      "epoch": 0.39,
      "grad_norm": 0.8719130754470825,
      "learning_rate": 1.6084862150251104e-05,
      "loss": 0.4924,
      "step": 1915
    },
    {
      "epoch": 0.39,
      "grad_norm": 1.3657498359680176,
      "learning_rate": 1.6082812339858564e-05,
      "loss": 0.6112,
      "step": 1916
    },
    {
      "epoch": 0.39,
      "grad_norm": 0.7506153583526611,
      "learning_rate": 1.6080762529466024e-05,
      "loss": 0.6526,
      "step": 1917
    },
    {
      "epoch": 0.39,
      "grad_norm": 0.7875415086746216,
      "learning_rate": 1.6078712719073484e-05,
      "loss": 0.6879,
      "step": 1918
    },
    {
      "epoch": 0.39,
      "grad_norm": 1.185727596282959,
      "learning_rate": 1.6076662908680948e-05,
      "loss": 0.4842,
      "step": 1919
    },
    {
      "epoch": 0.39,
      "grad_norm": 0.5396188497543335,
      "learning_rate": 1.6074613098288408e-05,
      "loss": 0.4245,
      "step": 1920
    },
    {
      "epoch": 0.39,
      "grad_norm": 0.8587225079536438,
      "learning_rate": 1.607256328789587e-05,
      "loss": 0.429,
      "step": 1921
    },
    {
      "epoch": 0.39,
      "grad_norm": 0.980834424495697,
      "learning_rate": 1.6070513477503332e-05,
      "loss": 0.5585,
      "step": 1922
    },
    {
      "epoch": 0.39,
      "grad_norm": 0.8722456097602844,
      "learning_rate": 1.6068463667110795e-05,
      "loss": 0.5308,
      "step": 1923
    },
    {
      "epoch": 0.39,
      "grad_norm": 1.7987935543060303,
      "learning_rate": 1.6066413856718255e-05,
      "loss": 0.5708,
      "step": 1924
    },
    {
      "epoch": 0.39,
      "grad_norm": 0.8293377757072449,
      "learning_rate": 1.6064364046325716e-05,
      "loss": 0.5435,
      "step": 1925
    },
    {
      "epoch": 0.39,
      "grad_norm": 1.7104713916778564,
      "learning_rate": 1.606231423593318e-05,
      "loss": 0.5508,
      "step": 1926
    },
    {
      "epoch": 0.39,
      "grad_norm": 1.0108709335327148,
      "learning_rate": 1.606026442554064e-05,
      "loss": 0.4095,
      "step": 1927
    },
    {
      "epoch": 0.4,
      "grad_norm": 0.7379631996154785,
      "learning_rate": 1.60582146151481e-05,
      "loss": 0.4881,
      "step": 1928
    },
    {
      "epoch": 0.4,
      "grad_norm": 0.9860415458679199,
      "learning_rate": 1.605616480475556e-05,
      "loss": 0.5392,
      "step": 1929
    },
    {
      "epoch": 0.4,
      "grad_norm": 0.6677926182746887,
      "learning_rate": 1.6054114994363023e-05,
      "loss": 0.4514,
      "step": 1930
    },
    {
      "epoch": 0.4,
      "grad_norm": 0.7725856900215149,
      "learning_rate": 1.6052065183970483e-05,
      "loss": 0.5643,
      "step": 1931
    },
    {
      "epoch": 0.4,
      "grad_norm": 1.568423867225647,
      "learning_rate": 1.6050015373577944e-05,
      "loss": 0.3871,
      "step": 1932
    },
    {
      "epoch": 0.4,
      "grad_norm": 1.2813116312026978,
      "learning_rate": 1.6047965563185407e-05,
      "loss": 0.4771,
      "step": 1933
    },
    {
      "epoch": 0.4,
      "grad_norm": 0.8488960862159729,
      "learning_rate": 1.6045915752792867e-05,
      "loss": 0.467,
      "step": 1934
    },
    {
      "epoch": 0.4,
      "grad_norm": 0.8131090402603149,
      "learning_rate": 1.604386594240033e-05,
      "loss": 0.5569,
      "step": 1935
    },
    {
      "epoch": 0.4,
      "grad_norm": 1.0271868705749512,
      "learning_rate": 1.604181613200779e-05,
      "loss": 0.6291,
      "step": 1936
    },
    {
      "epoch": 0.4,
      "grad_norm": 1.192600965499878,
      "learning_rate": 1.603976632161525e-05,
      "loss": 0.5289,
      "step": 1937
    },
    {
      "epoch": 0.4,
      "grad_norm": 1.0119279623031616,
      "learning_rate": 1.6037716511222715e-05,
      "loss": 0.6502,
      "step": 1938
    },
    {
      "epoch": 0.4,
      "grad_norm": 1.8251680135726929,
      "learning_rate": 1.6035666700830175e-05,
      "loss": 0.5877,
      "step": 1939
    },
    {
      "epoch": 0.4,
      "grad_norm": 1.3258721828460693,
      "learning_rate": 1.6033616890437635e-05,
      "loss": 0.4734,
      "step": 1940
    },
    {
      "epoch": 0.4,
      "grad_norm": 1.167506456375122,
      "learning_rate": 1.6031567080045095e-05,
      "loss": 0.423,
      "step": 1941
    },
    {
      "epoch": 0.4,
      "grad_norm": 1.0750092267990112,
      "learning_rate": 1.602951726965256e-05,
      "loss": 0.5269,
      "step": 1942
    },
    {
      "epoch": 0.4,
      "grad_norm": 1.4258203506469727,
      "learning_rate": 1.602746745926002e-05,
      "loss": 0.4259,
      "step": 1943
    },
    {
      "epoch": 0.4,
      "grad_norm": 0.9564337730407715,
      "learning_rate": 1.602541764886748e-05,
      "loss": 0.5465,
      "step": 1944
    },
    {
      "epoch": 0.4,
      "grad_norm": 2.058434247970581,
      "learning_rate": 1.6023367838474943e-05,
      "loss": 0.5486,
      "step": 1945
    },
    {
      "epoch": 0.4,
      "grad_norm": 1.4934232234954834,
      "learning_rate": 1.6021318028082403e-05,
      "loss": 0.4801,
      "step": 1946
    },
    {
      "epoch": 0.4,
      "grad_norm": 1.472892165184021,
      "learning_rate": 1.6019268217689866e-05,
      "loss": 0.4291,
      "step": 1947
    },
    {
      "epoch": 0.4,
      "grad_norm": 1.0014437437057495,
      "learning_rate": 1.6017218407297326e-05,
      "loss": 0.4926,
      "step": 1948
    },
    {
      "epoch": 0.4,
      "grad_norm": 0.8849875926971436,
      "learning_rate": 1.6015168596904787e-05,
      "loss": 0.5678,
      "step": 1949
    },
    {
      "epoch": 0.4,
      "grad_norm": 1.6354453563690186,
      "learning_rate": 1.601311878651225e-05,
      "loss": 0.5006,
      "step": 1950
    },
    {
      "epoch": 0.4,
      "grad_norm": 1.0958939790725708,
      "learning_rate": 1.601106897611971e-05,
      "loss": 0.6617,
      "step": 1951
    },
    {
      "epoch": 0.4,
      "grad_norm": 0.7901096940040588,
      "learning_rate": 1.600901916572717e-05,
      "loss": 0.5994,
      "step": 1952
    },
    {
      "epoch": 0.4,
      "grad_norm": 1.2714778184890747,
      "learning_rate": 1.6006969355334634e-05,
      "loss": 0.5159,
      "step": 1953
    },
    {
      "epoch": 0.4,
      "grad_norm": 0.8754715919494629,
      "learning_rate": 1.6004919544942094e-05,
      "loss": 0.4489,
      "step": 1954
    },
    {
      "epoch": 0.4,
      "grad_norm": 0.7366582155227661,
      "learning_rate": 1.6002869734549554e-05,
      "loss": 0.4661,
      "step": 1955
    },
    {
      "epoch": 0.4,
      "grad_norm": 1.133507251739502,
      "learning_rate": 1.6000819924157015e-05,
      "loss": 0.5377,
      "step": 1956
    },
    {
      "epoch": 0.4,
      "grad_norm": 1.2171673774719238,
      "learning_rate": 1.5998770113764478e-05,
      "loss": 0.4208,
      "step": 1957
    },
    {
      "epoch": 0.4,
      "grad_norm": 0.6789277791976929,
      "learning_rate": 1.5996720303371938e-05,
      "loss": 0.5827,
      "step": 1958
    },
    {
      "epoch": 0.4,
      "grad_norm": 0.850418746471405,
      "learning_rate": 1.5994670492979402e-05,
      "loss": 0.7402,
      "step": 1959
    },
    {
      "epoch": 0.4,
      "grad_norm": 1.6695168018341064,
      "learning_rate": 1.5992620682586862e-05,
      "loss": 0.6289,
      "step": 1960
    },
    {
      "epoch": 0.4,
      "grad_norm": 0.9684321880340576,
      "learning_rate": 1.5990570872194326e-05,
      "loss": 0.6005,
      "step": 1961
    },
    {
      "epoch": 0.4,
      "grad_norm": 1.4561340808868408,
      "learning_rate": 1.5988521061801786e-05,
      "loss": 0.4899,
      "step": 1962
    },
    {
      "epoch": 0.4,
      "grad_norm": 1.1261545419692993,
      "learning_rate": 1.5986471251409246e-05,
      "loss": 0.4853,
      "step": 1963
    },
    {
      "epoch": 0.4,
      "grad_norm": 0.9612806439399719,
      "learning_rate": 1.5984421441016706e-05,
      "loss": 0.5343,
      "step": 1964
    },
    {
      "epoch": 0.4,
      "grad_norm": 1.4810503721237183,
      "learning_rate": 1.598237163062417e-05,
      "loss": 0.5082,
      "step": 1965
    },
    {
      "epoch": 0.4,
      "grad_norm": 0.9941333532333374,
      "learning_rate": 1.598032182023163e-05,
      "loss": 0.5135,
      "step": 1966
    },
    {
      "epoch": 0.4,
      "grad_norm": 0.893284797668457,
      "learning_rate": 1.597827200983909e-05,
      "loss": 0.564,
      "step": 1967
    },
    {
      "epoch": 0.4,
      "grad_norm": 1.5925734043121338,
      "learning_rate": 1.597622219944655e-05,
      "loss": 0.436,
      "step": 1968
    },
    {
      "epoch": 0.4,
      "grad_norm": 0.9685428142547607,
      "learning_rate": 1.5974172389054014e-05,
      "loss": 0.4391,
      "step": 1969
    },
    {
      "epoch": 0.4,
      "grad_norm": 1.1866545677185059,
      "learning_rate": 1.5972122578661474e-05,
      "loss": 0.33,
      "step": 1970
    },
    {
      "epoch": 0.4,
      "grad_norm": 0.7240698933601379,
      "learning_rate": 1.5970072768268937e-05,
      "loss": 0.5375,
      "step": 1971
    },
    {
      "epoch": 0.4,
      "grad_norm": 1.0899056196212769,
      "learning_rate": 1.5968022957876397e-05,
      "loss": 0.5249,
      "step": 1972
    },
    {
      "epoch": 0.4,
      "grad_norm": 0.5854936838150024,
      "learning_rate": 1.596597314748386e-05,
      "loss": 0.6233,
      "step": 1973
    },
    {
      "epoch": 0.4,
      "grad_norm": 0.7463777661323547,
      "learning_rate": 1.596392333709132e-05,
      "loss": 0.6716,
      "step": 1974
    },
    {
      "epoch": 0.4,
      "grad_norm": 0.956966757774353,
      "learning_rate": 1.596187352669878e-05,
      "loss": 0.5215,
      "step": 1975
    },
    {
      "epoch": 0.4,
      "grad_norm": 1.100002408027649,
      "learning_rate": 1.595982371630624e-05,
      "loss": 0.6038,
      "step": 1976
    },
    {
      "epoch": 0.41,
      "grad_norm": 0.6492906808853149,
      "learning_rate": 1.5957773905913705e-05,
      "loss": 0.3782,
      "step": 1977
    },
    {
      "epoch": 0.41,
      "grad_norm": 0.8091133236885071,
      "learning_rate": 1.5955724095521165e-05,
      "loss": 0.3926,
      "step": 1978
    },
    {
      "epoch": 0.41,
      "grad_norm": 0.8715875148773193,
      "learning_rate": 1.5953674285128625e-05,
      "loss": 0.5047,
      "step": 1979
    },
    {
      "epoch": 0.41,
      "grad_norm": 1.1248875856399536,
      "learning_rate": 1.595162447473609e-05,
      "loss": 0.4316,
      "step": 1980
    },
    {
      "epoch": 0.41,
      "grad_norm": 1.0833219289779663,
      "learning_rate": 1.594957466434355e-05,
      "loss": 0.4853,
      "step": 1981
    },
    {
      "epoch": 0.41,
      "grad_norm": 0.670222818851471,
      "learning_rate": 1.594752485395101e-05,
      "loss": 0.5142,
      "step": 1982
    },
    {
      "epoch": 0.41,
      "grad_norm": 0.849718451499939,
      "learning_rate": 1.5945475043558473e-05,
      "loss": 0.4328,
      "step": 1983
    },
    {
      "epoch": 0.41,
      "grad_norm": 1.4758237600326538,
      "learning_rate": 1.5943425233165933e-05,
      "loss": 0.4781,
      "step": 1984
    },
    {
      "epoch": 0.41,
      "grad_norm": 0.7689403295516968,
      "learning_rate": 1.5941375422773397e-05,
      "loss": 0.3403,
      "step": 1985
    },
    {
      "epoch": 0.41,
      "grad_norm": 0.8208795189857483,
      "learning_rate": 1.5939325612380857e-05,
      "loss": 0.5036,
      "step": 1986
    },
    {
      "epoch": 0.41,
      "grad_norm": 1.2618650197982788,
      "learning_rate": 1.5937275801988317e-05,
      "loss": 0.4419,
      "step": 1987
    },
    {
      "epoch": 0.41,
      "grad_norm": 1.3423880338668823,
      "learning_rate": 1.593522599159578e-05,
      "loss": 0.503,
      "step": 1988
    },
    {
      "epoch": 0.41,
      "grad_norm": 0.8431075215339661,
      "learning_rate": 1.593317618120324e-05,
      "loss": 0.5148,
      "step": 1989
    },
    {
      "epoch": 0.41,
      "grad_norm": 0.9605334997177124,
      "learning_rate": 1.59311263708107e-05,
      "loss": 0.616,
      "step": 1990
    },
    {
      "epoch": 0.41,
      "grad_norm": 0.9373587369918823,
      "learning_rate": 1.592907656041816e-05,
      "loss": 0.5077,
      "step": 1991
    },
    {
      "epoch": 0.41,
      "grad_norm": 0.6402922868728638,
      "learning_rate": 1.5927026750025624e-05,
      "loss": 0.4767,
      "step": 1992
    },
    {
      "epoch": 0.41,
      "grad_norm": 0.6487061381340027,
      "learning_rate": 1.5924976939633085e-05,
      "loss": 0.4676,
      "step": 1993
    },
    {
      "epoch": 0.41,
      "grad_norm": 0.7314309477806091,
      "learning_rate": 1.5922927129240545e-05,
      "loss": 0.5878,
      "step": 1994
    },
    {
      "epoch": 0.41,
      "grad_norm": 1.1414071321487427,
      "learning_rate": 1.5920877318848008e-05,
      "loss": 0.5834,
      "step": 1995
    },
    {
      "epoch": 0.41,
      "grad_norm": 0.8482404351234436,
      "learning_rate": 1.591882750845547e-05,
      "loss": 0.5692,
      "step": 1996
    },
    {
      "epoch": 0.41,
      "grad_norm": 0.8580048680305481,
      "learning_rate": 1.5916777698062932e-05,
      "loss": 0.6164,
      "step": 1997
    },
    {
      "epoch": 0.41,
      "grad_norm": 0.8269129395484924,
      "learning_rate": 1.5914727887670392e-05,
      "loss": 0.4581,
      "step": 1998
    },
    {
      "epoch": 0.41,
      "grad_norm": 1.0608601570129395,
      "learning_rate": 1.5912678077277852e-05,
      "loss": 0.6098,
      "step": 1999
    },
    {
      "epoch": 0.41,
      "grad_norm": 0.8446157574653625,
      "learning_rate": 1.5910628266885316e-05,
      "loss": 0.5506,
      "step": 2000
    },
    {
      "epoch": 0.41,
      "eval_loss": 0.5047377943992615,
      "eval_runtime": 662.2523,
      "eval_samples_per_second": 15.1,
      "eval_steps_per_second": 1.887,
      "step": 2000
    },
    {
      "epoch": 0.41,
      "grad_norm": 1.0511940717697144,
      "learning_rate": 1.5908578456492776e-05,
      "loss": 0.5068,
      "step": 2001
    },
    {
      "epoch": 0.41,
      "grad_norm": 0.9707214832305908,
      "learning_rate": 1.5906528646100236e-05,
      "loss": 0.5849,
      "step": 2002
    },
    {
      "epoch": 0.41,
      "grad_norm": 0.6857143640518188,
      "learning_rate": 1.5904478835707696e-05,
      "loss": 0.6269,
      "step": 2003
    },
    {
      "epoch": 0.41,
      "grad_norm": 0.6794658303260803,
      "learning_rate": 1.590242902531516e-05,
      "loss": 0.5974,
      "step": 2004
    },
    {
      "epoch": 0.41,
      "grad_norm": 0.7886322140693665,
      "learning_rate": 1.590037921492262e-05,
      "loss": 0.6544,
      "step": 2005
    },
    {
      "epoch": 0.41,
      "grad_norm": 1.1946450471878052,
      "learning_rate": 1.589832940453008e-05,
      "loss": 0.5316,
      "step": 2006
    },
    {
      "epoch": 0.41,
      "grad_norm": 0.8042477369308472,
      "learning_rate": 1.5896279594137544e-05,
      "loss": 0.6277,
      "step": 2007
    },
    {
      "epoch": 0.41,
      "grad_norm": 0.792835533618927,
      "learning_rate": 1.5894229783745004e-05,
      "loss": 0.5015,
      "step": 2008
    },
    {
      "epoch": 0.41,
      "grad_norm": 1.3815221786499023,
      "learning_rate": 1.5892179973352468e-05,
      "loss": 0.4468,
      "step": 2009
    },
    {
      "epoch": 0.41,
      "grad_norm": 0.9288621544837952,
      "learning_rate": 1.5890130162959928e-05,
      "loss": 0.4262,
      "step": 2010
    },
    {
      "epoch": 0.41,
      "grad_norm": 0.676608681678772,
      "learning_rate": 1.588808035256739e-05,
      "loss": 0.6286,
      "step": 2011
    },
    {
      "epoch": 0.41,
      "grad_norm": 0.847676694393158,
      "learning_rate": 1.588603054217485e-05,
      "loss": 0.5575,
      "step": 2012
    },
    {
      "epoch": 0.41,
      "grad_norm": 0.7414212226867676,
      "learning_rate": 1.588398073178231e-05,
      "loss": 0.5145,
      "step": 2013
    },
    {
      "epoch": 0.41,
      "grad_norm": 0.8045880794525146,
      "learning_rate": 1.5881930921389772e-05,
      "loss": 0.5224,
      "step": 2014
    },
    {
      "epoch": 0.41,
      "grad_norm": 0.6381759643554688,
      "learning_rate": 1.5879881110997235e-05,
      "loss": 0.4466,
      "step": 2015
    },
    {
      "epoch": 0.41,
      "grad_norm": 0.8535764813423157,
      "learning_rate": 1.5877831300604695e-05,
      "loss": 0.4246,
      "step": 2016
    },
    {
      "epoch": 0.41,
      "grad_norm": 0.7750169634819031,
      "learning_rate": 1.5875781490212156e-05,
      "loss": 0.533,
      "step": 2017
    },
    {
      "epoch": 0.41,
      "grad_norm": 1.5625391006469727,
      "learning_rate": 1.5873731679819616e-05,
      "loss": 0.5702,
      "step": 2018
    },
    {
      "epoch": 0.41,
      "grad_norm": 0.8559758067131042,
      "learning_rate": 1.587168186942708e-05,
      "loss": 0.4737,
      "step": 2019
    },
    {
      "epoch": 0.41,
      "grad_norm": 0.6440094113349915,
      "learning_rate": 1.586963205903454e-05,
      "loss": 0.6376,
      "step": 2020
    },
    {
      "epoch": 0.41,
      "grad_norm": 1.5550190210342407,
      "learning_rate": 1.5867582248642003e-05,
      "loss": 0.6619,
      "step": 2021
    },
    {
      "epoch": 0.41,
      "grad_norm": 0.7445527911186218,
      "learning_rate": 1.5865532438249463e-05,
      "loss": 0.4714,
      "step": 2022
    },
    {
      "epoch": 0.41,
      "grad_norm": 0.9145827293395996,
      "learning_rate": 1.5863482627856927e-05,
      "loss": 0.5066,
      "step": 2023
    },
    {
      "epoch": 0.41,
      "grad_norm": 1.1539065837860107,
      "learning_rate": 1.5861432817464387e-05,
      "loss": 0.5533,
      "step": 2024
    },
    {
      "epoch": 0.41,
      "grad_norm": 1.356127142906189,
      "learning_rate": 1.5859383007071847e-05,
      "loss": 0.4946,
      "step": 2025
    },
    {
      "epoch": 0.42,
      "grad_norm": 0.6685317754745483,
      "learning_rate": 1.5857333196679307e-05,
      "loss": 0.2552,
      "step": 2026
    },
    {
      "epoch": 0.42,
      "grad_norm": 1.2365517616271973,
      "learning_rate": 1.585528338628677e-05,
      "loss": 0.5383,
      "step": 2027
    },
    {
      "epoch": 0.42,
      "grad_norm": 0.5667086839675903,
      "learning_rate": 1.585323357589423e-05,
      "loss": 0.4765,
      "step": 2028
    },
    {
      "epoch": 0.42,
      "grad_norm": 1.8990203142166138,
      "learning_rate": 1.585118376550169e-05,
      "loss": 0.4472,
      "step": 2029
    },
    {
      "epoch": 0.42,
      "grad_norm": 0.7496761083602905,
      "learning_rate": 1.584913395510915e-05,
      "loss": 0.4286,
      "step": 2030
    },
    {
      "epoch": 0.42,
      "grad_norm": 1.2097340822219849,
      "learning_rate": 1.5847084144716615e-05,
      "loss": 0.5779,
      "step": 2031
    },
    {
      "epoch": 0.42,
      "grad_norm": 1.1397589445114136,
      "learning_rate": 1.5845034334324075e-05,
      "loss": 0.3989,
      "step": 2032
    },
    {
      "epoch": 0.42,
      "grad_norm": 0.8061482906341553,
      "learning_rate": 1.584298452393154e-05,
      "loss": 0.4058,
      "step": 2033
    },
    {
      "epoch": 0.42,
      "grad_norm": 1.1240532398223877,
      "learning_rate": 1.5840934713539e-05,
      "loss": 0.4511,
      "step": 2034
    },
    {
      "epoch": 0.42,
      "grad_norm": 0.7828224301338196,
      "learning_rate": 1.5838884903146462e-05,
      "loss": 0.5069,
      "step": 2035
    },
    {
      "epoch": 0.42,
      "grad_norm": 1.2103759050369263,
      "learning_rate": 1.5836835092753922e-05,
      "loss": 0.5843,
      "step": 2036
    },
    {
      "epoch": 0.42,
      "grad_norm": 1.2967866659164429,
      "learning_rate": 1.5834785282361383e-05,
      "loss": 0.4276,
      "step": 2037
    },
    {
      "epoch": 0.42,
      "grad_norm": 0.8683269619941711,
      "learning_rate": 1.5832735471968843e-05,
      "loss": 0.6837,
      "step": 2038
    },
    {
      "epoch": 0.42,
      "grad_norm": 0.803689181804657,
      "learning_rate": 1.5830685661576306e-05,
      "loss": 0.6933,
      "step": 2039
    },
    {
      "epoch": 0.42,
      "grad_norm": 0.8162477612495422,
      "learning_rate": 1.5828635851183766e-05,
      "loss": 0.5404,
      "step": 2040
    },
    {
      "epoch": 0.42,
      "grad_norm": 0.8547784090042114,
      "learning_rate": 1.5826586040791227e-05,
      "loss": 0.4027,
      "step": 2041
    },
    {
      "epoch": 0.42,
      "grad_norm": 0.9781336784362793,
      "learning_rate": 1.582453623039869e-05,
      "loss": 0.4945,
      "step": 2042
    },
    {
      "epoch": 0.42,
      "grad_norm": 0.7365509271621704,
      "learning_rate": 1.582248642000615e-05,
      "loss": 0.5538,
      "step": 2043
    },
    {
      "epoch": 0.42,
      "grad_norm": 1.3436388969421387,
      "learning_rate": 1.582043660961361e-05,
      "loss": 0.6021,
      "step": 2044
    },
    {
      "epoch": 0.42,
      "grad_norm": 0.6411257982254028,
      "learning_rate": 1.5818386799221074e-05,
      "loss": 0.4885,
      "step": 2045
    },
    {
      "epoch": 0.42,
      "grad_norm": 0.9466177821159363,
      "learning_rate": 1.5816336988828534e-05,
      "loss": 0.5867,
      "step": 2046
    },
    {
      "epoch": 0.42,
      "grad_norm": 1.0734310150146484,
      "learning_rate": 1.5814287178435998e-05,
      "loss": 0.5642,
      "step": 2047
    },
    {
      "epoch": 0.42,
      "grad_norm": 0.8859537839889526,
      "learning_rate": 1.5812237368043458e-05,
      "loss": 0.6296,
      "step": 2048
    },
    {
      "epoch": 0.42,
      "grad_norm": 1.4180817604064941,
      "learning_rate": 1.5810187557650918e-05,
      "loss": 0.3719,
      "step": 2049
    },
    {
      "epoch": 0.42,
      "grad_norm": 1.7644366025924683,
      "learning_rate": 1.580813774725838e-05,
      "loss": 0.4043,
      "step": 2050
    },
    {
      "epoch": 0.42,
      "grad_norm": 1.5336575508117676,
      "learning_rate": 1.5806087936865842e-05,
      "loss": 0.3418,
      "step": 2051
    },
    {
      "epoch": 0.42,
      "grad_norm": 1.1484198570251465,
      "learning_rate": 1.5804038126473302e-05,
      "loss": 0.6653,
      "step": 2052
    },
    {
      "epoch": 0.42,
      "grad_norm": 1.7904082536697388,
      "learning_rate": 1.5801988316080762e-05,
      "loss": 0.4063,
      "step": 2053
    },
    {
      "epoch": 0.42,
      "grad_norm": 1.0594890117645264,
      "learning_rate": 1.5799938505688226e-05,
      "loss": 0.474,
      "step": 2054
    },
    {
      "epoch": 0.42,
      "grad_norm": 1.1106493473052979,
      "learning_rate": 1.5797888695295686e-05,
      "loss": 0.6354,
      "step": 2055
    },
    {
      "epoch": 0.42,
      "grad_norm": 1.7215068340301514,
      "learning_rate": 1.5795838884903146e-05,
      "loss": 0.5722,
      "step": 2056
    },
    {
      "epoch": 0.42,
      "grad_norm": 1.0837373733520508,
      "learning_rate": 1.579378907451061e-05,
      "loss": 0.4319,
      "step": 2057
    },
    {
      "epoch": 0.42,
      "grad_norm": 1.0427491664886475,
      "learning_rate": 1.579173926411807e-05,
      "loss": 0.5963,
      "step": 2058
    },
    {
      "epoch": 0.42,
      "grad_norm": 0.6217710375785828,
      "learning_rate": 1.5789689453725533e-05,
      "loss": 0.617,
      "step": 2059
    },
    {
      "epoch": 0.42,
      "grad_norm": 1.4177560806274414,
      "learning_rate": 1.5787639643332993e-05,
      "loss": 0.5537,
      "step": 2060
    },
    {
      "epoch": 0.42,
      "grad_norm": 0.8612774610519409,
      "learning_rate": 1.5785589832940454e-05,
      "loss": 0.506,
      "step": 2061
    },
    {
      "epoch": 0.42,
      "grad_norm": 1.55678391456604,
      "learning_rate": 1.5783540022547917e-05,
      "loss": 0.3958,
      "step": 2062
    },
    {
      "epoch": 0.42,
      "grad_norm": 0.7218495607376099,
      "learning_rate": 1.5781490212155377e-05,
      "loss": 0.5252,
      "step": 2063
    },
    {
      "epoch": 0.42,
      "grad_norm": 1.105220079421997,
      "learning_rate": 1.5779440401762837e-05,
      "loss": 0.3772,
      "step": 2064
    },
    {
      "epoch": 0.42,
      "grad_norm": 1.0301518440246582,
      "learning_rate": 1.5777390591370298e-05,
      "loss": 0.3917,
      "step": 2065
    },
    {
      "epoch": 0.42,
      "grad_norm": 1.1867598295211792,
      "learning_rate": 1.577534078097776e-05,
      "loss": 0.6932,
      "step": 2066
    },
    {
      "epoch": 0.42,
      "grad_norm": 1.3530750274658203,
      "learning_rate": 1.577329097058522e-05,
      "loss": 0.3773,
      "step": 2067
    },
    {
      "epoch": 0.42,
      "grad_norm": 0.6657067537307739,
      "learning_rate": 1.577124116019268e-05,
      "loss": 0.5658,
      "step": 2068
    },
    {
      "epoch": 0.42,
      "grad_norm": 0.617572546005249,
      "learning_rate": 1.5769191349800145e-05,
      "loss": 0.6883,
      "step": 2069
    },
    {
      "epoch": 0.42,
      "grad_norm": 1.087776780128479,
      "learning_rate": 1.5767141539407605e-05,
      "loss": 0.4829,
      "step": 2070
    },
    {
      "epoch": 0.42,
      "grad_norm": 1.8383723497390747,
      "learning_rate": 1.576509172901507e-05,
      "loss": 0.486,
      "step": 2071
    },
    {
      "epoch": 0.42,
      "grad_norm": 0.7933163046836853,
      "learning_rate": 1.576304191862253e-05,
      "loss": 0.4682,
      "step": 2072
    },
    {
      "epoch": 0.42,
      "grad_norm": 1.50412917137146,
      "learning_rate": 1.5760992108229992e-05,
      "loss": 0.5113,
      "step": 2073
    },
    {
      "epoch": 0.42,
      "grad_norm": 1.1029132604599,
      "learning_rate": 1.5758942297837453e-05,
      "loss": 0.5375,
      "step": 2074
    },
    {
      "epoch": 0.43,
      "grad_norm": 1.301163911819458,
      "learning_rate": 1.5756892487444913e-05,
      "loss": 0.4918,
      "step": 2075
    },
    {
      "epoch": 0.43,
      "grad_norm": 1.0731266736984253,
      "learning_rate": 1.5754842677052373e-05,
      "loss": 0.4616,
      "step": 2076
    },
    {
      "epoch": 0.43,
      "grad_norm": 1.544938325881958,
      "learning_rate": 1.5752792866659836e-05,
      "loss": 0.3367,
      "step": 2077
    },
    {
      "epoch": 0.43,
      "grad_norm": 0.8217620253562927,
      "learning_rate": 1.5750743056267297e-05,
      "loss": 0.5946,
      "step": 2078
    },
    {
      "epoch": 0.43,
      "grad_norm": 0.6446661949157715,
      "learning_rate": 1.5748693245874757e-05,
      "loss": 0.4404,
      "step": 2079
    },
    {
      "epoch": 0.43,
      "grad_norm": 0.6675161719322205,
      "learning_rate": 1.5746643435482217e-05,
      "loss": 0.3135,
      "step": 2080
    },
    {
      "epoch": 0.43,
      "grad_norm": 0.5228404402732849,
      "learning_rate": 1.574459362508968e-05,
      "loss": 0.3588,
      "step": 2081
    },
    {
      "epoch": 0.43,
      "grad_norm": 1.418054461479187,
      "learning_rate": 1.574254381469714e-05,
      "loss": 0.6186,
      "step": 2082
    },
    {
      "epoch": 0.43,
      "grad_norm": 0.8530039191246033,
      "learning_rate": 1.5740494004304604e-05,
      "loss": 0.7224,
      "step": 2083
    },
    {
      "epoch": 0.43,
      "grad_norm": 0.9005798101425171,
      "learning_rate": 1.5738444193912064e-05,
      "loss": 0.3142,
      "step": 2084
    },
    {
      "epoch": 0.43,
      "grad_norm": 0.6214786767959595,
      "learning_rate": 1.5736394383519528e-05,
      "loss": 0.4231,
      "step": 2085
    },
    {
      "epoch": 0.43,
      "grad_norm": 0.8483048677444458,
      "learning_rate": 1.5734344573126988e-05,
      "loss": 0.4645,
      "step": 2086
    },
    {
      "epoch": 0.43,
      "grad_norm": 0.9939825534820557,
      "learning_rate": 1.5732294762734448e-05,
      "loss": 0.6388,
      "step": 2087
    },
    {
      "epoch": 0.43,
      "grad_norm": 0.9998186826705933,
      "learning_rate": 1.573024495234191e-05,
      "loss": 0.5307,
      "step": 2088
    },
    {
      "epoch": 0.43,
      "grad_norm": 1.2213550806045532,
      "learning_rate": 1.5728195141949372e-05,
      "loss": 0.5506,
      "step": 2089
    },
    {
      "epoch": 0.43,
      "grad_norm": 1.015924096107483,
      "learning_rate": 1.5726145331556832e-05,
      "loss": 0.465,
      "step": 2090
    },
    {
      "epoch": 0.43,
      "grad_norm": 1.6481986045837402,
      "learning_rate": 1.5724095521164292e-05,
      "loss": 0.5796,
      "step": 2091
    },
    {
      "epoch": 0.43,
      "grad_norm": 1.0267772674560547,
      "learning_rate": 1.5722045710771752e-05,
      "loss": 0.5734,
      "step": 2092
    },
    {
      "epoch": 0.43,
      "grad_norm": 0.932117760181427,
      "learning_rate": 1.5719995900379216e-05,
      "loss": 0.3551,
      "step": 2093
    },
    {
      "epoch": 0.43,
      "grad_norm": 1.0101109743118286,
      "learning_rate": 1.5717946089986676e-05,
      "loss": 0.5312,
      "step": 2094
    },
    {
      "epoch": 0.43,
      "grad_norm": 0.7643352746963501,
      "learning_rate": 1.571589627959414e-05,
      "loss": 0.4764,
      "step": 2095
    },
    {
      "epoch": 0.43,
      "grad_norm": 1.4958775043487549,
      "learning_rate": 1.57138464692016e-05,
      "loss": 0.4889,
      "step": 2096
    },
    {
      "epoch": 0.43,
      "grad_norm": 1.1514828205108643,
      "learning_rate": 1.5711796658809063e-05,
      "loss": 0.4775,
      "step": 2097
    },
    {
      "epoch": 0.43,
      "grad_norm": 0.669793426990509,
      "learning_rate": 1.5709746848416524e-05,
      "loss": 0.6547,
      "step": 2098
    },
    {
      "epoch": 0.43,
      "grad_norm": 0.6883272528648376,
      "learning_rate": 1.5707697038023984e-05,
      "loss": 0.3442,
      "step": 2099
    },
    {
      "epoch": 0.43,
      "grad_norm": 0.7107018828392029,
      "learning_rate": 1.5705647227631447e-05,
      "loss": 0.4726,
      "step": 2100
    },
    {
      "epoch": 0.43,
      "grad_norm": 0.796275794506073,
      "learning_rate": 1.5703597417238907e-05,
      "loss": 0.5634,
      "step": 2101
    },
    {
      "epoch": 0.43,
      "grad_norm": 0.775999128818512,
      "learning_rate": 1.5701547606846368e-05,
      "loss": 0.4734,
      "step": 2102
    },
    {
      "epoch": 0.43,
      "grad_norm": 0.6655245423316956,
      "learning_rate": 1.5699497796453828e-05,
      "loss": 0.4372,
      "step": 2103
    },
    {
      "epoch": 0.43,
      "grad_norm": 0.8158257007598877,
      "learning_rate": 1.569744798606129e-05,
      "loss": 0.5232,
      "step": 2104
    },
    {
      "epoch": 0.43,
      "grad_norm": 1.135516881942749,
      "learning_rate": 1.569539817566875e-05,
      "loss": 0.585,
      "step": 2105
    },
    {
      "epoch": 0.43,
      "grad_norm": 0.9156106114387512,
      "learning_rate": 1.569334836527621e-05,
      "loss": 0.5042,
      "step": 2106
    },
    {
      "epoch": 0.43,
      "grad_norm": 0.8876755833625793,
      "learning_rate": 1.5691298554883675e-05,
      "loss": 0.5263,
      "step": 2107
    },
    {
      "epoch": 0.43,
      "grad_norm": 1.3557614088058472,
      "learning_rate": 1.5689248744491135e-05,
      "loss": 0.4685,
      "step": 2108
    },
    {
      "epoch": 0.43,
      "grad_norm": 0.7042186260223389,
      "learning_rate": 1.56871989340986e-05,
      "loss": 0.5751,
      "step": 2109
    },
    {
      "epoch": 0.43,
      "grad_norm": 1.5414866209030151,
      "learning_rate": 1.568514912370606e-05,
      "loss": 0.4161,
      "step": 2110
    },
    {
      "epoch": 0.43,
      "grad_norm": 0.5613951086997986,
      "learning_rate": 1.568309931331352e-05,
      "loss": 0.533,
      "step": 2111
    },
    {
      "epoch": 0.43,
      "grad_norm": 0.8946567177772522,
      "learning_rate": 1.5681049502920983e-05,
      "loss": 0.4654,
      "step": 2112
    },
    {
      "epoch": 0.43,
      "grad_norm": 1.1768968105316162,
      "learning_rate": 1.5678999692528443e-05,
      "loss": 0.5746,
      "step": 2113
    },
    {
      "epoch": 0.43,
      "grad_norm": 2.3294641971588135,
      "learning_rate": 1.5676949882135903e-05,
      "loss": 0.4685,
      "step": 2114
    },
    {
      "epoch": 0.43,
      "grad_norm": 0.7886550426483154,
      "learning_rate": 1.5674900071743363e-05,
      "loss": 0.4907,
      "step": 2115
    },
    {
      "epoch": 0.43,
      "grad_norm": 0.6190203428268433,
      "learning_rate": 1.5672850261350827e-05,
      "loss": 0.4439,
      "step": 2116
    },
    {
      "epoch": 0.43,
      "grad_norm": 0.8789772391319275,
      "learning_rate": 1.5670800450958287e-05,
      "loss": 0.6042,
      "step": 2117
    },
    {
      "epoch": 0.43,
      "grad_norm": 0.9173942804336548,
      "learning_rate": 1.5668750640565747e-05,
      "loss": 0.4385,
      "step": 2118
    },
    {
      "epoch": 0.43,
      "grad_norm": 0.8768936991691589,
      "learning_rate": 1.566670083017321e-05,
      "loss": 0.5757,
      "step": 2119
    },
    {
      "epoch": 0.43,
      "grad_norm": 0.7874490022659302,
      "learning_rate": 1.566465101978067e-05,
      "loss": 0.5636,
      "step": 2120
    },
    {
      "epoch": 0.43,
      "grad_norm": 0.8956121802330017,
      "learning_rate": 1.5662601209388134e-05,
      "loss": 0.5649,
      "step": 2121
    },
    {
      "epoch": 0.43,
      "grad_norm": 0.9664419889450073,
      "learning_rate": 1.5660551398995595e-05,
      "loss": 0.4624,
      "step": 2122
    },
    {
      "epoch": 0.43,
      "grad_norm": 0.7394748330116272,
      "learning_rate": 1.5658501588603055e-05,
      "loss": 0.4437,
      "step": 2123
    },
    {
      "epoch": 0.44,
      "grad_norm": 1.1251187324523926,
      "learning_rate": 1.565645177821052e-05,
      "loss": 0.4075,
      "step": 2124
    },
    {
      "epoch": 0.44,
      "grad_norm": 1.057958722114563,
      "learning_rate": 1.565440196781798e-05,
      "loss": 0.4896,
      "step": 2125
    },
    {
      "epoch": 0.44,
      "grad_norm": 0.9013018012046814,
      "learning_rate": 1.565235215742544e-05,
      "loss": 0.6638,
      "step": 2126
    },
    {
      "epoch": 0.44,
      "grad_norm": 0.8399822115898132,
      "learning_rate": 1.56503023470329e-05,
      "loss": 0.5084,
      "step": 2127
    },
    {
      "epoch": 0.44,
      "grad_norm": 0.7744280099868774,
      "learning_rate": 1.5648252536640362e-05,
      "loss": 0.3867,
      "step": 2128
    },
    {
      "epoch": 0.44,
      "grad_norm": 0.7673399448394775,
      "learning_rate": 1.5646202726247823e-05,
      "loss": 0.392,
      "step": 2129
    },
    {
      "epoch": 0.44,
      "grad_norm": 1.8730897903442383,
      "learning_rate": 1.5644152915855283e-05,
      "loss": 0.5164,
      "step": 2130
    },
    {
      "epoch": 0.44,
      "grad_norm": 0.7010650038719177,
      "learning_rate": 1.5642103105462746e-05,
      "loss": 0.4004,
      "step": 2131
    },
    {
      "epoch": 0.44,
      "grad_norm": 0.7424700260162354,
      "learning_rate": 1.5640053295070206e-05,
      "loss": 0.5747,
      "step": 2132
    },
    {
      "epoch": 0.44,
      "grad_norm": 0.8191335797309875,
      "learning_rate": 1.563800348467767e-05,
      "loss": 0.3753,
      "step": 2133
    },
    {
      "epoch": 0.44,
      "grad_norm": 1.2058295011520386,
      "learning_rate": 1.563595367428513e-05,
      "loss": 0.4656,
      "step": 2134
    },
    {
      "epoch": 0.44,
      "grad_norm": 1.5430928468704224,
      "learning_rate": 1.5633903863892594e-05,
      "loss": 0.5185,
      "step": 2135
    },
    {
      "epoch": 0.44,
      "grad_norm": 0.8684849739074707,
      "learning_rate": 1.5631854053500054e-05,
      "loss": 0.5474,
      "step": 2136
    },
    {
      "epoch": 0.44,
      "grad_norm": 1.1016836166381836,
      "learning_rate": 1.5629804243107514e-05,
      "loss": 0.6234,
      "step": 2137
    },
    {
      "epoch": 0.44,
      "grad_norm": 2.0119407176971436,
      "learning_rate": 1.5627754432714974e-05,
      "loss": 0.4812,
      "step": 2138
    },
    {
      "epoch": 0.44,
      "grad_norm": 0.8042519688606262,
      "learning_rate": 1.5625704622322438e-05,
      "loss": 0.4568,
      "step": 2139
    },
    {
      "epoch": 0.44,
      "grad_norm": 0.7064275145530701,
      "learning_rate": 1.5623654811929898e-05,
      "loss": 0.4399,
      "step": 2140
    },
    {
      "epoch": 0.44,
      "grad_norm": 0.8523053526878357,
      "learning_rate": 1.5621605001537358e-05,
      "loss": 0.4821,
      "step": 2141
    },
    {
      "epoch": 0.44,
      "grad_norm": 1.5742590427398682,
      "learning_rate": 1.5619555191144818e-05,
      "loss": 0.6307,
      "step": 2142
    },
    {
      "epoch": 0.44,
      "grad_norm": 1.1684057712554932,
      "learning_rate": 1.5617505380752282e-05,
      "loss": 0.4352,
      "step": 2143
    },
    {
      "epoch": 0.44,
      "grad_norm": 0.499188095331192,
      "learning_rate": 1.5615455570359742e-05,
      "loss": 0.3959,
      "step": 2144
    },
    {
      "epoch": 0.44,
      "grad_norm": 0.6893628239631653,
      "learning_rate": 1.5613405759967205e-05,
      "loss": 0.6135,
      "step": 2145
    },
    {
      "epoch": 0.44,
      "grad_norm": 0.5743582248687744,
      "learning_rate": 1.5611355949574666e-05,
      "loss": 0.3865,
      "step": 2146
    },
    {
      "epoch": 0.44,
      "grad_norm": 1.0011390447616577,
      "learning_rate": 1.560930613918213e-05,
      "loss": 0.4361,
      "step": 2147
    },
    {
      "epoch": 0.44,
      "grad_norm": 0.7864087820053101,
      "learning_rate": 1.560725632878959e-05,
      "loss": 0.5489,
      "step": 2148
    },
    {
      "epoch": 0.44,
      "grad_norm": 1.9015319347381592,
      "learning_rate": 1.560520651839705e-05,
      "loss": 0.4351,
      "step": 2149
    },
    {
      "epoch": 0.44,
      "grad_norm": 1.2078205347061157,
      "learning_rate": 1.560315670800451e-05,
      "loss": 0.3442,
      "step": 2150
    },
    {
      "epoch": 0.44,
      "grad_norm": 1.0081464052200317,
      "learning_rate": 1.5601106897611973e-05,
      "loss": 0.4142,
      "step": 2151
    },
    {
      "epoch": 0.44,
      "grad_norm": 1.131568431854248,
      "learning_rate": 1.5599057087219433e-05,
      "loss": 0.6563,
      "step": 2152
    },
    {
      "epoch": 0.44,
      "grad_norm": 1.2324765920639038,
      "learning_rate": 1.5597007276826894e-05,
      "loss": 0.6002,
      "step": 2153
    },
    {
      "epoch": 0.44,
      "grad_norm": 1.1628350019454956,
      "learning_rate": 1.5594957466434354e-05,
      "loss": 0.416,
      "step": 2154
    },
    {
      "epoch": 0.44,
      "grad_norm": 1.232857584953308,
      "learning_rate": 1.5592907656041817e-05,
      "loss": 0.4842,
      "step": 2155
    },
    {
      "epoch": 0.44,
      "grad_norm": 1.4002338647842407,
      "learning_rate": 1.5590857845649277e-05,
      "loss": 0.4778,
      "step": 2156
    },
    {
      "epoch": 0.44,
      "grad_norm": 0.7921110987663269,
      "learning_rate": 1.558880803525674e-05,
      "loss": 0.7215,
      "step": 2157
    },
    {
      "epoch": 0.44,
      "grad_norm": 1.1556634902954102,
      "learning_rate": 1.55867582248642e-05,
      "loss": 0.6053,
      "step": 2158
    },
    {
      "epoch": 0.44,
      "grad_norm": 1.2619173526763916,
      "learning_rate": 1.5584708414471665e-05,
      "loss": 0.4881,
      "step": 2159
    },
    {
      "epoch": 0.44,
      "grad_norm": 1.4244204759597778,
      "learning_rate": 1.5582658604079125e-05,
      "loss": 0.6515,
      "step": 2160
    },
    {
      "epoch": 0.44,
      "grad_norm": 0.6839366555213928,
      "learning_rate": 1.5580608793686585e-05,
      "loss": 0.5272,
      "step": 2161
    },
    {
      "epoch": 0.44,
      "grad_norm": 1.0522245168685913,
      "learning_rate": 1.557855898329405e-05,
      "loss": 0.5366,
      "step": 2162
    },
    {
      "epoch": 0.44,
      "grad_norm": 1.0335760116577148,
      "learning_rate": 1.557650917290151e-05,
      "loss": 0.4726,
      "step": 2163
    },
    {
      "epoch": 0.44,
      "grad_norm": 1.4694554805755615,
      "learning_rate": 1.557445936250897e-05,
      "loss": 0.6178,
      "step": 2164
    },
    {
      "epoch": 0.44,
      "grad_norm": 1.2675268650054932,
      "learning_rate": 1.557240955211643e-05,
      "loss": 0.4505,
      "step": 2165
    },
    {
      "epoch": 0.44,
      "grad_norm": 1.3369362354278564,
      "learning_rate": 1.5570359741723893e-05,
      "loss": 0.3142,
      "step": 2166
    },
    {
      "epoch": 0.44,
      "grad_norm": 1.667901873588562,
      "learning_rate": 1.5568309931331353e-05,
      "loss": 0.4958,
      "step": 2167
    },
    {
      "epoch": 0.44,
      "grad_norm": 0.7918468713760376,
      "learning_rate": 1.5566260120938813e-05,
      "loss": 0.3717,
      "step": 2168
    },
    {
      "epoch": 0.44,
      "grad_norm": 0.765387773513794,
      "learning_rate": 1.5564210310546276e-05,
      "loss": 0.5802,
      "step": 2169
    },
    {
      "epoch": 0.44,
      "grad_norm": 0.7481263875961304,
      "learning_rate": 1.5562160500153737e-05,
      "loss": 0.4392,
      "step": 2170
    },
    {
      "epoch": 0.44,
      "grad_norm": 1.8288770914077759,
      "learning_rate": 1.55601106897612e-05,
      "loss": 0.5356,
      "step": 2171
    },
    {
      "epoch": 0.44,
      "grad_norm": 1.0658259391784668,
      "learning_rate": 1.555806087936866e-05,
      "loss": 0.4096,
      "step": 2172
    },
    {
      "epoch": 0.45,
      "grad_norm": 1.3393508195877075,
      "learning_rate": 1.555601106897612e-05,
      "loss": 0.5646,
      "step": 2173
    },
    {
      "epoch": 0.45,
      "grad_norm": 0.7870877981185913,
      "learning_rate": 1.5553961258583584e-05,
      "loss": 0.6787,
      "step": 2174
    },
    {
      "epoch": 0.45,
      "grad_norm": 1.7874811887741089,
      "learning_rate": 1.5551911448191044e-05,
      "loss": 0.5822,
      "step": 2175
    },
    {
      "epoch": 0.45,
      "grad_norm": 1.2484402656555176,
      "learning_rate": 1.5549861637798504e-05,
      "loss": 0.5052,
      "step": 2176
    },
    {
      "epoch": 0.45,
      "grad_norm": 0.880179762840271,
      "learning_rate": 1.5547811827405965e-05,
      "loss": 0.4886,
      "step": 2177
    },
    {
      "epoch": 0.45,
      "grad_norm": 0.6945215463638306,
      "learning_rate": 1.5545762017013428e-05,
      "loss": 0.3347,
      "step": 2178
    },
    {
      "epoch": 0.45,
      "grad_norm": 1.255920648574829,
      "learning_rate": 1.5543712206620888e-05,
      "loss": 0.4136,
      "step": 2179
    },
    {
      "epoch": 0.45,
      "grad_norm": 1.0664430856704712,
      "learning_rate": 1.554166239622835e-05,
      "loss": 0.5562,
      "step": 2180
    },
    {
      "epoch": 0.45,
      "grad_norm": 1.6795117855072021,
      "learning_rate": 1.5539612585835812e-05,
      "loss": 0.499,
      "step": 2181
    },
    {
      "epoch": 0.45,
      "grad_norm": 0.6650044322013855,
      "learning_rate": 1.5537562775443272e-05,
      "loss": 0.5223,
      "step": 2182
    },
    {
      "epoch": 0.45,
      "grad_norm": 2.0210282802581787,
      "learning_rate": 1.5535512965050736e-05,
      "loss": 0.5222,
      "step": 2183
    },
    {
      "epoch": 0.45,
      "grad_norm": 1.0541809797286987,
      "learning_rate": 1.5533463154658196e-05,
      "loss": 0.4439,
      "step": 2184
    },
    {
      "epoch": 0.45,
      "grad_norm": 0.7968710064888,
      "learning_rate": 1.5531413344265656e-05,
      "loss": 0.5341,
      "step": 2185
    },
    {
      "epoch": 0.45,
      "grad_norm": 1.209399938583374,
      "learning_rate": 1.552936353387312e-05,
      "loss": 0.4502,
      "step": 2186
    },
    {
      "epoch": 0.45,
      "grad_norm": 1.3910448551177979,
      "learning_rate": 1.552731372348058e-05,
      "loss": 0.5263,
      "step": 2187
    },
    {
      "epoch": 0.45,
      "grad_norm": 0.5671313405036926,
      "learning_rate": 1.552526391308804e-05,
      "loss": 0.4782,
      "step": 2188
    },
    {
      "epoch": 0.45,
      "grad_norm": 0.9881293773651123,
      "learning_rate": 1.5523214102695503e-05,
      "loss": 0.515,
      "step": 2189
    },
    {
      "epoch": 0.45,
      "grad_norm": 1.4114434719085693,
      "learning_rate": 1.5521164292302964e-05,
      "loss": 0.6029,
      "step": 2190
    },
    {
      "epoch": 0.45,
      "grad_norm": 0.5741744041442871,
      "learning_rate": 1.5519114481910424e-05,
      "loss": 0.5872,
      "step": 2191
    },
    {
      "epoch": 0.45,
      "grad_norm": 0.7109807729721069,
      "learning_rate": 1.5517064671517884e-05,
      "loss": 0.3441,
      "step": 2192
    },
    {
      "epoch": 0.45,
      "grad_norm": 0.6118992567062378,
      "learning_rate": 1.5515014861125347e-05,
      "loss": 0.4375,
      "step": 2193
    },
    {
      "epoch": 0.45,
      "grad_norm": 0.8112924695014954,
      "learning_rate": 1.5512965050732808e-05,
      "loss": 0.3823,
      "step": 2194
    },
    {
      "epoch": 0.45,
      "grad_norm": 0.7536270618438721,
      "learning_rate": 1.551091524034027e-05,
      "loss": 0.4116,
      "step": 2195
    },
    {
      "epoch": 0.45,
      "grad_norm": 0.7342718243598938,
      "learning_rate": 1.550886542994773e-05,
      "loss": 0.3992,
      "step": 2196
    },
    {
      "epoch": 0.45,
      "grad_norm": 1.0502936840057373,
      "learning_rate": 1.5506815619555195e-05,
      "loss": 0.4689,
      "step": 2197
    },
    {
      "epoch": 0.45,
      "grad_norm": 0.7565938234329224,
      "learning_rate": 1.5504765809162655e-05,
      "loss": 0.5442,
      "step": 2198
    },
    {
      "epoch": 0.45,
      "grad_norm": 2.4089195728302,
      "learning_rate": 1.5502715998770115e-05,
      "loss": 0.4808,
      "step": 2199
    },
    {
      "epoch": 0.45,
      "grad_norm": 0.8401941061019897,
      "learning_rate": 1.5500666188377575e-05,
      "loss": 0.5191,
      "step": 2200
    },
    {
      "epoch": 0.45,
      "grad_norm": 0.8659058213233948,
      "learning_rate": 1.549861637798504e-05,
      "loss": 0.328,
      "step": 2201
    },
    {
      "epoch": 0.45,
      "grad_norm": 0.9184033274650574,
      "learning_rate": 1.54965665675925e-05,
      "loss": 0.6448,
      "step": 2202
    },
    {
      "epoch": 0.45,
      "grad_norm": 1.1228607892990112,
      "learning_rate": 1.549451675719996e-05,
      "loss": 0.4934,
      "step": 2203
    },
    {
      "epoch": 0.45,
      "grad_norm": 1.6767096519470215,
      "learning_rate": 1.549246694680742e-05,
      "loss": 0.4686,
      "step": 2204
    },
    {
      "epoch": 0.45,
      "grad_norm": 0.6579710245132446,
      "learning_rate": 1.5490417136414883e-05,
      "loss": 0.5171,
      "step": 2205
    },
    {
      "epoch": 0.45,
      "grad_norm": 1.3435053825378418,
      "learning_rate": 1.5488367326022343e-05,
      "loss": 0.3446,
      "step": 2206
    },
    {
      "epoch": 0.45,
      "grad_norm": 0.8691650629043579,
      "learning_rate": 1.5486317515629807e-05,
      "loss": 0.5161,
      "step": 2207
    },
    {
      "epoch": 0.45,
      "grad_norm": 0.891531229019165,
      "learning_rate": 1.5484267705237267e-05,
      "loss": 0.6387,
      "step": 2208
    },
    {
      "epoch": 0.45,
      "grad_norm": 0.9282382130622864,
      "learning_rate": 1.548221789484473e-05,
      "loss": 0.387,
      "step": 2209
    },
    {
      "epoch": 0.45,
      "grad_norm": 0.8606425523757935,
      "learning_rate": 1.548016808445219e-05,
      "loss": 0.3837,
      "step": 2210
    },
    {
      "epoch": 0.45,
      "grad_norm": 0.961881697177887,
      "learning_rate": 1.547811827405965e-05,
      "loss": 0.4137,
      "step": 2211
    },
    {
      "epoch": 0.45,
      "grad_norm": 1.024262547492981,
      "learning_rate": 1.547606846366711e-05,
      "loss": 0.5681,
      "step": 2212
    },
    {
      "epoch": 0.45,
      "grad_norm": 0.7473705410957336,
      "learning_rate": 1.5474018653274574e-05,
      "loss": 0.3401,
      "step": 2213
    },
    {
      "epoch": 0.45,
      "grad_norm": 0.8088539242744446,
      "learning_rate": 1.5471968842882035e-05,
      "loss": 0.5983,
      "step": 2214
    },
    {
      "epoch": 0.45,
      "grad_norm": 1.4923861026763916,
      "learning_rate": 1.5469919032489495e-05,
      "loss": 0.4936,
      "step": 2215
    },
    {
      "epoch": 0.45,
      "grad_norm": 0.7876701951026917,
      "learning_rate": 1.5467869222096958e-05,
      "loss": 0.4156,
      "step": 2216
    },
    {
      "epoch": 0.45,
      "grad_norm": 1.5153112411499023,
      "learning_rate": 1.546581941170442e-05,
      "loss": 0.5181,
      "step": 2217
    },
    {
      "epoch": 0.45,
      "grad_norm": 1.5362670421600342,
      "learning_rate": 1.546376960131188e-05,
      "loss": 0.4467,
      "step": 2218
    },
    {
      "epoch": 0.45,
      "grad_norm": 1.6293493509292603,
      "learning_rate": 1.5461719790919342e-05,
      "loss": 0.4374,
      "step": 2219
    },
    {
      "epoch": 0.45,
      "grad_norm": 1.341827154159546,
      "learning_rate": 1.5459669980526802e-05,
      "loss": 0.5561,
      "step": 2220
    },
    {
      "epoch": 0.46,
      "grad_norm": 0.7356947064399719,
      "learning_rate": 1.5457620170134266e-05,
      "loss": 0.4178,
      "step": 2221
    },
    {
      "epoch": 0.46,
      "grad_norm": 0.5964138507843018,
      "learning_rate": 1.5455570359741726e-05,
      "loss": 0.3959,
      "step": 2222
    },
    {
      "epoch": 0.46,
      "grad_norm": 0.768296480178833,
      "learning_rate": 1.5453520549349186e-05,
      "loss": 0.6345,
      "step": 2223
    },
    {
      "epoch": 0.46,
      "grad_norm": 1.6924735307693481,
      "learning_rate": 1.545147073895665e-05,
      "loss": 0.3887,
      "step": 2224
    },
    {
      "epoch": 0.46,
      "grad_norm": 1.0641865730285645,
      "learning_rate": 1.544942092856411e-05,
      "loss": 0.5188,
      "step": 2225
    },
    {
      "epoch": 0.46,
      "grad_norm": 0.7002860307693481,
      "learning_rate": 1.544737111817157e-05,
      "loss": 0.477,
      "step": 2226
    },
    {
      "epoch": 0.46,
      "grad_norm": 2.1905901432037354,
      "learning_rate": 1.544532130777903e-05,
      "loss": 0.4199,
      "step": 2227
    },
    {
      "epoch": 0.46,
      "grad_norm": 1.0460374355316162,
      "learning_rate": 1.5443271497386494e-05,
      "loss": 0.4861,
      "step": 2228
    },
    {
      "epoch": 0.46,
      "grad_norm": 1.1861040592193604,
      "learning_rate": 1.5441221686993954e-05,
      "loss": 0.5907,
      "step": 2229
    },
    {
      "epoch": 0.46,
      "grad_norm": 1.1533067226409912,
      "learning_rate": 1.5439171876601414e-05,
      "loss": 0.4887,
      "step": 2230
    },
    {
      "epoch": 0.46,
      "grad_norm": 0.9766476154327393,
      "learning_rate": 1.5437122066208878e-05,
      "loss": 0.5053,
      "step": 2231
    },
    {
      "epoch": 0.46,
      "grad_norm": 1.1092466115951538,
      "learning_rate": 1.5435072255816338e-05,
      "loss": 0.5632,
      "step": 2232
    },
    {
      "epoch": 0.46,
      "grad_norm": 0.8561396598815918,
      "learning_rate": 1.54330224454238e-05,
      "loss": 0.5892,
      "step": 2233
    },
    {
      "epoch": 0.46,
      "grad_norm": 1.665722131729126,
      "learning_rate": 1.543097263503126e-05,
      "loss": 0.5973,
      "step": 2234
    },
    {
      "epoch": 0.46,
      "grad_norm": 0.6256427764892578,
      "learning_rate": 1.5428922824638722e-05,
      "loss": 0.4222,
      "step": 2235
    },
    {
      "epoch": 0.46,
      "grad_norm": 1.169060230255127,
      "learning_rate": 1.5426873014246185e-05,
      "loss": 0.3527,
      "step": 2236
    },
    {
      "epoch": 0.46,
      "grad_norm": 1.465972661972046,
      "learning_rate": 1.5424823203853645e-05,
      "loss": 0.3151,
      "step": 2237
    },
    {
      "epoch": 0.46,
      "grad_norm": 1.841009497642517,
      "learning_rate": 1.5422773393461106e-05,
      "loss": 0.4655,
      "step": 2238
    },
    {
      "epoch": 0.46,
      "grad_norm": 2.016104221343994,
      "learning_rate": 1.5420723583068566e-05,
      "loss": 0.5116,
      "step": 2239
    },
    {
      "epoch": 0.46,
      "grad_norm": 0.7912639379501343,
      "learning_rate": 1.541867377267603e-05,
      "loss": 0.6454,
      "step": 2240
    },
    {
      "epoch": 0.46,
      "grad_norm": 0.9713414907455444,
      "learning_rate": 1.541662396228349e-05,
      "loss": 0.5763,
      "step": 2241
    },
    {
      "epoch": 0.46,
      "grad_norm": 1.4895471334457397,
      "learning_rate": 1.541457415189095e-05,
      "loss": 0.4797,
      "step": 2242
    },
    {
      "epoch": 0.46,
      "grad_norm": 0.7293054461479187,
      "learning_rate": 1.5412524341498413e-05,
      "loss": 0.4236,
      "step": 2243
    },
    {
      "epoch": 0.46,
      "grad_norm": 3.2154011726379395,
      "learning_rate": 1.5410474531105873e-05,
      "loss": 0.5315,
      "step": 2244
    },
    {
      "epoch": 0.46,
      "grad_norm": 1.7510212659835815,
      "learning_rate": 1.5408424720713337e-05,
      "loss": 0.4985,
      "step": 2245
    },
    {
      "epoch": 0.46,
      "grad_norm": 0.8986544609069824,
      "learning_rate": 1.5406374910320797e-05,
      "loss": 0.7118,
      "step": 2246
    },
    {
      "epoch": 0.46,
      "grad_norm": 1.8060030937194824,
      "learning_rate": 1.540432509992826e-05,
      "loss": 0.3539,
      "step": 2247
    },
    {
      "epoch": 0.46,
      "grad_norm": 0.7005752921104431,
      "learning_rate": 1.540227528953572e-05,
      "loss": 0.3344,
      "step": 2248
    },
    {
      "epoch": 0.46,
      "grad_norm": 0.6635324954986572,
      "learning_rate": 1.540022547914318e-05,
      "loss": 0.4975,
      "step": 2249
    },
    {
      "epoch": 0.46,
      "grad_norm": 1.0808831453323364,
      "learning_rate": 1.539817566875064e-05,
      "loss": 0.5607,
      "step": 2250
    },
    {
      "epoch": 0.46,
      "grad_norm": 1.1756173372268677,
      "learning_rate": 1.5396125858358105e-05,
      "loss": 0.5395,
      "step": 2251
    },
    {
      "epoch": 0.46,
      "grad_norm": 0.985988199710846,
      "learning_rate": 1.5394076047965565e-05,
      "loss": 0.4322,
      "step": 2252
    },
    {
      "epoch": 0.46,
      "grad_norm": 0.6730608344078064,
      "learning_rate": 1.5392026237573025e-05,
      "loss": 0.3987,
      "step": 2253
    },
    {
      "epoch": 0.46,
      "grad_norm": 1.5046693086624146,
      "learning_rate": 1.5389976427180485e-05,
      "loss": 0.5141,
      "step": 2254
    },
    {
      "epoch": 0.46,
      "grad_norm": 0.9092057943344116,
      "learning_rate": 1.538792661678795e-05,
      "loss": 0.49,
      "step": 2255
    },
    {
      "epoch": 0.46,
      "grad_norm": 1.0397353172302246,
      "learning_rate": 1.538587680639541e-05,
      "loss": 0.5479,
      "step": 2256
    },
    {
      "epoch": 0.46,
      "grad_norm": 1.1158446073532104,
      "learning_rate": 1.5383826996002872e-05,
      "loss": 0.4553,
      "step": 2257
    },
    {
      "epoch": 0.46,
      "grad_norm": 0.9934431910514832,
      "learning_rate": 1.5381777185610333e-05,
      "loss": 0.4535,
      "step": 2258
    },
    {
      "epoch": 0.46,
      "grad_norm": 0.5717322826385498,
      "learning_rate": 1.5379727375217796e-05,
      "loss": 0.4856,
      "step": 2259
    },
    {
      "epoch": 0.46,
      "grad_norm": 0.9903457760810852,
      "learning_rate": 1.5377677564825256e-05,
      "loss": 0.4321,
      "step": 2260
    },
    {
      "epoch": 0.46,
      "grad_norm": 0.7062474489212036,
      "learning_rate": 1.5375627754432716e-05,
      "loss": 0.5361,
      "step": 2261
    },
    {
      "epoch": 0.46,
      "grad_norm": 0.965830385684967,
      "learning_rate": 1.5373577944040177e-05,
      "loss": 0.3913,
      "step": 2262
    },
    {
      "epoch": 0.46,
      "grad_norm": 1.1184263229370117,
      "learning_rate": 1.537152813364764e-05,
      "loss": 0.5438,
      "step": 2263
    },
    {
      "epoch": 0.46,
      "grad_norm": 0.934360921382904,
      "learning_rate": 1.53694783232551e-05,
      "loss": 0.5469,
      "step": 2264
    },
    {
      "epoch": 0.46,
      "grad_norm": 1.5233923196792603,
      "learning_rate": 1.536742851286256e-05,
      "loss": 0.4107,
      "step": 2265
    },
    {
      "epoch": 0.46,
      "grad_norm": 0.9661927819252014,
      "learning_rate": 1.536537870247002e-05,
      "loss": 0.4116,
      "step": 2266
    },
    {
      "epoch": 0.46,
      "grad_norm": 0.8357121348381042,
      "learning_rate": 1.5363328892077484e-05,
      "loss": 0.4686,
      "step": 2267
    },
    {
      "epoch": 0.46,
      "grad_norm": 0.5506798028945923,
      "learning_rate": 1.5361279081684944e-05,
      "loss": 0.4563,
      "step": 2268
    },
    {
      "epoch": 0.46,
      "grad_norm": 1.807282567024231,
      "learning_rate": 1.5359229271292408e-05,
      "loss": 0.4133,
      "step": 2269
    },
    {
      "epoch": 0.47,
      "grad_norm": 2.011136531829834,
      "learning_rate": 1.5357179460899868e-05,
      "loss": 0.3821,
      "step": 2270
    },
    {
      "epoch": 0.47,
      "grad_norm": 0.6903606057167053,
      "learning_rate": 1.535512965050733e-05,
      "loss": 0.5228,
      "step": 2271
    },
    {
      "epoch": 0.47,
      "grad_norm": 0.6763584613800049,
      "learning_rate": 1.5353079840114792e-05,
      "loss": 0.5039,
      "step": 2272
    },
    {
      "epoch": 0.47,
      "grad_norm": 0.6733695268630981,
      "learning_rate": 1.5351030029722252e-05,
      "loss": 0.327,
      "step": 2273
    },
    {
      "epoch": 0.47,
      "grad_norm": 2.807647705078125,
      "learning_rate": 1.5348980219329712e-05,
      "loss": 0.5838,
      "step": 2274
    },
    {
      "epoch": 0.47,
      "grad_norm": 1.0014281272888184,
      "learning_rate": 1.5346930408937176e-05,
      "loss": 0.6019,
      "step": 2275
    },
    {
      "epoch": 0.47,
      "grad_norm": 0.9370754361152649,
      "learning_rate": 1.5344880598544636e-05,
      "loss": 0.6114,
      "step": 2276
    },
    {
      "epoch": 0.47,
      "grad_norm": 1.6638779640197754,
      "learning_rate": 1.5342830788152096e-05,
      "loss": 0.3979,
      "step": 2277
    },
    {
      "epoch": 0.47,
      "grad_norm": 1.1048014163970947,
      "learning_rate": 1.534078097775956e-05,
      "loss": 0.4332,
      "step": 2278
    },
    {
      "epoch": 0.47,
      "grad_norm": 1.1965218782424927,
      "learning_rate": 1.533873116736702e-05,
      "loss": 0.5064,
      "step": 2279
    },
    {
      "epoch": 0.47,
      "grad_norm": 1.8543686866760254,
      "learning_rate": 1.533668135697448e-05,
      "loss": 0.4839,
      "step": 2280
    },
    {
      "epoch": 0.47,
      "grad_norm": 2.40183687210083,
      "learning_rate": 1.5334631546581943e-05,
      "loss": 0.6788,
      "step": 2281
    },
    {
      "epoch": 0.47,
      "grad_norm": 1.7646522521972656,
      "learning_rate": 1.5332581736189404e-05,
      "loss": 0.4663,
      "step": 2282
    },
    {
      "epoch": 0.47,
      "grad_norm": 1.0677263736724854,
      "learning_rate": 1.5330531925796867e-05,
      "loss": 0.5103,
      "step": 2283
    },
    {
      "epoch": 0.47,
      "grad_norm": 1.3096319437026978,
      "learning_rate": 1.5328482115404327e-05,
      "loss": 0.3999,
      "step": 2284
    },
    {
      "epoch": 0.47,
      "grad_norm": 0.9844738841056824,
      "learning_rate": 1.5326432305011787e-05,
      "loss": 0.4448,
      "step": 2285
    },
    {
      "epoch": 0.47,
      "grad_norm": 0.8107011318206787,
      "learning_rate": 1.532438249461925e-05,
      "loss": 0.6358,
      "step": 2286
    },
    {
      "epoch": 0.47,
      "grad_norm": 1.2468862533569336,
      "learning_rate": 1.532233268422671e-05,
      "loss": 0.3075,
      "step": 2287
    },
    {
      "epoch": 0.47,
      "grad_norm": 0.8388816714286804,
      "learning_rate": 1.532028287383417e-05,
      "loss": 0.3737,
      "step": 2288
    },
    {
      "epoch": 0.47,
      "grad_norm": 0.6639811992645264,
      "learning_rate": 1.531823306344163e-05,
      "loss": 0.385,
      "step": 2289
    },
    {
      "epoch": 0.47,
      "grad_norm": 0.8928037881851196,
      "learning_rate": 1.5316183253049095e-05,
      "loss": 0.4589,
      "step": 2290
    },
    {
      "epoch": 0.47,
      "grad_norm": 0.7029617428779602,
      "learning_rate": 1.5314133442656555e-05,
      "loss": 0.4634,
      "step": 2291
    },
    {
      "epoch": 0.47,
      "grad_norm": 1.4451690912246704,
      "learning_rate": 1.5312083632264015e-05,
      "loss": 0.417,
      "step": 2292
    },
    {
      "epoch": 0.47,
      "grad_norm": 0.6244314312934875,
      "learning_rate": 1.531003382187148e-05,
      "loss": 0.3081,
      "step": 2293
    },
    {
      "epoch": 0.47,
      "grad_norm": 0.9455553889274597,
      "learning_rate": 1.530798401147894e-05,
      "loss": 0.4086,
      "step": 2294
    },
    {
      "epoch": 0.47,
      "grad_norm": 0.7847464084625244,
      "learning_rate": 1.5305934201086403e-05,
      "loss": 0.4705,
      "step": 2295
    },
    {
      "epoch": 0.47,
      "grad_norm": 1.0639160871505737,
      "learning_rate": 1.5303884390693863e-05,
      "loss": 0.4908,
      "step": 2296
    },
    {
      "epoch": 0.47,
      "grad_norm": 0.7651649713516235,
      "learning_rate": 1.5301834580301323e-05,
      "loss": 0.5963,
      "step": 2297
    },
    {
      "epoch": 0.47,
      "grad_norm": 1.0063012838363647,
      "learning_rate": 1.5299784769908786e-05,
      "loss": 0.5224,
      "step": 2298
    },
    {
      "epoch": 0.47,
      "grad_norm": 1.2339096069335938,
      "learning_rate": 1.5297734959516247e-05,
      "loss": 0.4742,
      "step": 2299
    },
    {
      "epoch": 0.47,
      "grad_norm": 1.1301268339157104,
      "learning_rate": 1.5295685149123707e-05,
      "loss": 0.4048,
      "step": 2300
    },
    {
      "epoch": 0.47,
      "grad_norm": 1.3873425722122192,
      "learning_rate": 1.5293635338731167e-05,
      "loss": 0.3961,
      "step": 2301
    },
    {
      "epoch": 0.47,
      "grad_norm": 1.1970022916793823,
      "learning_rate": 1.529158552833863e-05,
      "loss": 0.5227,
      "step": 2302
    },
    {
      "epoch": 0.47,
      "grad_norm": 1.3486826419830322,
      "learning_rate": 1.528953571794609e-05,
      "loss": 0.3203,
      "step": 2303
    },
    {
      "epoch": 0.47,
      "grad_norm": 0.868331789970398,
      "learning_rate": 1.528748590755355e-05,
      "loss": 0.5858,
      "step": 2304
    },
    {
      "epoch": 0.47,
      "grad_norm": 1.277785062789917,
      "learning_rate": 1.5285436097161014e-05,
      "loss": 0.575,
      "step": 2305
    },
    {
      "epoch": 0.47,
      "grad_norm": 0.7697628140449524,
      "learning_rate": 1.5283386286768475e-05,
      "loss": 0.4962,
      "step": 2306
    },
    {
      "epoch": 0.47,
      "grad_norm": 0.8632085919380188,
      "learning_rate": 1.5281336476375938e-05,
      "loss": 0.5785,
      "step": 2307
    },
    {
      "epoch": 0.47,
      "grad_norm": 1.1477059125900269,
      "learning_rate": 1.5279286665983398e-05,
      "loss": 0.4092,
      "step": 2308
    },
    {
      "epoch": 0.47,
      "grad_norm": 1.0164283514022827,
      "learning_rate": 1.5277236855590862e-05,
      "loss": 0.5799,
      "step": 2309
    },
    {
      "epoch": 0.47,
      "grad_norm": 0.9220234155654907,
      "learning_rate": 1.5275187045198322e-05,
      "loss": 0.3947,
      "step": 2310
    },
    {
      "epoch": 0.47,
      "grad_norm": 1.7714887857437134,
      "learning_rate": 1.5273137234805782e-05,
      "loss": 0.4104,
      "step": 2311
    },
    {
      "epoch": 0.47,
      "grad_norm": 1.2706782817840576,
      "learning_rate": 1.5271087424413242e-05,
      "loss": 0.5662,
      "step": 2312
    },
    {
      "epoch": 0.47,
      "grad_norm": 0.6789814233779907,
      "learning_rate": 1.5269037614020706e-05,
      "loss": 0.5387,
      "step": 2313
    },
    {
      "epoch": 0.47,
      "grad_norm": 0.5746080875396729,
      "learning_rate": 1.5266987803628166e-05,
      "loss": 0.4736,
      "step": 2314
    },
    {
      "epoch": 0.47,
      "grad_norm": 2.5977907180786133,
      "learning_rate": 1.5264937993235626e-05,
      "loss": 0.4658,
      "step": 2315
    },
    {
      "epoch": 0.47,
      "grad_norm": 0.9877371191978455,
      "learning_rate": 1.5262888182843086e-05,
      "loss": 0.5087,
      "step": 2316
    },
    {
      "epoch": 0.47,
      "grad_norm": 1.2231626510620117,
      "learning_rate": 1.526083837245055e-05,
      "loss": 0.6093,
      "step": 2317
    },
    {
      "epoch": 0.47,
      "grad_norm": 1.0969992876052856,
      "learning_rate": 1.5258788562058012e-05,
      "loss": 0.578,
      "step": 2318
    },
    {
      "epoch": 0.48,
      "grad_norm": 1.2056002616882324,
      "learning_rate": 1.5256738751665472e-05,
      "loss": 0.4953,
      "step": 2319
    },
    {
      "epoch": 0.48,
      "grad_norm": 1.4045591354370117,
      "learning_rate": 1.5254688941272932e-05,
      "loss": 0.5855,
      "step": 2320
    },
    {
      "epoch": 0.48,
      "grad_norm": 0.7441479563713074,
      "learning_rate": 1.5252639130880396e-05,
      "loss": 0.5472,
      "step": 2321
    },
    {
      "epoch": 0.48,
      "grad_norm": 1.0771280527114868,
      "learning_rate": 1.5250589320487856e-05,
      "loss": 0.5201,
      "step": 2322
    },
    {
      "epoch": 0.48,
      "grad_norm": 0.8792422413825989,
      "learning_rate": 1.5248539510095318e-05,
      "loss": 0.5067,
      "step": 2323
    },
    {
      "epoch": 0.48,
      "grad_norm": 1.0794166326522827,
      "learning_rate": 1.5246489699702778e-05,
      "loss": 0.4553,
      "step": 2324
    },
    {
      "epoch": 0.48,
      "grad_norm": 0.5775021910667419,
      "learning_rate": 1.5244439889310241e-05,
      "loss": 0.3752,
      "step": 2325
    },
    {
      "epoch": 0.48,
      "grad_norm": 1.0958740711212158,
      "learning_rate": 1.5242390078917702e-05,
      "loss": 0.3891,
      "step": 2326
    },
    {
      "epoch": 0.48,
      "grad_norm": 0.759131133556366,
      "learning_rate": 1.5240340268525162e-05,
      "loss": 0.4754,
      "step": 2327
    },
    {
      "epoch": 0.48,
      "grad_norm": 0.6612756252288818,
      "learning_rate": 1.5238290458132624e-05,
      "loss": 0.5395,
      "step": 2328
    },
    {
      "epoch": 0.48,
      "grad_norm": 0.7283391952514648,
      "learning_rate": 1.5236240647740085e-05,
      "loss": 0.4826,
      "step": 2329
    },
    {
      "epoch": 0.48,
      "grad_norm": 0.7286397218704224,
      "learning_rate": 1.5234190837347547e-05,
      "loss": 0.3636,
      "step": 2330
    },
    {
      "epoch": 0.48,
      "grad_norm": 0.7684622406959534,
      "learning_rate": 1.5232141026955007e-05,
      "loss": 0.5081,
      "step": 2331
    },
    {
      "epoch": 0.48,
      "grad_norm": 0.6991771459579468,
      "learning_rate": 1.5230091216562468e-05,
      "loss": 0.341,
      "step": 2332
    },
    {
      "epoch": 0.48,
      "grad_norm": 0.9393710494041443,
      "learning_rate": 1.5228041406169931e-05,
      "loss": 0.5567,
      "step": 2333
    },
    {
      "epoch": 0.48,
      "grad_norm": 0.7297393679618835,
      "learning_rate": 1.5225991595777391e-05,
      "loss": 0.5798,
      "step": 2334
    },
    {
      "epoch": 0.48,
      "grad_norm": 0.6696963310241699,
      "learning_rate": 1.5223941785384853e-05,
      "loss": 0.4945,
      "step": 2335
    },
    {
      "epoch": 0.48,
      "grad_norm": 1.113402009010315,
      "learning_rate": 1.5221891974992315e-05,
      "loss": 0.4982,
      "step": 2336
    },
    {
      "epoch": 0.48,
      "grad_norm": 0.7650272846221924,
      "learning_rate": 1.5219842164599777e-05,
      "loss": 0.4972,
      "step": 2337
    },
    {
      "epoch": 0.48,
      "grad_norm": 0.9931010603904724,
      "learning_rate": 1.5217792354207237e-05,
      "loss": 0.5032,
      "step": 2338
    },
    {
      "epoch": 0.48,
      "grad_norm": 0.9084917306900024,
      "learning_rate": 1.5215742543814697e-05,
      "loss": 0.4978,
      "step": 2339
    },
    {
      "epoch": 0.48,
      "grad_norm": 1.3416967391967773,
      "learning_rate": 1.521369273342216e-05,
      "loss": 0.3703,
      "step": 2340
    },
    {
      "epoch": 0.48,
      "grad_norm": 1.3299109935760498,
      "learning_rate": 1.5211642923029621e-05,
      "loss": 0.4311,
      "step": 2341
    },
    {
      "epoch": 0.48,
      "grad_norm": 1.161586046218872,
      "learning_rate": 1.5209593112637083e-05,
      "loss": 0.4526,
      "step": 2342
    },
    {
      "epoch": 0.48,
      "grad_norm": 1.2131071090698242,
      "learning_rate": 1.5207543302244543e-05,
      "loss": 0.473,
      "step": 2343
    },
    {
      "epoch": 0.48,
      "grad_norm": 1.131475567817688,
      "learning_rate": 1.5205493491852006e-05,
      "loss": 0.573,
      "step": 2344
    },
    {
      "epoch": 0.48,
      "grad_norm": 1.0827568769454956,
      "learning_rate": 1.5203443681459467e-05,
      "loss": 0.5005,
      "step": 2345
    },
    {
      "epoch": 0.48,
      "grad_norm": 0.5268421769142151,
      "learning_rate": 1.5201393871066927e-05,
      "loss": 0.4408,
      "step": 2346
    },
    {
      "epoch": 0.48,
      "grad_norm": 1.3557515144348145,
      "learning_rate": 1.5199344060674389e-05,
      "loss": 0.5339,
      "step": 2347
    },
    {
      "epoch": 0.48,
      "grad_norm": 1.5292022228240967,
      "learning_rate": 1.519729425028185e-05,
      "loss": 0.5195,
      "step": 2348
    },
    {
      "epoch": 0.48,
      "grad_norm": 0.938636839389801,
      "learning_rate": 1.5195244439889312e-05,
      "loss": 0.4012,
      "step": 2349
    },
    {
      "epoch": 0.48,
      "grad_norm": 0.8404025435447693,
      "learning_rate": 1.5193194629496773e-05,
      "loss": 0.6696,
      "step": 2350
    },
    {
      "epoch": 0.48,
      "grad_norm": 1.0752123594284058,
      "learning_rate": 1.5191144819104233e-05,
      "loss": 0.4736,
      "step": 2351
    },
    {
      "epoch": 0.48,
      "grad_norm": 2.7371227741241455,
      "learning_rate": 1.5189095008711696e-05,
      "loss": 0.3949,
      "step": 2352
    },
    {
      "epoch": 0.48,
      "grad_norm": 0.46696725487709045,
      "learning_rate": 1.5187045198319156e-05,
      "loss": 0.356,
      "step": 2353
    },
    {
      "epoch": 0.48,
      "grad_norm": 0.8291383981704712,
      "learning_rate": 1.5184995387926618e-05,
      "loss": 0.6823,
      "step": 2354
    },
    {
      "epoch": 0.48,
      "grad_norm": 0.55543452501297,
      "learning_rate": 1.5182945577534078e-05,
      "loss": 0.6065,
      "step": 2355
    },
    {
      "epoch": 0.48,
      "grad_norm": 0.7018769383430481,
      "learning_rate": 1.5180895767141542e-05,
      "loss": 0.4735,
      "step": 2356
    },
    {
      "epoch": 0.48,
      "grad_norm": 2.1305367946624756,
      "learning_rate": 1.5178845956749002e-05,
      "loss": 0.3159,
      "step": 2357
    },
    {
      "epoch": 0.48,
      "grad_norm": 1.371109127998352,
      "learning_rate": 1.5176796146356462e-05,
      "loss": 0.4573,
      "step": 2358
    },
    {
      "epoch": 0.48,
      "grad_norm": 0.9022133350372314,
      "learning_rate": 1.5174746335963924e-05,
      "loss": 0.5145,
      "step": 2359
    },
    {
      "epoch": 0.48,
      "grad_norm": 0.8308839201927185,
      "learning_rate": 1.5172696525571386e-05,
      "loss": 0.4008,
      "step": 2360
    },
    {
      "epoch": 0.48,
      "grad_norm": 2.1341912746429443,
      "learning_rate": 1.5170646715178848e-05,
      "loss": 0.5858,
      "step": 2361
    },
    {
      "epoch": 0.48,
      "grad_norm": 1.3304766416549683,
      "learning_rate": 1.5168596904786308e-05,
      "loss": 0.5914,
      "step": 2362
    },
    {
      "epoch": 0.48,
      "grad_norm": 1.5540827512741089,
      "learning_rate": 1.5166547094393768e-05,
      "loss": 0.4416,
      "step": 2363
    },
    {
      "epoch": 0.48,
      "grad_norm": 2.1112096309661865,
      "learning_rate": 1.5164497284001232e-05,
      "loss": 0.4894,
      "step": 2364
    },
    {
      "epoch": 0.48,
      "grad_norm": 1.8856033086776733,
      "learning_rate": 1.5162447473608692e-05,
      "loss": 0.4134,
      "step": 2365
    },
    {
      "epoch": 0.48,
      "grad_norm": 1.0920648574829102,
      "learning_rate": 1.5160397663216154e-05,
      "loss": 0.4273,
      "step": 2366
    },
    {
      "epoch": 0.48,
      "grad_norm": 1.2381317615509033,
      "learning_rate": 1.5158347852823616e-05,
      "loss": 0.5006,
      "step": 2367
    },
    {
      "epoch": 0.49,
      "grad_norm": 1.7706471681594849,
      "learning_rate": 1.5156298042431077e-05,
      "loss": 0.4104,
      "step": 2368
    },
    {
      "epoch": 0.49,
      "grad_norm": 0.576615035533905,
      "learning_rate": 1.5154248232038538e-05,
      "loss": 0.4742,
      "step": 2369
    },
    {
      "epoch": 0.49,
      "grad_norm": 1.4298783540725708,
      "learning_rate": 1.5152198421645998e-05,
      "loss": 0.5233,
      "step": 2370
    },
    {
      "epoch": 0.49,
      "grad_norm": 0.8223472833633423,
      "learning_rate": 1.5150148611253461e-05,
      "loss": 0.5556,
      "step": 2371
    },
    {
      "epoch": 0.49,
      "grad_norm": 1.3949979543685913,
      "learning_rate": 1.5148098800860921e-05,
      "loss": 0.4371,
      "step": 2372
    },
    {
      "epoch": 0.49,
      "grad_norm": 1.2953015565872192,
      "learning_rate": 1.5146048990468383e-05,
      "loss": 0.6601,
      "step": 2373
    },
    {
      "epoch": 0.49,
      "grad_norm": 1.034224271774292,
      "learning_rate": 1.5143999180075844e-05,
      "loss": 0.4384,
      "step": 2374
    },
    {
      "epoch": 0.49,
      "grad_norm": 2.0596108436584473,
      "learning_rate": 1.5141949369683307e-05,
      "loss": 0.4712,
      "step": 2375
    },
    {
      "epoch": 0.49,
      "grad_norm": 0.7536822557449341,
      "learning_rate": 1.5139899559290767e-05,
      "loss": 0.5667,
      "step": 2376
    },
    {
      "epoch": 0.49,
      "grad_norm": 1.6502419710159302,
      "learning_rate": 1.5137849748898227e-05,
      "loss": 0.3348,
      "step": 2377
    },
    {
      "epoch": 0.49,
      "grad_norm": 0.9392074346542358,
      "learning_rate": 1.513579993850569e-05,
      "loss": 0.5972,
      "step": 2378
    },
    {
      "epoch": 0.49,
      "grad_norm": 0.8334396481513977,
      "learning_rate": 1.5133750128113151e-05,
      "loss": 0.3125,
      "step": 2379
    },
    {
      "epoch": 0.49,
      "grad_norm": 0.6644366383552551,
      "learning_rate": 1.5131700317720613e-05,
      "loss": 0.455,
      "step": 2380
    },
    {
      "epoch": 0.49,
      "grad_norm": 0.5446476340293884,
      "learning_rate": 1.5129650507328073e-05,
      "loss": 0.3108,
      "step": 2381
    },
    {
      "epoch": 0.49,
      "grad_norm": 1.5517324209213257,
      "learning_rate": 1.5127600696935533e-05,
      "loss": 0.4194,
      "step": 2382
    },
    {
      "epoch": 0.49,
      "grad_norm": 0.8025555610656738,
      "learning_rate": 1.5125550886542997e-05,
      "loss": 0.4456,
      "step": 2383
    },
    {
      "epoch": 0.49,
      "grad_norm": 1.0720710754394531,
      "learning_rate": 1.5123501076150457e-05,
      "loss": 0.3238,
      "step": 2384
    },
    {
      "epoch": 0.49,
      "grad_norm": 1.4051311016082764,
      "learning_rate": 1.5121451265757919e-05,
      "loss": 0.5984,
      "step": 2385
    },
    {
      "epoch": 0.49,
      "grad_norm": 0.8839018940925598,
      "learning_rate": 1.5119401455365379e-05,
      "loss": 0.4743,
      "step": 2386
    },
    {
      "epoch": 0.49,
      "grad_norm": 1.856702446937561,
      "learning_rate": 1.5117351644972843e-05,
      "loss": 0.4544,
      "step": 2387
    },
    {
      "epoch": 0.49,
      "grad_norm": 0.6813578605651855,
      "learning_rate": 1.5115301834580303e-05,
      "loss": 0.4565,
      "step": 2388
    },
    {
      "epoch": 0.49,
      "grad_norm": 2.764709711074829,
      "learning_rate": 1.5113252024187763e-05,
      "loss": 0.4709,
      "step": 2389
    },
    {
      "epoch": 0.49,
      "grad_norm": 0.8023648858070374,
      "learning_rate": 1.5111202213795225e-05,
      "loss": 0.5404,
      "step": 2390
    },
    {
      "epoch": 0.49,
      "grad_norm": 1.9159001111984253,
      "learning_rate": 1.5109152403402687e-05,
      "loss": 0.5386,
      "step": 2391
    },
    {
      "epoch": 0.49,
      "grad_norm": 1.3246546983718872,
      "learning_rate": 1.5107102593010148e-05,
      "loss": 0.4526,
      "step": 2392
    },
    {
      "epoch": 0.49,
      "grad_norm": 0.5997852087020874,
      "learning_rate": 1.5105052782617609e-05,
      "loss": 0.4435,
      "step": 2393
    },
    {
      "epoch": 0.49,
      "grad_norm": 0.9919496774673462,
      "learning_rate": 1.5103002972225072e-05,
      "loss": 0.4792,
      "step": 2394
    },
    {
      "epoch": 0.49,
      "grad_norm": 0.7979291677474976,
      "learning_rate": 1.5100953161832532e-05,
      "loss": 0.6469,
      "step": 2395
    },
    {
      "epoch": 0.49,
      "grad_norm": 3.070895195007324,
      "learning_rate": 1.5098903351439992e-05,
      "loss": 0.3115,
      "step": 2396
    },
    {
      "epoch": 0.49,
      "grad_norm": 2.5366382598876953,
      "learning_rate": 1.5096853541047454e-05,
      "loss": 0.4544,
      "step": 2397
    },
    {
      "epoch": 0.49,
      "grad_norm": 1.2637184858322144,
      "learning_rate": 1.5094803730654916e-05,
      "loss": 0.5638,
      "step": 2398
    },
    {
      "epoch": 0.49,
      "grad_norm": 1.4586443901062012,
      "learning_rate": 1.5092753920262378e-05,
      "loss": 0.5732,
      "step": 2399
    },
    {
      "epoch": 0.49,
      "grad_norm": 1.8101028203964233,
      "learning_rate": 1.5090704109869838e-05,
      "loss": 0.661,
      "step": 2400
    },
    {
      "epoch": 0.49,
      "grad_norm": 1.216736912727356,
      "learning_rate": 1.5088654299477298e-05,
      "loss": 0.4468,
      "step": 2401
    },
    {
      "epoch": 0.49,
      "grad_norm": 0.8402936458587646,
      "learning_rate": 1.5086604489084762e-05,
      "loss": 0.449,
      "step": 2402
    },
    {
      "epoch": 0.49,
      "grad_norm": 1.3420780897140503,
      "learning_rate": 1.5084554678692222e-05,
      "loss": 0.5134,
      "step": 2403
    },
    {
      "epoch": 0.49,
      "grad_norm": 1.3588048219680786,
      "learning_rate": 1.5082504868299684e-05,
      "loss": 0.3934,
      "step": 2404
    },
    {
      "epoch": 0.49,
      "grad_norm": 0.9509856700897217,
      "learning_rate": 1.5080455057907144e-05,
      "loss": 0.4113,
      "step": 2405
    },
    {
      "epoch": 0.49,
      "grad_norm": 0.9155850410461426,
      "learning_rate": 1.5078405247514608e-05,
      "loss": 0.4973,
      "step": 2406
    },
    {
      "epoch": 0.49,
      "grad_norm": 1.935995101928711,
      "learning_rate": 1.5076355437122068e-05,
      "loss": 0.4264,
      "step": 2407
    },
    {
      "epoch": 0.49,
      "grad_norm": 1.0444469451904297,
      "learning_rate": 1.5074305626729528e-05,
      "loss": 0.4055,
      "step": 2408
    },
    {
      "epoch": 0.49,
      "grad_norm": 1.3498713970184326,
      "learning_rate": 1.507225581633699e-05,
      "loss": 0.5359,
      "step": 2409
    },
    {
      "epoch": 0.49,
      "grad_norm": 0.7206975221633911,
      "learning_rate": 1.5070206005944452e-05,
      "loss": 0.6338,
      "step": 2410
    },
    {
      "epoch": 0.49,
      "grad_norm": 1.0119752883911133,
      "learning_rate": 1.5068156195551914e-05,
      "loss": 0.5213,
      "step": 2411
    },
    {
      "epoch": 0.49,
      "grad_norm": 2.659756898880005,
      "learning_rate": 1.5066106385159374e-05,
      "loss": 0.4502,
      "step": 2412
    },
    {
      "epoch": 0.49,
      "grad_norm": 1.116519808769226,
      "learning_rate": 1.5064056574766834e-05,
      "loss": 0.386,
      "step": 2413
    },
    {
      "epoch": 0.49,
      "grad_norm": 1.2015717029571533,
      "learning_rate": 1.5062006764374297e-05,
      "loss": 0.4962,
      "step": 2414
    },
    {
      "epoch": 0.49,
      "grad_norm": 2.7390995025634766,
      "learning_rate": 1.5059956953981758e-05,
      "loss": 0.4669,
      "step": 2415
    },
    {
      "epoch": 0.49,
      "grad_norm": 1.0881203413009644,
      "learning_rate": 1.505790714358922e-05,
      "loss": 0.5431,
      "step": 2416
    },
    {
      "epoch": 0.5,
      "grad_norm": 1.298661231994629,
      "learning_rate": 1.505585733319668e-05,
      "loss": 0.3065,
      "step": 2417
    },
    {
      "epoch": 0.5,
      "grad_norm": 2.1760504245758057,
      "learning_rate": 1.5053807522804143e-05,
      "loss": 0.3905,
      "step": 2418
    },
    {
      "epoch": 0.5,
      "grad_norm": 1.335236668586731,
      "learning_rate": 1.5051757712411603e-05,
      "loss": 0.6938,
      "step": 2419
    },
    {
      "epoch": 0.5,
      "grad_norm": 1.0060889720916748,
      "learning_rate": 1.5049707902019063e-05,
      "loss": 0.4409,
      "step": 2420
    },
    {
      "epoch": 0.5,
      "grad_norm": 0.8939909934997559,
      "learning_rate": 1.5047658091626525e-05,
      "loss": 0.5535,
      "step": 2421
    },
    {
      "epoch": 0.5,
      "grad_norm": 1.0956745147705078,
      "learning_rate": 1.5045608281233987e-05,
      "loss": 0.4627,
      "step": 2422
    },
    {
      "epoch": 0.5,
      "grad_norm": 1.747492790222168,
      "learning_rate": 1.5043558470841449e-05,
      "loss": 0.6142,
      "step": 2423
    },
    {
      "epoch": 0.5,
      "grad_norm": 0.733977198600769,
      "learning_rate": 1.504150866044891e-05,
      "loss": 0.4411,
      "step": 2424
    },
    {
      "epoch": 0.5,
      "grad_norm": 0.7384598255157471,
      "learning_rate": 1.5039458850056373e-05,
      "loss": 0.3849,
      "step": 2425
    },
    {
      "epoch": 0.5,
      "grad_norm": 1.043513536453247,
      "learning_rate": 1.5037409039663833e-05,
      "loss": 0.4813,
      "step": 2426
    },
    {
      "epoch": 0.5,
      "grad_norm": 2.1391403675079346,
      "learning_rate": 1.5035359229271293e-05,
      "loss": 0.4872,
      "step": 2427
    },
    {
      "epoch": 0.5,
      "grad_norm": 0.7870432734489441,
      "learning_rate": 1.5033309418878755e-05,
      "loss": 0.4928,
      "step": 2428
    },
    {
      "epoch": 0.5,
      "grad_norm": 1.9322593212127686,
      "learning_rate": 1.5031259608486217e-05,
      "loss": 0.427,
      "step": 2429
    },
    {
      "epoch": 0.5,
      "grad_norm": 1.295182704925537,
      "learning_rate": 1.5029209798093679e-05,
      "loss": 0.5162,
      "step": 2430
    },
    {
      "epoch": 0.5,
      "grad_norm": 0.9069504737854004,
      "learning_rate": 1.5027159987701139e-05,
      "loss": 0.5286,
      "step": 2431
    },
    {
      "epoch": 0.5,
      "grad_norm": 0.8621139526367188,
      "learning_rate": 1.5025110177308599e-05,
      "loss": 0.4741,
      "step": 2432
    },
    {
      "epoch": 0.5,
      "grad_norm": 0.720133900642395,
      "learning_rate": 1.5023060366916063e-05,
      "loss": 0.4716,
      "step": 2433
    },
    {
      "epoch": 0.5,
      "grad_norm": 2.3552870750427246,
      "learning_rate": 1.5021010556523523e-05,
      "loss": 0.3652,
      "step": 2434
    },
    {
      "epoch": 0.5,
      "grad_norm": 0.5989448428153992,
      "learning_rate": 1.5018960746130985e-05,
      "loss": 0.4956,
      "step": 2435
    },
    {
      "epoch": 0.5,
      "grad_norm": 1.226605772972107,
      "learning_rate": 1.5016910935738445e-05,
      "loss": 0.6612,
      "step": 2436
    },
    {
      "epoch": 0.5,
      "grad_norm": 1.9620463848114014,
      "learning_rate": 1.5014861125345908e-05,
      "loss": 0.3157,
      "step": 2437
    },
    {
      "epoch": 0.5,
      "grad_norm": 1.0855536460876465,
      "learning_rate": 1.5012811314953368e-05,
      "loss": 0.5023,
      "step": 2438
    },
    {
      "epoch": 0.5,
      "grad_norm": 1.1347283124923706,
      "learning_rate": 1.5010761504560829e-05,
      "loss": 0.5359,
      "step": 2439
    },
    {
      "epoch": 0.5,
      "grad_norm": 0.9699468612670898,
      "learning_rate": 1.500871169416829e-05,
      "loss": 0.3248,
      "step": 2440
    },
    {
      "epoch": 0.5,
      "grad_norm": 1.0323002338409424,
      "learning_rate": 1.5006661883775752e-05,
      "loss": 0.6197,
      "step": 2441
    },
    {
      "epoch": 0.5,
      "grad_norm": 1.5966771841049194,
      "learning_rate": 1.5004612073383214e-05,
      "loss": 0.46,
      "step": 2442
    },
    {
      "epoch": 0.5,
      "grad_norm": 1.3481190204620361,
      "learning_rate": 1.5002562262990674e-05,
      "loss": 0.3262,
      "step": 2443
    },
    {
      "epoch": 0.5,
      "grad_norm": 0.7727866172790527,
      "learning_rate": 1.5000512452598134e-05,
      "loss": 0.4295,
      "step": 2444
    },
    {
      "epoch": 0.5,
      "grad_norm": 1.2877715826034546,
      "learning_rate": 1.4998462642205598e-05,
      "loss": 0.4495,
      "step": 2445
    },
    {
      "epoch": 0.5,
      "grad_norm": 1.9251997470855713,
      "learning_rate": 1.4996412831813058e-05,
      "loss": 0.3998,
      "step": 2446
    },
    {
      "epoch": 0.5,
      "grad_norm": 0.9297968149185181,
      "learning_rate": 1.499436302142052e-05,
      "loss": 0.4404,
      "step": 2447
    },
    {
      "epoch": 0.5,
      "grad_norm": 1.916147232055664,
      "learning_rate": 1.499231321102798e-05,
      "loss": 0.5267,
      "step": 2448
    },
    {
      "epoch": 0.5,
      "grad_norm": 2.249380111694336,
      "learning_rate": 1.4990263400635444e-05,
      "loss": 0.5107,
      "step": 2449
    },
    {
      "epoch": 0.5,
      "grad_norm": 2.5221970081329346,
      "learning_rate": 1.4988213590242904e-05,
      "loss": 0.3882,
      "step": 2450
    },
    {
      "epoch": 0.5,
      "grad_norm": 1.043688178062439,
      "learning_rate": 1.4986163779850364e-05,
      "loss": 0.5036,
      "step": 2451
    },
    {
      "epoch": 0.5,
      "grad_norm": 1.161388874053955,
      "learning_rate": 1.4984113969457828e-05,
      "loss": 0.4472,
      "step": 2452
    },
    {
      "epoch": 0.5,
      "grad_norm": 1.7633861303329468,
      "learning_rate": 1.4982064159065288e-05,
      "loss": 0.4615,
      "step": 2453
    },
    {
      "epoch": 0.5,
      "grad_norm": 1.314443588256836,
      "learning_rate": 1.498001434867275e-05,
      "loss": 0.3892,
      "step": 2454
    },
    {
      "epoch": 0.5,
      "grad_norm": 0.9945225119590759,
      "learning_rate": 1.497796453828021e-05,
      "loss": 0.4827,
      "step": 2455
    },
    {
      "epoch": 0.5,
      "grad_norm": 0.9185830354690552,
      "learning_rate": 1.4975914727887673e-05,
      "loss": 0.4754,
      "step": 2456
    },
    {
      "epoch": 0.5,
      "grad_norm": 2.1637697219848633,
      "learning_rate": 1.4973864917495134e-05,
      "loss": 0.3831,
      "step": 2457
    },
    {
      "epoch": 0.5,
      "grad_norm": 2.5715882778167725,
      "learning_rate": 1.4971815107102594e-05,
      "loss": 0.4769,
      "step": 2458
    },
    {
      "epoch": 0.5,
      "grad_norm": 1.3109863996505737,
      "learning_rate": 1.4969765296710056e-05,
      "loss": 0.4614,
      "step": 2459
    },
    {
      "epoch": 0.5,
      "grad_norm": 1.853422999382019,
      "learning_rate": 1.4967715486317517e-05,
      "loss": 0.4168,
      "step": 2460
    },
    {
      "epoch": 0.5,
      "grad_norm": 1.1322652101516724,
      "learning_rate": 1.496566567592498e-05,
      "loss": 0.4998,
      "step": 2461
    },
    {
      "epoch": 0.5,
      "grad_norm": 0.8091339468955994,
      "learning_rate": 1.496361586553244e-05,
      "loss": 0.5266,
      "step": 2462
    },
    {
      "epoch": 0.5,
      "grad_norm": 1.0747241973876953,
      "learning_rate": 1.49615660551399e-05,
      "loss": 0.4212,
      "step": 2463
    },
    {
      "epoch": 0.5,
      "grad_norm": 1.5130051374435425,
      "learning_rate": 1.4959516244747363e-05,
      "loss": 0.4377,
      "step": 2464
    },
    {
      "epoch": 0.51,
      "grad_norm": 1.1652566194534302,
      "learning_rate": 1.4957466434354823e-05,
      "loss": 0.5619,
      "step": 2465
    },
    {
      "epoch": 0.51,
      "grad_norm": 1.1804035902023315,
      "learning_rate": 1.4955416623962285e-05,
      "loss": 0.5848,
      "step": 2466
    },
    {
      "epoch": 0.51,
      "grad_norm": 0.9899980425834656,
      "learning_rate": 1.4953366813569745e-05,
      "loss": 0.6972,
      "step": 2467
    },
    {
      "epoch": 0.51,
      "grad_norm": 0.941084086894989,
      "learning_rate": 1.4951317003177209e-05,
      "loss": 0.508,
      "step": 2468
    },
    {
      "epoch": 0.51,
      "grad_norm": 0.784442126750946,
      "learning_rate": 1.4949267192784669e-05,
      "loss": 0.4762,
      "step": 2469
    },
    {
      "epoch": 0.51,
      "grad_norm": 1.1793373823165894,
      "learning_rate": 1.494721738239213e-05,
      "loss": 0.6056,
      "step": 2470
    },
    {
      "epoch": 0.51,
      "grad_norm": 1.3366048336029053,
      "learning_rate": 1.4945167571999591e-05,
      "loss": 0.5972,
      "step": 2471
    },
    {
      "epoch": 0.51,
      "grad_norm": 2.4779300689697266,
      "learning_rate": 1.4943117761607053e-05,
      "loss": 0.5501,
      "step": 2472
    },
    {
      "epoch": 0.51,
      "grad_norm": 0.898056149482727,
      "learning_rate": 1.4941067951214515e-05,
      "loss": 0.5034,
      "step": 2473
    },
    {
      "epoch": 0.51,
      "grad_norm": 1.0743845701217651,
      "learning_rate": 1.4939018140821975e-05,
      "loss": 0.5659,
      "step": 2474
    },
    {
      "epoch": 0.51,
      "grad_norm": 1.248730182647705,
      "learning_rate": 1.4936968330429435e-05,
      "loss": 0.4389,
      "step": 2475
    },
    {
      "epoch": 0.51,
      "grad_norm": 1.0568660497665405,
      "learning_rate": 1.4934918520036899e-05,
      "loss": 0.5179,
      "step": 2476
    },
    {
      "epoch": 0.51,
      "grad_norm": 0.8765088319778442,
      "learning_rate": 1.4932868709644359e-05,
      "loss": 0.3666,
      "step": 2477
    },
    {
      "epoch": 0.51,
      "grad_norm": 0.7114601135253906,
      "learning_rate": 1.493081889925182e-05,
      "loss": 0.4334,
      "step": 2478
    },
    {
      "epoch": 0.51,
      "grad_norm": 3.155115842819214,
      "learning_rate": 1.492876908885928e-05,
      "loss": 0.569,
      "step": 2479
    },
    {
      "epoch": 0.51,
      "grad_norm": 1.30255925655365,
      "learning_rate": 1.4926719278466744e-05,
      "loss": 0.3799,
      "step": 2480
    },
    {
      "epoch": 0.51,
      "grad_norm": 1.2902268171310425,
      "learning_rate": 1.4924669468074205e-05,
      "loss": 0.5051,
      "step": 2481
    },
    {
      "epoch": 0.51,
      "grad_norm": 0.9126717448234558,
      "learning_rate": 1.4922619657681665e-05,
      "loss": 0.4206,
      "step": 2482
    },
    {
      "epoch": 0.51,
      "grad_norm": 0.8093662858009338,
      "learning_rate": 1.4920569847289128e-05,
      "loss": 0.4118,
      "step": 2483
    },
    {
      "epoch": 0.51,
      "grad_norm": 0.6398886442184448,
      "learning_rate": 1.4918520036896588e-05,
      "loss": 0.4514,
      "step": 2484
    },
    {
      "epoch": 0.51,
      "grad_norm": 0.9541448354721069,
      "learning_rate": 1.491647022650405e-05,
      "loss": 0.5209,
      "step": 2485
    },
    {
      "epoch": 0.51,
      "grad_norm": 2.2530529499053955,
      "learning_rate": 1.491442041611151e-05,
      "loss": 0.4616,
      "step": 2486
    },
    {
      "epoch": 0.51,
      "grad_norm": 1.754709243774414,
      "learning_rate": 1.4912370605718974e-05,
      "loss": 0.477,
      "step": 2487
    },
    {
      "epoch": 0.51,
      "grad_norm": 0.661855161190033,
      "learning_rate": 1.4910320795326434e-05,
      "loss": 0.4705,
      "step": 2488
    },
    {
      "epoch": 0.51,
      "grad_norm": 1.875955581665039,
      "learning_rate": 1.4908270984933894e-05,
      "loss": 0.5543,
      "step": 2489
    },
    {
      "epoch": 0.51,
      "grad_norm": 1.437381625175476,
      "learning_rate": 1.4906221174541356e-05,
      "loss": 0.4437,
      "step": 2490
    },
    {
      "epoch": 0.51,
      "grad_norm": 1.26522958278656,
      "learning_rate": 1.4904171364148818e-05,
      "loss": 0.2962,
      "step": 2491
    },
    {
      "epoch": 0.51,
      "grad_norm": 0.7508142590522766,
      "learning_rate": 1.490212155375628e-05,
      "loss": 0.4268,
      "step": 2492
    },
    {
      "epoch": 0.51,
      "grad_norm": 2.205104351043701,
      "learning_rate": 1.490007174336374e-05,
      "loss": 0.5194,
      "step": 2493
    },
    {
      "epoch": 0.51,
      "grad_norm": 1.1913752555847168,
      "learning_rate": 1.48980219329712e-05,
      "loss": 0.5457,
      "step": 2494
    },
    {
      "epoch": 0.51,
      "grad_norm": 1.421531081199646,
      "learning_rate": 1.4895972122578664e-05,
      "loss": 0.5614,
      "step": 2495
    },
    {
      "epoch": 0.51,
      "grad_norm": 1.472683072090149,
      "learning_rate": 1.4893922312186124e-05,
      "loss": 0.4404,
      "step": 2496
    },
    {
      "epoch": 0.51,
      "grad_norm": 0.9302709698677063,
      "learning_rate": 1.4891872501793586e-05,
      "loss": 0.4282,
      "step": 2497
    },
    {
      "epoch": 0.51,
      "grad_norm": 1.1174073219299316,
      "learning_rate": 1.4889822691401046e-05,
      "loss": 0.4473,
      "step": 2498
    },
    {
      "epoch": 0.51,
      "grad_norm": 0.9395501017570496,
      "learning_rate": 1.488777288100851e-05,
      "loss": 0.4349,
      "step": 2499
    },
    {
      "epoch": 0.51,
      "grad_norm": 0.7621497511863708,
      "learning_rate": 1.488572307061597e-05,
      "loss": 0.4351,
      "step": 2500
    },
    {
      "epoch": 0.51,
      "grad_norm": 0.9156638979911804,
      "learning_rate": 1.488367326022343e-05,
      "loss": 0.4846,
      "step": 2501
    },
    {
      "epoch": 0.51,
      "grad_norm": 0.8702825307846069,
      "learning_rate": 1.4881623449830892e-05,
      "loss": 0.3814,
      "step": 2502
    },
    {
      "epoch": 0.51,
      "grad_norm": 0.7936203479766846,
      "learning_rate": 1.4879573639438354e-05,
      "loss": 0.5373,
      "step": 2503
    },
    {
      "epoch": 0.51,
      "grad_norm": 4.098694801330566,
      "learning_rate": 1.4877523829045815e-05,
      "loss": 0.3225,
      "step": 2504
    },
    {
      "epoch": 0.51,
      "grad_norm": 0.9134196043014526,
      "learning_rate": 1.4875474018653276e-05,
      "loss": 0.5446,
      "step": 2505
    },
    {
      "epoch": 0.51,
      "grad_norm": 1.224520206451416,
      "learning_rate": 1.4873424208260736e-05,
      "loss": 0.5125,
      "step": 2506
    },
    {
      "epoch": 0.51,
      "grad_norm": 1.6974068880081177,
      "learning_rate": 1.48713743978682e-05,
      "loss": 0.4044,
      "step": 2507
    },
    {
      "epoch": 0.51,
      "grad_norm": 1.2058436870574951,
      "learning_rate": 1.486932458747566e-05,
      "loss": 0.5283,
      "step": 2508
    },
    {
      "epoch": 0.51,
      "grad_norm": 1.2826015949249268,
      "learning_rate": 1.4867274777083121e-05,
      "loss": 0.4489,
      "step": 2509
    },
    {
      "epoch": 0.51,
      "grad_norm": 2.219752073287964,
      "learning_rate": 1.4865224966690581e-05,
      "loss": 0.3282,
      "step": 2510
    },
    {
      "epoch": 0.51,
      "grad_norm": 1.2515288591384888,
      "learning_rate": 1.4863175156298045e-05,
      "loss": 0.5138,
      "step": 2511
    },
    {
      "epoch": 0.51,
      "grad_norm": 1.0292291641235352,
      "learning_rate": 1.4861125345905505e-05,
      "loss": 0.5184,
      "step": 2512
    },
    {
      "epoch": 0.51,
      "grad_norm": 1.0776526927947998,
      "learning_rate": 1.4859075535512965e-05,
      "loss": 0.5204,
      "step": 2513
    },
    {
      "epoch": 0.52,
      "grad_norm": 1.152207374572754,
      "learning_rate": 1.4857025725120429e-05,
      "loss": 0.4142,
      "step": 2514
    },
    {
      "epoch": 0.52,
      "grad_norm": 0.6817649602890015,
      "learning_rate": 1.4854975914727889e-05,
      "loss": 0.3825,
      "step": 2515
    },
    {
      "epoch": 0.52,
      "grad_norm": 1.776623249053955,
      "learning_rate": 1.4852926104335351e-05,
      "loss": 0.4914,
      "step": 2516
    },
    {
      "epoch": 0.52,
      "grad_norm": 1.5394278764724731,
      "learning_rate": 1.4850876293942811e-05,
      "loss": 0.4561,
      "step": 2517
    },
    {
      "epoch": 0.52,
      "grad_norm": 1.0842527151107788,
      "learning_rate": 1.4848826483550275e-05,
      "loss": 0.4665,
      "step": 2518
    },
    {
      "epoch": 0.52,
      "grad_norm": 1.5068485736846924,
      "learning_rate": 1.4846776673157735e-05,
      "loss": 0.4186,
      "step": 2519
    },
    {
      "epoch": 0.52,
      "grad_norm": 0.7980037927627563,
      "learning_rate": 1.4844726862765195e-05,
      "loss": 0.5952,
      "step": 2520
    },
    {
      "epoch": 0.52,
      "grad_norm": 0.6229041814804077,
      "learning_rate": 1.4842677052372657e-05,
      "loss": 0.5248,
      "step": 2521
    },
    {
      "epoch": 0.52,
      "grad_norm": 1.0493460893630981,
      "learning_rate": 1.4840627241980119e-05,
      "loss": 0.5701,
      "step": 2522
    },
    {
      "epoch": 0.52,
      "grad_norm": 1.3366191387176514,
      "learning_rate": 1.483857743158758e-05,
      "loss": 0.44,
      "step": 2523
    },
    {
      "epoch": 0.52,
      "grad_norm": 1.006371021270752,
      "learning_rate": 1.483652762119504e-05,
      "loss": 0.4113,
      "step": 2524
    },
    {
      "epoch": 0.52,
      "grad_norm": 1.4596445560455322,
      "learning_rate": 1.48344778108025e-05,
      "loss": 0.5198,
      "step": 2525
    },
    {
      "epoch": 0.52,
      "grad_norm": 1.350449800491333,
      "learning_rate": 1.4832428000409964e-05,
      "loss": 0.5024,
      "step": 2526
    },
    {
      "epoch": 0.52,
      "grad_norm": 1.085831642150879,
      "learning_rate": 1.4830378190017425e-05,
      "loss": 0.4864,
      "step": 2527
    },
    {
      "epoch": 0.52,
      "grad_norm": 2.453561544418335,
      "learning_rate": 1.4828328379624886e-05,
      "loss": 0.4201,
      "step": 2528
    },
    {
      "epoch": 0.52,
      "grad_norm": 0.5886144042015076,
      "learning_rate": 1.4826278569232347e-05,
      "loss": 0.491,
      "step": 2529
    },
    {
      "epoch": 0.52,
      "grad_norm": 0.713424026966095,
      "learning_rate": 1.482422875883981e-05,
      "loss": 0.4243,
      "step": 2530
    },
    {
      "epoch": 0.52,
      "grad_norm": 2.875540256500244,
      "learning_rate": 1.482217894844727e-05,
      "loss": 0.4846,
      "step": 2531
    },
    {
      "epoch": 0.52,
      "grad_norm": 1.1136929988861084,
      "learning_rate": 1.482012913805473e-05,
      "loss": 0.564,
      "step": 2532
    },
    {
      "epoch": 0.52,
      "grad_norm": 1.5022157430648804,
      "learning_rate": 1.4818079327662192e-05,
      "loss": 0.5734,
      "step": 2533
    },
    {
      "epoch": 0.52,
      "grad_norm": 0.9852935671806335,
      "learning_rate": 1.4816029517269654e-05,
      "loss": 0.4456,
      "step": 2534
    },
    {
      "epoch": 0.52,
      "grad_norm": 0.9950397610664368,
      "learning_rate": 1.4813979706877116e-05,
      "loss": 0.3398,
      "step": 2535
    },
    {
      "epoch": 0.52,
      "grad_norm": 0.7397972345352173,
      "learning_rate": 1.4811929896484576e-05,
      "loss": 0.3927,
      "step": 2536
    },
    {
      "epoch": 0.52,
      "grad_norm": 0.7830454707145691,
      "learning_rate": 1.4809880086092036e-05,
      "loss": 0.4875,
      "step": 2537
    },
    {
      "epoch": 0.52,
      "grad_norm": 1.2338502407073975,
      "learning_rate": 1.48078302756995e-05,
      "loss": 0.3851,
      "step": 2538
    },
    {
      "epoch": 0.52,
      "grad_norm": 0.6699730157852173,
      "learning_rate": 1.480578046530696e-05,
      "loss": 0.4806,
      "step": 2539
    },
    {
      "epoch": 0.52,
      "grad_norm": 1.174372673034668,
      "learning_rate": 1.4803730654914422e-05,
      "loss": 0.5788,
      "step": 2540
    },
    {
      "epoch": 0.52,
      "grad_norm": 0.68864905834198,
      "learning_rate": 1.4801680844521884e-05,
      "loss": 0.6072,
      "step": 2541
    },
    {
      "epoch": 0.52,
      "grad_norm": 0.6448415517807007,
      "learning_rate": 1.4799631034129346e-05,
      "loss": 0.4633,
      "step": 2542
    },
    {
      "epoch": 0.52,
      "grad_norm": 1.1559107303619385,
      "learning_rate": 1.4797581223736806e-05,
      "loss": 0.5649,
      "step": 2543
    },
    {
      "epoch": 0.52,
      "grad_norm": 1.2819161415100098,
      "learning_rate": 1.4795531413344266e-05,
      "loss": 0.4575,
      "step": 2544
    },
    {
      "epoch": 0.52,
      "grad_norm": 1.8192192316055298,
      "learning_rate": 1.479348160295173e-05,
      "loss": 0.6091,
      "step": 2545
    },
    {
      "epoch": 0.52,
      "grad_norm": 2.8561153411865234,
      "learning_rate": 1.479143179255919e-05,
      "loss": 0.6068,
      "step": 2546
    },
    {
      "epoch": 0.52,
      "grad_norm": 0.9752907156944275,
      "learning_rate": 1.4789381982166651e-05,
      "loss": 0.3797,
      "step": 2547
    },
    {
      "epoch": 0.52,
      "grad_norm": 1.210914134979248,
      "learning_rate": 1.4787332171774112e-05,
      "loss": 0.5258,
      "step": 2548
    },
    {
      "epoch": 0.52,
      "grad_norm": 2.356468439102173,
      "learning_rate": 1.4785282361381574e-05,
      "loss": 0.3404,
      "step": 2549
    },
    {
      "epoch": 0.52,
      "grad_norm": 1.0244163274765015,
      "learning_rate": 1.4783232550989035e-05,
      "loss": 0.446,
      "step": 2550
    },
    {
      "epoch": 0.52,
      "grad_norm": 1.0716410875320435,
      "learning_rate": 1.4781182740596496e-05,
      "loss": 0.4937,
      "step": 2551
    },
    {
      "epoch": 0.52,
      "grad_norm": 0.8069106936454773,
      "learning_rate": 1.4779132930203957e-05,
      "loss": 0.3218,
      "step": 2552
    },
    {
      "epoch": 0.52,
      "grad_norm": 0.9309032559394836,
      "learning_rate": 1.477708311981142e-05,
      "loss": 0.3814,
      "step": 2553
    },
    {
      "epoch": 0.52,
      "grad_norm": 1.227420687675476,
      "learning_rate": 1.4775033309418881e-05,
      "loss": 0.4072,
      "step": 2554
    },
    {
      "epoch": 0.52,
      "grad_norm": 1.1866401433944702,
      "learning_rate": 1.4772983499026341e-05,
      "loss": 0.5028,
      "step": 2555
    },
    {
      "epoch": 0.52,
      "grad_norm": 0.9743258357048035,
      "learning_rate": 1.4770933688633801e-05,
      "loss": 0.5039,
      "step": 2556
    },
    {
      "epoch": 0.52,
      "grad_norm": 1.0258054733276367,
      "learning_rate": 1.4768883878241265e-05,
      "loss": 0.5033,
      "step": 2557
    },
    {
      "epoch": 0.52,
      "grad_norm": 0.9561159014701843,
      "learning_rate": 1.4766834067848725e-05,
      "loss": 0.4285,
      "step": 2558
    },
    {
      "epoch": 0.52,
      "grad_norm": 0.8969693779945374,
      "learning_rate": 1.4764784257456187e-05,
      "loss": 0.4114,
      "step": 2559
    },
    {
      "epoch": 0.52,
      "grad_norm": 1.3110603094100952,
      "learning_rate": 1.4762734447063647e-05,
      "loss": 0.5282,
      "step": 2560
    },
    {
      "epoch": 0.52,
      "grad_norm": 0.8138812780380249,
      "learning_rate": 1.4760684636671109e-05,
      "loss": 0.461,
      "step": 2561
    },
    {
      "epoch": 0.52,
      "grad_norm": 1.3072035312652588,
      "learning_rate": 1.4758634826278571e-05,
      "loss": 0.5667,
      "step": 2562
    },
    {
      "epoch": 0.53,
      "grad_norm": 1.0127509832382202,
      "learning_rate": 1.4756585015886031e-05,
      "loss": 0.5536,
      "step": 2563
    },
    {
      "epoch": 0.53,
      "grad_norm": 1.1442224979400635,
      "learning_rate": 1.4754535205493493e-05,
      "loss": 0.3874,
      "step": 2564
    },
    {
      "epoch": 0.53,
      "grad_norm": 1.1280155181884766,
      "learning_rate": 1.4752485395100955e-05,
      "loss": 0.6194,
      "step": 2565
    },
    {
      "epoch": 0.53,
      "grad_norm": 0.8824883103370667,
      "learning_rate": 1.4750435584708415e-05,
      "loss": 0.5049,
      "step": 2566
    },
    {
      "epoch": 0.53,
      "grad_norm": 1.2340352535247803,
      "learning_rate": 1.4748385774315877e-05,
      "loss": 0.3495,
      "step": 2567
    },
    {
      "epoch": 0.53,
      "grad_norm": 0.7018783688545227,
      "learning_rate": 1.4746335963923337e-05,
      "loss": 0.6156,
      "step": 2568
    },
    {
      "epoch": 0.53,
      "grad_norm": 1.098876953125,
      "learning_rate": 1.47442861535308e-05,
      "loss": 0.3364,
      "step": 2569
    },
    {
      "epoch": 0.53,
      "grad_norm": 0.9401988387107849,
      "learning_rate": 1.474223634313826e-05,
      "loss": 0.3702,
      "step": 2570
    },
    {
      "epoch": 0.53,
      "grad_norm": 1.0651267766952515,
      "learning_rate": 1.474018653274572e-05,
      "loss": 0.3111,
      "step": 2571
    },
    {
      "epoch": 0.53,
      "grad_norm": 0.9732580184936523,
      "learning_rate": 1.4738136722353184e-05,
      "loss": 0.431,
      "step": 2572
    },
    {
      "epoch": 0.53,
      "grad_norm": 0.6586969494819641,
      "learning_rate": 1.4736086911960645e-05,
      "loss": 0.4781,
      "step": 2573
    },
    {
      "epoch": 0.53,
      "grad_norm": 0.7839106321334839,
      "learning_rate": 1.4734037101568106e-05,
      "loss": 0.4319,
      "step": 2574
    },
    {
      "epoch": 0.53,
      "grad_norm": 1.1969528198242188,
      "learning_rate": 1.4731987291175567e-05,
      "loss": 0.4392,
      "step": 2575
    },
    {
      "epoch": 0.53,
      "grad_norm": 0.7168787717819214,
      "learning_rate": 1.472993748078303e-05,
      "loss": 0.3872,
      "step": 2576
    },
    {
      "epoch": 0.53,
      "grad_norm": 3.2487335205078125,
      "learning_rate": 1.472788767039049e-05,
      "loss": 0.4995,
      "step": 2577
    },
    {
      "epoch": 0.53,
      "grad_norm": 0.8237999081611633,
      "learning_rate": 1.472583785999795e-05,
      "loss": 0.4678,
      "step": 2578
    },
    {
      "epoch": 0.53,
      "grad_norm": 0.7617215514183044,
      "learning_rate": 1.4723788049605412e-05,
      "loss": 0.4391,
      "step": 2579
    },
    {
      "epoch": 0.53,
      "grad_norm": 1.4787452220916748,
      "learning_rate": 1.4721738239212874e-05,
      "loss": 0.568,
      "step": 2580
    },
    {
      "epoch": 0.53,
      "grad_norm": 1.2312452793121338,
      "learning_rate": 1.4719688428820336e-05,
      "loss": 0.5487,
      "step": 2581
    },
    {
      "epoch": 0.53,
      "grad_norm": 0.8986818790435791,
      "learning_rate": 1.4717638618427796e-05,
      "loss": 0.3892,
      "step": 2582
    },
    {
      "epoch": 0.53,
      "grad_norm": 2.5877132415771484,
      "learning_rate": 1.4715588808035256e-05,
      "loss": 0.5112,
      "step": 2583
    },
    {
      "epoch": 0.53,
      "grad_norm": 0.8626839518547058,
      "learning_rate": 1.471353899764272e-05,
      "loss": 0.7368,
      "step": 2584
    },
    {
      "epoch": 0.53,
      "grad_norm": 1.277398943901062,
      "learning_rate": 1.471148918725018e-05,
      "loss": 0.5312,
      "step": 2585
    },
    {
      "epoch": 0.53,
      "grad_norm": 0.9022834897041321,
      "learning_rate": 1.4709439376857642e-05,
      "loss": 0.5316,
      "step": 2586
    },
    {
      "epoch": 0.53,
      "grad_norm": 1.3675169944763184,
      "learning_rate": 1.4707389566465102e-05,
      "loss": 0.43,
      "step": 2587
    },
    {
      "epoch": 0.53,
      "grad_norm": 1.5008292198181152,
      "learning_rate": 1.4705339756072566e-05,
      "loss": 0.4507,
      "step": 2588
    },
    {
      "epoch": 0.53,
      "grad_norm": 1.4558621644973755,
      "learning_rate": 1.4703289945680026e-05,
      "loss": 0.5261,
      "step": 2589
    },
    {
      "epoch": 0.53,
      "grad_norm": 1.661344289779663,
      "learning_rate": 1.4701240135287486e-05,
      "loss": 0.3435,
      "step": 2590
    },
    {
      "epoch": 0.53,
      "grad_norm": 2.029067039489746,
      "learning_rate": 1.4699190324894948e-05,
      "loss": 0.5236,
      "step": 2591
    },
    {
      "epoch": 0.53,
      "grad_norm": 1.1075388193130493,
      "learning_rate": 1.469714051450241e-05,
      "loss": 0.5522,
      "step": 2592
    },
    {
      "epoch": 0.53,
      "grad_norm": 1.98308265209198,
      "learning_rate": 1.4695090704109871e-05,
      "loss": 0.4381,
      "step": 2593
    },
    {
      "epoch": 0.53,
      "grad_norm": 1.1076191663742065,
      "learning_rate": 1.4693040893717332e-05,
      "loss": 0.3599,
      "step": 2594
    },
    {
      "epoch": 0.53,
      "grad_norm": 0.9306461811065674,
      "learning_rate": 1.4690991083324792e-05,
      "loss": 0.2578,
      "step": 2595
    },
    {
      "epoch": 0.53,
      "grad_norm": 0.9572471976280212,
      "learning_rate": 1.4688941272932255e-05,
      "loss": 0.5071,
      "step": 2596
    },
    {
      "epoch": 0.53,
      "grad_norm": 2.2622323036193848,
      "learning_rate": 1.4686891462539716e-05,
      "loss": 0.3732,
      "step": 2597
    },
    {
      "epoch": 0.53,
      "grad_norm": 1.319424033164978,
      "learning_rate": 1.4684841652147177e-05,
      "loss": 0.3661,
      "step": 2598
    },
    {
      "epoch": 0.53,
      "grad_norm": 1.2511954307556152,
      "learning_rate": 1.4682791841754638e-05,
      "loss": 0.5558,
      "step": 2599
    },
    {
      "epoch": 0.53,
      "grad_norm": 1.1674320697784424,
      "learning_rate": 1.4680742031362101e-05,
      "loss": 0.4076,
      "step": 2600
    },
    {
      "epoch": 0.53,
      "grad_norm": 0.8237162828445435,
      "learning_rate": 1.4678692220969561e-05,
      "loss": 0.502,
      "step": 2601
    },
    {
      "epoch": 0.53,
      "grad_norm": 0.9535679221153259,
      "learning_rate": 1.4676642410577021e-05,
      "loss": 0.3703,
      "step": 2602
    },
    {
      "epoch": 0.53,
      "grad_norm": 0.6521360874176025,
      "learning_rate": 1.4674592600184485e-05,
      "loss": 0.4706,
      "step": 2603
    },
    {
      "epoch": 0.53,
      "grad_norm": 1.2778578996658325,
      "learning_rate": 1.4672542789791945e-05,
      "loss": 0.3921,
      "step": 2604
    },
    {
      "epoch": 0.53,
      "grad_norm": 1.1366243362426758,
      "learning_rate": 1.4670492979399407e-05,
      "loss": 0.4334,
      "step": 2605
    },
    {
      "epoch": 0.53,
      "grad_norm": 0.9368764162063599,
      "learning_rate": 1.4668443169006867e-05,
      "loss": 0.5205,
      "step": 2606
    },
    {
      "epoch": 0.53,
      "grad_norm": 1.5131428241729736,
      "learning_rate": 1.466639335861433e-05,
      "loss": 0.359,
      "step": 2607
    },
    {
      "epoch": 0.53,
      "grad_norm": 1.6261017322540283,
      "learning_rate": 1.4664343548221791e-05,
      "loss": 0.4448,
      "step": 2608
    },
    {
      "epoch": 0.53,
      "grad_norm": 1.1053537130355835,
      "learning_rate": 1.4662293737829251e-05,
      "loss": 0.4569,
      "step": 2609
    },
    {
      "epoch": 0.53,
      "grad_norm": 0.9986915588378906,
      "learning_rate": 1.4660243927436713e-05,
      "loss": 0.5315,
      "step": 2610
    },
    {
      "epoch": 0.53,
      "grad_norm": 1.1228548288345337,
      "learning_rate": 1.4658194117044175e-05,
      "loss": 0.4446,
      "step": 2611
    },
    {
      "epoch": 0.54,
      "grad_norm": 0.8136095404624939,
      "learning_rate": 1.4656144306651637e-05,
      "loss": 0.5138,
      "step": 2612
    },
    {
      "epoch": 0.54,
      "grad_norm": 1.0570372343063354,
      "learning_rate": 1.4654094496259097e-05,
      "loss": 0.3675,
      "step": 2613
    },
    {
      "epoch": 0.54,
      "grad_norm": 0.7504953742027283,
      "learning_rate": 1.4652044685866557e-05,
      "loss": 0.3976,
      "step": 2614
    },
    {
      "epoch": 0.54,
      "grad_norm": 1.5366427898406982,
      "learning_rate": 1.464999487547402e-05,
      "loss": 0.5498,
      "step": 2615
    },
    {
      "epoch": 0.54,
      "grad_norm": 1.2454266548156738,
      "learning_rate": 1.464794506508148e-05,
      "loss": 0.4364,
      "step": 2616
    },
    {
      "epoch": 0.54,
      "grad_norm": 0.9491122364997864,
      "learning_rate": 1.4645895254688942e-05,
      "loss": 0.5502,
      "step": 2617
    },
    {
      "epoch": 0.54,
      "grad_norm": 2.4299349784851074,
      "learning_rate": 1.4643845444296403e-05,
      "loss": 0.3979,
      "step": 2618
    },
    {
      "epoch": 0.54,
      "grad_norm": 1.5206317901611328,
      "learning_rate": 1.4641795633903866e-05,
      "loss": 0.4095,
      "step": 2619
    },
    {
      "epoch": 0.54,
      "grad_norm": 3.229351043701172,
      "learning_rate": 1.4639745823511326e-05,
      "loss": 0.4758,
      "step": 2620
    },
    {
      "epoch": 0.54,
      "grad_norm": 1.878461480140686,
      "learning_rate": 1.4637696013118787e-05,
      "loss": 0.3481,
      "step": 2621
    },
    {
      "epoch": 0.54,
      "grad_norm": 1.8844680786132812,
      "learning_rate": 1.4635646202726248e-05,
      "loss": 0.3241,
      "step": 2622
    },
    {
      "epoch": 0.54,
      "grad_norm": 0.8274142742156982,
      "learning_rate": 1.463359639233371e-05,
      "loss": 0.3746,
      "step": 2623
    },
    {
      "epoch": 0.54,
      "grad_norm": 0.7694247961044312,
      "learning_rate": 1.4631546581941172e-05,
      "loss": 0.3858,
      "step": 2624
    },
    {
      "epoch": 0.54,
      "grad_norm": 0.826077401638031,
      "learning_rate": 1.4629496771548632e-05,
      "loss": 0.5661,
      "step": 2625
    },
    {
      "epoch": 0.54,
      "grad_norm": 1.8142032623291016,
      "learning_rate": 1.4627446961156092e-05,
      "loss": 0.4637,
      "step": 2626
    },
    {
      "epoch": 0.54,
      "grad_norm": 1.7399365901947021,
      "learning_rate": 1.4625397150763556e-05,
      "loss": 0.3929,
      "step": 2627
    },
    {
      "epoch": 0.54,
      "grad_norm": 1.0823681354522705,
      "learning_rate": 1.4623347340371016e-05,
      "loss": 0.535,
      "step": 2628
    },
    {
      "epoch": 0.54,
      "grad_norm": 1.363808035850525,
      "learning_rate": 1.4621297529978478e-05,
      "loss": 0.4694,
      "step": 2629
    },
    {
      "epoch": 0.54,
      "grad_norm": 0.7596849203109741,
      "learning_rate": 1.461924771958594e-05,
      "loss": 0.4283,
      "step": 2630
    },
    {
      "epoch": 0.54,
      "grad_norm": 0.9585691094398499,
      "learning_rate": 1.4617197909193402e-05,
      "loss": 0.4255,
      "step": 2631
    },
    {
      "epoch": 0.54,
      "grad_norm": 0.9111747741699219,
      "learning_rate": 1.4615148098800862e-05,
      "loss": 0.4986,
      "step": 2632
    },
    {
      "epoch": 0.54,
      "grad_norm": 0.9276443123817444,
      "learning_rate": 1.4613098288408322e-05,
      "loss": 0.361,
      "step": 2633
    },
    {
      "epoch": 0.54,
      "grad_norm": 0.9770301580429077,
      "learning_rate": 1.4611048478015786e-05,
      "loss": 0.4473,
      "step": 2634
    },
    {
      "epoch": 0.54,
      "grad_norm": 1.4143118858337402,
      "learning_rate": 1.4608998667623246e-05,
      "loss": 0.3978,
      "step": 2635
    },
    {
      "epoch": 0.54,
      "grad_norm": 1.061945915222168,
      "learning_rate": 1.4606948857230708e-05,
      "loss": 0.3845,
      "step": 2636
    },
    {
      "epoch": 0.54,
      "grad_norm": 0.9329358339309692,
      "learning_rate": 1.4604899046838168e-05,
      "loss": 0.4603,
      "step": 2637
    },
    {
      "epoch": 0.54,
      "grad_norm": 0.9059256315231323,
      "learning_rate": 1.4602849236445631e-05,
      "loss": 0.4775,
      "step": 2638
    },
    {
      "epoch": 0.54,
      "grad_norm": 1.0367029905319214,
      "learning_rate": 1.4600799426053091e-05,
      "loss": 0.5725,
      "step": 2639
    },
    {
      "epoch": 0.54,
      "grad_norm": 1.2720274925231934,
      "learning_rate": 1.4598749615660552e-05,
      "loss": 0.4493,
      "step": 2640
    },
    {
      "epoch": 0.54,
      "grad_norm": 0.912116289138794,
      "learning_rate": 1.4596699805268013e-05,
      "loss": 0.539,
      "step": 2641
    },
    {
      "epoch": 0.54,
      "grad_norm": 1.5893335342407227,
      "learning_rate": 1.4594649994875475e-05,
      "loss": 0.5004,
      "step": 2642
    },
    {
      "epoch": 0.54,
      "grad_norm": 0.7370589971542358,
      "learning_rate": 1.4592600184482937e-05,
      "loss": 0.475,
      "step": 2643
    },
    {
      "epoch": 0.54,
      "grad_norm": 0.8655999302864075,
      "learning_rate": 1.4590550374090397e-05,
      "loss": 0.535,
      "step": 2644
    },
    {
      "epoch": 0.54,
      "grad_norm": 1.1425237655639648,
      "learning_rate": 1.4588500563697858e-05,
      "loss": 0.4029,
      "step": 2645
    },
    {
      "epoch": 0.54,
      "grad_norm": 1.3524327278137207,
      "learning_rate": 1.4586450753305321e-05,
      "loss": 0.4894,
      "step": 2646
    },
    {
      "epoch": 0.54,
      "grad_norm": 1.1826902627944946,
      "learning_rate": 1.4584400942912781e-05,
      "loss": 0.4502,
      "step": 2647
    },
    {
      "epoch": 0.54,
      "grad_norm": 1.0160224437713623,
      "learning_rate": 1.4582351132520243e-05,
      "loss": 0.3974,
      "step": 2648
    },
    {
      "epoch": 0.54,
      "grad_norm": 2.6137845516204834,
      "learning_rate": 1.4580301322127703e-05,
      "loss": 0.4584,
      "step": 2649
    },
    {
      "epoch": 0.54,
      "grad_norm": 0.9498724937438965,
      "learning_rate": 1.4578251511735167e-05,
      "loss": 0.4403,
      "step": 2650
    },
    {
      "epoch": 0.54,
      "grad_norm": 0.7630237936973572,
      "learning_rate": 1.4576201701342627e-05,
      "loss": 0.4023,
      "step": 2651
    },
    {
      "epoch": 0.54,
      "grad_norm": 0.6424211263656616,
      "learning_rate": 1.4574151890950087e-05,
      "loss": 0.4446,
      "step": 2652
    },
    {
      "epoch": 0.54,
      "grad_norm": 0.7990327477455139,
      "learning_rate": 1.4572102080557549e-05,
      "loss": 0.3252,
      "step": 2653
    },
    {
      "epoch": 0.54,
      "grad_norm": 1.2291746139526367,
      "learning_rate": 1.457005227016501e-05,
      "loss": 0.5295,
      "step": 2654
    },
    {
      "epoch": 0.54,
      "grad_norm": 1.106310248374939,
      "learning_rate": 1.4568002459772473e-05,
      "loss": 0.5673,
      "step": 2655
    },
    {
      "epoch": 0.54,
      "grad_norm": 0.9786501526832581,
      "learning_rate": 1.4565952649379933e-05,
      "loss": 0.4924,
      "step": 2656
    },
    {
      "epoch": 0.54,
      "grad_norm": 1.0968096256256104,
      "learning_rate": 1.4563902838987393e-05,
      "loss": 0.5174,
      "step": 2657
    },
    {
      "epoch": 0.54,
      "grad_norm": 1.7044085264205933,
      "learning_rate": 1.4561853028594857e-05,
      "loss": 0.4009,
      "step": 2658
    },
    {
      "epoch": 0.54,
      "grad_norm": 0.8387946486473083,
      "learning_rate": 1.4559803218202317e-05,
      "loss": 0.5509,
      "step": 2659
    },
    {
      "epoch": 0.54,
      "grad_norm": 1.35149347782135,
      "learning_rate": 1.4557753407809779e-05,
      "loss": 0.3838,
      "step": 2660
    },
    {
      "epoch": 0.55,
      "grad_norm": 1.5506470203399658,
      "learning_rate": 1.455570359741724e-05,
      "loss": 0.4282,
      "step": 2661
    },
    {
      "epoch": 0.55,
      "grad_norm": 0.9275880455970764,
      "learning_rate": 1.4553653787024702e-05,
      "loss": 0.4738,
      "step": 2662
    },
    {
      "epoch": 0.55,
      "grad_norm": 0.8036693334579468,
      "learning_rate": 1.4551603976632162e-05,
      "loss": 0.5683,
      "step": 2663
    },
    {
      "epoch": 0.55,
      "grad_norm": 1.1284818649291992,
      "learning_rate": 1.4549554166239623e-05,
      "loss": 0.3467,
      "step": 2664
    },
    {
      "epoch": 0.55,
      "grad_norm": 1.657334327697754,
      "learning_rate": 1.4547504355847086e-05,
      "loss": 0.3797,
      "step": 2665
    },
    {
      "epoch": 0.55,
      "grad_norm": 1.1547119617462158,
      "learning_rate": 1.4545454545454546e-05,
      "loss": 0.5402,
      "step": 2666
    },
    {
      "epoch": 0.55,
      "grad_norm": 0.8918876647949219,
      "learning_rate": 1.4543404735062008e-05,
      "loss": 0.5512,
      "step": 2667
    },
    {
      "epoch": 0.55,
      "grad_norm": 0.7175599336624146,
      "learning_rate": 1.4541354924669468e-05,
      "loss": 0.4027,
      "step": 2668
    },
    {
      "epoch": 0.55,
      "grad_norm": 1.1328051090240479,
      "learning_rate": 1.4539305114276932e-05,
      "loss": 0.3102,
      "step": 2669
    },
    {
      "epoch": 0.55,
      "grad_norm": 0.733843982219696,
      "learning_rate": 1.4537255303884392e-05,
      "loss": 0.424,
      "step": 2670
    },
    {
      "epoch": 0.55,
      "grad_norm": 1.2038402557373047,
      "learning_rate": 1.4535205493491852e-05,
      "loss": 0.576,
      "step": 2671
    },
    {
      "epoch": 0.55,
      "grad_norm": 1.2706141471862793,
      "learning_rate": 1.4533155683099314e-05,
      "loss": 0.5729,
      "step": 2672
    },
    {
      "epoch": 0.55,
      "grad_norm": 1.0778015851974487,
      "learning_rate": 1.4531105872706776e-05,
      "loss": 0.5742,
      "step": 2673
    },
    {
      "epoch": 0.55,
      "grad_norm": 0.6602329015731812,
      "learning_rate": 1.4529056062314238e-05,
      "loss": 0.4657,
      "step": 2674
    },
    {
      "epoch": 0.55,
      "grad_norm": 2.012230157852173,
      "learning_rate": 1.4527006251921698e-05,
      "loss": 0.5189,
      "step": 2675
    },
    {
      "epoch": 0.55,
      "grad_norm": 0.8563241958618164,
      "learning_rate": 1.4524956441529158e-05,
      "loss": 0.6101,
      "step": 2676
    },
    {
      "epoch": 0.55,
      "grad_norm": 2.233721971511841,
      "learning_rate": 1.4522906631136622e-05,
      "loss": 0.3532,
      "step": 2677
    },
    {
      "epoch": 0.55,
      "grad_norm": 1.088723063468933,
      "learning_rate": 1.4520856820744082e-05,
      "loss": 0.5279,
      "step": 2678
    },
    {
      "epoch": 0.55,
      "grad_norm": 0.9387180209159851,
      "learning_rate": 1.4518807010351544e-05,
      "loss": 0.5774,
      "step": 2679
    },
    {
      "epoch": 0.55,
      "grad_norm": 2.8418893814086914,
      "learning_rate": 1.4516757199959004e-05,
      "loss": 0.3836,
      "step": 2680
    },
    {
      "epoch": 0.55,
      "grad_norm": 1.0538411140441895,
      "learning_rate": 1.4514707389566467e-05,
      "loss": 0.5323,
      "step": 2681
    },
    {
      "epoch": 0.55,
      "grad_norm": 0.9105294346809387,
      "learning_rate": 1.4512657579173928e-05,
      "loss": 0.4164,
      "step": 2682
    },
    {
      "epoch": 0.55,
      "grad_norm": 0.8520392775535583,
      "learning_rate": 1.4510607768781388e-05,
      "loss": 0.3108,
      "step": 2683
    },
    {
      "epoch": 0.55,
      "grad_norm": 1.9777977466583252,
      "learning_rate": 1.450855795838885e-05,
      "loss": 0.4632,
      "step": 2684
    },
    {
      "epoch": 0.55,
      "grad_norm": 1.117640733718872,
      "learning_rate": 1.4506508147996311e-05,
      "loss": 0.4549,
      "step": 2685
    },
    {
      "epoch": 0.55,
      "grad_norm": 0.8474204540252686,
      "learning_rate": 1.4504458337603773e-05,
      "loss": 0.6113,
      "step": 2686
    },
    {
      "epoch": 0.55,
      "grad_norm": 2.153616428375244,
      "learning_rate": 1.4502408527211233e-05,
      "loss": 0.4009,
      "step": 2687
    },
    {
      "epoch": 0.55,
      "grad_norm": 2.309783458709717,
      "learning_rate": 1.4500358716818697e-05,
      "loss": 0.5155,
      "step": 2688
    },
    {
      "epoch": 0.55,
      "grad_norm": 1.9491780996322632,
      "learning_rate": 1.4498308906426157e-05,
      "loss": 0.4947,
      "step": 2689
    },
    {
      "epoch": 0.55,
      "grad_norm": 0.8492417931556702,
      "learning_rate": 1.4496259096033617e-05,
      "loss": 0.4615,
      "step": 2690
    },
    {
      "epoch": 0.55,
      "grad_norm": 0.880757749080658,
      "learning_rate": 1.449420928564108e-05,
      "loss": 0.3951,
      "step": 2691
    },
    {
      "epoch": 0.55,
      "grad_norm": 0.9590258598327637,
      "learning_rate": 1.4492159475248541e-05,
      "loss": 0.4604,
      "step": 2692
    },
    {
      "epoch": 0.55,
      "grad_norm": 0.6785157918930054,
      "learning_rate": 1.4490109664856003e-05,
      "loss": 0.347,
      "step": 2693
    },
    {
      "epoch": 0.55,
      "grad_norm": 0.8877938985824585,
      "learning_rate": 1.4488059854463463e-05,
      "loss": 0.482,
      "step": 2694
    },
    {
      "epoch": 0.55,
      "grad_norm": 0.7485752105712891,
      "learning_rate": 1.4486010044070923e-05,
      "loss": 0.427,
      "step": 2695
    },
    {
      "epoch": 0.55,
      "grad_norm": 1.080544352531433,
      "learning_rate": 1.4483960233678387e-05,
      "loss": 0.3108,
      "step": 2696
    },
    {
      "epoch": 0.55,
      "grad_norm": 0.929394543170929,
      "learning_rate": 1.4481910423285847e-05,
      "loss": 0.4484,
      "step": 2697
    },
    {
      "epoch": 0.55,
      "grad_norm": 1.0700149536132812,
      "learning_rate": 1.4479860612893309e-05,
      "loss": 0.3066,
      "step": 2698
    },
    {
      "epoch": 0.55,
      "grad_norm": 0.972938597202301,
      "learning_rate": 1.4477810802500769e-05,
      "loss": 0.4996,
      "step": 2699
    },
    {
      "epoch": 0.55,
      "grad_norm": 1.3605865240097046,
      "learning_rate": 1.4475760992108233e-05,
      "loss": 0.3687,
      "step": 2700
    },
    {
      "epoch": 0.55,
      "grad_norm": 1.5353379249572754,
      "learning_rate": 1.4473711181715693e-05,
      "loss": 0.3123,
      "step": 2701
    },
    {
      "epoch": 0.55,
      "grad_norm": 0.6541821360588074,
      "learning_rate": 1.4471661371323153e-05,
      "loss": 0.4459,
      "step": 2702
    },
    {
      "epoch": 0.55,
      "grad_norm": 1.5861213207244873,
      "learning_rate": 1.4469611560930615e-05,
      "loss": 0.3449,
      "step": 2703
    },
    {
      "epoch": 0.55,
      "grad_norm": 1.2657749652862549,
      "learning_rate": 1.4467561750538077e-05,
      "loss": 0.4374,
      "step": 2704
    },
    {
      "epoch": 0.55,
      "grad_norm": 0.7513740062713623,
      "learning_rate": 1.4465511940145538e-05,
      "loss": 0.286,
      "step": 2705
    },
    {
      "epoch": 0.55,
      "grad_norm": 2.10371732711792,
      "learning_rate": 1.4463462129752999e-05,
      "loss": 0.4696,
      "step": 2706
    },
    {
      "epoch": 0.55,
      "grad_norm": 1.0421907901763916,
      "learning_rate": 1.4461412319360459e-05,
      "loss": 0.5884,
      "step": 2707
    },
    {
      "epoch": 0.55,
      "grad_norm": 1.148634433746338,
      "learning_rate": 1.4459362508967922e-05,
      "loss": 0.5263,
      "step": 2708
    },
    {
      "epoch": 0.56,
      "grad_norm": 2.011594533920288,
      "learning_rate": 1.4457312698575382e-05,
      "loss": 0.4841,
      "step": 2709
    },
    {
      "epoch": 0.56,
      "grad_norm": 1.0466498136520386,
      "learning_rate": 1.4455262888182844e-05,
      "loss": 0.434,
      "step": 2710
    },
    {
      "epoch": 0.56,
      "grad_norm": 1.2639541625976562,
      "learning_rate": 1.4453213077790304e-05,
      "loss": 0.3979,
      "step": 2711
    },
    {
      "epoch": 0.56,
      "grad_norm": 1.0420538187026978,
      "learning_rate": 1.4451163267397768e-05,
      "loss": 0.5383,
      "step": 2712
    },
    {
      "epoch": 0.56,
      "grad_norm": 1.0336459875106812,
      "learning_rate": 1.4449113457005228e-05,
      "loss": 0.2379,
      "step": 2713
    },
    {
      "epoch": 0.56,
      "grad_norm": 1.1142250299453735,
      "learning_rate": 1.4447063646612688e-05,
      "loss": 0.5761,
      "step": 2714
    },
    {
      "epoch": 0.56,
      "grad_norm": 1.433213472366333,
      "learning_rate": 1.444501383622015e-05,
      "loss": 0.4595,
      "step": 2715
    },
    {
      "epoch": 0.56,
      "grad_norm": 0.8627854585647583,
      "learning_rate": 1.4442964025827612e-05,
      "loss": 0.6075,
      "step": 2716
    },
    {
      "epoch": 0.56,
      "grad_norm": 1.9782795906066895,
      "learning_rate": 1.4440914215435074e-05,
      "loss": 0.2985,
      "step": 2717
    },
    {
      "epoch": 0.56,
      "grad_norm": 1.3034034967422485,
      "learning_rate": 1.4438864405042534e-05,
      "loss": 0.5065,
      "step": 2718
    },
    {
      "epoch": 0.56,
      "grad_norm": 0.9978224635124207,
      "learning_rate": 1.4436814594649998e-05,
      "loss": 0.5389,
      "step": 2719
    },
    {
      "epoch": 0.56,
      "grad_norm": 0.96844482421875,
      "learning_rate": 1.4434764784257458e-05,
      "loss": 0.3307,
      "step": 2720
    },
    {
      "epoch": 0.56,
      "grad_norm": 1.3274019956588745,
      "learning_rate": 1.4432714973864918e-05,
      "loss": 0.3365,
      "step": 2721
    },
    {
      "epoch": 0.56,
      "grad_norm": 1.493645429611206,
      "learning_rate": 1.443066516347238e-05,
      "loss": 0.401,
      "step": 2722
    },
    {
      "epoch": 0.56,
      "grad_norm": 0.8382410407066345,
      "learning_rate": 1.4428615353079842e-05,
      "loss": 0.4589,
      "step": 2723
    },
    {
      "epoch": 0.56,
      "grad_norm": 2.9314703941345215,
      "learning_rate": 1.4426565542687304e-05,
      "loss": 0.4086,
      "step": 2724
    },
    {
      "epoch": 0.56,
      "grad_norm": 3.203045129776001,
      "learning_rate": 1.4424515732294764e-05,
      "loss": 0.4698,
      "step": 2725
    },
    {
      "epoch": 0.56,
      "grad_norm": 1.5242034196853638,
      "learning_rate": 1.4422465921902224e-05,
      "loss": 0.3542,
      "step": 2726
    },
    {
      "epoch": 0.56,
      "grad_norm": 2.012152910232544,
      "learning_rate": 1.4420416111509687e-05,
      "loss": 0.4237,
      "step": 2727
    },
    {
      "epoch": 0.56,
      "grad_norm": 1.9409931898117065,
      "learning_rate": 1.4418366301117148e-05,
      "loss": 0.468,
      "step": 2728
    },
    {
      "epoch": 0.56,
      "grad_norm": 1.0784645080566406,
      "learning_rate": 1.441631649072461e-05,
      "loss": 0.3185,
      "step": 2729
    },
    {
      "epoch": 0.56,
      "grad_norm": 1.3699307441711426,
      "learning_rate": 1.441426668033207e-05,
      "loss": 0.4748,
      "step": 2730
    },
    {
      "epoch": 0.56,
      "grad_norm": 1.2344273328781128,
      "learning_rate": 1.4412216869939533e-05,
      "loss": 0.3111,
      "step": 2731
    },
    {
      "epoch": 0.56,
      "grad_norm": 1.6792300939559937,
      "learning_rate": 1.4410167059546993e-05,
      "loss": 0.5088,
      "step": 2732
    },
    {
      "epoch": 0.56,
      "grad_norm": 1.1881048679351807,
      "learning_rate": 1.4408117249154453e-05,
      "loss": 0.4746,
      "step": 2733
    },
    {
      "epoch": 0.56,
      "grad_norm": 0.8163602352142334,
      "learning_rate": 1.4406067438761915e-05,
      "loss": 0.3964,
      "step": 2734
    },
    {
      "epoch": 0.56,
      "grad_norm": 1.1857457160949707,
      "learning_rate": 1.4404017628369377e-05,
      "loss": 0.4464,
      "step": 2735
    },
    {
      "epoch": 0.56,
      "grad_norm": 0.7149863839149475,
      "learning_rate": 1.4401967817976839e-05,
      "loss": 0.4946,
      "step": 2736
    },
    {
      "epoch": 0.56,
      "grad_norm": 3.1541521549224854,
      "learning_rate": 1.43999180075843e-05,
      "loss": 0.395,
      "step": 2737
    },
    {
      "epoch": 0.56,
      "grad_norm": 1.5238345861434937,
      "learning_rate": 1.439786819719176e-05,
      "loss": 0.4606,
      "step": 2738
    },
    {
      "epoch": 0.56,
      "grad_norm": 0.9796364903450012,
      "learning_rate": 1.4395818386799223e-05,
      "loss": 0.4701,
      "step": 2739
    },
    {
      "epoch": 0.56,
      "grad_norm": 1.4399610757827759,
      "learning_rate": 1.4393768576406683e-05,
      "loss": 0.3749,
      "step": 2740
    },
    {
      "epoch": 0.56,
      "grad_norm": 1.5087779760360718,
      "learning_rate": 1.4391718766014145e-05,
      "loss": 0.5173,
      "step": 2741
    },
    {
      "epoch": 0.56,
      "grad_norm": 0.8071604371070862,
      "learning_rate": 1.4389668955621605e-05,
      "loss": 0.3118,
      "step": 2742
    },
    {
      "epoch": 0.56,
      "grad_norm": 1.6173580884933472,
      "learning_rate": 1.4387619145229069e-05,
      "loss": 0.4119,
      "step": 2743
    },
    {
      "epoch": 0.56,
      "grad_norm": 0.8884178400039673,
      "learning_rate": 1.4385569334836529e-05,
      "loss": 0.4865,
      "step": 2744
    },
    {
      "epoch": 0.56,
      "grad_norm": 0.6985644698143005,
      "learning_rate": 1.4383519524443989e-05,
      "loss": 0.5863,
      "step": 2745
    },
    {
      "epoch": 0.56,
      "grad_norm": 1.0743671655654907,
      "learning_rate": 1.438146971405145e-05,
      "loss": 0.6151,
      "step": 2746
    },
    {
      "epoch": 0.56,
      "grad_norm": 1.7734960317611694,
      "learning_rate": 1.4379419903658913e-05,
      "loss": 0.4081,
      "step": 2747
    },
    {
      "epoch": 0.56,
      "grad_norm": 1.0463985204696655,
      "learning_rate": 1.4377370093266375e-05,
      "loss": 0.6375,
      "step": 2748
    },
    {
      "epoch": 0.56,
      "grad_norm": 1.1937997341156006,
      "learning_rate": 1.4375320282873835e-05,
      "loss": 0.4579,
      "step": 2749
    },
    {
      "epoch": 0.56,
      "grad_norm": 1.20559823513031,
      "learning_rate": 1.4373270472481298e-05,
      "loss": 0.4688,
      "step": 2750
    },
    {
      "epoch": 0.56,
      "grad_norm": 0.6113927364349365,
      "learning_rate": 1.4371220662088758e-05,
      "loss": 0.4549,
      "step": 2751
    },
    {
      "epoch": 0.56,
      "grad_norm": 2.0945396423339844,
      "learning_rate": 1.4369170851696219e-05,
      "loss": 0.3703,
      "step": 2752
    },
    {
      "epoch": 0.56,
      "grad_norm": 0.8518765568733215,
      "learning_rate": 1.436712104130368e-05,
      "loss": 0.3678,
      "step": 2753
    },
    {
      "epoch": 0.56,
      "grad_norm": 1.3982678651809692,
      "learning_rate": 1.4365071230911142e-05,
      "loss": 0.3466,
      "step": 2754
    },
    {
      "epoch": 0.56,
      "grad_norm": 1.4675917625427246,
      "learning_rate": 1.4363021420518604e-05,
      "loss": 0.4069,
      "step": 2755
    },
    {
      "epoch": 0.56,
      "grad_norm": 0.819844126701355,
      "learning_rate": 1.4360971610126064e-05,
      "loss": 0.5078,
      "step": 2756
    },
    {
      "epoch": 0.56,
      "grad_norm": 1.9067591428756714,
      "learning_rate": 1.4358921799733524e-05,
      "loss": 0.5342,
      "step": 2757
    },
    {
      "epoch": 0.57,
      "grad_norm": 0.9055383205413818,
      "learning_rate": 1.4356871989340988e-05,
      "loss": 0.4822,
      "step": 2758
    },
    {
      "epoch": 0.57,
      "grad_norm": 1.9019675254821777,
      "learning_rate": 1.4354822178948448e-05,
      "loss": 0.4734,
      "step": 2759
    },
    {
      "epoch": 0.57,
      "grad_norm": 0.9232966303825378,
      "learning_rate": 1.435277236855591e-05,
      "loss": 0.4268,
      "step": 2760
    },
    {
      "epoch": 0.57,
      "grad_norm": 0.8651950359344482,
      "learning_rate": 1.435072255816337e-05,
      "loss": 0.4611,
      "step": 2761
    },
    {
      "epoch": 0.57,
      "grad_norm": 1.5921308994293213,
      "learning_rate": 1.4348672747770834e-05,
      "loss": 0.4334,
      "step": 2762
    },
    {
      "epoch": 0.57,
      "grad_norm": 2.3368382453918457,
      "learning_rate": 1.4346622937378294e-05,
      "loss": 0.3481,
      "step": 2763
    },
    {
      "epoch": 0.57,
      "grad_norm": 1.3006224632263184,
      "learning_rate": 1.4344573126985754e-05,
      "loss": 0.2536,
      "step": 2764
    },
    {
      "epoch": 0.57,
      "grad_norm": 0.923607349395752,
      "learning_rate": 1.4342523316593216e-05,
      "loss": 0.5218,
      "step": 2765
    },
    {
      "epoch": 0.57,
      "grad_norm": 1.749452829360962,
      "learning_rate": 1.4340473506200678e-05,
      "loss": 0.5091,
      "step": 2766
    },
    {
      "epoch": 0.57,
      "grad_norm": 1.1541792154312134,
      "learning_rate": 1.433842369580814e-05,
      "loss": 0.4431,
      "step": 2767
    },
    {
      "epoch": 0.57,
      "grad_norm": 1.135534644126892,
      "learning_rate": 1.43363738854156e-05,
      "loss": 0.6629,
      "step": 2768
    },
    {
      "epoch": 0.57,
      "grad_norm": 1.1646778583526611,
      "learning_rate": 1.433432407502306e-05,
      "loss": 0.4082,
      "step": 2769
    },
    {
      "epoch": 0.57,
      "grad_norm": 0.9747617244720459,
      "learning_rate": 1.4332274264630523e-05,
      "loss": 0.5355,
      "step": 2770
    },
    {
      "epoch": 0.57,
      "grad_norm": 1.0272278785705566,
      "learning_rate": 1.4330224454237984e-05,
      "loss": 0.2326,
      "step": 2771
    },
    {
      "epoch": 0.57,
      "grad_norm": 0.9820098876953125,
      "learning_rate": 1.4328174643845446e-05,
      "loss": 0.574,
      "step": 2772
    },
    {
      "epoch": 0.57,
      "grad_norm": 0.8725738525390625,
      "learning_rate": 1.4326124833452906e-05,
      "loss": 0.5726,
      "step": 2773
    },
    {
      "epoch": 0.57,
      "grad_norm": 2.439542293548584,
      "learning_rate": 1.432407502306037e-05,
      "loss": 0.433,
      "step": 2774
    },
    {
      "epoch": 0.57,
      "grad_norm": 1.1754790544509888,
      "learning_rate": 1.432202521266783e-05,
      "loss": 0.5312,
      "step": 2775
    },
    {
      "epoch": 0.57,
      "grad_norm": 1.0640984773635864,
      "learning_rate": 1.431997540227529e-05,
      "loss": 0.3973,
      "step": 2776
    },
    {
      "epoch": 0.57,
      "grad_norm": 0.9988648891448975,
      "learning_rate": 1.4317925591882753e-05,
      "loss": 0.4002,
      "step": 2777
    },
    {
      "epoch": 0.57,
      "grad_norm": 1.236660122871399,
      "learning_rate": 1.4315875781490213e-05,
      "loss": 0.6306,
      "step": 2778
    },
    {
      "epoch": 0.57,
      "grad_norm": 1.5579038858413696,
      "learning_rate": 1.4313825971097675e-05,
      "loss": 0.3815,
      "step": 2779
    },
    {
      "epoch": 0.57,
      "grad_norm": 1.791481852531433,
      "learning_rate": 1.4311776160705135e-05,
      "loss": 0.3416,
      "step": 2780
    },
    {
      "epoch": 0.57,
      "grad_norm": 0.9038289189338684,
      "learning_rate": 1.4309726350312599e-05,
      "loss": 0.4159,
      "step": 2781
    },
    {
      "epoch": 0.57,
      "grad_norm": 0.761604368686676,
      "learning_rate": 1.4307676539920059e-05,
      "loss": 0.5248,
      "step": 2782
    },
    {
      "epoch": 0.57,
      "grad_norm": 0.9811084866523743,
      "learning_rate": 1.430562672952752e-05,
      "loss": 0.5278,
      "step": 2783
    },
    {
      "epoch": 0.57,
      "grad_norm": 1.8746514320373535,
      "learning_rate": 1.4303576919134981e-05,
      "loss": 0.3756,
      "step": 2784
    },
    {
      "epoch": 0.57,
      "grad_norm": 1.5524057149887085,
      "learning_rate": 1.4301527108742443e-05,
      "loss": 0.6009,
      "step": 2785
    },
    {
      "epoch": 0.57,
      "grad_norm": 0.9258565306663513,
      "learning_rate": 1.4299477298349905e-05,
      "loss": 0.4411,
      "step": 2786
    },
    {
      "epoch": 0.57,
      "grad_norm": 1.6958608627319336,
      "learning_rate": 1.4297427487957365e-05,
      "loss": 0.4532,
      "step": 2787
    },
    {
      "epoch": 0.57,
      "grad_norm": 1.17826509475708,
      "learning_rate": 1.4295377677564825e-05,
      "loss": 0.3477,
      "step": 2788
    },
    {
      "epoch": 0.57,
      "grad_norm": 2.3393516540527344,
      "learning_rate": 1.4293327867172289e-05,
      "loss": 0.5681,
      "step": 2789
    },
    {
      "epoch": 0.57,
      "grad_norm": 1.3153706789016724,
      "learning_rate": 1.4291278056779749e-05,
      "loss": 0.5802,
      "step": 2790
    },
    {
      "epoch": 0.57,
      "grad_norm": 0.9963333010673523,
      "learning_rate": 1.428922824638721e-05,
      "loss": 0.534,
      "step": 2791
    },
    {
      "epoch": 0.57,
      "grad_norm": 1.291737675666809,
      "learning_rate": 1.428717843599467e-05,
      "loss": 0.306,
      "step": 2792
    },
    {
      "epoch": 0.57,
      "grad_norm": 2.2797656059265137,
      "learning_rate": 1.4285128625602134e-05,
      "loss": 0.5181,
      "step": 2793
    },
    {
      "epoch": 0.57,
      "grad_norm": 0.767344057559967,
      "learning_rate": 1.4283078815209594e-05,
      "loss": 0.5083,
      "step": 2794
    },
    {
      "epoch": 0.57,
      "grad_norm": 0.9382791519165039,
      "learning_rate": 1.4281029004817055e-05,
      "loss": 0.4389,
      "step": 2795
    },
    {
      "epoch": 0.57,
      "grad_norm": 0.8811342716217041,
      "learning_rate": 1.4278979194424517e-05,
      "loss": 0.5885,
      "step": 2796
    },
    {
      "epoch": 0.57,
      "grad_norm": 1.069705605506897,
      "learning_rate": 1.4276929384031978e-05,
      "loss": 0.4495,
      "step": 2797
    },
    {
      "epoch": 0.57,
      "grad_norm": 0.9789589047431946,
      "learning_rate": 1.427487957363944e-05,
      "loss": 0.369,
      "step": 2798
    },
    {
      "epoch": 0.57,
      "grad_norm": 3.2456016540527344,
      "learning_rate": 1.42728297632469e-05,
      "loss": 0.4303,
      "step": 2799
    },
    {
      "epoch": 0.57,
      "grad_norm": 1.1112505197525024,
      "learning_rate": 1.427077995285436e-05,
      "loss": 0.3812,
      "step": 2800
    },
    {
      "epoch": 0.57,
      "grad_norm": 0.7531527280807495,
      "learning_rate": 1.4268730142461824e-05,
      "loss": 0.3643,
      "step": 2801
    },
    {
      "epoch": 0.57,
      "grad_norm": 0.9864336848258972,
      "learning_rate": 1.4266680332069284e-05,
      "loss": 0.3316,
      "step": 2802
    },
    {
      "epoch": 0.57,
      "grad_norm": 2.150184392929077,
      "learning_rate": 1.4264630521676746e-05,
      "loss": 0.491,
      "step": 2803
    },
    {
      "epoch": 0.57,
      "grad_norm": 1.0326273441314697,
      "learning_rate": 1.4262580711284206e-05,
      "loss": 0.4926,
      "step": 2804
    },
    {
      "epoch": 0.57,
      "grad_norm": 2.1070353984832764,
      "learning_rate": 1.426053090089167e-05,
      "loss": 0.4663,
      "step": 2805
    },
    {
      "epoch": 0.57,
      "grad_norm": 0.8355094790458679,
      "learning_rate": 1.425848109049913e-05,
      "loss": 0.6674,
      "step": 2806
    },
    {
      "epoch": 0.58,
      "grad_norm": 2.104165554046631,
      "learning_rate": 1.425643128010659e-05,
      "loss": 0.3187,
      "step": 2807
    },
    {
      "epoch": 0.58,
      "grad_norm": 1.095733642578125,
      "learning_rate": 1.4254381469714054e-05,
      "loss": 0.4144,
      "step": 2808
    },
    {
      "epoch": 0.58,
      "grad_norm": 1.356500267982483,
      "learning_rate": 1.4252331659321514e-05,
      "loss": 0.4241,
      "step": 2809
    },
    {
      "epoch": 0.58,
      "grad_norm": 2.8419601917266846,
      "learning_rate": 1.4250281848928976e-05,
      "loss": 0.4699,
      "step": 2810
    },
    {
      "epoch": 0.58,
      "grad_norm": 1.393953561782837,
      "learning_rate": 1.4248232038536436e-05,
      "loss": 0.5517,
      "step": 2811
    },
    {
      "epoch": 0.58,
      "grad_norm": 1.0793113708496094,
      "learning_rate": 1.42461822281439e-05,
      "loss": 0.2974,
      "step": 2812
    },
    {
      "epoch": 0.58,
      "grad_norm": 1.2577345371246338,
      "learning_rate": 1.424413241775136e-05,
      "loss": 0.317,
      "step": 2813
    },
    {
      "epoch": 0.58,
      "grad_norm": 0.7888454794883728,
      "learning_rate": 1.424208260735882e-05,
      "loss": 0.5978,
      "step": 2814
    },
    {
      "epoch": 0.58,
      "grad_norm": 1.1055617332458496,
      "learning_rate": 1.4240032796966282e-05,
      "loss": 0.4718,
      "step": 2815
    },
    {
      "epoch": 0.58,
      "grad_norm": 1.0435599088668823,
      "learning_rate": 1.4237982986573743e-05,
      "loss": 0.4191,
      "step": 2816
    },
    {
      "epoch": 0.58,
      "grad_norm": 1.6398959159851074,
      "learning_rate": 1.4235933176181205e-05,
      "loss": 0.3367,
      "step": 2817
    },
    {
      "epoch": 0.58,
      "grad_norm": 1.0723081827163696,
      "learning_rate": 1.4233883365788666e-05,
      "loss": 0.6729,
      "step": 2818
    },
    {
      "epoch": 0.58,
      "grad_norm": 1.6397974491119385,
      "learning_rate": 1.4231833555396126e-05,
      "loss": 0.4461,
      "step": 2819
    },
    {
      "epoch": 0.58,
      "grad_norm": 0.6846542954444885,
      "learning_rate": 1.422978374500359e-05,
      "loss": 0.5654,
      "step": 2820
    },
    {
      "epoch": 0.58,
      "grad_norm": 2.5085246562957764,
      "learning_rate": 1.422773393461105e-05,
      "loss": 0.3885,
      "step": 2821
    },
    {
      "epoch": 0.58,
      "grad_norm": 1.6117886304855347,
      "learning_rate": 1.4225684124218511e-05,
      "loss": 0.3779,
      "step": 2822
    },
    {
      "epoch": 0.58,
      "grad_norm": 0.6554625630378723,
      "learning_rate": 1.4223634313825971e-05,
      "loss": 0.3831,
      "step": 2823
    },
    {
      "epoch": 0.58,
      "grad_norm": 1.7168220281600952,
      "learning_rate": 1.4221584503433435e-05,
      "loss": 0.3087,
      "step": 2824
    },
    {
      "epoch": 0.58,
      "grad_norm": 0.9173123836517334,
      "learning_rate": 1.4219534693040895e-05,
      "loss": 0.3809,
      "step": 2825
    },
    {
      "epoch": 0.58,
      "grad_norm": 1.1408791542053223,
      "learning_rate": 1.4217484882648355e-05,
      "loss": 0.4307,
      "step": 2826
    },
    {
      "epoch": 0.58,
      "grad_norm": 0.922801673412323,
      "learning_rate": 1.4215435072255817e-05,
      "loss": 0.3345,
      "step": 2827
    },
    {
      "epoch": 0.58,
      "grad_norm": 1.0218777656555176,
      "learning_rate": 1.4213385261863279e-05,
      "loss": 0.6015,
      "step": 2828
    },
    {
      "epoch": 0.58,
      "grad_norm": 1.6414481401443481,
      "learning_rate": 1.421133545147074e-05,
      "loss": 0.4614,
      "step": 2829
    },
    {
      "epoch": 0.58,
      "grad_norm": 1.372632622718811,
      "learning_rate": 1.4209285641078201e-05,
      "loss": 0.5724,
      "step": 2830
    },
    {
      "epoch": 0.58,
      "grad_norm": 1.483716607093811,
      "learning_rate": 1.4207235830685661e-05,
      "loss": 0.546,
      "step": 2831
    },
    {
      "epoch": 0.58,
      "grad_norm": 1.153558611869812,
      "learning_rate": 1.4205186020293125e-05,
      "loss": 0.3718,
      "step": 2832
    },
    {
      "epoch": 0.58,
      "grad_norm": 0.9800085425376892,
      "learning_rate": 1.4203136209900585e-05,
      "loss": 0.364,
      "step": 2833
    },
    {
      "epoch": 0.58,
      "grad_norm": 2.491671323776245,
      "learning_rate": 1.4201086399508047e-05,
      "loss": 0.5412,
      "step": 2834
    },
    {
      "epoch": 0.58,
      "grad_norm": 0.7879099249839783,
      "learning_rate": 1.4199036589115509e-05,
      "loss": 0.4397,
      "step": 2835
    },
    {
      "epoch": 0.58,
      "grad_norm": 1.0491527318954468,
      "learning_rate": 1.419698677872297e-05,
      "loss": 0.4242,
      "step": 2836
    },
    {
      "epoch": 0.58,
      "grad_norm": 2.354889392852783,
      "learning_rate": 1.419493696833043e-05,
      "loss": 0.4592,
      "step": 2837
    },
    {
      "epoch": 0.58,
      "grad_norm": 2.200298547744751,
      "learning_rate": 1.419288715793789e-05,
      "loss": 0.5496,
      "step": 2838
    },
    {
      "epoch": 0.58,
      "grad_norm": 1.006977915763855,
      "learning_rate": 1.4190837347545354e-05,
      "loss": 0.4034,
      "step": 2839
    },
    {
      "epoch": 0.58,
      "grad_norm": 1.9438849687576294,
      "learning_rate": 1.4188787537152814e-05,
      "loss": 0.3104,
      "step": 2840
    },
    {
      "epoch": 0.58,
      "grad_norm": 0.9588999152183533,
      "learning_rate": 1.4186737726760276e-05,
      "loss": 0.3903,
      "step": 2841
    },
    {
      "epoch": 0.58,
      "grad_norm": 1.2158316373825073,
      "learning_rate": 1.4184687916367737e-05,
      "loss": 0.4427,
      "step": 2842
    },
    {
      "epoch": 0.58,
      "grad_norm": 1.3711252212524414,
      "learning_rate": 1.41826381059752e-05,
      "loss": 0.4321,
      "step": 2843
    },
    {
      "epoch": 0.58,
      "grad_norm": 1.856122374534607,
      "learning_rate": 1.418058829558266e-05,
      "loss": 0.4197,
      "step": 2844
    },
    {
      "epoch": 0.58,
      "grad_norm": 1.1342874765396118,
      "learning_rate": 1.417853848519012e-05,
      "loss": 0.5324,
      "step": 2845
    },
    {
      "epoch": 0.58,
      "grad_norm": 1.0488429069519043,
      "learning_rate": 1.4176488674797582e-05,
      "loss": 0.4505,
      "step": 2846
    },
    {
      "epoch": 0.58,
      "grad_norm": 0.6922404170036316,
      "learning_rate": 1.4174438864405044e-05,
      "loss": 0.419,
      "step": 2847
    },
    {
      "epoch": 0.58,
      "grad_norm": 1.0276285409927368,
      "learning_rate": 1.4172389054012506e-05,
      "loss": 0.3925,
      "step": 2848
    },
    {
      "epoch": 0.58,
      "grad_norm": 0.6271659731864929,
      "learning_rate": 1.4170339243619966e-05,
      "loss": 0.4196,
      "step": 2849
    },
    {
      "epoch": 0.58,
      "grad_norm": 0.8920170664787292,
      "learning_rate": 1.4168289433227426e-05,
      "loss": 0.603,
      "step": 2850
    },
    {
      "epoch": 0.58,
      "grad_norm": 1.5244064331054688,
      "learning_rate": 1.416623962283489e-05,
      "loss": 0.4697,
      "step": 2851
    },
    {
      "epoch": 0.58,
      "grad_norm": 0.8724473118782043,
      "learning_rate": 1.416418981244235e-05,
      "loss": 0.6603,
      "step": 2852
    },
    {
      "epoch": 0.58,
      "grad_norm": 1.4633857011795044,
      "learning_rate": 1.4162140002049812e-05,
      "loss": 0.5343,
      "step": 2853
    },
    {
      "epoch": 0.58,
      "grad_norm": 1.2969008684158325,
      "learning_rate": 1.4160090191657272e-05,
      "loss": 0.5815,
      "step": 2854
    },
    {
      "epoch": 0.58,
      "grad_norm": 0.7677163481712341,
      "learning_rate": 1.4158040381264736e-05,
      "loss": 0.404,
      "step": 2855
    },
    {
      "epoch": 0.59,
      "grad_norm": 1.372619390487671,
      "learning_rate": 1.4155990570872196e-05,
      "loss": 0.4532,
      "step": 2856
    },
    {
      "epoch": 0.59,
      "grad_norm": 1.3119958639144897,
      "learning_rate": 1.4153940760479656e-05,
      "loss": 0.4806,
      "step": 2857
    },
    {
      "epoch": 0.59,
      "grad_norm": 1.0592089891433716,
      "learning_rate": 1.4151890950087118e-05,
      "loss": 0.3253,
      "step": 2858
    },
    {
      "epoch": 0.59,
      "grad_norm": 1.7547650337219238,
      "learning_rate": 1.414984113969458e-05,
      "loss": 0.4474,
      "step": 2859
    },
    {
      "epoch": 0.59,
      "grad_norm": 1.1408296823501587,
      "learning_rate": 1.4147791329302041e-05,
      "loss": 0.5253,
      "step": 2860
    },
    {
      "epoch": 0.59,
      "grad_norm": 1.209930419921875,
      "learning_rate": 1.4145741518909502e-05,
      "loss": 0.485,
      "step": 2861
    },
    {
      "epoch": 0.59,
      "grad_norm": 0.8730654716491699,
      "learning_rate": 1.4143691708516962e-05,
      "loss": 0.5212,
      "step": 2862
    },
    {
      "epoch": 0.59,
      "grad_norm": 1.7980339527130127,
      "learning_rate": 1.4141641898124425e-05,
      "loss": 0.6026,
      "step": 2863
    },
    {
      "epoch": 0.59,
      "grad_norm": 1.0259662866592407,
      "learning_rate": 1.4139592087731885e-05,
      "loss": 0.3662,
      "step": 2864
    },
    {
      "epoch": 0.59,
      "grad_norm": 1.1798745393753052,
      "learning_rate": 1.4137542277339347e-05,
      "loss": 0.2746,
      "step": 2865
    },
    {
      "epoch": 0.59,
      "grad_norm": 1.1450238227844238,
      "learning_rate": 1.413549246694681e-05,
      "loss": 0.4442,
      "step": 2866
    },
    {
      "epoch": 0.59,
      "grad_norm": 0.8522194027900696,
      "learning_rate": 1.4133442656554271e-05,
      "loss": 0.4336,
      "step": 2867
    },
    {
      "epoch": 0.59,
      "grad_norm": 0.9882183074951172,
      "learning_rate": 1.4131392846161731e-05,
      "loss": 0.4217,
      "step": 2868
    },
    {
      "epoch": 0.59,
      "grad_norm": 1.1945734024047852,
      "learning_rate": 1.4129343035769191e-05,
      "loss": 0.398,
      "step": 2869
    },
    {
      "epoch": 0.59,
      "grad_norm": 0.9338312745094299,
      "learning_rate": 1.4127293225376655e-05,
      "loss": 0.4374,
      "step": 2870
    },
    {
      "epoch": 0.59,
      "grad_norm": 0.6679659485816956,
      "learning_rate": 1.4125243414984115e-05,
      "loss": 0.3472,
      "step": 2871
    },
    {
      "epoch": 0.59,
      "grad_norm": 0.8114677667617798,
      "learning_rate": 1.4123193604591577e-05,
      "loss": 0.4072,
      "step": 2872
    },
    {
      "epoch": 0.59,
      "grad_norm": 0.8413222432136536,
      "learning_rate": 1.4121143794199037e-05,
      "loss": 0.5473,
      "step": 2873
    },
    {
      "epoch": 0.59,
      "grad_norm": 1.3034929037094116,
      "learning_rate": 1.41190939838065e-05,
      "loss": 0.5401,
      "step": 2874
    },
    {
      "epoch": 0.59,
      "grad_norm": 0.719142735004425,
      "learning_rate": 1.411704417341396e-05,
      "loss": 0.4499,
      "step": 2875
    },
    {
      "epoch": 0.59,
      "grad_norm": 1.0119259357452393,
      "learning_rate": 1.4114994363021421e-05,
      "loss": 0.4974,
      "step": 2876
    },
    {
      "epoch": 0.59,
      "grad_norm": 1.4243460893630981,
      "learning_rate": 1.4112944552628883e-05,
      "loss": 0.4248,
      "step": 2877
    },
    {
      "epoch": 0.59,
      "grad_norm": 1.67984139919281,
      "learning_rate": 1.4110894742236345e-05,
      "loss": 0.45,
      "step": 2878
    },
    {
      "epoch": 0.59,
      "grad_norm": 0.7337429523468018,
      "learning_rate": 1.4108844931843807e-05,
      "loss": 0.504,
      "step": 2879
    },
    {
      "epoch": 0.59,
      "grad_norm": 1.6103869676589966,
      "learning_rate": 1.4106795121451267e-05,
      "loss": 0.4777,
      "step": 2880
    },
    {
      "epoch": 0.59,
      "grad_norm": 0.6557824015617371,
      "learning_rate": 1.4104745311058727e-05,
      "loss": 0.4396,
      "step": 2881
    },
    {
      "epoch": 0.59,
      "grad_norm": 0.9824172854423523,
      "learning_rate": 1.410269550066619e-05,
      "loss": 0.4242,
      "step": 2882
    },
    {
      "epoch": 0.59,
      "grad_norm": 1.2575796842575073,
      "learning_rate": 1.410064569027365e-05,
      "loss": 0.45,
      "step": 2883
    },
    {
      "epoch": 0.59,
      "grad_norm": 1.205820918083191,
      "learning_rate": 1.4098595879881112e-05,
      "loss": 0.384,
      "step": 2884
    },
    {
      "epoch": 0.59,
      "grad_norm": 1.8447577953338623,
      "learning_rate": 1.4096546069488573e-05,
      "loss": 0.5438,
      "step": 2885
    },
    {
      "epoch": 0.59,
      "grad_norm": 1.0736933946609497,
      "learning_rate": 1.4094496259096036e-05,
      "loss": 0.4987,
      "step": 2886
    },
    {
      "epoch": 0.59,
      "grad_norm": 0.9790982604026794,
      "learning_rate": 1.4092446448703496e-05,
      "loss": 0.4026,
      "step": 2887
    },
    {
      "epoch": 0.59,
      "grad_norm": 1.5271931886672974,
      "learning_rate": 1.4090396638310956e-05,
      "loss": 0.4681,
      "step": 2888
    },
    {
      "epoch": 0.59,
      "grad_norm": 0.7535625100135803,
      "learning_rate": 1.4088346827918418e-05,
      "loss": 0.6918,
      "step": 2889
    },
    {
      "epoch": 0.59,
      "grad_norm": 1.2128249406814575,
      "learning_rate": 1.408629701752588e-05,
      "loss": 0.4117,
      "step": 2890
    },
    {
      "epoch": 0.59,
      "grad_norm": 1.8058185577392578,
      "learning_rate": 1.4084247207133342e-05,
      "loss": 0.5321,
      "step": 2891
    },
    {
      "epoch": 0.59,
      "grad_norm": 1.5301880836486816,
      "learning_rate": 1.4082197396740802e-05,
      "loss": 0.2455,
      "step": 2892
    },
    {
      "epoch": 0.59,
      "grad_norm": 1.1373428106307983,
      "learning_rate": 1.4080147586348262e-05,
      "loss": 0.4792,
      "step": 2893
    },
    {
      "epoch": 0.59,
      "grad_norm": 1.386626124382019,
      "learning_rate": 1.4078097775955726e-05,
      "loss": 0.4499,
      "step": 2894
    },
    {
      "epoch": 0.59,
      "grad_norm": 0.9235613346099854,
      "learning_rate": 1.4076047965563186e-05,
      "loss": 0.4911,
      "step": 2895
    },
    {
      "epoch": 0.59,
      "grad_norm": 1.4851561784744263,
      "learning_rate": 1.4073998155170648e-05,
      "loss": 0.604,
      "step": 2896
    },
    {
      "epoch": 0.59,
      "grad_norm": 1.3876768350601196,
      "learning_rate": 1.407194834477811e-05,
      "loss": 0.3922,
      "step": 2897
    },
    {
      "epoch": 0.59,
      "grad_norm": 0.9544584155082703,
      "learning_rate": 1.4069898534385572e-05,
      "loss": 0.4095,
      "step": 2898
    },
    {
      "epoch": 0.59,
      "grad_norm": 1.927943229675293,
      "learning_rate": 1.4067848723993032e-05,
      "loss": 0.5291,
      "step": 2899
    },
    {
      "epoch": 0.59,
      "grad_norm": 1.0979257822036743,
      "learning_rate": 1.4065798913600492e-05,
      "loss": 0.4322,
      "step": 2900
    },
    {
      "epoch": 0.59,
      "grad_norm": 1.8346818685531616,
      "learning_rate": 1.4063749103207956e-05,
      "loss": 0.3673,
      "step": 2901
    },
    {
      "epoch": 0.59,
      "grad_norm": 1.8327882289886475,
      "learning_rate": 1.4061699292815416e-05,
      "loss": 0.5583,
      "step": 2902
    },
    {
      "epoch": 0.59,
      "grad_norm": 1.119951605796814,
      "learning_rate": 1.4059649482422878e-05,
      "loss": 0.3573,
      "step": 2903
    },
    {
      "epoch": 0.59,
      "grad_norm": 1.141741156578064,
      "learning_rate": 1.4057599672030338e-05,
      "loss": 0.4271,
      "step": 2904
    },
    {
      "epoch": 0.6,
      "grad_norm": 0.952129065990448,
      "learning_rate": 1.4055549861637801e-05,
      "loss": 0.5744,
      "step": 2905
    },
    {
      "epoch": 0.6,
      "grad_norm": 1.2773842811584473,
      "learning_rate": 1.4053500051245261e-05,
      "loss": 0.5982,
      "step": 2906
    },
    {
      "epoch": 0.6,
      "grad_norm": 0.9159146547317505,
      "learning_rate": 1.4051450240852722e-05,
      "loss": 0.3985,
      "step": 2907
    },
    {
      "epoch": 0.6,
      "grad_norm": 0.58890700340271,
      "learning_rate": 1.4049400430460183e-05,
      "loss": 0.3862,
      "step": 2908
    },
    {
      "epoch": 0.6,
      "grad_norm": 0.887109100818634,
      "learning_rate": 1.4047350620067645e-05,
      "loss": 0.4103,
      "step": 2909
    },
    {
      "epoch": 0.6,
      "grad_norm": 0.9815865755081177,
      "learning_rate": 1.4045300809675107e-05,
      "loss": 0.4653,
      "step": 2910
    },
    {
      "epoch": 0.6,
      "grad_norm": 0.7989691495895386,
      "learning_rate": 1.4043250999282567e-05,
      "loss": 0.4623,
      "step": 2911
    },
    {
      "epoch": 0.6,
      "grad_norm": 1.549512505531311,
      "learning_rate": 1.4041201188890027e-05,
      "loss": 0.5419,
      "step": 2912
    },
    {
      "epoch": 0.6,
      "grad_norm": 1.0186845064163208,
      "learning_rate": 1.4039151378497491e-05,
      "loss": 0.4709,
      "step": 2913
    },
    {
      "epoch": 0.6,
      "grad_norm": 1.0027128458023071,
      "learning_rate": 1.4037101568104951e-05,
      "loss": 0.3449,
      "step": 2914
    },
    {
      "epoch": 0.6,
      "grad_norm": 1.226369857788086,
      "learning_rate": 1.4035051757712413e-05,
      "loss": 0.4419,
      "step": 2915
    },
    {
      "epoch": 0.6,
      "grad_norm": 0.9050703644752502,
      "learning_rate": 1.4033001947319873e-05,
      "loss": 0.5367,
      "step": 2916
    },
    {
      "epoch": 0.6,
      "grad_norm": 0.6623044610023499,
      "learning_rate": 1.4030952136927337e-05,
      "loss": 0.4303,
      "step": 2917
    },
    {
      "epoch": 0.6,
      "grad_norm": 0.9465950131416321,
      "learning_rate": 1.4028902326534797e-05,
      "loss": 0.3703,
      "step": 2918
    },
    {
      "epoch": 0.6,
      "grad_norm": 0.7313974499702454,
      "learning_rate": 1.4026852516142257e-05,
      "loss": 0.4104,
      "step": 2919
    },
    {
      "epoch": 0.6,
      "grad_norm": 0.5744356513023376,
      "learning_rate": 1.4024802705749719e-05,
      "loss": 0.4852,
      "step": 2920
    },
    {
      "epoch": 0.6,
      "grad_norm": 1.0842957496643066,
      "learning_rate": 1.402275289535718e-05,
      "loss": 0.2498,
      "step": 2921
    },
    {
      "epoch": 0.6,
      "grad_norm": 0.7886454463005066,
      "learning_rate": 1.4020703084964643e-05,
      "loss": 0.4179,
      "step": 2922
    },
    {
      "epoch": 0.6,
      "grad_norm": 1.125968098640442,
      "learning_rate": 1.4018653274572103e-05,
      "loss": 0.353,
      "step": 2923
    },
    {
      "epoch": 0.6,
      "grad_norm": 0.8093606233596802,
      "learning_rate": 1.4016603464179566e-05,
      "loss": 0.5267,
      "step": 2924
    },
    {
      "epoch": 0.6,
      "grad_norm": 1.457519769668579,
      "learning_rate": 1.4014553653787027e-05,
      "loss": 0.3785,
      "step": 2925
    },
    {
      "epoch": 0.6,
      "grad_norm": 1.157429575920105,
      "learning_rate": 1.4012503843394487e-05,
      "loss": 0.4906,
      "step": 2926
    },
    {
      "epoch": 0.6,
      "grad_norm": 1.0649993419647217,
      "learning_rate": 1.4010454033001949e-05,
      "loss": 0.4948,
      "step": 2927
    },
    {
      "epoch": 0.6,
      "grad_norm": 1.3406600952148438,
      "learning_rate": 1.400840422260941e-05,
      "loss": 0.4486,
      "step": 2928
    },
    {
      "epoch": 0.6,
      "grad_norm": 2.022390604019165,
      "learning_rate": 1.4006354412216872e-05,
      "loss": 0.4462,
      "step": 2929
    },
    {
      "epoch": 0.6,
      "grad_norm": 1.3385977745056152,
      "learning_rate": 1.4004304601824332e-05,
      "loss": 0.3304,
      "step": 2930
    },
    {
      "epoch": 0.6,
      "grad_norm": 1.4210712909698486,
      "learning_rate": 1.4002254791431793e-05,
      "loss": 0.4075,
      "step": 2931
    },
    {
      "epoch": 0.6,
      "grad_norm": 1.262666940689087,
      "learning_rate": 1.4000204981039256e-05,
      "loss": 0.3903,
      "step": 2932
    },
    {
      "epoch": 0.6,
      "grad_norm": 0.990223228931427,
      "learning_rate": 1.3998155170646716e-05,
      "loss": 0.324,
      "step": 2933
    },
    {
      "epoch": 0.6,
      "grad_norm": 0.9709223508834839,
      "learning_rate": 1.3996105360254178e-05,
      "loss": 0.4647,
      "step": 2934
    },
    {
      "epoch": 0.6,
      "grad_norm": 0.9727086424827576,
      "learning_rate": 1.3994055549861638e-05,
      "loss": 0.5676,
      "step": 2935
    },
    {
      "epoch": 0.6,
      "grad_norm": 1.3501226902008057,
      "learning_rate": 1.3992005739469102e-05,
      "loss": 0.3892,
      "step": 2936
    },
    {
      "epoch": 0.6,
      "grad_norm": 1.0422735214233398,
      "learning_rate": 1.3989955929076562e-05,
      "loss": 0.4131,
      "step": 2937
    },
    {
      "epoch": 0.6,
      "grad_norm": 1.1381770372390747,
      "learning_rate": 1.3987906118684022e-05,
      "loss": 0.4337,
      "step": 2938
    },
    {
      "epoch": 0.6,
      "grad_norm": 1.1245887279510498,
      "learning_rate": 1.3985856308291484e-05,
      "loss": 0.5133,
      "step": 2939
    },
    {
      "epoch": 0.6,
      "grad_norm": 1.0162605047225952,
      "learning_rate": 1.3983806497898946e-05,
      "loss": 0.4407,
      "step": 2940
    },
    {
      "epoch": 0.6,
      "grad_norm": 1.6119543313980103,
      "learning_rate": 1.3981756687506408e-05,
      "loss": 0.5273,
      "step": 2941
    },
    {
      "epoch": 0.6,
      "grad_norm": 1.191917061805725,
      "learning_rate": 1.3979706877113868e-05,
      "loss": 0.6233,
      "step": 2942
    },
    {
      "epoch": 0.6,
      "grad_norm": 0.7515696287155151,
      "learning_rate": 1.3977657066721328e-05,
      "loss": 0.4684,
      "step": 2943
    },
    {
      "epoch": 0.6,
      "grad_norm": 1.0906277894973755,
      "learning_rate": 1.3975607256328792e-05,
      "loss": 0.3329,
      "step": 2944
    },
    {
      "epoch": 0.6,
      "grad_norm": 1.1192820072174072,
      "learning_rate": 1.3973557445936252e-05,
      "loss": 0.4814,
      "step": 2945
    },
    {
      "epoch": 0.6,
      "grad_norm": 1.0283929109573364,
      "learning_rate": 1.3971507635543714e-05,
      "loss": 0.4259,
      "step": 2946
    },
    {
      "epoch": 0.6,
      "grad_norm": 0.9431195855140686,
      "learning_rate": 1.3969457825151174e-05,
      "loss": 0.3013,
      "step": 2947
    },
    {
      "epoch": 0.6,
      "grad_norm": 0.9189856648445129,
      "learning_rate": 1.3967408014758637e-05,
      "loss": 0.4146,
      "step": 2948
    },
    {
      "epoch": 0.6,
      "grad_norm": 0.9507817029953003,
      "learning_rate": 1.3965358204366098e-05,
      "loss": 0.6177,
      "step": 2949
    },
    {
      "epoch": 0.6,
      "grad_norm": 1.7002205848693848,
      "learning_rate": 1.3963308393973558e-05,
      "loss": 0.3536,
      "step": 2950
    },
    {
      "epoch": 0.6,
      "grad_norm": 1.2076226472854614,
      "learning_rate": 1.396125858358102e-05,
      "loss": 0.366,
      "step": 2951
    },
    {
      "epoch": 0.6,
      "grad_norm": 1.3203870058059692,
      "learning_rate": 1.3959208773188481e-05,
      "loss": 0.5026,
      "step": 2952
    },
    {
      "epoch": 0.6,
      "grad_norm": 1.0049155950546265,
      "learning_rate": 1.3957158962795943e-05,
      "loss": 0.4574,
      "step": 2953
    },
    {
      "epoch": 0.61,
      "grad_norm": 0.8367515802383423,
      "learning_rate": 1.3955109152403403e-05,
      "loss": 0.404,
      "step": 2954
    },
    {
      "epoch": 0.61,
      "grad_norm": 0.7688595056533813,
      "learning_rate": 1.3953059342010867e-05,
      "loss": 0.3367,
      "step": 2955
    },
    {
      "epoch": 0.61,
      "grad_norm": 0.7958887815475464,
      "learning_rate": 1.3951009531618327e-05,
      "loss": 0.5425,
      "step": 2956
    },
    {
      "epoch": 0.61,
      "grad_norm": 0.9010629057884216,
      "learning_rate": 1.3948959721225787e-05,
      "loss": 0.4589,
      "step": 2957
    },
    {
      "epoch": 0.61,
      "grad_norm": 1.4963096380233765,
      "learning_rate": 1.394690991083325e-05,
      "loss": 0.4914,
      "step": 2958
    },
    {
      "epoch": 0.61,
      "grad_norm": 1.1425604820251465,
      "learning_rate": 1.3944860100440711e-05,
      "loss": 0.478,
      "step": 2959
    },
    {
      "epoch": 0.61,
      "grad_norm": 1.36156165599823,
      "learning_rate": 1.3942810290048173e-05,
      "loss": 0.5422,
      "step": 2960
    },
    {
      "epoch": 0.61,
      "grad_norm": 0.8524919152259827,
      "learning_rate": 1.3940760479655633e-05,
      "loss": 0.6433,
      "step": 2961
    },
    {
      "epoch": 0.61,
      "grad_norm": 0.9246964454650879,
      "learning_rate": 1.3938710669263093e-05,
      "loss": 0.4517,
      "step": 2962
    },
    {
      "epoch": 0.61,
      "grad_norm": 0.8984944820404053,
      "learning_rate": 1.3936660858870557e-05,
      "loss": 0.4411,
      "step": 2963
    },
    {
      "epoch": 0.61,
      "grad_norm": 0.9351286888122559,
      "learning_rate": 1.3934611048478017e-05,
      "loss": 0.4606,
      "step": 2964
    },
    {
      "epoch": 0.61,
      "grad_norm": 1.142136573791504,
      "learning_rate": 1.3932561238085479e-05,
      "loss": 0.4749,
      "step": 2965
    },
    {
      "epoch": 0.61,
      "grad_norm": 1.2995338439941406,
      "learning_rate": 1.3930511427692939e-05,
      "loss": 0.3225,
      "step": 2966
    },
    {
      "epoch": 0.61,
      "grad_norm": 1.7512315511703491,
      "learning_rate": 1.3928461617300402e-05,
      "loss": 0.3346,
      "step": 2967
    },
    {
      "epoch": 0.61,
      "grad_norm": 1.5742090940475464,
      "learning_rate": 1.3926411806907863e-05,
      "loss": 0.3693,
      "step": 2968
    },
    {
      "epoch": 0.61,
      "grad_norm": 1.2539020776748657,
      "learning_rate": 1.3924361996515323e-05,
      "loss": 0.3211,
      "step": 2969
    },
    {
      "epoch": 0.61,
      "grad_norm": 0.9174209833145142,
      "learning_rate": 1.3922312186122785e-05,
      "loss": 0.6022,
      "step": 2970
    },
    {
      "epoch": 0.61,
      "grad_norm": 0.8717035055160522,
      "learning_rate": 1.3920262375730247e-05,
      "loss": 0.5511,
      "step": 2971
    },
    {
      "epoch": 0.61,
      "grad_norm": 1.0266337394714355,
      "learning_rate": 1.3918212565337708e-05,
      "loss": 0.4489,
      "step": 2972
    },
    {
      "epoch": 0.61,
      "grad_norm": 2.3903141021728516,
      "learning_rate": 1.3916162754945169e-05,
      "loss": 0.3245,
      "step": 2973
    },
    {
      "epoch": 0.61,
      "grad_norm": 1.0861849784851074,
      "learning_rate": 1.3914112944552629e-05,
      "loss": 0.5306,
      "step": 2974
    },
    {
      "epoch": 0.61,
      "grad_norm": 1.460039734840393,
      "learning_rate": 1.3912063134160092e-05,
      "loss": 0.3179,
      "step": 2975
    },
    {
      "epoch": 0.61,
      "grad_norm": 1.382391333580017,
      "learning_rate": 1.3910013323767552e-05,
      "loss": 0.4791,
      "step": 2976
    },
    {
      "epoch": 0.61,
      "grad_norm": 0.8934394121170044,
      "learning_rate": 1.3907963513375014e-05,
      "loss": 0.4082,
      "step": 2977
    },
    {
      "epoch": 0.61,
      "grad_norm": 1.3371071815490723,
      "learning_rate": 1.3905913702982474e-05,
      "loss": 0.4297,
      "step": 2978
    },
    {
      "epoch": 0.61,
      "grad_norm": 0.681488573551178,
      "learning_rate": 1.3903863892589938e-05,
      "loss": 0.589,
      "step": 2979
    },
    {
      "epoch": 0.61,
      "grad_norm": 1.0323200225830078,
      "learning_rate": 1.3901814082197398e-05,
      "loss": 0.5136,
      "step": 2980
    },
    {
      "epoch": 0.61,
      "grad_norm": 1.3000191450119019,
      "learning_rate": 1.3899764271804858e-05,
      "loss": 0.5915,
      "step": 2981
    },
    {
      "epoch": 0.61,
      "grad_norm": 1.8588987588882446,
      "learning_rate": 1.389771446141232e-05,
      "loss": 0.5334,
      "step": 2982
    },
    {
      "epoch": 0.61,
      "grad_norm": 0.8036278486251831,
      "learning_rate": 1.3895664651019782e-05,
      "loss": 0.2912,
      "step": 2983
    },
    {
      "epoch": 0.61,
      "grad_norm": 2.015533208847046,
      "learning_rate": 1.3893614840627244e-05,
      "loss": 0.383,
      "step": 2984
    },
    {
      "epoch": 0.61,
      "grad_norm": 1.3517241477966309,
      "learning_rate": 1.3891565030234704e-05,
      "loss": 0.5561,
      "step": 2985
    },
    {
      "epoch": 0.61,
      "grad_norm": 1.0920885801315308,
      "learning_rate": 1.3889515219842168e-05,
      "loss": 0.5858,
      "step": 2986
    },
    {
      "epoch": 0.61,
      "grad_norm": 1.5641041994094849,
      "learning_rate": 1.3887465409449628e-05,
      "loss": 0.6155,
      "step": 2987
    },
    {
      "epoch": 0.61,
      "grad_norm": 0.9671587944030762,
      "learning_rate": 1.3885415599057088e-05,
      "loss": 0.4565,
      "step": 2988
    },
    {
      "epoch": 0.61,
      "grad_norm": 1.3465473651885986,
      "learning_rate": 1.388336578866455e-05,
      "loss": 0.4815,
      "step": 2989
    },
    {
      "epoch": 0.61,
      "grad_norm": 0.9474124312400818,
      "learning_rate": 1.3881315978272012e-05,
      "loss": 0.3862,
      "step": 2990
    },
    {
      "epoch": 0.61,
      "grad_norm": 0.9592209458351135,
      "learning_rate": 1.3879266167879473e-05,
      "loss": 0.4859,
      "step": 2991
    },
    {
      "epoch": 0.61,
      "grad_norm": 2.1485493183135986,
      "learning_rate": 1.3877216357486934e-05,
      "loss": 0.4658,
      "step": 2992
    },
    {
      "epoch": 0.61,
      "grad_norm": 1.6276341676712036,
      "learning_rate": 1.3875166547094394e-05,
      "loss": 0.4786,
      "step": 2993
    },
    {
      "epoch": 0.61,
      "grad_norm": 1.1385847330093384,
      "learning_rate": 1.3873116736701857e-05,
      "loss": 0.4362,
      "step": 2994
    },
    {
      "epoch": 0.61,
      "grad_norm": 3.3326029777526855,
      "learning_rate": 1.3871066926309318e-05,
      "loss": 0.4502,
      "step": 2995
    },
    {
      "epoch": 0.61,
      "grad_norm": 1.4424391984939575,
      "learning_rate": 1.386901711591678e-05,
      "loss": 0.3608,
      "step": 2996
    },
    {
      "epoch": 0.61,
      "grad_norm": 0.8286874890327454,
      "learning_rate": 1.386696730552424e-05,
      "loss": 0.5094,
      "step": 2997
    },
    {
      "epoch": 0.61,
      "grad_norm": 1.3305922746658325,
      "learning_rate": 1.3864917495131703e-05,
      "loss": 0.4512,
      "step": 2998
    },
    {
      "epoch": 0.61,
      "grad_norm": 1.3251261711120605,
      "learning_rate": 1.3862867684739163e-05,
      "loss": 0.5026,
      "step": 2999
    },
    {
      "epoch": 0.61,
      "grad_norm": 0.8226915001869202,
      "learning_rate": 1.3860817874346623e-05,
      "loss": 0.5125,
      "step": 3000
    },
    {
      "epoch": 0.61,
      "eval_loss": 0.4402588903903961,
      "eval_runtime": 666.2228,
      "eval_samples_per_second": 15.01,
      "eval_steps_per_second": 1.876,
      "step": 3000
    },
    {
      "epoch": 0.61,
      "grad_norm": 1.7118452787399292,
      "learning_rate": 1.3858768063954085e-05,
      "loss": 0.3235,
      "step": 3001
    },
    {
      "epoch": 0.62,
      "grad_norm": 0.5370327234268188,
      "learning_rate": 1.3856718253561547e-05,
      "loss": 0.3355,
      "step": 3002
    },
    {
      "epoch": 0.62,
      "grad_norm": 1.6111513376235962,
      "learning_rate": 1.3854668443169009e-05,
      "loss": 0.547,
      "step": 3003
    },
    {
      "epoch": 0.62,
      "grad_norm": 0.9258527755737305,
      "learning_rate": 1.3852618632776469e-05,
      "loss": 0.4903,
      "step": 3004
    },
    {
      "epoch": 0.62,
      "grad_norm": 0.7372637987136841,
      "learning_rate": 1.385056882238393e-05,
      "loss": 0.333,
      "step": 3005
    },
    {
      "epoch": 0.62,
      "grad_norm": 1.3843035697937012,
      "learning_rate": 1.3848519011991393e-05,
      "loss": 0.4865,
      "step": 3006
    },
    {
      "epoch": 0.62,
      "grad_norm": 1.7832286357879639,
      "learning_rate": 1.3846469201598853e-05,
      "loss": 0.3491,
      "step": 3007
    },
    {
      "epoch": 0.62,
      "grad_norm": 0.6693866848945618,
      "learning_rate": 1.3844419391206315e-05,
      "loss": 0.306,
      "step": 3008
    },
    {
      "epoch": 0.62,
      "grad_norm": 2.8652899265289307,
      "learning_rate": 1.3842369580813775e-05,
      "loss": 0.4811,
      "step": 3009
    },
    {
      "epoch": 0.62,
      "grad_norm": 1.3709357976913452,
      "learning_rate": 1.3840319770421239e-05,
      "loss": 0.3765,
      "step": 3010
    },
    {
      "epoch": 0.62,
      "grad_norm": 1.266127109527588,
      "learning_rate": 1.3838269960028699e-05,
      "loss": 0.4168,
      "step": 3011
    },
    {
      "epoch": 0.62,
      "grad_norm": 0.8916023373603821,
      "learning_rate": 1.3836220149636159e-05,
      "loss": 0.641,
      "step": 3012
    },
    {
      "epoch": 0.62,
      "grad_norm": 2.389186382293701,
      "learning_rate": 1.3834170339243622e-05,
      "loss": 0.4535,
      "step": 3013
    },
    {
      "epoch": 0.62,
      "grad_norm": 1.3151872158050537,
      "learning_rate": 1.3832120528851083e-05,
      "loss": 0.6342,
      "step": 3014
    },
    {
      "epoch": 0.62,
      "grad_norm": 1.8576523065567017,
      "learning_rate": 1.3830070718458544e-05,
      "loss": 0.2965,
      "step": 3015
    },
    {
      "epoch": 0.62,
      "grad_norm": 0.6136784553527832,
      "learning_rate": 1.3828020908066005e-05,
      "loss": 0.3466,
      "step": 3016
    },
    {
      "epoch": 0.62,
      "grad_norm": 1.7547870874404907,
      "learning_rate": 1.3825971097673467e-05,
      "loss": 0.3997,
      "step": 3017
    },
    {
      "epoch": 0.62,
      "grad_norm": 3.0529017448425293,
      "learning_rate": 1.3823921287280928e-05,
      "loss": 0.4659,
      "step": 3018
    },
    {
      "epoch": 0.62,
      "grad_norm": 1.5235143899917603,
      "learning_rate": 1.3821871476888389e-05,
      "loss": 0.3353,
      "step": 3019
    },
    {
      "epoch": 0.62,
      "grad_norm": 0.741762101650238,
      "learning_rate": 1.381982166649585e-05,
      "loss": 0.5131,
      "step": 3020
    },
    {
      "epoch": 0.62,
      "grad_norm": 3.491600513458252,
      "learning_rate": 1.3817771856103312e-05,
      "loss": 0.4636,
      "step": 3021
    },
    {
      "epoch": 0.62,
      "grad_norm": 1.4528976678848267,
      "learning_rate": 1.3815722045710772e-05,
      "loss": 0.4433,
      "step": 3022
    },
    {
      "epoch": 0.62,
      "grad_norm": 0.754015326499939,
      "learning_rate": 1.3813672235318234e-05,
      "loss": 0.5039,
      "step": 3023
    },
    {
      "epoch": 0.62,
      "grad_norm": 1.7775057554244995,
      "learning_rate": 1.3811622424925694e-05,
      "loss": 0.4536,
      "step": 3024
    },
    {
      "epoch": 0.62,
      "grad_norm": 1.3117414712905884,
      "learning_rate": 1.3809572614533158e-05,
      "loss": 0.4269,
      "step": 3025
    },
    {
      "epoch": 0.62,
      "grad_norm": 1.1361814737319946,
      "learning_rate": 1.3807522804140618e-05,
      "loss": 0.5011,
      "step": 3026
    },
    {
      "epoch": 0.62,
      "grad_norm": 1.3085428476333618,
      "learning_rate": 1.380547299374808e-05,
      "loss": 0.4986,
      "step": 3027
    },
    {
      "epoch": 0.62,
      "grad_norm": 0.9058181047439575,
      "learning_rate": 1.380342318335554e-05,
      "loss": 0.4567,
      "step": 3028
    },
    {
      "epoch": 0.62,
      "grad_norm": 2.3659586906433105,
      "learning_rate": 1.3801373372963002e-05,
      "loss": 0.404,
      "step": 3029
    },
    {
      "epoch": 0.62,
      "grad_norm": 0.7341616749763489,
      "learning_rate": 1.3799323562570464e-05,
      "loss": 0.5816,
      "step": 3030
    },
    {
      "epoch": 0.62,
      "grad_norm": 1.0029045343399048,
      "learning_rate": 1.3797273752177924e-05,
      "loss": 0.4407,
      "step": 3031
    },
    {
      "epoch": 0.62,
      "grad_norm": 1.1745084524154663,
      "learning_rate": 1.3795223941785386e-05,
      "loss": 0.4733,
      "step": 3032
    },
    {
      "epoch": 0.62,
      "grad_norm": 0.7844404578208923,
      "learning_rate": 1.3793174131392848e-05,
      "loss": 0.4451,
      "step": 3033
    },
    {
      "epoch": 0.62,
      "grad_norm": 0.7248336672782898,
      "learning_rate": 1.3791124321000308e-05,
      "loss": 0.5147,
      "step": 3034
    },
    {
      "epoch": 0.62,
      "grad_norm": 0.9276901483535767,
      "learning_rate": 1.378907451060777e-05,
      "loss": 0.3776,
      "step": 3035
    },
    {
      "epoch": 0.62,
      "grad_norm": 0.9457794427871704,
      "learning_rate": 1.378702470021523e-05,
      "loss": 0.6112,
      "step": 3036
    },
    {
      "epoch": 0.62,
      "grad_norm": 1.0293060541152954,
      "learning_rate": 1.3784974889822693e-05,
      "loss": 0.5765,
      "step": 3037
    },
    {
      "epoch": 0.62,
      "grad_norm": 0.7489514946937561,
      "learning_rate": 1.3782925079430154e-05,
      "loss": 0.3408,
      "step": 3038
    },
    {
      "epoch": 0.62,
      "grad_norm": 0.9157760739326477,
      "learning_rate": 1.3780875269037614e-05,
      "loss": 0.2802,
      "step": 3039
    },
    {
      "epoch": 0.62,
      "grad_norm": 1.9495868682861328,
      "learning_rate": 1.3778825458645076e-05,
      "loss": 0.5275,
      "step": 3040
    },
    {
      "epoch": 0.62,
      "grad_norm": 1.0952117443084717,
      "learning_rate": 1.3776775648252538e-05,
      "loss": 0.4419,
      "step": 3041
    },
    {
      "epoch": 0.62,
      "grad_norm": 1.068952202796936,
      "learning_rate": 1.377472583786e-05,
      "loss": 0.509,
      "step": 3042
    },
    {
      "epoch": 0.62,
      "grad_norm": 1.3416202068328857,
      "learning_rate": 1.377267602746746e-05,
      "loss": 0.4772,
      "step": 3043
    },
    {
      "epoch": 0.62,
      "grad_norm": 0.9395173788070679,
      "learning_rate": 1.3770626217074923e-05,
      "loss": 0.3895,
      "step": 3044
    },
    {
      "epoch": 0.62,
      "grad_norm": 1.3091652393341064,
      "learning_rate": 1.3768576406682383e-05,
      "loss": 0.4246,
      "step": 3045
    },
    {
      "epoch": 0.62,
      "grad_norm": 0.6997696161270142,
      "learning_rate": 1.3766526596289843e-05,
      "loss": 0.3952,
      "step": 3046
    },
    {
      "epoch": 0.62,
      "grad_norm": 1.039531946182251,
      "learning_rate": 1.3764476785897305e-05,
      "loss": 0.4231,
      "step": 3047
    },
    {
      "epoch": 0.62,
      "grad_norm": 1.6006842851638794,
      "learning_rate": 1.3762426975504767e-05,
      "loss": 0.3184,
      "step": 3048
    },
    {
      "epoch": 0.62,
      "grad_norm": 1.3474599123001099,
      "learning_rate": 1.3760377165112229e-05,
      "loss": 0.3454,
      "step": 3049
    },
    {
      "epoch": 0.62,
      "grad_norm": 0.7877606153488159,
      "learning_rate": 1.3758327354719689e-05,
      "loss": 0.3061,
      "step": 3050
    },
    {
      "epoch": 0.63,
      "grad_norm": 1.6060795783996582,
      "learning_rate": 1.375627754432715e-05,
      "loss": 0.3563,
      "step": 3051
    },
    {
      "epoch": 0.63,
      "grad_norm": 1.4634531736373901,
      "learning_rate": 1.3754227733934613e-05,
      "loss": 0.296,
      "step": 3052
    },
    {
      "epoch": 0.63,
      "grad_norm": 1.2190032005310059,
      "learning_rate": 1.3752177923542073e-05,
      "loss": 0.385,
      "step": 3053
    },
    {
      "epoch": 0.63,
      "grad_norm": 1.202443242073059,
      "learning_rate": 1.3750128113149535e-05,
      "loss": 0.3323,
      "step": 3054
    },
    {
      "epoch": 0.63,
      "grad_norm": 1.6534780263900757,
      "learning_rate": 1.3748078302756995e-05,
      "loss": 0.5218,
      "step": 3055
    },
    {
      "epoch": 0.63,
      "grad_norm": 1.168315052986145,
      "learning_rate": 1.3746028492364459e-05,
      "loss": 0.5083,
      "step": 3056
    },
    {
      "epoch": 0.63,
      "grad_norm": 0.6955147981643677,
      "learning_rate": 1.3743978681971919e-05,
      "loss": 0.3921,
      "step": 3057
    },
    {
      "epoch": 0.63,
      "grad_norm": 0.8577086925506592,
      "learning_rate": 1.3741928871579379e-05,
      "loss": 0.4899,
      "step": 3058
    },
    {
      "epoch": 0.63,
      "grad_norm": 2.5432212352752686,
      "learning_rate": 1.373987906118684e-05,
      "loss": 0.3697,
      "step": 3059
    },
    {
      "epoch": 0.63,
      "grad_norm": 1.2663602828979492,
      "learning_rate": 1.3737829250794303e-05,
      "loss": 0.5495,
      "step": 3060
    },
    {
      "epoch": 0.63,
      "grad_norm": 1.0026028156280518,
      "learning_rate": 1.3735779440401764e-05,
      "loss": 0.6141,
      "step": 3061
    },
    {
      "epoch": 0.63,
      "grad_norm": 1.7722687721252441,
      "learning_rate": 1.3733729630009225e-05,
      "loss": 0.5938,
      "step": 3062
    },
    {
      "epoch": 0.63,
      "grad_norm": 1.3692259788513184,
      "learning_rate": 1.3731679819616685e-05,
      "loss": 0.4933,
      "step": 3063
    },
    {
      "epoch": 0.63,
      "grad_norm": 0.9783884286880493,
      "learning_rate": 1.3729630009224148e-05,
      "loss": 0.4207,
      "step": 3064
    },
    {
      "epoch": 0.63,
      "grad_norm": 1.0338133573532104,
      "learning_rate": 1.3727580198831609e-05,
      "loss": 0.4859,
      "step": 3065
    },
    {
      "epoch": 0.63,
      "grad_norm": 0.7708700895309448,
      "learning_rate": 1.372553038843907e-05,
      "loss": 0.4261,
      "step": 3066
    },
    {
      "epoch": 0.63,
      "grad_norm": 0.9973021149635315,
      "learning_rate": 1.372348057804653e-05,
      "loss": 0.3767,
      "step": 3067
    },
    {
      "epoch": 0.63,
      "grad_norm": 1.1610629558563232,
      "learning_rate": 1.3721430767653994e-05,
      "loss": 0.4837,
      "step": 3068
    },
    {
      "epoch": 0.63,
      "grad_norm": 0.9715977907180786,
      "learning_rate": 1.3719380957261454e-05,
      "loss": 0.477,
      "step": 3069
    },
    {
      "epoch": 0.63,
      "grad_norm": 1.4370630979537964,
      "learning_rate": 1.3717331146868914e-05,
      "loss": 0.4674,
      "step": 3070
    },
    {
      "epoch": 0.63,
      "grad_norm": 1.372572660446167,
      "learning_rate": 1.3715281336476378e-05,
      "loss": 0.4091,
      "step": 3071
    },
    {
      "epoch": 0.63,
      "grad_norm": 0.6597709655761719,
      "learning_rate": 1.3713231526083838e-05,
      "loss": 0.549,
      "step": 3072
    },
    {
      "epoch": 0.63,
      "grad_norm": 0.9958791732788086,
      "learning_rate": 1.37111817156913e-05,
      "loss": 0.5658,
      "step": 3073
    },
    {
      "epoch": 0.63,
      "grad_norm": 1.6562304496765137,
      "learning_rate": 1.370913190529876e-05,
      "loss": 0.4217,
      "step": 3074
    },
    {
      "epoch": 0.63,
      "grad_norm": 1.3084514141082764,
      "learning_rate": 1.3707082094906224e-05,
      "loss": 0.3963,
      "step": 3075
    },
    {
      "epoch": 0.63,
      "grad_norm": 1.2258223295211792,
      "learning_rate": 1.3705032284513684e-05,
      "loss": 0.2663,
      "step": 3076
    },
    {
      "epoch": 0.63,
      "grad_norm": 0.827151894569397,
      "learning_rate": 1.3702982474121144e-05,
      "loss": 0.5,
      "step": 3077
    },
    {
      "epoch": 0.63,
      "grad_norm": 1.7229479551315308,
      "learning_rate": 1.3700932663728606e-05,
      "loss": 0.4143,
      "step": 3078
    },
    {
      "epoch": 0.63,
      "grad_norm": 1.981520414352417,
      "learning_rate": 1.3698882853336068e-05,
      "loss": 0.3476,
      "step": 3079
    },
    {
      "epoch": 0.63,
      "grad_norm": 2.0532190799713135,
      "learning_rate": 1.369683304294353e-05,
      "loss": 0.2569,
      "step": 3080
    },
    {
      "epoch": 0.63,
      "grad_norm": 0.9934936761856079,
      "learning_rate": 1.369478323255099e-05,
      "loss": 0.4713,
      "step": 3081
    },
    {
      "epoch": 0.63,
      "grad_norm": 1.1857309341430664,
      "learning_rate": 1.369273342215845e-05,
      "loss": 0.3195,
      "step": 3082
    },
    {
      "epoch": 0.63,
      "grad_norm": 0.9837716221809387,
      "learning_rate": 1.3690683611765913e-05,
      "loss": 0.5235,
      "step": 3083
    },
    {
      "epoch": 0.63,
      "grad_norm": 1.434292197227478,
      "learning_rate": 1.3688633801373374e-05,
      "loss": 0.4394,
      "step": 3084
    },
    {
      "epoch": 0.63,
      "grad_norm": 1.8640785217285156,
      "learning_rate": 1.3686583990980835e-05,
      "loss": 0.3248,
      "step": 3085
    },
    {
      "epoch": 0.63,
      "grad_norm": 0.9571611881256104,
      "learning_rate": 1.3684534180588296e-05,
      "loss": 0.4174,
      "step": 3086
    },
    {
      "epoch": 0.63,
      "grad_norm": 1.8817106485366821,
      "learning_rate": 1.368248437019576e-05,
      "loss": 0.4174,
      "step": 3087
    },
    {
      "epoch": 0.63,
      "grad_norm": 5.211518287658691,
      "learning_rate": 1.368043455980322e-05,
      "loss": 0.3595,
      "step": 3088
    },
    {
      "epoch": 0.63,
      "grad_norm": 1.29468834400177,
      "learning_rate": 1.367838474941068e-05,
      "loss": 0.4568,
      "step": 3089
    },
    {
      "epoch": 0.63,
      "grad_norm": 0.8504528403282166,
      "learning_rate": 1.3676334939018141e-05,
      "loss": 0.4099,
      "step": 3090
    },
    {
      "epoch": 0.63,
      "grad_norm": 1.4423820972442627,
      "learning_rate": 1.3674285128625603e-05,
      "loss": 0.5825,
      "step": 3091
    },
    {
      "epoch": 0.63,
      "grad_norm": 1.2368022203445435,
      "learning_rate": 1.3672235318233065e-05,
      "loss": 0.4491,
      "step": 3092
    },
    {
      "epoch": 0.63,
      "grad_norm": 1.126774549484253,
      "learning_rate": 1.3670185507840525e-05,
      "loss": 0.4209,
      "step": 3093
    },
    {
      "epoch": 0.63,
      "grad_norm": 1.4213523864746094,
      "learning_rate": 1.3668135697447985e-05,
      "loss": 0.559,
      "step": 3094
    },
    {
      "epoch": 0.63,
      "grad_norm": 0.7923687100410461,
      "learning_rate": 1.3666085887055449e-05,
      "loss": 0.496,
      "step": 3095
    },
    {
      "epoch": 0.63,
      "grad_norm": 1.6408448219299316,
      "learning_rate": 1.3664036076662909e-05,
      "loss": 0.476,
      "step": 3096
    },
    {
      "epoch": 0.63,
      "grad_norm": 1.250044584274292,
      "learning_rate": 1.3661986266270371e-05,
      "loss": 0.446,
      "step": 3097
    },
    {
      "epoch": 0.63,
      "grad_norm": 1.153703212738037,
      "learning_rate": 1.3659936455877831e-05,
      "loss": 0.5851,
      "step": 3098
    },
    {
      "epoch": 0.63,
      "grad_norm": 2.9570629596710205,
      "learning_rate": 1.3657886645485295e-05,
      "loss": 0.3794,
      "step": 3099
    },
    {
      "epoch": 0.64,
      "grad_norm": 4.450995445251465,
      "learning_rate": 1.3655836835092755e-05,
      "loss": 0.4067,
      "step": 3100
    },
    {
      "epoch": 0.64,
      "grad_norm": 3.1843531131744385,
      "learning_rate": 1.3653787024700215e-05,
      "loss": 0.359,
      "step": 3101
    },
    {
      "epoch": 0.64,
      "grad_norm": 1.085842490196228,
      "learning_rate": 1.3651737214307679e-05,
      "loss": 0.5525,
      "step": 3102
    },
    {
      "epoch": 0.64,
      "grad_norm": 2.3734443187713623,
      "learning_rate": 1.3649687403915139e-05,
      "loss": 0.3304,
      "step": 3103
    },
    {
      "epoch": 0.64,
      "grad_norm": 2.9055168628692627,
      "learning_rate": 1.36476375935226e-05,
      "loss": 0.543,
      "step": 3104
    },
    {
      "epoch": 0.64,
      "grad_norm": 1.32173752784729,
      "learning_rate": 1.364558778313006e-05,
      "loss": 0.4289,
      "step": 3105
    },
    {
      "epoch": 0.64,
      "grad_norm": 1.3868454694747925,
      "learning_rate": 1.3643537972737524e-05,
      "loss": 0.4678,
      "step": 3106
    },
    {
      "epoch": 0.64,
      "grad_norm": 1.020079255104065,
      "learning_rate": 1.3641488162344984e-05,
      "loss": 0.5891,
      "step": 3107
    },
    {
      "epoch": 0.64,
      "grad_norm": 3.751713991165161,
      "learning_rate": 1.3639438351952445e-05,
      "loss": 0.4998,
      "step": 3108
    },
    {
      "epoch": 0.64,
      "grad_norm": 1.3443869352340698,
      "learning_rate": 1.3637388541559906e-05,
      "loss": 0.4493,
      "step": 3109
    },
    {
      "epoch": 0.64,
      "grad_norm": 1.1183876991271973,
      "learning_rate": 1.3635338731167368e-05,
      "loss": 0.385,
      "step": 3110
    },
    {
      "epoch": 0.64,
      "grad_norm": 1.1320977210998535,
      "learning_rate": 1.363328892077483e-05,
      "loss": 0.4334,
      "step": 3111
    },
    {
      "epoch": 0.64,
      "grad_norm": 1.8789654970169067,
      "learning_rate": 1.363123911038229e-05,
      "loss": 0.3546,
      "step": 3112
    },
    {
      "epoch": 0.64,
      "grad_norm": 3.2448713779449463,
      "learning_rate": 1.362918929998975e-05,
      "loss": 0.4084,
      "step": 3113
    },
    {
      "epoch": 0.64,
      "grad_norm": 5.380593776702881,
      "learning_rate": 1.3627139489597214e-05,
      "loss": 0.2959,
      "step": 3114
    },
    {
      "epoch": 0.64,
      "grad_norm": 1.4007021188735962,
      "learning_rate": 1.3625089679204674e-05,
      "loss": 0.3697,
      "step": 3115
    },
    {
      "epoch": 0.64,
      "grad_norm": 0.9007571339607239,
      "learning_rate": 1.3623039868812136e-05,
      "loss": 0.4796,
      "step": 3116
    },
    {
      "epoch": 0.64,
      "grad_norm": 2.410979747772217,
      "learning_rate": 1.3620990058419596e-05,
      "loss": 0.3768,
      "step": 3117
    },
    {
      "epoch": 0.64,
      "grad_norm": 0.9742788076400757,
      "learning_rate": 1.361894024802706e-05,
      "loss": 0.5331,
      "step": 3118
    },
    {
      "epoch": 0.64,
      "grad_norm": 1.0041892528533936,
      "learning_rate": 1.361689043763452e-05,
      "loss": 0.3733,
      "step": 3119
    },
    {
      "epoch": 0.64,
      "grad_norm": 1.423859715461731,
      "learning_rate": 1.361484062724198e-05,
      "loss": 0.382,
      "step": 3120
    },
    {
      "epoch": 0.64,
      "grad_norm": 0.9618098735809326,
      "learning_rate": 1.3612790816849442e-05,
      "loss": 0.4349,
      "step": 3121
    },
    {
      "epoch": 0.64,
      "grad_norm": 0.9594182372093201,
      "learning_rate": 1.3610741006456904e-05,
      "loss": 0.3462,
      "step": 3122
    },
    {
      "epoch": 0.64,
      "grad_norm": 2.7004098892211914,
      "learning_rate": 1.3608691196064366e-05,
      "loss": 0.5349,
      "step": 3123
    },
    {
      "epoch": 0.64,
      "grad_norm": 1.5218347311019897,
      "learning_rate": 1.3606641385671826e-05,
      "loss": 0.5157,
      "step": 3124
    },
    {
      "epoch": 0.64,
      "grad_norm": 1.4917515516281128,
      "learning_rate": 1.3604591575279286e-05,
      "loss": 0.3426,
      "step": 3125
    },
    {
      "epoch": 0.64,
      "grad_norm": 1.3612217903137207,
      "learning_rate": 1.360254176488675e-05,
      "loss": 0.5142,
      "step": 3126
    },
    {
      "epoch": 0.64,
      "grad_norm": 1.3939458131790161,
      "learning_rate": 1.360049195449421e-05,
      "loss": 0.3193,
      "step": 3127
    },
    {
      "epoch": 0.64,
      "grad_norm": 1.6820658445358276,
      "learning_rate": 1.3598442144101672e-05,
      "loss": 0.4988,
      "step": 3128
    },
    {
      "epoch": 0.64,
      "grad_norm": 1.0170797109603882,
      "learning_rate": 1.3596392333709132e-05,
      "loss": 0.4453,
      "step": 3129
    },
    {
      "epoch": 0.64,
      "grad_norm": 1.305579662322998,
      "learning_rate": 1.3594342523316595e-05,
      "loss": 0.2746,
      "step": 3130
    },
    {
      "epoch": 0.64,
      "grad_norm": 0.7300389409065247,
      "learning_rate": 1.3592292712924055e-05,
      "loss": 0.5172,
      "step": 3131
    },
    {
      "epoch": 0.64,
      "grad_norm": 1.1685450077056885,
      "learning_rate": 1.3590242902531516e-05,
      "loss": 0.6103,
      "step": 3132
    },
    {
      "epoch": 0.64,
      "grad_norm": 1.2341253757476807,
      "learning_rate": 1.358819309213898e-05,
      "loss": 0.2368,
      "step": 3133
    },
    {
      "epoch": 0.64,
      "grad_norm": 1.6436501741409302,
      "learning_rate": 1.358614328174644e-05,
      "loss": 0.3766,
      "step": 3134
    },
    {
      "epoch": 0.64,
      "grad_norm": 0.7473461031913757,
      "learning_rate": 1.3584093471353901e-05,
      "loss": 0.5215,
      "step": 3135
    },
    {
      "epoch": 0.64,
      "grad_norm": 1.2020269632339478,
      "learning_rate": 1.3582043660961361e-05,
      "loss": 0.4485,
      "step": 3136
    },
    {
      "epoch": 0.64,
      "grad_norm": 1.0880435705184937,
      "learning_rate": 1.3579993850568825e-05,
      "loss": 0.5098,
      "step": 3137
    },
    {
      "epoch": 0.64,
      "grad_norm": 0.9659225940704346,
      "learning_rate": 1.3577944040176285e-05,
      "loss": 0.3437,
      "step": 3138
    },
    {
      "epoch": 0.64,
      "grad_norm": 0.8721094131469727,
      "learning_rate": 1.3575894229783745e-05,
      "loss": 0.3001,
      "step": 3139
    },
    {
      "epoch": 0.64,
      "grad_norm": 3.302615165710449,
      "learning_rate": 1.3573844419391207e-05,
      "loss": 0.4878,
      "step": 3140
    },
    {
      "epoch": 0.64,
      "grad_norm": 1.9175753593444824,
      "learning_rate": 1.3571794608998669e-05,
      "loss": 0.4625,
      "step": 3141
    },
    {
      "epoch": 0.64,
      "grad_norm": 1.7955702543258667,
      "learning_rate": 1.356974479860613e-05,
      "loss": 0.4464,
      "step": 3142
    },
    {
      "epoch": 0.64,
      "grad_norm": 1.5022772550582886,
      "learning_rate": 1.3567694988213591e-05,
      "loss": 0.4028,
      "step": 3143
    },
    {
      "epoch": 0.64,
      "grad_norm": 1.1500905752182007,
      "learning_rate": 1.3565645177821051e-05,
      "loss": 0.402,
      "step": 3144
    },
    {
      "epoch": 0.64,
      "grad_norm": 1.9870564937591553,
      "learning_rate": 1.3563595367428515e-05,
      "loss": 0.4671,
      "step": 3145
    },
    {
      "epoch": 0.64,
      "grad_norm": 0.9883428812026978,
      "learning_rate": 1.3561545557035975e-05,
      "loss": 0.4939,
      "step": 3146
    },
    {
      "epoch": 0.64,
      "grad_norm": 2.922438859939575,
      "learning_rate": 1.3559495746643437e-05,
      "loss": 0.4622,
      "step": 3147
    },
    {
      "epoch": 0.64,
      "grad_norm": 1.8216519355773926,
      "learning_rate": 1.3557445936250897e-05,
      "loss": 0.3633,
      "step": 3148
    },
    {
      "epoch": 0.65,
      "grad_norm": 1.1414976119995117,
      "learning_rate": 1.355539612585836e-05,
      "loss": 0.3804,
      "step": 3149
    },
    {
      "epoch": 0.65,
      "grad_norm": 1.039255142211914,
      "learning_rate": 1.355334631546582e-05,
      "loss": 0.3632,
      "step": 3150
    },
    {
      "epoch": 0.65,
      "grad_norm": 2.4859249591827393,
      "learning_rate": 1.355129650507328e-05,
      "loss": 0.4223,
      "step": 3151
    },
    {
      "epoch": 0.65,
      "grad_norm": 1.011557698249817,
      "learning_rate": 1.3549246694680743e-05,
      "loss": 0.4109,
      "step": 3152
    },
    {
      "epoch": 0.65,
      "grad_norm": 1.5259853601455688,
      "learning_rate": 1.3547196884288204e-05,
      "loss": 0.4641,
      "step": 3153
    },
    {
      "epoch": 0.65,
      "grad_norm": 1.9875127077102661,
      "learning_rate": 1.3545147073895666e-05,
      "loss": 0.4349,
      "step": 3154
    },
    {
      "epoch": 0.65,
      "grad_norm": 1.619063138961792,
      "learning_rate": 1.3543097263503126e-05,
      "loss": 0.5215,
      "step": 3155
    },
    {
      "epoch": 0.65,
      "grad_norm": 1.2719675302505493,
      "learning_rate": 1.3541047453110587e-05,
      "loss": 0.3518,
      "step": 3156
    },
    {
      "epoch": 0.65,
      "grad_norm": 1.0770909786224365,
      "learning_rate": 1.353899764271805e-05,
      "loss": 0.5936,
      "step": 3157
    },
    {
      "epoch": 0.65,
      "grad_norm": 1.0871204137802124,
      "learning_rate": 1.353694783232551e-05,
      "loss": 0.4269,
      "step": 3158
    },
    {
      "epoch": 0.65,
      "grad_norm": 0.857273519039154,
      "learning_rate": 1.3534898021932972e-05,
      "loss": 0.5135,
      "step": 3159
    },
    {
      "epoch": 0.65,
      "grad_norm": 1.2927403450012207,
      "learning_rate": 1.3532848211540434e-05,
      "loss": 0.3255,
      "step": 3160
    },
    {
      "epoch": 0.65,
      "grad_norm": 0.982168436050415,
      "learning_rate": 1.3530798401147896e-05,
      "loss": 0.4202,
      "step": 3161
    },
    {
      "epoch": 0.65,
      "grad_norm": 1.0925315618515015,
      "learning_rate": 1.3528748590755356e-05,
      "loss": 0.5439,
      "step": 3162
    },
    {
      "epoch": 0.65,
      "grad_norm": 1.5515742301940918,
      "learning_rate": 1.3526698780362816e-05,
      "loss": 0.423,
      "step": 3163
    },
    {
      "epoch": 0.65,
      "grad_norm": 1.0143061876296997,
      "learning_rate": 1.352464896997028e-05,
      "loss": 0.5227,
      "step": 3164
    },
    {
      "epoch": 0.65,
      "grad_norm": 2.50174617767334,
      "learning_rate": 1.352259915957774e-05,
      "loss": 0.5238,
      "step": 3165
    },
    {
      "epoch": 0.65,
      "grad_norm": 0.9560314416885376,
      "learning_rate": 1.3520549349185202e-05,
      "loss": 0.4449,
      "step": 3166
    },
    {
      "epoch": 0.65,
      "grad_norm": 1.3926961421966553,
      "learning_rate": 1.3518499538792662e-05,
      "loss": 0.4189,
      "step": 3167
    },
    {
      "epoch": 0.65,
      "grad_norm": 1.2511454820632935,
      "learning_rate": 1.3516449728400126e-05,
      "loss": 0.4461,
      "step": 3168
    },
    {
      "epoch": 0.65,
      "grad_norm": 2.1554744243621826,
      "learning_rate": 1.3514399918007586e-05,
      "loss": 0.4512,
      "step": 3169
    },
    {
      "epoch": 0.65,
      "grad_norm": 2.1775238513946533,
      "learning_rate": 1.3512350107615046e-05,
      "loss": 0.3805,
      "step": 3170
    },
    {
      "epoch": 0.65,
      "grad_norm": 1.471318006515503,
      "learning_rate": 1.3510300297222508e-05,
      "loss": 0.3878,
      "step": 3171
    },
    {
      "epoch": 0.65,
      "grad_norm": 1.0985156297683716,
      "learning_rate": 1.350825048682997e-05,
      "loss": 0.5317,
      "step": 3172
    },
    {
      "epoch": 0.65,
      "grad_norm": 0.9563930630683899,
      "learning_rate": 1.3506200676437431e-05,
      "loss": 0.3233,
      "step": 3173
    },
    {
      "epoch": 0.65,
      "grad_norm": 4.570426940917969,
      "learning_rate": 1.3504150866044892e-05,
      "loss": 0.3265,
      "step": 3174
    },
    {
      "epoch": 0.65,
      "grad_norm": 2.166179895401001,
      "learning_rate": 1.3502101055652352e-05,
      "loss": 0.4683,
      "step": 3175
    },
    {
      "epoch": 0.65,
      "grad_norm": 1.0619157552719116,
      "learning_rate": 1.3500051245259815e-05,
      "loss": 0.4952,
      "step": 3176
    },
    {
      "epoch": 0.65,
      "grad_norm": 1.238838791847229,
      "learning_rate": 1.3498001434867275e-05,
      "loss": 0.5333,
      "step": 3177
    },
    {
      "epoch": 0.65,
      "grad_norm": 1.934213638305664,
      "learning_rate": 1.3495951624474737e-05,
      "loss": 0.416,
      "step": 3178
    },
    {
      "epoch": 0.65,
      "grad_norm": 1.4627450704574585,
      "learning_rate": 1.3493901814082197e-05,
      "loss": 0.2697,
      "step": 3179
    },
    {
      "epoch": 0.65,
      "grad_norm": 1.2697639465332031,
      "learning_rate": 1.3491852003689661e-05,
      "loss": 0.4154,
      "step": 3180
    },
    {
      "epoch": 0.65,
      "grad_norm": 1.4470912218093872,
      "learning_rate": 1.3489802193297121e-05,
      "loss": 0.5368,
      "step": 3181
    },
    {
      "epoch": 0.65,
      "grad_norm": 1.2504465579986572,
      "learning_rate": 1.3487752382904581e-05,
      "loss": 0.5451,
      "step": 3182
    },
    {
      "epoch": 0.65,
      "grad_norm": 1.6628053188323975,
      "learning_rate": 1.3485702572512043e-05,
      "loss": 0.4727,
      "step": 3183
    },
    {
      "epoch": 0.65,
      "grad_norm": 1.1735395193099976,
      "learning_rate": 1.3483652762119505e-05,
      "loss": 0.5612,
      "step": 3184
    },
    {
      "epoch": 0.65,
      "grad_norm": 2.6043245792388916,
      "learning_rate": 1.3481602951726967e-05,
      "loss": 0.5405,
      "step": 3185
    },
    {
      "epoch": 0.65,
      "grad_norm": 1.2823443412780762,
      "learning_rate": 1.3479553141334427e-05,
      "loss": 0.3837,
      "step": 3186
    },
    {
      "epoch": 0.65,
      "grad_norm": 2.253892660140991,
      "learning_rate": 1.3477503330941887e-05,
      "loss": 0.4435,
      "step": 3187
    },
    {
      "epoch": 0.65,
      "grad_norm": 1.318231463432312,
      "learning_rate": 1.347545352054935e-05,
      "loss": 0.4343,
      "step": 3188
    },
    {
      "epoch": 0.65,
      "grad_norm": 1.7863202095031738,
      "learning_rate": 1.3473403710156811e-05,
      "loss": 0.4783,
      "step": 3189
    },
    {
      "epoch": 0.65,
      "grad_norm": 0.981692373752594,
      "learning_rate": 1.3471353899764273e-05,
      "loss": 0.4592,
      "step": 3190
    },
    {
      "epoch": 0.65,
      "grad_norm": 1.188307762145996,
      "learning_rate": 1.3469304089371735e-05,
      "loss": 0.4764,
      "step": 3191
    },
    {
      "epoch": 0.65,
      "grad_norm": 2.7547409534454346,
      "learning_rate": 1.3467254278979197e-05,
      "loss": 0.3018,
      "step": 3192
    },
    {
      "epoch": 0.65,
      "grad_norm": 1.8231779336929321,
      "learning_rate": 1.3465204468586657e-05,
      "loss": 0.4654,
      "step": 3193
    },
    {
      "epoch": 0.65,
      "grad_norm": 0.7960487604141235,
      "learning_rate": 1.3463154658194117e-05,
      "loss": 0.3712,
      "step": 3194
    },
    {
      "epoch": 0.65,
      "grad_norm": 0.792198657989502,
      "learning_rate": 1.346110484780158e-05,
      "loss": 0.5607,
      "step": 3195
    },
    {
      "epoch": 0.65,
      "grad_norm": 3.341536283493042,
      "learning_rate": 1.345905503740904e-05,
      "loss": 0.4604,
      "step": 3196
    },
    {
      "epoch": 0.65,
      "grad_norm": 1.0249704122543335,
      "learning_rate": 1.3457005227016502e-05,
      "loss": 0.4612,
      "step": 3197
    },
    {
      "epoch": 0.66,
      "grad_norm": 0.9006132483482361,
      "learning_rate": 1.3454955416623963e-05,
      "loss": 0.4637,
      "step": 3198
    },
    {
      "epoch": 0.66,
      "grad_norm": 1.0540074110031128,
      "learning_rate": 1.3452905606231426e-05,
      "loss": 0.4307,
      "step": 3199
    },
    {
      "epoch": 0.66,
      "grad_norm": 1.1692636013031006,
      "learning_rate": 1.3450855795838886e-05,
      "loss": 0.3199,
      "step": 3200
    },
    {
      "epoch": 0.66,
      "grad_norm": 1.0593918561935425,
      "learning_rate": 1.3448805985446346e-05,
      "loss": 0.465,
      "step": 3201
    },
    {
      "epoch": 0.66,
      "grad_norm": 0.9304012060165405,
      "learning_rate": 1.3446756175053808e-05,
      "loss": 0.4463,
      "step": 3202
    },
    {
      "epoch": 0.66,
      "grad_norm": 1.9278751611709595,
      "learning_rate": 1.344470636466127e-05,
      "loss": 0.4957,
      "step": 3203
    },
    {
      "epoch": 0.66,
      "grad_norm": 1.5444520711898804,
      "learning_rate": 1.3442656554268732e-05,
      "loss": 0.4121,
      "step": 3204
    },
    {
      "epoch": 0.66,
      "grad_norm": 2.055636167526245,
      "learning_rate": 1.3440606743876192e-05,
      "loss": 0.3418,
      "step": 3205
    },
    {
      "epoch": 0.66,
      "grad_norm": 1.2809547185897827,
      "learning_rate": 1.3438556933483652e-05,
      "loss": 0.3784,
      "step": 3206
    },
    {
      "epoch": 0.66,
      "grad_norm": 0.862556517124176,
      "learning_rate": 1.3436507123091116e-05,
      "loss": 0.4741,
      "step": 3207
    },
    {
      "epoch": 0.66,
      "grad_norm": 1.0458990335464478,
      "learning_rate": 1.3434457312698576e-05,
      "loss": 0.4118,
      "step": 3208
    },
    {
      "epoch": 0.66,
      "grad_norm": 1.1568117141723633,
      "learning_rate": 1.3432407502306038e-05,
      "loss": 0.3935,
      "step": 3209
    },
    {
      "epoch": 0.66,
      "grad_norm": 1.2595906257629395,
      "learning_rate": 1.3430357691913498e-05,
      "loss": 0.38,
      "step": 3210
    },
    {
      "epoch": 0.66,
      "grad_norm": 0.9215636253356934,
      "learning_rate": 1.3428307881520962e-05,
      "loss": 0.4888,
      "step": 3211
    },
    {
      "epoch": 0.66,
      "grad_norm": 3.8437273502349854,
      "learning_rate": 1.3426258071128422e-05,
      "loss": 0.4193,
      "step": 3212
    },
    {
      "epoch": 0.66,
      "grad_norm": 2.2321386337280273,
      "learning_rate": 1.3424208260735882e-05,
      "loss": 0.3645,
      "step": 3213
    },
    {
      "epoch": 0.66,
      "grad_norm": 1.1852225065231323,
      "learning_rate": 1.3422158450343344e-05,
      "loss": 0.5817,
      "step": 3214
    },
    {
      "epoch": 0.66,
      "grad_norm": 1.9732359647750854,
      "learning_rate": 1.3420108639950806e-05,
      "loss": 0.3643,
      "step": 3215
    },
    {
      "epoch": 0.66,
      "grad_norm": 1.2606452703475952,
      "learning_rate": 1.3418058829558268e-05,
      "loss": 0.4394,
      "step": 3216
    },
    {
      "epoch": 0.66,
      "grad_norm": 1.6116652488708496,
      "learning_rate": 1.3416009019165728e-05,
      "loss": 0.4368,
      "step": 3217
    },
    {
      "epoch": 0.66,
      "grad_norm": 1.6862163543701172,
      "learning_rate": 1.3413959208773188e-05,
      "loss": 0.3748,
      "step": 3218
    },
    {
      "epoch": 0.66,
      "grad_norm": 3.9982120990753174,
      "learning_rate": 1.3411909398380651e-05,
      "loss": 0.4183,
      "step": 3219
    },
    {
      "epoch": 0.66,
      "grad_norm": 2.484661340713501,
      "learning_rate": 1.3409859587988112e-05,
      "loss": 0.3285,
      "step": 3220
    },
    {
      "epoch": 0.66,
      "grad_norm": 0.9371450543403625,
      "learning_rate": 1.3407809777595573e-05,
      "loss": 0.4144,
      "step": 3221
    },
    {
      "epoch": 0.66,
      "grad_norm": 1.8941843509674072,
      "learning_rate": 1.3405759967203035e-05,
      "loss": 0.3765,
      "step": 3222
    },
    {
      "epoch": 0.66,
      "grad_norm": 1.4539623260498047,
      "learning_rate": 1.3403710156810497e-05,
      "loss": 0.5599,
      "step": 3223
    },
    {
      "epoch": 0.66,
      "grad_norm": 0.965200662612915,
      "learning_rate": 1.3401660346417957e-05,
      "loss": 0.4821,
      "step": 3224
    },
    {
      "epoch": 0.66,
      "grad_norm": 1.400273084640503,
      "learning_rate": 1.3399610536025417e-05,
      "loss": 0.3852,
      "step": 3225
    },
    {
      "epoch": 0.66,
      "grad_norm": 1.0732389688491821,
      "learning_rate": 1.3397560725632881e-05,
      "loss": 0.602,
      "step": 3226
    },
    {
      "epoch": 0.66,
      "grad_norm": 1.2693148851394653,
      "learning_rate": 1.3395510915240341e-05,
      "loss": 0.4542,
      "step": 3227
    },
    {
      "epoch": 0.66,
      "grad_norm": 1.5259195566177368,
      "learning_rate": 1.3393461104847803e-05,
      "loss": 0.5496,
      "step": 3228
    },
    {
      "epoch": 0.66,
      "grad_norm": 2.3749759197235107,
      "learning_rate": 1.3391411294455263e-05,
      "loss": 0.5017,
      "step": 3229
    },
    {
      "epoch": 0.66,
      "grad_norm": 1.1451456546783447,
      "learning_rate": 1.3389361484062727e-05,
      "loss": 0.487,
      "step": 3230
    },
    {
      "epoch": 0.66,
      "grad_norm": 1.199716567993164,
      "learning_rate": 1.3387311673670187e-05,
      "loss": 0.393,
      "step": 3231
    },
    {
      "epoch": 0.66,
      "grad_norm": 1.8374247550964355,
      "learning_rate": 1.3385261863277647e-05,
      "loss": 0.4174,
      "step": 3232
    },
    {
      "epoch": 0.66,
      "grad_norm": 1.5341527462005615,
      "learning_rate": 1.3383212052885109e-05,
      "loss": 0.3474,
      "step": 3233
    },
    {
      "epoch": 0.66,
      "grad_norm": 1.085634469985962,
      "learning_rate": 1.338116224249257e-05,
      "loss": 0.3423,
      "step": 3234
    },
    {
      "epoch": 0.66,
      "grad_norm": 1.2090693712234497,
      "learning_rate": 1.3379112432100033e-05,
      "loss": 0.399,
      "step": 3235
    },
    {
      "epoch": 0.66,
      "grad_norm": 1.0889902114868164,
      "learning_rate": 1.3377062621707493e-05,
      "loss": 0.4674,
      "step": 3236
    },
    {
      "epoch": 0.66,
      "grad_norm": 0.723977267742157,
      "learning_rate": 1.3375012811314953e-05,
      "loss": 0.4362,
      "step": 3237
    },
    {
      "epoch": 0.66,
      "grad_norm": 1.1653523445129395,
      "learning_rate": 1.3372963000922416e-05,
      "loss": 0.4597,
      "step": 3238
    },
    {
      "epoch": 0.66,
      "grad_norm": 2.064802408218384,
      "learning_rate": 1.3370913190529877e-05,
      "loss": 0.3459,
      "step": 3239
    },
    {
      "epoch": 0.66,
      "grad_norm": 1.1725218296051025,
      "learning_rate": 1.3368863380137339e-05,
      "loss": 0.4786,
      "step": 3240
    },
    {
      "epoch": 0.66,
      "grad_norm": 1.4921669960021973,
      "learning_rate": 1.3366813569744799e-05,
      "loss": 0.4167,
      "step": 3241
    },
    {
      "epoch": 0.66,
      "grad_norm": 1.3027160167694092,
      "learning_rate": 1.3364763759352262e-05,
      "loss": 0.3531,
      "step": 3242
    },
    {
      "epoch": 0.66,
      "grad_norm": 0.8373923897743225,
      "learning_rate": 1.3362713948959722e-05,
      "loss": 0.4308,
      "step": 3243
    },
    {
      "epoch": 0.66,
      "grad_norm": 1.3523139953613281,
      "learning_rate": 1.3360664138567183e-05,
      "loss": 0.4235,
      "step": 3244
    },
    {
      "epoch": 0.66,
      "grad_norm": 1.622164249420166,
      "learning_rate": 1.3358614328174644e-05,
      "loss": 0.3896,
      "step": 3245
    },
    {
      "epoch": 0.67,
      "grad_norm": 1.3003489971160889,
      "learning_rate": 1.3356564517782106e-05,
      "loss": 0.4148,
      "step": 3246
    },
    {
      "epoch": 0.67,
      "grad_norm": 1.2882450819015503,
      "learning_rate": 1.3354514707389568e-05,
      "loss": 0.3806,
      "step": 3247
    },
    {
      "epoch": 0.67,
      "grad_norm": 1.0181479454040527,
      "learning_rate": 1.3352464896997028e-05,
      "loss": 0.4408,
      "step": 3248
    },
    {
      "epoch": 0.67,
      "grad_norm": 1.1234359741210938,
      "learning_rate": 1.3350415086604492e-05,
      "loss": 0.4037,
      "step": 3249
    },
    {
      "epoch": 0.67,
      "grad_norm": 1.2732840776443481,
      "learning_rate": 1.3348365276211952e-05,
      "loss": 0.32,
      "step": 3250
    },
    {
      "epoch": 0.67,
      "grad_norm": 1.2855329513549805,
      "learning_rate": 1.3346315465819412e-05,
      "loss": 0.5444,
      "step": 3251
    },
    {
      "epoch": 0.67,
      "grad_norm": 0.8513709306716919,
      "learning_rate": 1.3344265655426874e-05,
      "loss": 0.3699,
      "step": 3252
    },
    {
      "epoch": 0.67,
      "grad_norm": 0.922534167766571,
      "learning_rate": 1.3342215845034336e-05,
      "loss": 0.3663,
      "step": 3253
    },
    {
      "epoch": 0.67,
      "grad_norm": 1.2581547498703003,
      "learning_rate": 1.3340166034641798e-05,
      "loss": 0.3895,
      "step": 3254
    },
    {
      "epoch": 0.67,
      "grad_norm": 1.113599181175232,
      "learning_rate": 1.3338116224249258e-05,
      "loss": 0.4667,
      "step": 3255
    },
    {
      "epoch": 0.67,
      "grad_norm": 1.810319423675537,
      "learning_rate": 1.3336066413856718e-05,
      "loss": 0.4608,
      "step": 3256
    },
    {
      "epoch": 0.67,
      "grad_norm": 1.534239411354065,
      "learning_rate": 1.3334016603464182e-05,
      "loss": 0.3317,
      "step": 3257
    },
    {
      "epoch": 0.67,
      "grad_norm": 1.0220638513565063,
      "learning_rate": 1.3331966793071642e-05,
      "loss": 0.4513,
      "step": 3258
    },
    {
      "epoch": 0.67,
      "grad_norm": 0.921282947063446,
      "learning_rate": 1.3329916982679104e-05,
      "loss": 0.3647,
      "step": 3259
    },
    {
      "epoch": 0.67,
      "grad_norm": 0.9442595839500427,
      "learning_rate": 1.3327867172286564e-05,
      "loss": 0.5356,
      "step": 3260
    },
    {
      "epoch": 0.67,
      "grad_norm": 1.1223597526550293,
      "learning_rate": 1.3325817361894027e-05,
      "loss": 0.4349,
      "step": 3261
    },
    {
      "epoch": 0.67,
      "grad_norm": 0.84290611743927,
      "learning_rate": 1.3323767551501487e-05,
      "loss": 0.3633,
      "step": 3262
    },
    {
      "epoch": 0.67,
      "grad_norm": 1.1026328802108765,
      "learning_rate": 1.3321717741108948e-05,
      "loss": 0.5474,
      "step": 3263
    },
    {
      "epoch": 0.67,
      "grad_norm": 0.9097306132316589,
      "learning_rate": 1.331966793071641e-05,
      "loss": 0.5316,
      "step": 3264
    },
    {
      "epoch": 0.67,
      "grad_norm": 1.4350990056991577,
      "learning_rate": 1.3317618120323871e-05,
      "loss": 0.3888,
      "step": 3265
    },
    {
      "epoch": 0.67,
      "grad_norm": 1.6583044528961182,
      "learning_rate": 1.3315568309931333e-05,
      "loss": 0.3883,
      "step": 3266
    },
    {
      "epoch": 0.67,
      "grad_norm": 0.9251955151557922,
      "learning_rate": 1.3313518499538793e-05,
      "loss": 0.5443,
      "step": 3267
    },
    {
      "epoch": 0.67,
      "grad_norm": 0.8471166491508484,
      "learning_rate": 1.3311468689146254e-05,
      "loss": 0.4932,
      "step": 3268
    },
    {
      "epoch": 0.67,
      "grad_norm": 1.0482958555221558,
      "learning_rate": 1.3309418878753717e-05,
      "loss": 0.3952,
      "step": 3269
    },
    {
      "epoch": 0.67,
      "grad_norm": 1.0053738355636597,
      "learning_rate": 1.3307369068361177e-05,
      "loss": 0.3573,
      "step": 3270
    },
    {
      "epoch": 0.67,
      "grad_norm": 0.720342218875885,
      "learning_rate": 1.3305319257968639e-05,
      "loss": 0.3859,
      "step": 3271
    },
    {
      "epoch": 0.67,
      "grad_norm": 0.8974020481109619,
      "learning_rate": 1.33032694475761e-05,
      "loss": 0.416,
      "step": 3272
    },
    {
      "epoch": 0.67,
      "grad_norm": 0.9373469948768616,
      "learning_rate": 1.3301219637183563e-05,
      "loss": 0.3486,
      "step": 3273
    },
    {
      "epoch": 0.67,
      "grad_norm": 2.5907399654388428,
      "learning_rate": 1.3299169826791023e-05,
      "loss": 0.4038,
      "step": 3274
    },
    {
      "epoch": 0.67,
      "grad_norm": 1.7868229150772095,
      "learning_rate": 1.3297120016398483e-05,
      "loss": 0.4288,
      "step": 3275
    },
    {
      "epoch": 0.67,
      "grad_norm": 1.1741375923156738,
      "learning_rate": 1.3295070206005945e-05,
      "loss": 0.3411,
      "step": 3276
    },
    {
      "epoch": 0.67,
      "grad_norm": 2.2863759994506836,
      "learning_rate": 1.3293020395613407e-05,
      "loss": 0.5075,
      "step": 3277
    },
    {
      "epoch": 0.67,
      "grad_norm": 1.121999740600586,
      "learning_rate": 1.3290970585220869e-05,
      "loss": 0.4287,
      "step": 3278
    },
    {
      "epoch": 0.67,
      "grad_norm": 1.0912326574325562,
      "learning_rate": 1.3288920774828329e-05,
      "loss": 0.3496,
      "step": 3279
    },
    {
      "epoch": 0.67,
      "grad_norm": 1.517080545425415,
      "learning_rate": 1.3286870964435792e-05,
      "loss": 0.4513,
      "step": 3280
    },
    {
      "epoch": 0.67,
      "grad_norm": 1.7000190019607544,
      "learning_rate": 1.3284821154043253e-05,
      "loss": 0.4566,
      "step": 3281
    },
    {
      "epoch": 0.67,
      "grad_norm": 1.3254953622817993,
      "learning_rate": 1.3282771343650713e-05,
      "loss": 0.4179,
      "step": 3282
    },
    {
      "epoch": 0.67,
      "grad_norm": 1.7275335788726807,
      "learning_rate": 1.3280721533258175e-05,
      "loss": 0.3568,
      "step": 3283
    },
    {
      "epoch": 0.67,
      "grad_norm": 1.76888906955719,
      "learning_rate": 1.3278671722865636e-05,
      "loss": 0.3104,
      "step": 3284
    },
    {
      "epoch": 0.67,
      "grad_norm": 1.336775541305542,
      "learning_rate": 1.3276621912473098e-05,
      "loss": 0.5458,
      "step": 3285
    },
    {
      "epoch": 0.67,
      "grad_norm": 0.8690446615219116,
      "learning_rate": 1.3274572102080558e-05,
      "loss": 0.5061,
      "step": 3286
    },
    {
      "epoch": 0.67,
      "grad_norm": 1.4120571613311768,
      "learning_rate": 1.3272522291688019e-05,
      "loss": 0.5011,
      "step": 3287
    },
    {
      "epoch": 0.67,
      "grad_norm": 0.8289677500724792,
      "learning_rate": 1.3270472481295482e-05,
      "loss": 0.514,
      "step": 3288
    },
    {
      "epoch": 0.67,
      "grad_norm": 1.041569709777832,
      "learning_rate": 1.3268422670902942e-05,
      "loss": 0.3333,
      "step": 3289
    },
    {
      "epoch": 0.67,
      "grad_norm": 1.572418212890625,
      "learning_rate": 1.3266372860510404e-05,
      "loss": 0.4998,
      "step": 3290
    },
    {
      "epoch": 0.67,
      "grad_norm": 1.9599080085754395,
      "learning_rate": 1.3264323050117864e-05,
      "loss": 0.5876,
      "step": 3291
    },
    {
      "epoch": 0.67,
      "grad_norm": 3.6392641067504883,
      "learning_rate": 1.3262273239725328e-05,
      "loss": 0.5289,
      "step": 3292
    },
    {
      "epoch": 0.67,
      "grad_norm": 1.8561010360717773,
      "learning_rate": 1.3260223429332788e-05,
      "loss": 0.3709,
      "step": 3293
    },
    {
      "epoch": 0.67,
      "grad_norm": 1.1650625467300415,
      "learning_rate": 1.3258173618940248e-05,
      "loss": 0.4785,
      "step": 3294
    },
    {
      "epoch": 0.68,
      "grad_norm": 3.6261789798736572,
      "learning_rate": 1.325612380854771e-05,
      "loss": 0.4926,
      "step": 3295
    },
    {
      "epoch": 0.68,
      "grad_norm": 1.0352792739868164,
      "learning_rate": 1.3254073998155172e-05,
      "loss": 0.4513,
      "step": 3296
    },
    {
      "epoch": 0.68,
      "grad_norm": 0.8875322341918945,
      "learning_rate": 1.3252024187762634e-05,
      "loss": 0.5845,
      "step": 3297
    },
    {
      "epoch": 0.68,
      "grad_norm": 1.2386583089828491,
      "learning_rate": 1.3249974377370094e-05,
      "loss": 0.3734,
      "step": 3298
    },
    {
      "epoch": 0.68,
      "grad_norm": 1.1799386739730835,
      "learning_rate": 1.3247924566977554e-05,
      "loss": 0.4374,
      "step": 3299
    },
    {
      "epoch": 0.68,
      "grad_norm": 1.2170300483703613,
      "learning_rate": 1.3245874756585018e-05,
      "loss": 0.4222,
      "step": 3300
    },
    {
      "epoch": 0.68,
      "grad_norm": 1.4784661531448364,
      "learning_rate": 1.3243824946192478e-05,
      "loss": 0.4358,
      "step": 3301
    },
    {
      "epoch": 0.68,
      "grad_norm": 1.7976667881011963,
      "learning_rate": 1.324177513579994e-05,
      "loss": 0.3041,
      "step": 3302
    },
    {
      "epoch": 0.68,
      "grad_norm": 0.8794077634811401,
      "learning_rate": 1.32397253254074e-05,
      "loss": 0.3894,
      "step": 3303
    },
    {
      "epoch": 0.68,
      "grad_norm": 1.4494571685791016,
      "learning_rate": 1.3237675515014863e-05,
      "loss": 0.3581,
      "step": 3304
    },
    {
      "epoch": 0.68,
      "grad_norm": 0.9784459471702576,
      "learning_rate": 1.3235625704622324e-05,
      "loss": 0.3331,
      "step": 3305
    },
    {
      "epoch": 0.68,
      "grad_norm": 1.8846062421798706,
      "learning_rate": 1.3233575894229784e-05,
      "loss": 0.3087,
      "step": 3306
    },
    {
      "epoch": 0.68,
      "grad_norm": 3.0458076000213623,
      "learning_rate": 1.3231526083837247e-05,
      "loss": 0.4119,
      "step": 3307
    },
    {
      "epoch": 0.68,
      "grad_norm": 1.806411862373352,
      "learning_rate": 1.3229476273444707e-05,
      "loss": 0.4243,
      "step": 3308
    },
    {
      "epoch": 0.68,
      "grad_norm": 0.6447246074676514,
      "learning_rate": 1.322742646305217e-05,
      "loss": 0.322,
      "step": 3309
    },
    {
      "epoch": 0.68,
      "grad_norm": 1.6133763790130615,
      "learning_rate": 1.322537665265963e-05,
      "loss": 0.3878,
      "step": 3310
    },
    {
      "epoch": 0.68,
      "grad_norm": 2.1785173416137695,
      "learning_rate": 1.3223326842267093e-05,
      "loss": 0.392,
      "step": 3311
    },
    {
      "epoch": 0.68,
      "grad_norm": 1.1340643167495728,
      "learning_rate": 1.3221277031874553e-05,
      "loss": 0.5132,
      "step": 3312
    },
    {
      "epoch": 0.68,
      "grad_norm": 0.9593860507011414,
      "learning_rate": 1.3219227221482013e-05,
      "loss": 0.4695,
      "step": 3313
    },
    {
      "epoch": 0.68,
      "grad_norm": 1.7855864763259888,
      "learning_rate": 1.3217177411089475e-05,
      "loss": 0.3872,
      "step": 3314
    },
    {
      "epoch": 0.68,
      "grad_norm": 1.960689902305603,
      "learning_rate": 1.3215127600696937e-05,
      "loss": 0.4486,
      "step": 3315
    },
    {
      "epoch": 0.68,
      "grad_norm": 1.5914522409439087,
      "learning_rate": 1.3213077790304399e-05,
      "loss": 0.5308,
      "step": 3316
    },
    {
      "epoch": 0.68,
      "grad_norm": 1.5749140977859497,
      "learning_rate": 1.3211027979911859e-05,
      "loss": 0.3082,
      "step": 3317
    },
    {
      "epoch": 0.68,
      "grad_norm": 1.0635666847229004,
      "learning_rate": 1.320897816951932e-05,
      "loss": 0.4049,
      "step": 3318
    },
    {
      "epoch": 0.68,
      "grad_norm": 1.1819519996643066,
      "learning_rate": 1.3206928359126783e-05,
      "loss": 0.5733,
      "step": 3319
    },
    {
      "epoch": 0.68,
      "grad_norm": 1.650128960609436,
      "learning_rate": 1.3204878548734243e-05,
      "loss": 0.4501,
      "step": 3320
    },
    {
      "epoch": 0.68,
      "grad_norm": 1.7173113822937012,
      "learning_rate": 1.3202828738341705e-05,
      "loss": 0.4691,
      "step": 3321
    },
    {
      "epoch": 0.68,
      "grad_norm": 1.3796216249465942,
      "learning_rate": 1.3200778927949165e-05,
      "loss": 0.3579,
      "step": 3322
    },
    {
      "epoch": 0.68,
      "grad_norm": 2.9894163608551025,
      "learning_rate": 1.3198729117556629e-05,
      "loss": 0.4221,
      "step": 3323
    },
    {
      "epoch": 0.68,
      "grad_norm": 1.022179126739502,
      "learning_rate": 1.3196679307164089e-05,
      "loss": 0.4467,
      "step": 3324
    },
    {
      "epoch": 0.68,
      "grad_norm": 1.4076696634292603,
      "learning_rate": 1.3194629496771549e-05,
      "loss": 0.4673,
      "step": 3325
    },
    {
      "epoch": 0.68,
      "grad_norm": 2.016104221343994,
      "learning_rate": 1.319257968637901e-05,
      "loss": 0.4691,
      "step": 3326
    },
    {
      "epoch": 0.68,
      "grad_norm": 1.810002088546753,
      "learning_rate": 1.3190529875986473e-05,
      "loss": 0.4616,
      "step": 3327
    },
    {
      "epoch": 0.68,
      "grad_norm": 0.9638830423355103,
      "learning_rate": 1.3188480065593934e-05,
      "loss": 0.4458,
      "step": 3328
    },
    {
      "epoch": 0.68,
      "grad_norm": 4.2810163497924805,
      "learning_rate": 1.3186430255201395e-05,
      "loss": 0.483,
      "step": 3329
    },
    {
      "epoch": 0.68,
      "grad_norm": 2.271777629852295,
      "learning_rate": 1.3184380444808855e-05,
      "loss": 0.5281,
      "step": 3330
    },
    {
      "epoch": 0.68,
      "grad_norm": 1.2541760206222534,
      "learning_rate": 1.3182330634416318e-05,
      "loss": 0.4865,
      "step": 3331
    },
    {
      "epoch": 0.68,
      "grad_norm": 0.8886200785636902,
      "learning_rate": 1.3180280824023778e-05,
      "loss": 0.4472,
      "step": 3332
    },
    {
      "epoch": 0.68,
      "grad_norm": 3.9822936058044434,
      "learning_rate": 1.317823101363124e-05,
      "loss": 0.4498,
      "step": 3333
    },
    {
      "epoch": 0.68,
      "grad_norm": 2.1719846725463867,
      "learning_rate": 1.31761812032387e-05,
      "loss": 0.6077,
      "step": 3334
    },
    {
      "epoch": 0.68,
      "grad_norm": 0.8656853437423706,
      "learning_rate": 1.3174131392846164e-05,
      "loss": 0.4268,
      "step": 3335
    },
    {
      "epoch": 0.68,
      "grad_norm": 1.858741283416748,
      "learning_rate": 1.3172081582453624e-05,
      "loss": 0.5493,
      "step": 3336
    },
    {
      "epoch": 0.68,
      "grad_norm": 1.9951550960540771,
      "learning_rate": 1.3170031772061084e-05,
      "loss": 0.5047,
      "step": 3337
    },
    {
      "epoch": 0.68,
      "grad_norm": 1.5808839797973633,
      "learning_rate": 1.3167981961668548e-05,
      "loss": 0.3093,
      "step": 3338
    },
    {
      "epoch": 0.68,
      "grad_norm": 1.8196306228637695,
      "learning_rate": 1.3165932151276008e-05,
      "loss": 0.4392,
      "step": 3339
    },
    {
      "epoch": 0.68,
      "grad_norm": 1.7113209962844849,
      "learning_rate": 1.316388234088347e-05,
      "loss": 0.399,
      "step": 3340
    },
    {
      "epoch": 0.68,
      "grad_norm": 0.8961384296417236,
      "learning_rate": 1.316183253049093e-05,
      "loss": 0.5419,
      "step": 3341
    },
    {
      "epoch": 0.68,
      "grad_norm": 1.3890641927719116,
      "learning_rate": 1.3159782720098394e-05,
      "loss": 0.2214,
      "step": 3342
    },
    {
      "epoch": 0.68,
      "grad_norm": 1.3143881559371948,
      "learning_rate": 1.3157732909705854e-05,
      "loss": 0.4517,
      "step": 3343
    },
    {
      "epoch": 0.69,
      "grad_norm": 0.8788685202598572,
      "learning_rate": 1.3155683099313314e-05,
      "loss": 0.407,
      "step": 3344
    },
    {
      "epoch": 0.69,
      "grad_norm": 1.4213106632232666,
      "learning_rate": 1.3153633288920776e-05,
      "loss": 0.4054,
      "step": 3345
    },
    {
      "epoch": 0.69,
      "grad_norm": 2.4457647800445557,
      "learning_rate": 1.3151583478528238e-05,
      "loss": 0.3915,
      "step": 3346
    },
    {
      "epoch": 0.69,
      "grad_norm": 1.6927454471588135,
      "learning_rate": 1.31495336681357e-05,
      "loss": 0.5125,
      "step": 3347
    },
    {
      "epoch": 0.69,
      "grad_norm": 1.5160086154937744,
      "learning_rate": 1.314748385774316e-05,
      "loss": 0.4211,
      "step": 3348
    },
    {
      "epoch": 0.69,
      "grad_norm": 1.0836594104766846,
      "learning_rate": 1.314543404735062e-05,
      "loss": 0.4903,
      "step": 3349
    },
    {
      "epoch": 0.69,
      "grad_norm": 0.8135381937026978,
      "learning_rate": 1.3143384236958083e-05,
      "loss": 0.4294,
      "step": 3350
    },
    {
      "epoch": 0.69,
      "grad_norm": 0.5821081399917603,
      "learning_rate": 1.3141334426565544e-05,
      "loss": 0.2492,
      "step": 3351
    },
    {
      "epoch": 0.69,
      "grad_norm": 2.7263076305389404,
      "learning_rate": 1.3139284616173005e-05,
      "loss": 0.379,
      "step": 3352
    },
    {
      "epoch": 0.69,
      "grad_norm": 1.1576886177062988,
      "learning_rate": 1.3137234805780466e-05,
      "loss": 0.4851,
      "step": 3353
    },
    {
      "epoch": 0.69,
      "grad_norm": 1.047685980796814,
      "learning_rate": 1.313518499538793e-05,
      "loss": 0.517,
      "step": 3354
    },
    {
      "epoch": 0.69,
      "grad_norm": 2.0708093643188477,
      "learning_rate": 1.313313518499539e-05,
      "loss": 0.4289,
      "step": 3355
    },
    {
      "epoch": 0.69,
      "grad_norm": 0.957219123840332,
      "learning_rate": 1.313108537460285e-05,
      "loss": 0.4152,
      "step": 3356
    },
    {
      "epoch": 0.69,
      "grad_norm": 1.0324819087982178,
      "learning_rate": 1.3129035564210311e-05,
      "loss": 0.4519,
      "step": 3357
    },
    {
      "epoch": 0.69,
      "grad_norm": 1.1256614923477173,
      "learning_rate": 1.3126985753817773e-05,
      "loss": 0.508,
      "step": 3358
    },
    {
      "epoch": 0.69,
      "grad_norm": 0.5833227038383484,
      "learning_rate": 1.3124935943425235e-05,
      "loss": 0.2895,
      "step": 3359
    },
    {
      "epoch": 0.69,
      "grad_norm": 1.628629446029663,
      "learning_rate": 1.3122886133032695e-05,
      "loss": 0.3546,
      "step": 3360
    },
    {
      "epoch": 0.69,
      "grad_norm": 1.664797067642212,
      "learning_rate": 1.3120836322640155e-05,
      "loss": 0.4244,
      "step": 3361
    },
    {
      "epoch": 0.69,
      "grad_norm": 0.8138782978057861,
      "learning_rate": 1.3118786512247619e-05,
      "loss": 0.4105,
      "step": 3362
    },
    {
      "epoch": 0.69,
      "grad_norm": 2.0937492847442627,
      "learning_rate": 1.3116736701855079e-05,
      "loss": 0.4696,
      "step": 3363
    },
    {
      "epoch": 0.69,
      "grad_norm": 1.6342111825942993,
      "learning_rate": 1.3114686891462541e-05,
      "loss": 0.4209,
      "step": 3364
    },
    {
      "epoch": 0.69,
      "grad_norm": 0.985706627368927,
      "learning_rate": 1.3112637081070001e-05,
      "loss": 0.4187,
      "step": 3365
    },
    {
      "epoch": 0.69,
      "grad_norm": 0.8374158143997192,
      "learning_rate": 1.3110587270677465e-05,
      "loss": 0.4787,
      "step": 3366
    },
    {
      "epoch": 0.69,
      "grad_norm": 2.435194969177246,
      "learning_rate": 1.3108537460284925e-05,
      "loss": 0.4182,
      "step": 3367
    },
    {
      "epoch": 0.69,
      "grad_norm": 2.788801908493042,
      "learning_rate": 1.3106487649892385e-05,
      "loss": 0.3856,
      "step": 3368
    },
    {
      "epoch": 0.69,
      "grad_norm": 1.0480804443359375,
      "learning_rate": 1.3104437839499849e-05,
      "loss": 0.455,
      "step": 3369
    },
    {
      "epoch": 0.69,
      "grad_norm": 1.9028207063674927,
      "learning_rate": 1.3102388029107309e-05,
      "loss": 0.4507,
      "step": 3370
    },
    {
      "epoch": 0.69,
      "grad_norm": 1.3067654371261597,
      "learning_rate": 1.310033821871477e-05,
      "loss": 0.3234,
      "step": 3371
    },
    {
      "epoch": 0.69,
      "grad_norm": 1.5577222108840942,
      "learning_rate": 1.309828840832223e-05,
      "loss": 0.4237,
      "step": 3372
    },
    {
      "epoch": 0.69,
      "grad_norm": 1.2540303468704224,
      "learning_rate": 1.3096238597929694e-05,
      "loss": 0.5072,
      "step": 3373
    },
    {
      "epoch": 0.69,
      "grad_norm": 1.918358325958252,
      "learning_rate": 1.3094188787537154e-05,
      "loss": 0.398,
      "step": 3374
    },
    {
      "epoch": 0.69,
      "grad_norm": 2.5687320232391357,
      "learning_rate": 1.3092138977144615e-05,
      "loss": 0.3065,
      "step": 3375
    },
    {
      "epoch": 0.69,
      "grad_norm": 1.2081719636917114,
      "learning_rate": 1.3090089166752076e-05,
      "loss": 0.3571,
      "step": 3376
    },
    {
      "epoch": 0.69,
      "grad_norm": 1.181497573852539,
      "learning_rate": 1.3088039356359538e-05,
      "loss": 0.3814,
      "step": 3377
    },
    {
      "epoch": 0.69,
      "grad_norm": 2.194640874862671,
      "learning_rate": 1.3085989545967e-05,
      "loss": 0.3183,
      "step": 3378
    },
    {
      "epoch": 0.69,
      "grad_norm": 2.1024742126464844,
      "learning_rate": 1.308393973557446e-05,
      "loss": 0.4878,
      "step": 3379
    },
    {
      "epoch": 0.69,
      "grad_norm": 1.0415431261062622,
      "learning_rate": 1.308188992518192e-05,
      "loss": 0.4666,
      "step": 3380
    },
    {
      "epoch": 0.69,
      "grad_norm": 1.9410195350646973,
      "learning_rate": 1.3079840114789384e-05,
      "loss": 0.3393,
      "step": 3381
    },
    {
      "epoch": 0.69,
      "grad_norm": 1.195546269416809,
      "learning_rate": 1.3077790304396844e-05,
      "loss": 0.4087,
      "step": 3382
    },
    {
      "epoch": 0.69,
      "grad_norm": 0.7892405390739441,
      "learning_rate": 1.3075740494004306e-05,
      "loss": 0.3832,
      "step": 3383
    },
    {
      "epoch": 0.69,
      "grad_norm": 1.3479918241500854,
      "learning_rate": 1.3073690683611766e-05,
      "loss": 0.4942,
      "step": 3384
    },
    {
      "epoch": 0.69,
      "grad_norm": 1.6910561323165894,
      "learning_rate": 1.307164087321923e-05,
      "loss": 0.3415,
      "step": 3385
    },
    {
      "epoch": 0.69,
      "grad_norm": 0.9667848348617554,
      "learning_rate": 1.306959106282669e-05,
      "loss": 0.4721,
      "step": 3386
    },
    {
      "epoch": 0.69,
      "grad_norm": 1.078964114189148,
      "learning_rate": 1.306754125243415e-05,
      "loss": 0.4061,
      "step": 3387
    },
    {
      "epoch": 0.69,
      "grad_norm": 2.6424617767333984,
      "learning_rate": 1.3065491442041612e-05,
      "loss": 0.3517,
      "step": 3388
    },
    {
      "epoch": 0.69,
      "grad_norm": 1.368086576461792,
      "learning_rate": 1.3063441631649074e-05,
      "loss": 0.3942,
      "step": 3389
    },
    {
      "epoch": 0.69,
      "grad_norm": 1.15131676197052,
      "learning_rate": 1.3061391821256536e-05,
      "loss": 0.5645,
      "step": 3390
    },
    {
      "epoch": 0.69,
      "grad_norm": 1.817995548248291,
      "learning_rate": 1.3059342010863996e-05,
      "loss": 0.4071,
      "step": 3391
    },
    {
      "epoch": 0.69,
      "grad_norm": 1.1245745420455933,
      "learning_rate": 1.3057292200471456e-05,
      "loss": 0.4821,
      "step": 3392
    },
    {
      "epoch": 0.7,
      "grad_norm": 1.0540785789489746,
      "learning_rate": 1.305524239007892e-05,
      "loss": 0.5296,
      "step": 3393
    },
    {
      "epoch": 0.7,
      "grad_norm": 2.093510627746582,
      "learning_rate": 1.305319257968638e-05,
      "loss": 0.4661,
      "step": 3394
    },
    {
      "epoch": 0.7,
      "grad_norm": 0.7661919593811035,
      "learning_rate": 1.3051142769293842e-05,
      "loss": 0.4341,
      "step": 3395
    },
    {
      "epoch": 0.7,
      "grad_norm": 1.5912796258926392,
      "learning_rate": 1.3049092958901303e-05,
      "loss": 0.5035,
      "step": 3396
    },
    {
      "epoch": 0.7,
      "grad_norm": 0.9254574775695801,
      "learning_rate": 1.3047043148508765e-05,
      "loss": 0.3699,
      "step": 3397
    },
    {
      "epoch": 0.7,
      "grad_norm": 1.2380986213684082,
      "learning_rate": 1.3044993338116225e-05,
      "loss": 0.5791,
      "step": 3398
    },
    {
      "epoch": 0.7,
      "grad_norm": 1.2157317399978638,
      "learning_rate": 1.3042943527723686e-05,
      "loss": 0.4023,
      "step": 3399
    },
    {
      "epoch": 0.7,
      "grad_norm": 1.2960450649261475,
      "learning_rate": 1.3040893717331149e-05,
      "loss": 0.414,
      "step": 3400
    },
    {
      "epoch": 0.7,
      "grad_norm": 0.8841567635536194,
      "learning_rate": 1.303884390693861e-05,
      "loss": 0.476,
      "step": 3401
    },
    {
      "epoch": 0.7,
      "grad_norm": 2.3416922092437744,
      "learning_rate": 1.3036794096546071e-05,
      "loss": 0.4969,
      "step": 3402
    },
    {
      "epoch": 0.7,
      "grad_norm": 0.6979777812957764,
      "learning_rate": 1.3034744286153531e-05,
      "loss": 0.5025,
      "step": 3403
    },
    {
      "epoch": 0.7,
      "grad_norm": 1.7599221467971802,
      "learning_rate": 1.3032694475760995e-05,
      "loss": 0.3637,
      "step": 3404
    },
    {
      "epoch": 0.7,
      "grad_norm": 0.5677685141563416,
      "learning_rate": 1.3030644665368455e-05,
      "loss": 0.4145,
      "step": 3405
    },
    {
      "epoch": 0.7,
      "grad_norm": 0.8723301291465759,
      "learning_rate": 1.3028594854975915e-05,
      "loss": 0.3609,
      "step": 3406
    },
    {
      "epoch": 0.7,
      "grad_norm": 1.2652156352996826,
      "learning_rate": 1.3026545044583377e-05,
      "loss": 0.5347,
      "step": 3407
    },
    {
      "epoch": 0.7,
      "grad_norm": 0.7968655824661255,
      "learning_rate": 1.3024495234190839e-05,
      "loss": 0.5629,
      "step": 3408
    },
    {
      "epoch": 0.7,
      "grad_norm": 1.2408372163772583,
      "learning_rate": 1.30224454237983e-05,
      "loss": 0.4218,
      "step": 3409
    },
    {
      "epoch": 0.7,
      "grad_norm": 1.1902546882629395,
      "learning_rate": 1.3020395613405761e-05,
      "loss": 0.625,
      "step": 3410
    },
    {
      "epoch": 0.7,
      "grad_norm": 0.9873590469360352,
      "learning_rate": 1.3018345803013221e-05,
      "loss": 0.5027,
      "step": 3411
    },
    {
      "epoch": 0.7,
      "grad_norm": 0.7357501983642578,
      "learning_rate": 1.3016295992620685e-05,
      "loss": 0.3133,
      "step": 3412
    },
    {
      "epoch": 0.7,
      "grad_norm": 1.718858242034912,
      "learning_rate": 1.3014246182228145e-05,
      "loss": 0.5282,
      "step": 3413
    },
    {
      "epoch": 0.7,
      "grad_norm": 1.214018702507019,
      "learning_rate": 1.3012196371835607e-05,
      "loss": 0.4549,
      "step": 3414
    },
    {
      "epoch": 0.7,
      "grad_norm": 1.1505175828933716,
      "learning_rate": 1.3010146561443067e-05,
      "loss": 0.2871,
      "step": 3415
    },
    {
      "epoch": 0.7,
      "grad_norm": 1.0639731884002686,
      "learning_rate": 1.300809675105053e-05,
      "loss": 0.4101,
      "step": 3416
    },
    {
      "epoch": 0.7,
      "grad_norm": 1.2918647527694702,
      "learning_rate": 1.300604694065799e-05,
      "loss": 0.3041,
      "step": 3417
    },
    {
      "epoch": 0.7,
      "grad_norm": 1.1268999576568604,
      "learning_rate": 1.300399713026545e-05,
      "loss": 0.3543,
      "step": 3418
    },
    {
      "epoch": 0.7,
      "grad_norm": 1.0544192790985107,
      "learning_rate": 1.3001947319872913e-05,
      "loss": 0.6214,
      "step": 3419
    },
    {
      "epoch": 0.7,
      "grad_norm": 1.0186737775802612,
      "learning_rate": 1.2999897509480374e-05,
      "loss": 0.4023,
      "step": 3420
    },
    {
      "epoch": 0.7,
      "grad_norm": 1.332409143447876,
      "learning_rate": 1.2997847699087836e-05,
      "loss": 0.4864,
      "step": 3421
    },
    {
      "epoch": 0.7,
      "grad_norm": 1.4202595949172974,
      "learning_rate": 1.2995797888695296e-05,
      "loss": 0.548,
      "step": 3422
    },
    {
      "epoch": 0.7,
      "grad_norm": 1.0171095132827759,
      "learning_rate": 1.2993748078302757e-05,
      "loss": 0.5106,
      "step": 3423
    },
    {
      "epoch": 0.7,
      "grad_norm": 1.5215882062911987,
      "learning_rate": 1.299169826791022e-05,
      "loss": 0.4843,
      "step": 3424
    },
    {
      "epoch": 0.7,
      "grad_norm": 2.243431329727173,
      "learning_rate": 1.298964845751768e-05,
      "loss": 0.443,
      "step": 3425
    },
    {
      "epoch": 0.7,
      "grad_norm": 0.8331742882728577,
      "learning_rate": 1.2987598647125142e-05,
      "loss": 0.5491,
      "step": 3426
    },
    {
      "epoch": 0.7,
      "grad_norm": 2.1724343299865723,
      "learning_rate": 1.2985548836732604e-05,
      "loss": 0.3998,
      "step": 3427
    },
    {
      "epoch": 0.7,
      "grad_norm": 2.546609401702881,
      "learning_rate": 1.2983499026340066e-05,
      "loss": 0.5145,
      "step": 3428
    },
    {
      "epoch": 0.7,
      "grad_norm": 0.9437785744667053,
      "learning_rate": 1.2981449215947526e-05,
      "loss": 0.4054,
      "step": 3429
    },
    {
      "epoch": 0.7,
      "grad_norm": 1.26897132396698,
      "learning_rate": 1.2979399405554986e-05,
      "loss": 0.5569,
      "step": 3430
    },
    {
      "epoch": 0.7,
      "grad_norm": 1.0382130146026611,
      "learning_rate": 1.297734959516245e-05,
      "loss": 0.4935,
      "step": 3431
    },
    {
      "epoch": 0.7,
      "grad_norm": 1.9373449087142944,
      "learning_rate": 1.297529978476991e-05,
      "loss": 0.5501,
      "step": 3432
    },
    {
      "epoch": 0.7,
      "grad_norm": 0.8011989593505859,
      "learning_rate": 1.2973249974377372e-05,
      "loss": 0.4028,
      "step": 3433
    },
    {
      "epoch": 0.7,
      "grad_norm": 1.4625324010849,
      "learning_rate": 1.2971200163984832e-05,
      "loss": 0.4898,
      "step": 3434
    },
    {
      "epoch": 0.7,
      "grad_norm": 1.4801549911499023,
      "learning_rate": 1.2969150353592295e-05,
      "loss": 0.3652,
      "step": 3435
    },
    {
      "epoch": 0.7,
      "grad_norm": 0.7583913207054138,
      "learning_rate": 1.2967100543199756e-05,
      "loss": 0.4131,
      "step": 3436
    },
    {
      "epoch": 0.7,
      "grad_norm": 1.1373279094696045,
      "learning_rate": 1.2965050732807216e-05,
      "loss": 0.2951,
      "step": 3437
    },
    {
      "epoch": 0.7,
      "grad_norm": 1.664066195487976,
      "learning_rate": 1.2963000922414678e-05,
      "loss": 0.3774,
      "step": 3438
    },
    {
      "epoch": 0.7,
      "grad_norm": 1.2823747396469116,
      "learning_rate": 1.296095111202214e-05,
      "loss": 0.4124,
      "step": 3439
    },
    {
      "epoch": 0.7,
      "grad_norm": 0.9558702707290649,
      "learning_rate": 1.2958901301629601e-05,
      "loss": 0.4013,
      "step": 3440
    },
    {
      "epoch": 0.7,
      "grad_norm": 1.490253210067749,
      "learning_rate": 1.2956851491237062e-05,
      "loss": 0.3781,
      "step": 3441
    },
    {
      "epoch": 0.71,
      "grad_norm": 1.3639575242996216,
      "learning_rate": 1.2954801680844522e-05,
      "loss": 0.4118,
      "step": 3442
    },
    {
      "epoch": 0.71,
      "grad_norm": 1.3837682008743286,
      "learning_rate": 1.2952751870451985e-05,
      "loss": 0.4634,
      "step": 3443
    },
    {
      "epoch": 0.71,
      "grad_norm": 1.9626142978668213,
      "learning_rate": 1.2950702060059445e-05,
      "loss": 0.4518,
      "step": 3444
    },
    {
      "epoch": 0.71,
      "grad_norm": 1.8419172763824463,
      "learning_rate": 1.2948652249666907e-05,
      "loss": 0.4418,
      "step": 3445
    },
    {
      "epoch": 0.71,
      "grad_norm": 1.557243824005127,
      "learning_rate": 1.2946602439274367e-05,
      "loss": 0.3694,
      "step": 3446
    },
    {
      "epoch": 0.71,
      "grad_norm": 1.0995701551437378,
      "learning_rate": 1.2944552628881831e-05,
      "loss": 0.4478,
      "step": 3447
    },
    {
      "epoch": 0.71,
      "grad_norm": 2.043148994445801,
      "learning_rate": 1.2942502818489291e-05,
      "loss": 0.4369,
      "step": 3448
    },
    {
      "epoch": 0.71,
      "grad_norm": 1.1209183931350708,
      "learning_rate": 1.2940453008096751e-05,
      "loss": 0.4314,
      "step": 3449
    },
    {
      "epoch": 0.71,
      "grad_norm": 1.126369595527649,
      "learning_rate": 1.2938403197704213e-05,
      "loss": 0.5181,
      "step": 3450
    },
    {
      "epoch": 0.71,
      "grad_norm": 1.0004075765609741,
      "learning_rate": 1.2936353387311675e-05,
      "loss": 0.5527,
      "step": 3451
    },
    {
      "epoch": 0.71,
      "grad_norm": 1.3546522855758667,
      "learning_rate": 1.2934303576919137e-05,
      "loss": 0.3609,
      "step": 3452
    },
    {
      "epoch": 0.71,
      "grad_norm": 2.087369441986084,
      "learning_rate": 1.2932253766526597e-05,
      "loss": 0.5248,
      "step": 3453
    },
    {
      "epoch": 0.71,
      "grad_norm": 1.3926335573196411,
      "learning_rate": 1.293020395613406e-05,
      "loss": 0.4157,
      "step": 3454
    },
    {
      "epoch": 0.71,
      "grad_norm": 1.4460543394088745,
      "learning_rate": 1.292815414574152e-05,
      "loss": 0.4403,
      "step": 3455
    },
    {
      "epoch": 0.71,
      "grad_norm": 1.4096018075942993,
      "learning_rate": 1.2926104335348981e-05,
      "loss": 0.5353,
      "step": 3456
    },
    {
      "epoch": 0.71,
      "grad_norm": 0.870836615562439,
      "learning_rate": 1.2924054524956443e-05,
      "loss": 0.5456,
      "step": 3457
    },
    {
      "epoch": 0.71,
      "grad_norm": 1.2387323379516602,
      "learning_rate": 1.2922004714563905e-05,
      "loss": 0.3406,
      "step": 3458
    },
    {
      "epoch": 0.71,
      "grad_norm": 1.0539114475250244,
      "learning_rate": 1.2919954904171366e-05,
      "loss": 0.4346,
      "step": 3459
    },
    {
      "epoch": 0.71,
      "grad_norm": 0.9633452892303467,
      "learning_rate": 1.2917905093778827e-05,
      "loss": 0.4512,
      "step": 3460
    },
    {
      "epoch": 0.71,
      "grad_norm": 1.0171912908554077,
      "learning_rate": 1.2915855283386287e-05,
      "loss": 0.4975,
      "step": 3461
    },
    {
      "epoch": 0.71,
      "grad_norm": 0.6473220586776733,
      "learning_rate": 1.291380547299375e-05,
      "loss": 0.2928,
      "step": 3462
    },
    {
      "epoch": 0.71,
      "grad_norm": 1.3912591934204102,
      "learning_rate": 1.291175566260121e-05,
      "loss": 0.3854,
      "step": 3463
    },
    {
      "epoch": 0.71,
      "grad_norm": 1.5645779371261597,
      "learning_rate": 1.2909705852208672e-05,
      "loss": 0.3678,
      "step": 3464
    },
    {
      "epoch": 0.71,
      "grad_norm": 1.5978209972381592,
      "learning_rate": 1.2907656041816133e-05,
      "loss": 0.3657,
      "step": 3465
    },
    {
      "epoch": 0.71,
      "grad_norm": 1.251523494720459,
      "learning_rate": 1.2905606231423596e-05,
      "loss": 0.4915,
      "step": 3466
    },
    {
      "epoch": 0.71,
      "grad_norm": 0.7497787475585938,
      "learning_rate": 1.2903556421031056e-05,
      "loss": 0.437,
      "step": 3467
    },
    {
      "epoch": 0.71,
      "grad_norm": 1.829750418663025,
      "learning_rate": 1.2901506610638516e-05,
      "loss": 0.4211,
      "step": 3468
    },
    {
      "epoch": 0.71,
      "grad_norm": 0.730715274810791,
      "learning_rate": 1.2899456800245978e-05,
      "loss": 0.4024,
      "step": 3469
    },
    {
      "epoch": 0.71,
      "grad_norm": 1.3833510875701904,
      "learning_rate": 1.289740698985344e-05,
      "loss": 0.5045,
      "step": 3470
    },
    {
      "epoch": 0.71,
      "grad_norm": 0.808971107006073,
      "learning_rate": 1.2895357179460902e-05,
      "loss": 0.3585,
      "step": 3471
    },
    {
      "epoch": 0.71,
      "grad_norm": 1.5097928047180176,
      "learning_rate": 1.2893307369068362e-05,
      "loss": 0.4691,
      "step": 3472
    },
    {
      "epoch": 0.71,
      "grad_norm": 2.058717727661133,
      "learning_rate": 1.2891257558675822e-05,
      "loss": 0.4779,
      "step": 3473
    },
    {
      "epoch": 0.71,
      "grad_norm": 1.2701197862625122,
      "learning_rate": 1.2889207748283286e-05,
      "loss": 0.4019,
      "step": 3474
    },
    {
      "epoch": 0.71,
      "grad_norm": 1.9831745624542236,
      "learning_rate": 1.2887157937890746e-05,
      "loss": 0.4212,
      "step": 3475
    },
    {
      "epoch": 0.71,
      "grad_norm": 2.219986915588379,
      "learning_rate": 1.2885108127498208e-05,
      "loss": 0.3722,
      "step": 3476
    },
    {
      "epoch": 0.71,
      "grad_norm": 1.6989456415176392,
      "learning_rate": 1.2883058317105668e-05,
      "loss": 0.4777,
      "step": 3477
    },
    {
      "epoch": 0.71,
      "grad_norm": 1.892741084098816,
      "learning_rate": 1.2881008506713132e-05,
      "loss": 0.4148,
      "step": 3478
    },
    {
      "epoch": 0.71,
      "grad_norm": 1.3806560039520264,
      "learning_rate": 1.2878958696320592e-05,
      "loss": 0.3608,
      "step": 3479
    },
    {
      "epoch": 0.71,
      "grad_norm": 2.1565566062927246,
      "learning_rate": 1.2876908885928052e-05,
      "loss": 0.4721,
      "step": 3480
    },
    {
      "epoch": 0.71,
      "grad_norm": 2.1805264949798584,
      "learning_rate": 1.2874859075535514e-05,
      "loss": 0.3574,
      "step": 3481
    },
    {
      "epoch": 0.71,
      "grad_norm": 1.0670946836471558,
      "learning_rate": 1.2872809265142976e-05,
      "loss": 0.6065,
      "step": 3482
    },
    {
      "epoch": 0.71,
      "grad_norm": 1.3147149085998535,
      "learning_rate": 1.2870759454750437e-05,
      "loss": 0.3843,
      "step": 3483
    },
    {
      "epoch": 0.71,
      "grad_norm": 0.9626150131225586,
      "learning_rate": 1.2868709644357898e-05,
      "loss": 0.5776,
      "step": 3484
    },
    {
      "epoch": 0.71,
      "grad_norm": 1.9762649536132812,
      "learning_rate": 1.286665983396536e-05,
      "loss": 0.4719,
      "step": 3485
    },
    {
      "epoch": 0.71,
      "grad_norm": 1.061286449432373,
      "learning_rate": 1.2864610023572821e-05,
      "loss": 0.3908,
      "step": 3486
    },
    {
      "epoch": 0.71,
      "grad_norm": 1.2732727527618408,
      "learning_rate": 1.2862560213180282e-05,
      "loss": 0.4541,
      "step": 3487
    },
    {
      "epoch": 0.71,
      "grad_norm": 0.9772886037826538,
      "learning_rate": 1.2860510402787743e-05,
      "loss": 0.191,
      "step": 3488
    },
    {
      "epoch": 0.71,
      "grad_norm": 1.0003361701965332,
      "learning_rate": 1.2858460592395205e-05,
      "loss": 0.3774,
      "step": 3489
    },
    {
      "epoch": 0.72,
      "grad_norm": 1.3769696950912476,
      "learning_rate": 1.2856410782002665e-05,
      "loss": 0.4752,
      "step": 3490
    },
    {
      "epoch": 0.72,
      "grad_norm": 0.8130587935447693,
      "learning_rate": 1.2854360971610127e-05,
      "loss": 0.5023,
      "step": 3491
    },
    {
      "epoch": 0.72,
      "grad_norm": 1.107483148574829,
      "learning_rate": 1.2852311161217587e-05,
      "loss": 0.4979,
      "step": 3492
    },
    {
      "epoch": 0.72,
      "grad_norm": 1.3818799257278442,
      "learning_rate": 1.2850261350825051e-05,
      "loss": 0.4467,
      "step": 3493
    },
    {
      "epoch": 0.72,
      "grad_norm": 1.2844821214675903,
      "learning_rate": 1.2848211540432511e-05,
      "loss": 0.4087,
      "step": 3494
    },
    {
      "epoch": 0.72,
      "grad_norm": 1.148610234260559,
      "learning_rate": 1.2846161730039971e-05,
      "loss": 0.4072,
      "step": 3495
    },
    {
      "epoch": 0.72,
      "grad_norm": 1.319179892539978,
      "learning_rate": 1.2844111919647433e-05,
      "loss": 0.421,
      "step": 3496
    },
    {
      "epoch": 0.72,
      "grad_norm": 0.966396689414978,
      "learning_rate": 1.2842062109254895e-05,
      "loss": 0.4054,
      "step": 3497
    },
    {
      "epoch": 0.72,
      "grad_norm": 1.2436120510101318,
      "learning_rate": 1.2840012298862357e-05,
      "loss": 0.3996,
      "step": 3498
    },
    {
      "epoch": 0.72,
      "grad_norm": 1.028557538986206,
      "learning_rate": 1.2837962488469817e-05,
      "loss": 0.4778,
      "step": 3499
    },
    {
      "epoch": 0.72,
      "grad_norm": 1.0749328136444092,
      "learning_rate": 1.2835912678077279e-05,
      "loss": 0.4501,
      "step": 3500
    },
    {
      "epoch": 0.72,
      "grad_norm": 1.01832115650177,
      "learning_rate": 1.283386286768474e-05,
      "loss": 0.4301,
      "step": 3501
    },
    {
      "epoch": 0.72,
      "grad_norm": 1.6170376539230347,
      "learning_rate": 1.2831813057292201e-05,
      "loss": 0.3388,
      "step": 3502
    },
    {
      "epoch": 0.72,
      "grad_norm": 0.7892104387283325,
      "learning_rate": 1.2829763246899663e-05,
      "loss": 0.3515,
      "step": 3503
    },
    {
      "epoch": 0.72,
      "grad_norm": 1.1204445362091064,
      "learning_rate": 1.2827713436507123e-05,
      "loss": 0.4168,
      "step": 3504
    },
    {
      "epoch": 0.72,
      "grad_norm": 1.7960206270217896,
      "learning_rate": 1.2825663626114586e-05,
      "loss": 0.3682,
      "step": 3505
    },
    {
      "epoch": 0.72,
      "grad_norm": 1.0243326425552368,
      "learning_rate": 1.2823613815722047e-05,
      "loss": 0.5147,
      "step": 3506
    },
    {
      "epoch": 0.72,
      "grad_norm": 1.4836701154708862,
      "learning_rate": 1.2821564005329507e-05,
      "loss": 0.3516,
      "step": 3507
    },
    {
      "epoch": 0.72,
      "grad_norm": 2.8908979892730713,
      "learning_rate": 1.2819514194936969e-05,
      "loss": 0.4086,
      "step": 3508
    },
    {
      "epoch": 0.72,
      "grad_norm": 1.2838929891586304,
      "learning_rate": 1.281746438454443e-05,
      "loss": 0.5028,
      "step": 3509
    },
    {
      "epoch": 0.72,
      "grad_norm": 2.519666910171509,
      "learning_rate": 1.2815414574151892e-05,
      "loss": 0.5775,
      "step": 3510
    },
    {
      "epoch": 0.72,
      "grad_norm": 2.809889793395996,
      "learning_rate": 1.2813364763759353e-05,
      "loss": 0.2402,
      "step": 3511
    },
    {
      "epoch": 0.72,
      "grad_norm": 0.7550774812698364,
      "learning_rate": 1.2811314953366813e-05,
      "loss": 0.3614,
      "step": 3512
    },
    {
      "epoch": 0.72,
      "grad_norm": 0.94640052318573,
      "learning_rate": 1.2809265142974276e-05,
      "loss": 0.2387,
      "step": 3513
    },
    {
      "epoch": 0.72,
      "grad_norm": 1.0238131284713745,
      "learning_rate": 1.2807215332581736e-05,
      "loss": 0.3681,
      "step": 3514
    },
    {
      "epoch": 0.72,
      "grad_norm": 1.3326258659362793,
      "learning_rate": 1.2805165522189198e-05,
      "loss": 0.2851,
      "step": 3515
    },
    {
      "epoch": 0.72,
      "grad_norm": 1.0838135480880737,
      "learning_rate": 1.280311571179666e-05,
      "loss": 0.4208,
      "step": 3516
    },
    {
      "epoch": 0.72,
      "grad_norm": 1.2463301420211792,
      "learning_rate": 1.2801065901404122e-05,
      "loss": 0.4689,
      "step": 3517
    },
    {
      "epoch": 0.72,
      "grad_norm": 2.345759153366089,
      "learning_rate": 1.2799016091011582e-05,
      "loss": 0.4514,
      "step": 3518
    },
    {
      "epoch": 0.72,
      "grad_norm": 0.6112889647483826,
      "learning_rate": 1.2796966280619042e-05,
      "loss": 0.2837,
      "step": 3519
    },
    {
      "epoch": 0.72,
      "grad_norm": 1.0387258529663086,
      "learning_rate": 1.2794916470226506e-05,
      "loss": 0.5725,
      "step": 3520
    },
    {
      "epoch": 0.72,
      "grad_norm": 2.956024408340454,
      "learning_rate": 1.2792866659833966e-05,
      "loss": 0.3137,
      "step": 3521
    },
    {
      "epoch": 0.72,
      "grad_norm": 2.0287697315216064,
      "learning_rate": 1.2790816849441428e-05,
      "loss": 0.2482,
      "step": 3522
    },
    {
      "epoch": 0.72,
      "grad_norm": 1.6465615034103394,
      "learning_rate": 1.2788767039048888e-05,
      "loss": 0.5432,
      "step": 3523
    },
    {
      "epoch": 0.72,
      "grad_norm": 1.634499192237854,
      "learning_rate": 1.2786717228656352e-05,
      "loss": 0.3491,
      "step": 3524
    },
    {
      "epoch": 0.72,
      "grad_norm": 1.9440946578979492,
      "learning_rate": 1.2784667418263812e-05,
      "loss": 0.4398,
      "step": 3525
    },
    {
      "epoch": 0.72,
      "grad_norm": 1.300127625465393,
      "learning_rate": 1.2782617607871272e-05,
      "loss": 0.4006,
      "step": 3526
    },
    {
      "epoch": 0.72,
      "grad_norm": 1.5325263738632202,
      "learning_rate": 1.2780567797478734e-05,
      "loss": 0.3771,
      "step": 3527
    },
    {
      "epoch": 0.72,
      "grad_norm": 1.7149040699005127,
      "learning_rate": 1.2778517987086196e-05,
      "loss": 0.365,
      "step": 3528
    },
    {
      "epoch": 0.72,
      "grad_norm": 2.6563501358032227,
      "learning_rate": 1.2776468176693657e-05,
      "loss": 0.518,
      "step": 3529
    },
    {
      "epoch": 0.72,
      "grad_norm": 1.920440435409546,
      "learning_rate": 1.2774418366301118e-05,
      "loss": 0.6284,
      "step": 3530
    },
    {
      "epoch": 0.72,
      "grad_norm": 1.1595776081085205,
      "learning_rate": 1.2772368555908578e-05,
      "loss": 0.533,
      "step": 3531
    },
    {
      "epoch": 0.72,
      "grad_norm": 0.9491862058639526,
      "learning_rate": 1.2770318745516041e-05,
      "loss": 0.3574,
      "step": 3532
    },
    {
      "epoch": 0.72,
      "grad_norm": 0.803069531917572,
      "learning_rate": 1.2768268935123502e-05,
      "loss": 0.4429,
      "step": 3533
    },
    {
      "epoch": 0.72,
      "grad_norm": 1.1464359760284424,
      "learning_rate": 1.2766219124730963e-05,
      "loss": 0.3882,
      "step": 3534
    },
    {
      "epoch": 0.72,
      "grad_norm": 1.0492231845855713,
      "learning_rate": 1.2764169314338424e-05,
      "loss": 0.3462,
      "step": 3535
    },
    {
      "epoch": 0.72,
      "grad_norm": 1.3746678829193115,
      "learning_rate": 1.2762119503945887e-05,
      "loss": 0.3302,
      "step": 3536
    },
    {
      "epoch": 0.72,
      "grad_norm": 1.6165152788162231,
      "learning_rate": 1.2760069693553347e-05,
      "loss": 0.2853,
      "step": 3537
    },
    {
      "epoch": 0.72,
      "grad_norm": 0.8765966892242432,
      "learning_rate": 1.2758019883160807e-05,
      "loss": 0.406,
      "step": 3538
    },
    {
      "epoch": 0.73,
      "grad_norm": 1.9986417293548584,
      "learning_rate": 1.275597007276827e-05,
      "loss": 0.2694,
      "step": 3539
    },
    {
      "epoch": 0.73,
      "grad_norm": 1.0361874103546143,
      "learning_rate": 1.2753920262375731e-05,
      "loss": 0.407,
      "step": 3540
    },
    {
      "epoch": 0.73,
      "grad_norm": 1.0093803405761719,
      "learning_rate": 1.2751870451983193e-05,
      "loss": 0.438,
      "step": 3541
    },
    {
      "epoch": 0.73,
      "grad_norm": 0.763326108455658,
      "learning_rate": 1.2749820641590653e-05,
      "loss": 0.4384,
      "step": 3542
    },
    {
      "epoch": 0.73,
      "grad_norm": 1.2500507831573486,
      "learning_rate": 1.2747770831198117e-05,
      "loss": 0.4937,
      "step": 3543
    },
    {
      "epoch": 0.73,
      "grad_norm": 1.4154943227767944,
      "learning_rate": 1.2745721020805577e-05,
      "loss": 0.4467,
      "step": 3544
    },
    {
      "epoch": 0.73,
      "grad_norm": 1.971186637878418,
      "learning_rate": 1.2743671210413037e-05,
      "loss": 0.3068,
      "step": 3545
    },
    {
      "epoch": 0.73,
      "grad_norm": 0.8780056834220886,
      "learning_rate": 1.2741621400020499e-05,
      "loss": 0.4114,
      "step": 3546
    },
    {
      "epoch": 0.73,
      "grad_norm": 1.6569995880126953,
      "learning_rate": 1.273957158962796e-05,
      "loss": 0.1683,
      "step": 3547
    },
    {
      "epoch": 0.73,
      "grad_norm": 1.3771843910217285,
      "learning_rate": 1.2737521779235423e-05,
      "loss": 0.3339,
      "step": 3548
    },
    {
      "epoch": 0.73,
      "grad_norm": 1.2232414484024048,
      "learning_rate": 1.2735471968842883e-05,
      "loss": 0.3826,
      "step": 3549
    },
    {
      "epoch": 0.73,
      "grad_norm": 1.1114091873168945,
      "learning_rate": 1.2733422158450343e-05,
      "loss": 0.434,
      "step": 3550
    },
    {
      "epoch": 0.73,
      "grad_norm": 1.0948084592819214,
      "learning_rate": 1.2731372348057806e-05,
      "loss": 0.3371,
      "step": 3551
    },
    {
      "epoch": 0.73,
      "grad_norm": 0.9269523620605469,
      "learning_rate": 1.2729322537665267e-05,
      "loss": 0.3288,
      "step": 3552
    },
    {
      "epoch": 0.73,
      "grad_norm": 0.7741032242774963,
      "learning_rate": 1.2727272727272728e-05,
      "loss": 0.3245,
      "step": 3553
    },
    {
      "epoch": 0.73,
      "grad_norm": 1.0778799057006836,
      "learning_rate": 1.2725222916880189e-05,
      "loss": 0.4545,
      "step": 3554
    },
    {
      "epoch": 0.73,
      "grad_norm": 1.361449956893921,
      "learning_rate": 1.2723173106487652e-05,
      "loss": 0.4524,
      "step": 3555
    },
    {
      "epoch": 0.73,
      "grad_norm": 0.9643557667732239,
      "learning_rate": 1.2721123296095112e-05,
      "loss": 0.3205,
      "step": 3556
    },
    {
      "epoch": 0.73,
      "grad_norm": 1.1953964233398438,
      "learning_rate": 1.2719073485702573e-05,
      "loss": 0.5622,
      "step": 3557
    },
    {
      "epoch": 0.73,
      "grad_norm": 1.2458385229110718,
      "learning_rate": 1.2717023675310034e-05,
      "loss": 0.3901,
      "step": 3558
    },
    {
      "epoch": 0.73,
      "grad_norm": 1.5104790925979614,
      "learning_rate": 1.2714973864917496e-05,
      "loss": 0.691,
      "step": 3559
    },
    {
      "epoch": 0.73,
      "grad_norm": 1.668392539024353,
      "learning_rate": 1.2712924054524958e-05,
      "loss": 0.449,
      "step": 3560
    },
    {
      "epoch": 0.73,
      "grad_norm": 1.397583246231079,
      "learning_rate": 1.2710874244132418e-05,
      "loss": 0.5384,
      "step": 3561
    },
    {
      "epoch": 0.73,
      "grad_norm": 0.9797616004943848,
      "learning_rate": 1.2708824433739878e-05,
      "loss": 0.4203,
      "step": 3562
    },
    {
      "epoch": 0.73,
      "grad_norm": 0.8975314497947693,
      "learning_rate": 1.2706774623347342e-05,
      "loss": 0.4882,
      "step": 3563
    },
    {
      "epoch": 0.73,
      "grad_norm": 1.2904491424560547,
      "learning_rate": 1.2704724812954802e-05,
      "loss": 0.4191,
      "step": 3564
    },
    {
      "epoch": 0.73,
      "grad_norm": 1.1809759140014648,
      "learning_rate": 1.2702675002562264e-05,
      "loss": 0.4845,
      "step": 3565
    },
    {
      "epoch": 0.73,
      "grad_norm": 1.4320051670074463,
      "learning_rate": 1.2700625192169724e-05,
      "loss": 0.325,
      "step": 3566
    },
    {
      "epoch": 0.73,
      "grad_norm": 0.9825988411903381,
      "learning_rate": 1.2698575381777188e-05,
      "loss": 0.4194,
      "step": 3567
    },
    {
      "epoch": 0.73,
      "grad_norm": 0.7633682489395142,
      "learning_rate": 1.2696525571384648e-05,
      "loss": 0.3594,
      "step": 3568
    },
    {
      "epoch": 0.73,
      "grad_norm": 1.3574949502944946,
      "learning_rate": 1.2694475760992108e-05,
      "loss": 0.417,
      "step": 3569
    },
    {
      "epoch": 0.73,
      "grad_norm": 1.275058388710022,
      "learning_rate": 1.269242595059957e-05,
      "loss": 0.4981,
      "step": 3570
    },
    {
      "epoch": 0.73,
      "grad_norm": 1.3547443151474,
      "learning_rate": 1.2690376140207032e-05,
      "loss": 0.2903,
      "step": 3571
    },
    {
      "epoch": 0.73,
      "grad_norm": 0.8641104698181152,
      "learning_rate": 1.2688326329814494e-05,
      "loss": 0.516,
      "step": 3572
    },
    {
      "epoch": 0.73,
      "grad_norm": 1.250897765159607,
      "learning_rate": 1.2686276519421954e-05,
      "loss": 0.2808,
      "step": 3573
    },
    {
      "epoch": 0.73,
      "grad_norm": 0.881401002407074,
      "learning_rate": 1.2684226709029417e-05,
      "loss": 0.4147,
      "step": 3574
    },
    {
      "epoch": 0.73,
      "grad_norm": 1.0233986377716064,
      "learning_rate": 1.2682176898636877e-05,
      "loss": 0.5305,
      "step": 3575
    },
    {
      "epoch": 0.73,
      "grad_norm": 1.1898446083068848,
      "learning_rate": 1.2680127088244338e-05,
      "loss": 0.3441,
      "step": 3576
    },
    {
      "epoch": 0.73,
      "grad_norm": 1.0040258169174194,
      "learning_rate": 1.26780772778518e-05,
      "loss": 0.3871,
      "step": 3577
    },
    {
      "epoch": 0.73,
      "grad_norm": 1.1311860084533691,
      "learning_rate": 1.2676027467459261e-05,
      "loss": 0.3963,
      "step": 3578
    },
    {
      "epoch": 0.73,
      "grad_norm": 1.426139235496521,
      "learning_rate": 1.2673977657066723e-05,
      "loss": 0.3512,
      "step": 3579
    },
    {
      "epoch": 0.73,
      "grad_norm": 1.144818663597107,
      "learning_rate": 1.2671927846674183e-05,
      "loss": 0.4708,
      "step": 3580
    },
    {
      "epoch": 0.73,
      "grad_norm": 0.9723884463310242,
      "learning_rate": 1.2669878036281644e-05,
      "loss": 0.5275,
      "step": 3581
    },
    {
      "epoch": 0.73,
      "grad_norm": 2.1670610904693604,
      "learning_rate": 1.2667828225889107e-05,
      "loss": 0.3836,
      "step": 3582
    },
    {
      "epoch": 0.73,
      "grad_norm": 2.589547634124756,
      "learning_rate": 1.2665778415496567e-05,
      "loss": 0.5707,
      "step": 3583
    },
    {
      "epoch": 0.73,
      "grad_norm": 1.6627342700958252,
      "learning_rate": 1.2663728605104029e-05,
      "loss": 0.4406,
      "step": 3584
    },
    {
      "epoch": 0.73,
      "grad_norm": 1.034688115119934,
      "learning_rate": 1.266167879471149e-05,
      "loss": 0.4203,
      "step": 3585
    },
    {
      "epoch": 0.73,
      "grad_norm": 0.9928979277610779,
      "learning_rate": 1.2659628984318953e-05,
      "loss": 0.4926,
      "step": 3586
    },
    {
      "epoch": 0.73,
      "grad_norm": 3.6282944679260254,
      "learning_rate": 1.2657579173926413e-05,
      "loss": 0.4818,
      "step": 3587
    },
    {
      "epoch": 0.74,
      "grad_norm": 1.0186024904251099,
      "learning_rate": 1.2655529363533873e-05,
      "loss": 0.3996,
      "step": 3588
    },
    {
      "epoch": 0.74,
      "grad_norm": 1.3371601104736328,
      "learning_rate": 1.2653479553141335e-05,
      "loss": 0.5321,
      "step": 3589
    },
    {
      "epoch": 0.74,
      "grad_norm": 1.7450655698776245,
      "learning_rate": 1.2651429742748797e-05,
      "loss": 0.3883,
      "step": 3590
    },
    {
      "epoch": 0.74,
      "grad_norm": 1.0871150493621826,
      "learning_rate": 1.2649379932356259e-05,
      "loss": 0.579,
      "step": 3591
    },
    {
      "epoch": 0.74,
      "grad_norm": 1.4559468030929565,
      "learning_rate": 1.2647330121963719e-05,
      "loss": 0.4657,
      "step": 3592
    },
    {
      "epoch": 0.74,
      "grad_norm": 1.9915003776550293,
      "learning_rate": 1.2645280311571179e-05,
      "loss": 0.3741,
      "step": 3593
    },
    {
      "epoch": 0.74,
      "grad_norm": 1.470906376838684,
      "learning_rate": 1.2643230501178643e-05,
      "loss": 0.2865,
      "step": 3594
    },
    {
      "epoch": 0.74,
      "grad_norm": 1.098031759262085,
      "learning_rate": 1.2641180690786103e-05,
      "loss": 0.5597,
      "step": 3595
    },
    {
      "epoch": 0.74,
      "grad_norm": 1.6749101877212524,
      "learning_rate": 1.2639130880393565e-05,
      "loss": 0.3974,
      "step": 3596
    },
    {
      "epoch": 0.74,
      "grad_norm": 2.020566463470459,
      "learning_rate": 1.2637081070001025e-05,
      "loss": 0.4839,
      "step": 3597
    },
    {
      "epoch": 0.74,
      "grad_norm": 1.4916092157363892,
      "learning_rate": 1.2635031259608488e-05,
      "loss": 0.3142,
      "step": 3598
    },
    {
      "epoch": 0.74,
      "grad_norm": 2.391525983810425,
      "learning_rate": 1.2632981449215948e-05,
      "loss": 0.3649,
      "step": 3599
    },
    {
      "epoch": 0.74,
      "grad_norm": 0.9979751110076904,
      "learning_rate": 1.2630931638823409e-05,
      "loss": 0.317,
      "step": 3600
    },
    {
      "epoch": 0.74,
      "grad_norm": 1.3073564767837524,
      "learning_rate": 1.262888182843087e-05,
      "loss": 0.3963,
      "step": 3601
    },
    {
      "epoch": 0.74,
      "grad_norm": 1.588365077972412,
      "learning_rate": 1.2626832018038332e-05,
      "loss": 0.4579,
      "step": 3602
    },
    {
      "epoch": 0.74,
      "grad_norm": 1.1959928274154663,
      "learning_rate": 1.2624782207645794e-05,
      "loss": 0.4208,
      "step": 3603
    },
    {
      "epoch": 0.74,
      "grad_norm": 0.9769668579101562,
      "learning_rate": 1.2622732397253254e-05,
      "loss": 0.4795,
      "step": 3604
    },
    {
      "epoch": 0.74,
      "grad_norm": 2.900867462158203,
      "learning_rate": 1.2620682586860718e-05,
      "loss": 0.3165,
      "step": 3605
    },
    {
      "epoch": 0.74,
      "grad_norm": 1.1823928356170654,
      "learning_rate": 1.2618632776468178e-05,
      "loss": 0.4414,
      "step": 3606
    },
    {
      "epoch": 0.74,
      "grad_norm": 1.3638416528701782,
      "learning_rate": 1.2616582966075638e-05,
      "loss": 0.4003,
      "step": 3607
    },
    {
      "epoch": 0.74,
      "grad_norm": 2.1047074794769287,
      "learning_rate": 1.26145331556831e-05,
      "loss": 0.5368,
      "step": 3608
    },
    {
      "epoch": 0.74,
      "grad_norm": 1.2984325885772705,
      "learning_rate": 1.2612483345290562e-05,
      "loss": 0.3676,
      "step": 3609
    },
    {
      "epoch": 0.74,
      "grad_norm": 1.1250289678573608,
      "learning_rate": 1.2610433534898024e-05,
      "loss": 0.3589,
      "step": 3610
    },
    {
      "epoch": 0.74,
      "grad_norm": 0.844872772693634,
      "learning_rate": 1.2608383724505484e-05,
      "loss": 0.2715,
      "step": 3611
    },
    {
      "epoch": 0.74,
      "grad_norm": 3.7656774520874023,
      "learning_rate": 1.2606333914112944e-05,
      "loss": 0.3456,
      "step": 3612
    },
    {
      "epoch": 0.74,
      "grad_norm": 1.2179542779922485,
      "learning_rate": 1.2604284103720408e-05,
      "loss": 0.3487,
      "step": 3613
    },
    {
      "epoch": 0.74,
      "grad_norm": 2.323181629180908,
      "learning_rate": 1.2602234293327868e-05,
      "loss": 0.386,
      "step": 3614
    },
    {
      "epoch": 0.74,
      "grad_norm": 0.9050140976905823,
      "learning_rate": 1.260018448293533e-05,
      "loss": 0.409,
      "step": 3615
    },
    {
      "epoch": 0.74,
      "grad_norm": 1.1086643934249878,
      "learning_rate": 1.259813467254279e-05,
      "loss": 0.3189,
      "step": 3616
    },
    {
      "epoch": 0.74,
      "grad_norm": 1.0750377178192139,
      "learning_rate": 1.2596084862150253e-05,
      "loss": 0.6274,
      "step": 3617
    },
    {
      "epoch": 0.74,
      "grad_norm": 2.0430548191070557,
      "learning_rate": 1.2594035051757714e-05,
      "loss": 0.4309,
      "step": 3618
    },
    {
      "epoch": 0.74,
      "grad_norm": 0.7378675937652588,
      "learning_rate": 1.2591985241365174e-05,
      "loss": 0.2923,
      "step": 3619
    },
    {
      "epoch": 0.74,
      "grad_norm": 1.2467275857925415,
      "learning_rate": 1.2589935430972636e-05,
      "loss": 0.4114,
      "step": 3620
    },
    {
      "epoch": 0.74,
      "grad_norm": 2.218209743499756,
      "learning_rate": 1.2587885620580097e-05,
      "loss": 0.4493,
      "step": 3621
    },
    {
      "epoch": 0.74,
      "grad_norm": 1.3406115770339966,
      "learning_rate": 1.258583581018756e-05,
      "loss": 0.4729,
      "step": 3622
    },
    {
      "epoch": 0.74,
      "grad_norm": 1.1320301294326782,
      "learning_rate": 1.258378599979502e-05,
      "loss": 0.474,
      "step": 3623
    },
    {
      "epoch": 0.74,
      "grad_norm": 1.335795521736145,
      "learning_rate": 1.258173618940248e-05,
      "loss": 0.3875,
      "step": 3624
    },
    {
      "epoch": 0.74,
      "grad_norm": 1.4760059118270874,
      "learning_rate": 1.2579686379009943e-05,
      "loss": 0.2218,
      "step": 3625
    },
    {
      "epoch": 0.74,
      "grad_norm": 1.2407031059265137,
      "learning_rate": 1.2577636568617403e-05,
      "loss": 0.4124,
      "step": 3626
    },
    {
      "epoch": 0.74,
      "grad_norm": 0.8332931399345398,
      "learning_rate": 1.2575586758224865e-05,
      "loss": 0.3387,
      "step": 3627
    },
    {
      "epoch": 0.74,
      "grad_norm": 1.83694589138031,
      "learning_rate": 1.2573536947832325e-05,
      "loss": 0.4176,
      "step": 3628
    },
    {
      "epoch": 0.74,
      "grad_norm": 1.3542871475219727,
      "learning_rate": 1.2571487137439789e-05,
      "loss": 0.4583,
      "step": 3629
    },
    {
      "epoch": 0.74,
      "grad_norm": 1.9484931230545044,
      "learning_rate": 1.2569437327047249e-05,
      "loss": 0.3719,
      "step": 3630
    },
    {
      "epoch": 0.74,
      "grad_norm": 1.6035380363464355,
      "learning_rate": 1.256738751665471e-05,
      "loss": 0.4486,
      "step": 3631
    },
    {
      "epoch": 0.74,
      "grad_norm": 2.0573272705078125,
      "learning_rate": 1.2565337706262173e-05,
      "loss": 0.2986,
      "step": 3632
    },
    {
      "epoch": 0.74,
      "grad_norm": 1.712546944618225,
      "learning_rate": 1.2563287895869633e-05,
      "loss": 0.46,
      "step": 3633
    },
    {
      "epoch": 0.74,
      "grad_norm": 1.727845549583435,
      "learning_rate": 1.2561238085477095e-05,
      "loss": 0.4399,
      "step": 3634
    },
    {
      "epoch": 0.74,
      "grad_norm": 1.059059500694275,
      "learning_rate": 1.2559188275084555e-05,
      "loss": 0.4259,
      "step": 3635
    },
    {
      "epoch": 0.74,
      "grad_norm": 1.6738404035568237,
      "learning_rate": 1.2557138464692019e-05,
      "loss": 0.4941,
      "step": 3636
    },
    {
      "epoch": 0.75,
      "grad_norm": 1.4092395305633545,
      "learning_rate": 1.2555088654299479e-05,
      "loss": 0.3145,
      "step": 3637
    },
    {
      "epoch": 0.75,
      "grad_norm": 0.9849687814712524,
      "learning_rate": 1.2553038843906939e-05,
      "loss": 0.5457,
      "step": 3638
    },
    {
      "epoch": 0.75,
      "grad_norm": 1.079620599746704,
      "learning_rate": 1.25509890335144e-05,
      "loss": 0.5373,
      "step": 3639
    },
    {
      "epoch": 0.75,
      "grad_norm": 2.364105224609375,
      "learning_rate": 1.2548939223121863e-05,
      "loss": 0.5839,
      "step": 3640
    },
    {
      "epoch": 0.75,
      "grad_norm": 1.5905227661132812,
      "learning_rate": 1.2546889412729324e-05,
      "loss": 0.4478,
      "step": 3641
    },
    {
      "epoch": 0.75,
      "grad_norm": 0.9529005289077759,
      "learning_rate": 1.2544839602336785e-05,
      "loss": 0.315,
      "step": 3642
    },
    {
      "epoch": 0.75,
      "grad_norm": 1.1116201877593994,
      "learning_rate": 1.2542789791944245e-05,
      "loss": 0.3407,
      "step": 3643
    },
    {
      "epoch": 0.75,
      "grad_norm": 1.23947012424469,
      "learning_rate": 1.2540739981551708e-05,
      "loss": 0.3581,
      "step": 3644
    },
    {
      "epoch": 0.75,
      "grad_norm": 1.192566156387329,
      "learning_rate": 1.2538690171159168e-05,
      "loss": 0.4162,
      "step": 3645
    },
    {
      "epoch": 0.75,
      "grad_norm": 0.7921381592750549,
      "learning_rate": 1.253664036076663e-05,
      "loss": 0.3728,
      "step": 3646
    },
    {
      "epoch": 0.75,
      "grad_norm": 2.394202947616577,
      "learning_rate": 1.253459055037409e-05,
      "loss": 0.4077,
      "step": 3647
    },
    {
      "epoch": 0.75,
      "grad_norm": 2.2702131271362305,
      "learning_rate": 1.2532540739981554e-05,
      "loss": 0.4654,
      "step": 3648
    },
    {
      "epoch": 0.75,
      "grad_norm": 1.4678689241409302,
      "learning_rate": 1.2530490929589014e-05,
      "loss": 0.4376,
      "step": 3649
    },
    {
      "epoch": 0.75,
      "grad_norm": 1.0168529748916626,
      "learning_rate": 1.2528441119196474e-05,
      "loss": 0.3776,
      "step": 3650
    },
    {
      "epoch": 0.75,
      "grad_norm": 1.1243007183074951,
      "learning_rate": 1.2526391308803936e-05,
      "loss": 0.4223,
      "step": 3651
    },
    {
      "epoch": 0.75,
      "grad_norm": 1.4327622652053833,
      "learning_rate": 1.2524341498411398e-05,
      "loss": 0.4382,
      "step": 3652
    },
    {
      "epoch": 0.75,
      "grad_norm": 1.5185216665267944,
      "learning_rate": 1.252229168801886e-05,
      "loss": 0.3214,
      "step": 3653
    },
    {
      "epoch": 0.75,
      "grad_norm": 0.7325195670127869,
      "learning_rate": 1.252024187762632e-05,
      "loss": 0.3291,
      "step": 3654
    },
    {
      "epoch": 0.75,
      "grad_norm": 1.220995306968689,
      "learning_rate": 1.251819206723378e-05,
      "loss": 0.6339,
      "step": 3655
    },
    {
      "epoch": 0.75,
      "grad_norm": 1.644709587097168,
      "learning_rate": 1.2516142256841244e-05,
      "loss": 0.3789,
      "step": 3656
    },
    {
      "epoch": 0.75,
      "grad_norm": 0.9719545841217041,
      "learning_rate": 1.2514092446448704e-05,
      "loss": 0.4353,
      "step": 3657
    },
    {
      "epoch": 0.75,
      "grad_norm": 1.9564298391342163,
      "learning_rate": 1.2512042636056166e-05,
      "loss": 0.3495,
      "step": 3658
    },
    {
      "epoch": 0.75,
      "grad_norm": 1.527506709098816,
      "learning_rate": 1.2509992825663626e-05,
      "loss": 0.4143,
      "step": 3659
    },
    {
      "epoch": 0.75,
      "grad_norm": 1.1168462038040161,
      "learning_rate": 1.250794301527109e-05,
      "loss": 0.3368,
      "step": 3660
    },
    {
      "epoch": 0.75,
      "grad_norm": 0.9703987836837769,
      "learning_rate": 1.250589320487855e-05,
      "loss": 0.3003,
      "step": 3661
    },
    {
      "epoch": 0.75,
      "grad_norm": 1.5927568674087524,
      "learning_rate": 1.250384339448601e-05,
      "loss": 0.3394,
      "step": 3662
    },
    {
      "epoch": 0.75,
      "grad_norm": 1.5668725967407227,
      "learning_rate": 1.2501793584093473e-05,
      "loss": 0.4782,
      "step": 3663
    },
    {
      "epoch": 0.75,
      "grad_norm": 0.7076439261436462,
      "learning_rate": 1.2499743773700934e-05,
      "loss": 0.4095,
      "step": 3664
    },
    {
      "epoch": 0.75,
      "grad_norm": 1.566606879234314,
      "learning_rate": 1.2497693963308395e-05,
      "loss": 0.3063,
      "step": 3665
    },
    {
      "epoch": 0.75,
      "grad_norm": 0.8777757883071899,
      "learning_rate": 1.2495644152915856e-05,
      "loss": 0.3892,
      "step": 3666
    },
    {
      "epoch": 0.75,
      "grad_norm": 1.916129469871521,
      "learning_rate": 1.2493594342523319e-05,
      "loss": 0.3966,
      "step": 3667
    },
    {
      "epoch": 0.75,
      "grad_norm": 1.2177553176879883,
      "learning_rate": 1.249154453213078e-05,
      "loss": 0.3488,
      "step": 3668
    },
    {
      "epoch": 0.75,
      "grad_norm": 1.289243459701538,
      "learning_rate": 1.248949472173824e-05,
      "loss": 0.4456,
      "step": 3669
    },
    {
      "epoch": 0.75,
      "grad_norm": 1.7235546112060547,
      "learning_rate": 1.2487444911345701e-05,
      "loss": 0.4337,
      "step": 3670
    },
    {
      "epoch": 0.75,
      "grad_norm": 1.18017578125,
      "learning_rate": 1.2485395100953163e-05,
      "loss": 0.4394,
      "step": 3671
    },
    {
      "epoch": 0.75,
      "grad_norm": 1.5048733949661255,
      "learning_rate": 1.2483345290560625e-05,
      "loss": 0.3695,
      "step": 3672
    },
    {
      "epoch": 0.75,
      "grad_norm": 1.21797513961792,
      "learning_rate": 1.2481295480168085e-05,
      "loss": 0.4488,
      "step": 3673
    },
    {
      "epoch": 0.75,
      "grad_norm": 0.8430120944976807,
      "learning_rate": 1.2479245669775545e-05,
      "loss": 0.4707,
      "step": 3674
    },
    {
      "epoch": 0.75,
      "grad_norm": 1.04999840259552,
      "learning_rate": 1.2477195859383009e-05,
      "loss": 0.6003,
      "step": 3675
    },
    {
      "epoch": 0.75,
      "grad_norm": 1.4263370037078857,
      "learning_rate": 1.2475146048990469e-05,
      "loss": 0.3603,
      "step": 3676
    },
    {
      "epoch": 0.75,
      "grad_norm": 1.4696170091629028,
      "learning_rate": 1.2473096238597931e-05,
      "loss": 0.4604,
      "step": 3677
    },
    {
      "epoch": 0.75,
      "grad_norm": 0.8325093388557434,
      "learning_rate": 1.2471046428205391e-05,
      "loss": 0.3165,
      "step": 3678
    },
    {
      "epoch": 0.75,
      "grad_norm": 1.613811731338501,
      "learning_rate": 1.2468996617812855e-05,
      "loss": 0.3351,
      "step": 3679
    },
    {
      "epoch": 0.75,
      "grad_norm": 2.3181233406066895,
      "learning_rate": 1.2466946807420315e-05,
      "loss": 0.4482,
      "step": 3680
    },
    {
      "epoch": 0.75,
      "grad_norm": 1.201050043106079,
      "learning_rate": 1.2464896997027775e-05,
      "loss": 0.2807,
      "step": 3681
    },
    {
      "epoch": 0.75,
      "grad_norm": 1.4577405452728271,
      "learning_rate": 1.2462847186635237e-05,
      "loss": 0.3663,
      "step": 3682
    },
    {
      "epoch": 0.75,
      "grad_norm": 1.7745184898376465,
      "learning_rate": 1.2460797376242699e-05,
      "loss": 0.4718,
      "step": 3683
    },
    {
      "epoch": 0.75,
      "grad_norm": 0.6224774718284607,
      "learning_rate": 1.245874756585016e-05,
      "loss": 0.4497,
      "step": 3684
    },
    {
      "epoch": 0.75,
      "grad_norm": 1.6369625329971313,
      "learning_rate": 1.245669775545762e-05,
      "loss": 0.4965,
      "step": 3685
    },
    {
      "epoch": 0.76,
      "grad_norm": 0.8558014631271362,
      "learning_rate": 1.245464794506508e-05,
      "loss": 0.3645,
      "step": 3686
    },
    {
      "epoch": 0.76,
      "grad_norm": 1.10099458694458,
      "learning_rate": 1.2452598134672544e-05,
      "loss": 0.3331,
      "step": 3687
    },
    {
      "epoch": 0.76,
      "grad_norm": 1.7990293502807617,
      "learning_rate": 1.2450548324280005e-05,
      "loss": 0.5671,
      "step": 3688
    },
    {
      "epoch": 0.76,
      "grad_norm": 1.464218258857727,
      "learning_rate": 1.2448498513887466e-05,
      "loss": 0.4703,
      "step": 3689
    },
    {
      "epoch": 0.76,
      "grad_norm": 1.2406628131866455,
      "learning_rate": 1.2446448703494928e-05,
      "loss": 0.4263,
      "step": 3690
    },
    {
      "epoch": 0.76,
      "grad_norm": 1.039232611656189,
      "learning_rate": 1.244439889310239e-05,
      "loss": 0.4802,
      "step": 3691
    },
    {
      "epoch": 0.76,
      "grad_norm": 1.0132163763046265,
      "learning_rate": 1.244234908270985e-05,
      "loss": 0.4236,
      "step": 3692
    },
    {
      "epoch": 0.76,
      "grad_norm": 0.9831961393356323,
      "learning_rate": 1.244029927231731e-05,
      "loss": 0.3283,
      "step": 3693
    },
    {
      "epoch": 0.76,
      "grad_norm": 1.298688530921936,
      "learning_rate": 1.2438249461924774e-05,
      "loss": 0.4713,
      "step": 3694
    },
    {
      "epoch": 0.76,
      "grad_norm": 1.0876538753509521,
      "learning_rate": 1.2436199651532234e-05,
      "loss": 0.4777,
      "step": 3695
    },
    {
      "epoch": 0.76,
      "grad_norm": 1.7523432970046997,
      "learning_rate": 1.2434149841139696e-05,
      "loss": 0.392,
      "step": 3696
    },
    {
      "epoch": 0.76,
      "grad_norm": 2.517812490463257,
      "learning_rate": 1.2432100030747156e-05,
      "loss": 0.4065,
      "step": 3697
    },
    {
      "epoch": 0.76,
      "grad_norm": 1.0546820163726807,
      "learning_rate": 1.243005022035462e-05,
      "loss": 0.6453,
      "step": 3698
    },
    {
      "epoch": 0.76,
      "grad_norm": 1.7034586668014526,
      "learning_rate": 1.242800040996208e-05,
      "loss": 0.4653,
      "step": 3699
    },
    {
      "epoch": 0.76,
      "grad_norm": 0.9164930582046509,
      "learning_rate": 1.242595059956954e-05,
      "loss": 0.3692,
      "step": 3700
    },
    {
      "epoch": 0.76,
      "grad_norm": 1.4724215269088745,
      "learning_rate": 1.2423900789177002e-05,
      "loss": 0.441,
      "step": 3701
    },
    {
      "epoch": 0.76,
      "grad_norm": 1.4969313144683838,
      "learning_rate": 1.2421850978784464e-05,
      "loss": 0.4071,
      "step": 3702
    },
    {
      "epoch": 0.76,
      "grad_norm": 0.9530113935470581,
      "learning_rate": 1.2419801168391926e-05,
      "loss": 0.555,
      "step": 3703
    },
    {
      "epoch": 0.76,
      "grad_norm": 1.253477692604065,
      "learning_rate": 1.2417751357999386e-05,
      "loss": 0.4621,
      "step": 3704
    },
    {
      "epoch": 0.76,
      "grad_norm": 1.383583903312683,
      "learning_rate": 1.2415701547606846e-05,
      "loss": 0.4853,
      "step": 3705
    },
    {
      "epoch": 0.76,
      "grad_norm": 1.6675714254379272,
      "learning_rate": 1.241365173721431e-05,
      "loss": 0.4419,
      "step": 3706
    },
    {
      "epoch": 0.76,
      "grad_norm": 0.9337651133537292,
      "learning_rate": 1.241160192682177e-05,
      "loss": 0.4323,
      "step": 3707
    },
    {
      "epoch": 0.76,
      "grad_norm": 1.2423735857009888,
      "learning_rate": 1.2409552116429232e-05,
      "loss": 0.3142,
      "step": 3708
    },
    {
      "epoch": 0.76,
      "grad_norm": 1.142174243927002,
      "learning_rate": 1.2407502306036692e-05,
      "loss": 0.4246,
      "step": 3709
    },
    {
      "epoch": 0.76,
      "grad_norm": 1.7048944234848022,
      "learning_rate": 1.2405452495644155e-05,
      "loss": 0.4905,
      "step": 3710
    },
    {
      "epoch": 0.76,
      "grad_norm": 1.39846670627594,
      "learning_rate": 1.2403402685251615e-05,
      "loss": 0.3958,
      "step": 3711
    },
    {
      "epoch": 0.76,
      "grad_norm": 0.818648636341095,
      "learning_rate": 1.2401352874859076e-05,
      "loss": 0.5179,
      "step": 3712
    },
    {
      "epoch": 0.76,
      "grad_norm": 0.9543313980102539,
      "learning_rate": 1.2399303064466537e-05,
      "loss": 0.3475,
      "step": 3713
    },
    {
      "epoch": 0.76,
      "grad_norm": 1.770242691040039,
      "learning_rate": 1.2397253254074e-05,
      "loss": 0.4399,
      "step": 3714
    },
    {
      "epoch": 0.76,
      "grad_norm": 1.1581109762191772,
      "learning_rate": 1.2395203443681461e-05,
      "loss": 0.4352,
      "step": 3715
    },
    {
      "epoch": 0.76,
      "grad_norm": 1.0567076206207275,
      "learning_rate": 1.2393153633288921e-05,
      "loss": 0.4487,
      "step": 3716
    },
    {
      "epoch": 0.76,
      "grad_norm": 1.5165339708328247,
      "learning_rate": 1.2391103822896381e-05,
      "loss": 0.4188,
      "step": 3717
    },
    {
      "epoch": 0.76,
      "grad_norm": 1.2070975303649902,
      "learning_rate": 1.2389054012503845e-05,
      "loss": 0.4558,
      "step": 3718
    },
    {
      "epoch": 0.76,
      "grad_norm": 1.2763196229934692,
      "learning_rate": 1.2387004202111305e-05,
      "loss": 0.4624,
      "step": 3719
    },
    {
      "epoch": 0.76,
      "grad_norm": 0.838361918926239,
      "learning_rate": 1.2384954391718767e-05,
      "loss": 0.2596,
      "step": 3720
    },
    {
      "epoch": 0.76,
      "grad_norm": 0.9850391149520874,
      "learning_rate": 1.2382904581326229e-05,
      "loss": 0.4349,
      "step": 3721
    },
    {
      "epoch": 0.76,
      "grad_norm": 1.5091817378997803,
      "learning_rate": 1.238085477093369e-05,
      "loss": 0.3537,
      "step": 3722
    },
    {
      "epoch": 0.76,
      "grad_norm": 1.0724964141845703,
      "learning_rate": 1.2378804960541151e-05,
      "loss": 0.4511,
      "step": 3723
    },
    {
      "epoch": 0.76,
      "grad_norm": 1.0505510568618774,
      "learning_rate": 1.2376755150148611e-05,
      "loss": 0.4653,
      "step": 3724
    },
    {
      "epoch": 0.76,
      "grad_norm": 0.9844414591789246,
      "learning_rate": 1.2374705339756075e-05,
      "loss": 0.5218,
      "step": 3725
    },
    {
      "epoch": 0.76,
      "grad_norm": 1.0980316400527954,
      "learning_rate": 1.2372655529363535e-05,
      "loss": 0.3186,
      "step": 3726
    },
    {
      "epoch": 0.76,
      "grad_norm": 0.9444685578346252,
      "learning_rate": 1.2370605718970997e-05,
      "loss": 0.4713,
      "step": 3727
    },
    {
      "epoch": 0.76,
      "grad_norm": 0.8619277477264404,
      "learning_rate": 1.2368555908578457e-05,
      "loss": 0.3856,
      "step": 3728
    },
    {
      "epoch": 0.76,
      "grad_norm": 1.3683233261108398,
      "learning_rate": 1.236650609818592e-05,
      "loss": 0.5122,
      "step": 3729
    },
    {
      "epoch": 0.76,
      "grad_norm": 1.264457106590271,
      "learning_rate": 1.236445628779338e-05,
      "loss": 0.2567,
      "step": 3730
    },
    {
      "epoch": 0.76,
      "grad_norm": 0.9553794264793396,
      "learning_rate": 1.236240647740084e-05,
      "loss": 0.4439,
      "step": 3731
    },
    {
      "epoch": 0.76,
      "grad_norm": 0.9290008544921875,
      "learning_rate": 1.2360356667008303e-05,
      "loss": 0.4954,
      "step": 3732
    },
    {
      "epoch": 0.76,
      "grad_norm": 2.3371989727020264,
      "learning_rate": 1.2358306856615764e-05,
      "loss": 0.4001,
      "step": 3733
    },
    {
      "epoch": 0.77,
      "grad_norm": 1.3833435773849487,
      "learning_rate": 1.2356257046223226e-05,
      "loss": 0.3238,
      "step": 3734
    },
    {
      "epoch": 0.77,
      "grad_norm": 0.8072580695152283,
      "learning_rate": 1.2354207235830686e-05,
      "loss": 0.2411,
      "step": 3735
    },
    {
      "epoch": 0.77,
      "grad_norm": 1.021959662437439,
      "learning_rate": 1.2352157425438147e-05,
      "loss": 0.5583,
      "step": 3736
    },
    {
      "epoch": 0.77,
      "grad_norm": 3.622502326965332,
      "learning_rate": 1.235010761504561e-05,
      "loss": 0.4244,
      "step": 3737
    },
    {
      "epoch": 0.77,
      "grad_norm": 1.0698821544647217,
      "learning_rate": 1.234805780465307e-05,
      "loss": 0.4456,
      "step": 3738
    },
    {
      "epoch": 0.77,
      "grad_norm": 1.0890278816223145,
      "learning_rate": 1.2346007994260532e-05,
      "loss": 0.417,
      "step": 3739
    },
    {
      "epoch": 0.77,
      "grad_norm": 1.1396983861923218,
      "learning_rate": 1.2343958183867992e-05,
      "loss": 0.3426,
      "step": 3740
    },
    {
      "epoch": 0.77,
      "grad_norm": 1.1640831232070923,
      "learning_rate": 1.2341908373475456e-05,
      "loss": 0.4244,
      "step": 3741
    },
    {
      "epoch": 0.77,
      "grad_norm": 1.3545427322387695,
      "learning_rate": 1.2339858563082916e-05,
      "loss": 0.4602,
      "step": 3742
    },
    {
      "epoch": 0.77,
      "grad_norm": 1.861276626586914,
      "learning_rate": 1.2337808752690376e-05,
      "loss": 0.4566,
      "step": 3743
    },
    {
      "epoch": 0.77,
      "grad_norm": 1.3218201398849487,
      "learning_rate": 1.2335758942297838e-05,
      "loss": 0.457,
      "step": 3744
    },
    {
      "epoch": 0.77,
      "grad_norm": 2.5508406162261963,
      "learning_rate": 1.23337091319053e-05,
      "loss": 0.4497,
      "step": 3745
    },
    {
      "epoch": 0.77,
      "grad_norm": 1.3053948879241943,
      "learning_rate": 1.2331659321512762e-05,
      "loss": 0.3817,
      "step": 3746
    },
    {
      "epoch": 0.77,
      "grad_norm": 1.0422934293746948,
      "learning_rate": 1.2329609511120222e-05,
      "loss": 0.4592,
      "step": 3747
    },
    {
      "epoch": 0.77,
      "grad_norm": 1.3437460660934448,
      "learning_rate": 1.2327559700727682e-05,
      "loss": 0.2577,
      "step": 3748
    },
    {
      "epoch": 0.77,
      "grad_norm": 1.3966859579086304,
      "learning_rate": 1.2325509890335146e-05,
      "loss": 0.4345,
      "step": 3749
    },
    {
      "epoch": 0.77,
      "grad_norm": 1.4930564165115356,
      "learning_rate": 1.2323460079942606e-05,
      "loss": 0.2738,
      "step": 3750
    },
    {
      "epoch": 0.77,
      "grad_norm": 4.43872594833374,
      "learning_rate": 1.2321410269550068e-05,
      "loss": 0.3278,
      "step": 3751
    },
    {
      "epoch": 0.77,
      "grad_norm": 1.007055640220642,
      "learning_rate": 1.231936045915753e-05,
      "loss": 0.43,
      "step": 3752
    },
    {
      "epoch": 0.77,
      "grad_norm": 1.5271652936935425,
      "learning_rate": 1.2317310648764991e-05,
      "loss": 0.3938,
      "step": 3753
    },
    {
      "epoch": 0.77,
      "grad_norm": 1.2852391004562378,
      "learning_rate": 1.2315260838372451e-05,
      "loss": 0.2345,
      "step": 3754
    },
    {
      "epoch": 0.77,
      "grad_norm": 1.5071536302566528,
      "learning_rate": 1.2313211027979912e-05,
      "loss": 0.4352,
      "step": 3755
    },
    {
      "epoch": 0.77,
      "grad_norm": 1.1238226890563965,
      "learning_rate": 1.2311161217587375e-05,
      "loss": 0.3779,
      "step": 3756
    },
    {
      "epoch": 0.77,
      "grad_norm": 0.7402597665786743,
      "learning_rate": 1.2309111407194835e-05,
      "loss": 0.3175,
      "step": 3757
    },
    {
      "epoch": 0.77,
      "grad_norm": 4.729639530181885,
      "learning_rate": 1.2307061596802297e-05,
      "loss": 0.3822,
      "step": 3758
    },
    {
      "epoch": 0.77,
      "grad_norm": 2.8447415828704834,
      "learning_rate": 1.2305011786409757e-05,
      "loss": 0.5001,
      "step": 3759
    },
    {
      "epoch": 0.77,
      "grad_norm": 2.08627986907959,
      "learning_rate": 1.2302961976017221e-05,
      "loss": 0.3668,
      "step": 3760
    },
    {
      "epoch": 0.77,
      "grad_norm": 1.2848384380340576,
      "learning_rate": 1.2300912165624681e-05,
      "loss": 0.3145,
      "step": 3761
    },
    {
      "epoch": 0.77,
      "grad_norm": 1.1139686107635498,
      "learning_rate": 1.2298862355232141e-05,
      "loss": 0.4392,
      "step": 3762
    },
    {
      "epoch": 0.77,
      "grad_norm": 5.013693332672119,
      "learning_rate": 1.2296812544839603e-05,
      "loss": 0.3018,
      "step": 3763
    },
    {
      "epoch": 0.77,
      "grad_norm": 2.5864596366882324,
      "learning_rate": 1.2294762734447065e-05,
      "loss": 0.3155,
      "step": 3764
    },
    {
      "epoch": 0.77,
      "grad_norm": 1.9489293098449707,
      "learning_rate": 1.2292712924054527e-05,
      "loss": 0.5113,
      "step": 3765
    },
    {
      "epoch": 0.77,
      "grad_norm": 1.6250998973846436,
      "learning_rate": 1.2290663113661987e-05,
      "loss": 0.3014,
      "step": 3766
    },
    {
      "epoch": 0.77,
      "grad_norm": 3.267669916152954,
      "learning_rate": 1.2288613303269447e-05,
      "loss": 0.3262,
      "step": 3767
    },
    {
      "epoch": 0.77,
      "grad_norm": 1.4458413124084473,
      "learning_rate": 1.228656349287691e-05,
      "loss": 0.3927,
      "step": 3768
    },
    {
      "epoch": 0.77,
      "grad_norm": 1.1053268909454346,
      "learning_rate": 1.2284513682484371e-05,
      "loss": 0.2933,
      "step": 3769
    },
    {
      "epoch": 0.77,
      "grad_norm": 0.8767555952072144,
      "learning_rate": 1.2282463872091833e-05,
      "loss": 0.3443,
      "step": 3770
    },
    {
      "epoch": 0.77,
      "grad_norm": 1.0291993618011475,
      "learning_rate": 1.2280414061699293e-05,
      "loss": 0.4318,
      "step": 3771
    },
    {
      "epoch": 0.77,
      "grad_norm": 1.6973899602890015,
      "learning_rate": 1.2278364251306756e-05,
      "loss": 0.4054,
      "step": 3772
    },
    {
      "epoch": 0.77,
      "grad_norm": 2.9495394229888916,
      "learning_rate": 1.2276314440914217e-05,
      "loss": 0.4608,
      "step": 3773
    },
    {
      "epoch": 0.77,
      "grad_norm": 0.8138522505760193,
      "learning_rate": 1.2274264630521677e-05,
      "loss": 0.4476,
      "step": 3774
    },
    {
      "epoch": 0.77,
      "grad_norm": 1.0701183080673218,
      "learning_rate": 1.2272214820129139e-05,
      "loss": 0.3685,
      "step": 3775
    },
    {
      "epoch": 0.77,
      "grad_norm": 2.973717212677002,
      "learning_rate": 1.22701650097366e-05,
      "loss": 0.3619,
      "step": 3776
    },
    {
      "epoch": 0.77,
      "grad_norm": 0.9714756608009338,
      "learning_rate": 1.2268115199344062e-05,
      "loss": 0.4242,
      "step": 3777
    },
    {
      "epoch": 0.77,
      "grad_norm": 0.975902795791626,
      "learning_rate": 1.2266065388951522e-05,
      "loss": 0.3144,
      "step": 3778
    },
    {
      "epoch": 0.77,
      "grad_norm": 0.9778187870979309,
      "learning_rate": 1.2264015578558986e-05,
      "loss": 0.446,
      "step": 3779
    },
    {
      "epoch": 0.77,
      "grad_norm": 0.9692533612251282,
      "learning_rate": 1.2261965768166446e-05,
      "loss": 0.4402,
      "step": 3780
    },
    {
      "epoch": 0.77,
      "grad_norm": 1.334049940109253,
      "learning_rate": 1.2259915957773906e-05,
      "loss": 0.4924,
      "step": 3781
    },
    {
      "epoch": 0.77,
      "grad_norm": 1.3121058940887451,
      "learning_rate": 1.2257866147381368e-05,
      "loss": 0.6058,
      "step": 3782
    },
    {
      "epoch": 0.78,
      "grad_norm": 1.4449976682662964,
      "learning_rate": 1.225581633698883e-05,
      "loss": 0.3651,
      "step": 3783
    },
    {
      "epoch": 0.78,
      "grad_norm": 0.9660130143165588,
      "learning_rate": 1.2253766526596292e-05,
      "loss": 0.5016,
      "step": 3784
    },
    {
      "epoch": 0.78,
      "grad_norm": 1.3205839395523071,
      "learning_rate": 1.2251716716203752e-05,
      "loss": 0.3485,
      "step": 3785
    },
    {
      "epoch": 0.78,
      "grad_norm": 1.1817524433135986,
      "learning_rate": 1.2249666905811212e-05,
      "loss": 0.4662,
      "step": 3786
    },
    {
      "epoch": 0.78,
      "grad_norm": 1.3879079818725586,
      "learning_rate": 1.2247617095418676e-05,
      "loss": 0.3991,
      "step": 3787
    },
    {
      "epoch": 0.78,
      "grad_norm": 1.4655565023422241,
      "learning_rate": 1.2245567285026136e-05,
      "loss": 0.3892,
      "step": 3788
    },
    {
      "epoch": 0.78,
      "grad_norm": 1.6741918325424194,
      "learning_rate": 1.2243517474633598e-05,
      "loss": 0.3863,
      "step": 3789
    },
    {
      "epoch": 0.78,
      "grad_norm": 1.168318271636963,
      "learning_rate": 1.2241467664241058e-05,
      "loss": 0.4504,
      "step": 3790
    },
    {
      "epoch": 0.78,
      "grad_norm": 1.4937138557434082,
      "learning_rate": 1.2239417853848522e-05,
      "loss": 0.4266,
      "step": 3791
    },
    {
      "epoch": 0.78,
      "grad_norm": 1.1225203275680542,
      "learning_rate": 1.2237368043455982e-05,
      "loss": 0.3511,
      "step": 3792
    },
    {
      "epoch": 0.78,
      "grad_norm": 1.363795518875122,
      "learning_rate": 1.2235318233063442e-05,
      "loss": 0.3503,
      "step": 3793
    },
    {
      "epoch": 0.78,
      "grad_norm": 1.0341696739196777,
      "learning_rate": 1.2233268422670904e-05,
      "loss": 0.322,
      "step": 3794
    },
    {
      "epoch": 0.78,
      "grad_norm": 0.7561960816383362,
      "learning_rate": 1.2231218612278366e-05,
      "loss": 0.4387,
      "step": 3795
    },
    {
      "epoch": 0.78,
      "grad_norm": 1.145567536354065,
      "learning_rate": 1.2229168801885827e-05,
      "loss": 0.4889,
      "step": 3796
    },
    {
      "epoch": 0.78,
      "grad_norm": 1.1252301931381226,
      "learning_rate": 1.2227118991493288e-05,
      "loss": 0.6427,
      "step": 3797
    },
    {
      "epoch": 0.78,
      "grad_norm": 2.1813647747039795,
      "learning_rate": 1.2225069181100748e-05,
      "loss": 0.5611,
      "step": 3798
    },
    {
      "epoch": 0.78,
      "grad_norm": 0.8493691086769104,
      "learning_rate": 1.2223019370708211e-05,
      "loss": 0.4338,
      "step": 3799
    },
    {
      "epoch": 0.78,
      "grad_norm": 2.1403958797454834,
      "learning_rate": 1.2220969560315671e-05,
      "loss": 0.5301,
      "step": 3800
    },
    {
      "epoch": 0.78,
      "grad_norm": 2.5075523853302,
      "learning_rate": 1.2218919749923133e-05,
      "loss": 0.3677,
      "step": 3801
    },
    {
      "epoch": 0.78,
      "grad_norm": 1.4384127855300903,
      "learning_rate": 1.2216869939530593e-05,
      "loss": 0.3498,
      "step": 3802
    },
    {
      "epoch": 0.78,
      "grad_norm": 1.899430274963379,
      "learning_rate": 1.2214820129138057e-05,
      "loss": 0.3345,
      "step": 3803
    },
    {
      "epoch": 0.78,
      "grad_norm": 0.9652764201164246,
      "learning_rate": 1.2212770318745517e-05,
      "loss": 0.4707,
      "step": 3804
    },
    {
      "epoch": 0.78,
      "grad_norm": 3.023601531982422,
      "learning_rate": 1.2210720508352977e-05,
      "loss": 0.4025,
      "step": 3805
    },
    {
      "epoch": 0.78,
      "grad_norm": 1.4325435161590576,
      "learning_rate": 1.220867069796044e-05,
      "loss": 0.4536,
      "step": 3806
    },
    {
      "epoch": 0.78,
      "grad_norm": 1.8397088050842285,
      "learning_rate": 1.2206620887567901e-05,
      "loss": 0.3576,
      "step": 3807
    },
    {
      "epoch": 0.78,
      "grad_norm": 1.3017901182174683,
      "learning_rate": 1.2204571077175363e-05,
      "loss": 0.3778,
      "step": 3808
    },
    {
      "epoch": 0.78,
      "grad_norm": 1.9067037105560303,
      "learning_rate": 1.2202521266782823e-05,
      "loss": 0.4565,
      "step": 3809
    },
    {
      "epoch": 0.78,
      "grad_norm": 1.1018624305725098,
      "learning_rate": 1.2200471456390287e-05,
      "loss": 0.5582,
      "step": 3810
    },
    {
      "epoch": 0.78,
      "grad_norm": 1.904815435409546,
      "learning_rate": 1.2198421645997747e-05,
      "loss": 0.5277,
      "step": 3811
    },
    {
      "epoch": 0.78,
      "grad_norm": 1.0968575477600098,
      "learning_rate": 1.2196371835605207e-05,
      "loss": 0.4565,
      "step": 3812
    },
    {
      "epoch": 0.78,
      "grad_norm": 2.5464601516723633,
      "learning_rate": 1.2194322025212669e-05,
      "loss": 0.3481,
      "step": 3813
    },
    {
      "epoch": 0.78,
      "grad_norm": 1.9619125127792358,
      "learning_rate": 1.219227221482013e-05,
      "loss": 0.38,
      "step": 3814
    },
    {
      "epoch": 0.78,
      "grad_norm": 1.379936933517456,
      "learning_rate": 1.2190222404427593e-05,
      "loss": 0.3242,
      "step": 3815
    },
    {
      "epoch": 0.78,
      "grad_norm": 0.9392798542976379,
      "learning_rate": 1.2188172594035053e-05,
      "loss": 0.4693,
      "step": 3816
    },
    {
      "epoch": 0.78,
      "grad_norm": 2.4344093799591064,
      "learning_rate": 1.2186122783642513e-05,
      "loss": 0.5103,
      "step": 3817
    },
    {
      "epoch": 0.78,
      "grad_norm": 1.3972721099853516,
      "learning_rate": 1.2184072973249976e-05,
      "loss": 0.4539,
      "step": 3818
    },
    {
      "epoch": 0.78,
      "grad_norm": 0.8554222583770752,
      "learning_rate": 1.2182023162857437e-05,
      "loss": 0.284,
      "step": 3819
    },
    {
      "epoch": 0.78,
      "grad_norm": 1.0259363651275635,
      "learning_rate": 1.2179973352464898e-05,
      "loss": 0.4492,
      "step": 3820
    },
    {
      "epoch": 0.78,
      "grad_norm": 0.914288341999054,
      "learning_rate": 1.2177923542072359e-05,
      "loss": 0.2799,
      "step": 3821
    },
    {
      "epoch": 0.78,
      "grad_norm": 1.5022106170654297,
      "learning_rate": 1.2175873731679822e-05,
      "loss": 0.3503,
      "step": 3822
    },
    {
      "epoch": 0.78,
      "grad_norm": 1.2286897897720337,
      "learning_rate": 1.2173823921287282e-05,
      "loss": 0.3851,
      "step": 3823
    },
    {
      "epoch": 0.78,
      "grad_norm": 0.844484269618988,
      "learning_rate": 1.2171774110894742e-05,
      "loss": 0.3493,
      "step": 3824
    },
    {
      "epoch": 0.78,
      "grad_norm": 1.032019853591919,
      "learning_rate": 1.2169724300502204e-05,
      "loss": 0.5143,
      "step": 3825
    },
    {
      "epoch": 0.78,
      "grad_norm": 1.0387859344482422,
      "learning_rate": 1.2167674490109666e-05,
      "loss": 0.5211,
      "step": 3826
    },
    {
      "epoch": 0.78,
      "grad_norm": 1.161224126815796,
      "learning_rate": 1.2165624679717128e-05,
      "loss": 0.4308,
      "step": 3827
    },
    {
      "epoch": 0.78,
      "grad_norm": 1.4272481203079224,
      "learning_rate": 1.2163574869324588e-05,
      "loss": 0.3504,
      "step": 3828
    },
    {
      "epoch": 0.78,
      "grad_norm": 1.372449278831482,
      "learning_rate": 1.2161525058932048e-05,
      "loss": 0.4271,
      "step": 3829
    },
    {
      "epoch": 0.78,
      "grad_norm": 0.9036755561828613,
      "learning_rate": 1.2159475248539512e-05,
      "loss": 0.4902,
      "step": 3830
    },
    {
      "epoch": 0.78,
      "grad_norm": 1.1731338500976562,
      "learning_rate": 1.2157425438146972e-05,
      "loss": 0.4179,
      "step": 3831
    },
    {
      "epoch": 0.79,
      "grad_norm": 1.3878611326217651,
      "learning_rate": 1.2155375627754434e-05,
      "loss": 0.4786,
      "step": 3832
    },
    {
      "epoch": 0.79,
      "grad_norm": 1.5969135761260986,
      "learning_rate": 1.2153325817361894e-05,
      "loss": 0.3698,
      "step": 3833
    },
    {
      "epoch": 0.79,
      "grad_norm": 1.3266215324401855,
      "learning_rate": 1.2151276006969358e-05,
      "loss": 0.4844,
      "step": 3834
    },
    {
      "epoch": 0.79,
      "grad_norm": 0.9485561847686768,
      "learning_rate": 1.2149226196576818e-05,
      "loss": 0.3336,
      "step": 3835
    },
    {
      "epoch": 0.79,
      "grad_norm": 1.2756186723709106,
      "learning_rate": 1.2147176386184278e-05,
      "loss": 0.3691,
      "step": 3836
    },
    {
      "epoch": 0.79,
      "grad_norm": 1.136070728302002,
      "learning_rate": 1.214512657579174e-05,
      "loss": 0.3691,
      "step": 3837
    },
    {
      "epoch": 0.79,
      "grad_norm": 1.2096962928771973,
      "learning_rate": 1.2143076765399202e-05,
      "loss": 0.2999,
      "step": 3838
    },
    {
      "epoch": 0.79,
      "grad_norm": 1.112170696258545,
      "learning_rate": 1.2141026955006664e-05,
      "loss": 0.3373,
      "step": 3839
    },
    {
      "epoch": 0.79,
      "grad_norm": 1.0931779146194458,
      "learning_rate": 1.2138977144614124e-05,
      "loss": 0.5444,
      "step": 3840
    },
    {
      "epoch": 0.79,
      "grad_norm": 1.0943505764007568,
      "learning_rate": 1.2136927334221587e-05,
      "loss": 0.4128,
      "step": 3841
    },
    {
      "epoch": 0.79,
      "grad_norm": 1.1518926620483398,
      "learning_rate": 1.2134877523829047e-05,
      "loss": 0.3711,
      "step": 3842
    },
    {
      "epoch": 0.79,
      "grad_norm": 0.9389217495918274,
      "learning_rate": 1.2132827713436508e-05,
      "loss": 0.5527,
      "step": 3843
    },
    {
      "epoch": 0.79,
      "grad_norm": 0.872910737991333,
      "learning_rate": 1.213077790304397e-05,
      "loss": 0.3233,
      "step": 3844
    },
    {
      "epoch": 0.79,
      "grad_norm": 1.2731444835662842,
      "learning_rate": 1.2128728092651431e-05,
      "loss": 0.3363,
      "step": 3845
    },
    {
      "epoch": 0.79,
      "grad_norm": 1.2937873601913452,
      "learning_rate": 1.2126678282258893e-05,
      "loss": 0.4574,
      "step": 3846
    },
    {
      "epoch": 0.79,
      "grad_norm": 0.9828187227249146,
      "learning_rate": 1.2124628471866353e-05,
      "loss": 0.4681,
      "step": 3847
    },
    {
      "epoch": 0.79,
      "grad_norm": 1.1988730430603027,
      "learning_rate": 1.2122578661473813e-05,
      "loss": 0.3249,
      "step": 3848
    },
    {
      "epoch": 0.79,
      "grad_norm": 0.8816931843757629,
      "learning_rate": 1.2120528851081277e-05,
      "loss": 0.1533,
      "step": 3849
    },
    {
      "epoch": 0.79,
      "grad_norm": 1.5540584325790405,
      "learning_rate": 1.2118479040688737e-05,
      "loss": 0.4585,
      "step": 3850
    },
    {
      "epoch": 0.79,
      "grad_norm": 1.4109050035476685,
      "learning_rate": 1.2116429230296199e-05,
      "loss": 0.5711,
      "step": 3851
    },
    {
      "epoch": 0.79,
      "grad_norm": 1.7944890260696411,
      "learning_rate": 1.211437941990366e-05,
      "loss": 0.353,
      "step": 3852
    },
    {
      "epoch": 0.79,
      "grad_norm": 2.1383299827575684,
      "learning_rate": 1.2112329609511123e-05,
      "loss": 0.5076,
      "step": 3853
    },
    {
      "epoch": 0.79,
      "grad_norm": 1.635467290878296,
      "learning_rate": 1.2110279799118583e-05,
      "loss": 0.3848,
      "step": 3854
    },
    {
      "epoch": 0.79,
      "grad_norm": 1.5117074251174927,
      "learning_rate": 1.2108229988726043e-05,
      "loss": 0.3766,
      "step": 3855
    },
    {
      "epoch": 0.79,
      "grad_norm": 1.6288543939590454,
      "learning_rate": 1.2106180178333505e-05,
      "loss": 0.4697,
      "step": 3856
    },
    {
      "epoch": 0.79,
      "grad_norm": 1.4478795528411865,
      "learning_rate": 1.2104130367940967e-05,
      "loss": 0.3508,
      "step": 3857
    },
    {
      "epoch": 0.79,
      "grad_norm": 1.7973188161849976,
      "learning_rate": 1.2102080557548429e-05,
      "loss": 0.3483,
      "step": 3858
    },
    {
      "epoch": 0.79,
      "grad_norm": 1.157524824142456,
      "learning_rate": 1.2100030747155889e-05,
      "loss": 0.5322,
      "step": 3859
    },
    {
      "epoch": 0.79,
      "grad_norm": 1.141781210899353,
      "learning_rate": 1.2097980936763349e-05,
      "loss": 0.3104,
      "step": 3860
    },
    {
      "epoch": 0.79,
      "grad_norm": 1.0446521043777466,
      "learning_rate": 1.2095931126370813e-05,
      "loss": 0.4032,
      "step": 3861
    },
    {
      "epoch": 0.79,
      "grad_norm": 1.2491117715835571,
      "learning_rate": 1.2093881315978273e-05,
      "loss": 0.4752,
      "step": 3862
    },
    {
      "epoch": 0.79,
      "grad_norm": 0.8527277112007141,
      "learning_rate": 1.2091831505585735e-05,
      "loss": 0.491,
      "step": 3863
    },
    {
      "epoch": 0.79,
      "grad_norm": 0.9195276498794556,
      "learning_rate": 1.2089781695193195e-05,
      "loss": 0.3551,
      "step": 3864
    },
    {
      "epoch": 0.79,
      "grad_norm": 1.3450136184692383,
      "learning_rate": 1.2087731884800658e-05,
      "loss": 0.4199,
      "step": 3865
    },
    {
      "epoch": 0.79,
      "grad_norm": 2.0481371879577637,
      "learning_rate": 1.2085682074408118e-05,
      "loss": 0.3191,
      "step": 3866
    },
    {
      "epoch": 0.79,
      "grad_norm": 1.4416024684906006,
      "learning_rate": 1.2083632264015579e-05,
      "loss": 0.3022,
      "step": 3867
    },
    {
      "epoch": 0.79,
      "grad_norm": 2.1224782466888428,
      "learning_rate": 1.2081582453623042e-05,
      "loss": 0.4061,
      "step": 3868
    },
    {
      "epoch": 0.79,
      "grad_norm": 1.12217378616333,
      "learning_rate": 1.2079532643230502e-05,
      "loss": 0.3978,
      "step": 3869
    },
    {
      "epoch": 0.79,
      "grad_norm": 1.8945424556732178,
      "learning_rate": 1.2077482832837964e-05,
      "loss": 0.3272,
      "step": 3870
    },
    {
      "epoch": 0.79,
      "grad_norm": 1.180877447128296,
      "learning_rate": 1.2075433022445424e-05,
      "loss": 0.3228,
      "step": 3871
    },
    {
      "epoch": 0.79,
      "grad_norm": 1.1251211166381836,
      "learning_rate": 1.2073383212052888e-05,
      "loss": 0.3634,
      "step": 3872
    },
    {
      "epoch": 0.79,
      "grad_norm": 1.873194694519043,
      "learning_rate": 1.2071333401660348e-05,
      "loss": 0.3871,
      "step": 3873
    },
    {
      "epoch": 0.79,
      "grad_norm": 2.0656275749206543,
      "learning_rate": 1.2069283591267808e-05,
      "loss": 0.3962,
      "step": 3874
    },
    {
      "epoch": 0.79,
      "grad_norm": 0.9912877678871155,
      "learning_rate": 1.206723378087527e-05,
      "loss": 0.2977,
      "step": 3875
    },
    {
      "epoch": 0.79,
      "grad_norm": 1.6544499397277832,
      "learning_rate": 1.2065183970482732e-05,
      "loss": 0.3919,
      "step": 3876
    },
    {
      "epoch": 0.79,
      "grad_norm": 2.5620853900909424,
      "learning_rate": 1.2063134160090194e-05,
      "loss": 0.3577,
      "step": 3877
    },
    {
      "epoch": 0.79,
      "grad_norm": 1.0943071842193604,
      "learning_rate": 1.2061084349697654e-05,
      "loss": 0.4376,
      "step": 3878
    },
    {
      "epoch": 0.79,
      "grad_norm": 1.791018009185791,
      "learning_rate": 1.2059034539305114e-05,
      "loss": 0.4515,
      "step": 3879
    },
    {
      "epoch": 0.79,
      "grad_norm": 0.9726452827453613,
      "learning_rate": 1.2056984728912578e-05,
      "loss": 0.5009,
      "step": 3880
    },
    {
      "epoch": 0.8,
      "grad_norm": 2.6439332962036133,
      "learning_rate": 1.2054934918520038e-05,
      "loss": 0.4337,
      "step": 3881
    },
    {
      "epoch": 0.8,
      "grad_norm": 1.1648510694503784,
      "learning_rate": 1.20528851081275e-05,
      "loss": 0.4933,
      "step": 3882
    },
    {
      "epoch": 0.8,
      "grad_norm": 1.4661000967025757,
      "learning_rate": 1.205083529773496e-05,
      "loss": 0.324,
      "step": 3883
    },
    {
      "epoch": 0.8,
      "grad_norm": 1.3885793685913086,
      "learning_rate": 1.2048785487342423e-05,
      "loss": 0.338,
      "step": 3884
    },
    {
      "epoch": 0.8,
      "grad_norm": 1.2563672065734863,
      "learning_rate": 1.2046735676949884e-05,
      "loss": 0.4005,
      "step": 3885
    },
    {
      "epoch": 0.8,
      "grad_norm": 1.410252332687378,
      "learning_rate": 1.2044685866557344e-05,
      "loss": 0.4458,
      "step": 3886
    },
    {
      "epoch": 0.8,
      "grad_norm": 2.1988532543182373,
      "learning_rate": 1.2042636056164806e-05,
      "loss": 0.3166,
      "step": 3887
    },
    {
      "epoch": 0.8,
      "grad_norm": 1.7009382247924805,
      "learning_rate": 1.2040586245772267e-05,
      "loss": 0.2563,
      "step": 3888
    },
    {
      "epoch": 0.8,
      "grad_norm": 1.06565260887146,
      "learning_rate": 1.203853643537973e-05,
      "loss": 0.3782,
      "step": 3889
    },
    {
      "epoch": 0.8,
      "grad_norm": 2.270927667617798,
      "learning_rate": 1.203648662498719e-05,
      "loss": 0.3724,
      "step": 3890
    },
    {
      "epoch": 0.8,
      "grad_norm": 1.8520389795303345,
      "learning_rate": 1.203443681459465e-05,
      "loss": 0.469,
      "step": 3891
    },
    {
      "epoch": 0.8,
      "grad_norm": 1.010000467300415,
      "learning_rate": 1.2032387004202113e-05,
      "loss": 0.325,
      "step": 3892
    },
    {
      "epoch": 0.8,
      "grad_norm": 1.6452137231826782,
      "learning_rate": 1.2030337193809573e-05,
      "loss": 0.4345,
      "step": 3893
    },
    {
      "epoch": 0.8,
      "grad_norm": 2.25015926361084,
      "learning_rate": 1.2028287383417035e-05,
      "loss": 0.5104,
      "step": 3894
    },
    {
      "epoch": 0.8,
      "grad_norm": 1.0266536474227905,
      "learning_rate": 1.2026237573024495e-05,
      "loss": 0.4078,
      "step": 3895
    },
    {
      "epoch": 0.8,
      "grad_norm": 1.7132751941680908,
      "learning_rate": 1.2024187762631959e-05,
      "loss": 0.31,
      "step": 3896
    },
    {
      "epoch": 0.8,
      "grad_norm": 1.3151627779006958,
      "learning_rate": 1.2022137952239419e-05,
      "loss": 0.3829,
      "step": 3897
    },
    {
      "epoch": 0.8,
      "grad_norm": 0.9666097164154053,
      "learning_rate": 1.202008814184688e-05,
      "loss": 0.3686,
      "step": 3898
    },
    {
      "epoch": 0.8,
      "grad_norm": 1.4353604316711426,
      "learning_rate": 1.2018038331454343e-05,
      "loss": 0.4582,
      "step": 3899
    },
    {
      "epoch": 0.8,
      "grad_norm": 2.0173776149749756,
      "learning_rate": 1.2015988521061803e-05,
      "loss": 0.4845,
      "step": 3900
    },
    {
      "epoch": 0.8,
      "grad_norm": 1.4816780090332031,
      "learning_rate": 1.2013938710669265e-05,
      "loss": 0.3625,
      "step": 3901
    },
    {
      "epoch": 0.8,
      "grad_norm": 1.9415415525436401,
      "learning_rate": 1.2011888900276725e-05,
      "loss": 0.3282,
      "step": 3902
    },
    {
      "epoch": 0.8,
      "grad_norm": 0.9400202035903931,
      "learning_rate": 1.2009839089884188e-05,
      "loss": 0.3425,
      "step": 3903
    },
    {
      "epoch": 0.8,
      "grad_norm": 1.3041852712631226,
      "learning_rate": 1.2007789279491649e-05,
      "loss": 0.4857,
      "step": 3904
    },
    {
      "epoch": 0.8,
      "grad_norm": 2.226163148880005,
      "learning_rate": 1.2005739469099109e-05,
      "loss": 0.3839,
      "step": 3905
    },
    {
      "epoch": 0.8,
      "grad_norm": 2.240253210067749,
      "learning_rate": 1.200368965870657e-05,
      "loss": 0.2509,
      "step": 3906
    },
    {
      "epoch": 0.8,
      "grad_norm": 0.6204902529716492,
      "learning_rate": 1.2001639848314033e-05,
      "loss": 0.2457,
      "step": 3907
    },
    {
      "epoch": 0.8,
      "grad_norm": 2.0126490592956543,
      "learning_rate": 1.1999590037921494e-05,
      "loss": 0.3706,
      "step": 3908
    },
    {
      "epoch": 0.8,
      "grad_norm": 3.189455986022949,
      "learning_rate": 1.1997540227528955e-05,
      "loss": 0.4567,
      "step": 3909
    },
    {
      "epoch": 0.8,
      "grad_norm": 2.1054158210754395,
      "learning_rate": 1.1995490417136415e-05,
      "loss": 0.4216,
      "step": 3910
    },
    {
      "epoch": 0.8,
      "grad_norm": 1.205989956855774,
      "learning_rate": 1.1993440606743878e-05,
      "loss": 0.4146,
      "step": 3911
    },
    {
      "epoch": 0.8,
      "grad_norm": 1.2128291130065918,
      "learning_rate": 1.1991390796351338e-05,
      "loss": 0.4843,
      "step": 3912
    },
    {
      "epoch": 0.8,
      "grad_norm": 3.9353363513946533,
      "learning_rate": 1.19893409859588e-05,
      "loss": 0.4442,
      "step": 3913
    },
    {
      "epoch": 0.8,
      "grad_norm": 1.3435548543930054,
      "learning_rate": 1.198729117556626e-05,
      "loss": 0.47,
      "step": 3914
    },
    {
      "epoch": 0.8,
      "grad_norm": 1.0169126987457275,
      "learning_rate": 1.1985241365173724e-05,
      "loss": 0.4485,
      "step": 3915
    },
    {
      "epoch": 0.8,
      "grad_norm": 3.1115331649780273,
      "learning_rate": 1.1983191554781184e-05,
      "loss": 0.4276,
      "step": 3916
    },
    {
      "epoch": 0.8,
      "grad_norm": 1.540400505065918,
      "learning_rate": 1.1981141744388644e-05,
      "loss": 0.4544,
      "step": 3917
    },
    {
      "epoch": 0.8,
      "grad_norm": 1.3900558948516846,
      "learning_rate": 1.1979091933996106e-05,
      "loss": 0.4699,
      "step": 3918
    },
    {
      "epoch": 0.8,
      "grad_norm": 1.477476716041565,
      "learning_rate": 1.1977042123603568e-05,
      "loss": 0.386,
      "step": 3919
    },
    {
      "epoch": 0.8,
      "grad_norm": 1.8625543117523193,
      "learning_rate": 1.197499231321103e-05,
      "loss": 0.3243,
      "step": 3920
    },
    {
      "epoch": 0.8,
      "grad_norm": 1.121410846710205,
      "learning_rate": 1.197294250281849e-05,
      "loss": 0.4036,
      "step": 3921
    },
    {
      "epoch": 0.8,
      "grad_norm": 0.6504498720169067,
      "learning_rate": 1.197089269242595e-05,
      "loss": 0.3419,
      "step": 3922
    },
    {
      "epoch": 0.8,
      "grad_norm": 1.904409408569336,
      "learning_rate": 1.1968842882033414e-05,
      "loss": 0.2808,
      "step": 3923
    },
    {
      "epoch": 0.8,
      "grad_norm": 1.6180585622787476,
      "learning_rate": 1.1966793071640874e-05,
      "loss": 0.3429,
      "step": 3924
    },
    {
      "epoch": 0.8,
      "grad_norm": 1.2256622314453125,
      "learning_rate": 1.1964743261248336e-05,
      "loss": 0.4602,
      "step": 3925
    },
    {
      "epoch": 0.8,
      "grad_norm": 1.7997243404388428,
      "learning_rate": 1.1962693450855798e-05,
      "loss": 0.4762,
      "step": 3926
    },
    {
      "epoch": 0.8,
      "grad_norm": 1.9593040943145752,
      "learning_rate": 1.196064364046326e-05,
      "loss": 0.4777,
      "step": 3927
    },
    {
      "epoch": 0.8,
      "grad_norm": 1.0070606470108032,
      "learning_rate": 1.195859383007072e-05,
      "loss": 0.4635,
      "step": 3928
    },
    {
      "epoch": 0.8,
      "grad_norm": 1.9358513355255127,
      "learning_rate": 1.195654401967818e-05,
      "loss": 0.2992,
      "step": 3929
    },
    {
      "epoch": 0.81,
      "grad_norm": 0.7635013461112976,
      "learning_rate": 1.1954494209285643e-05,
      "loss": 0.3421,
      "step": 3930
    },
    {
      "epoch": 0.81,
      "grad_norm": 2.0572640895843506,
      "learning_rate": 1.1952444398893104e-05,
      "loss": 0.4232,
      "step": 3931
    },
    {
      "epoch": 0.81,
      "grad_norm": 1.119192361831665,
      "learning_rate": 1.1950394588500565e-05,
      "loss": 0.4053,
      "step": 3932
    },
    {
      "epoch": 0.81,
      "grad_norm": 1.1054003238677979,
      "learning_rate": 1.1948344778108026e-05,
      "loss": 0.4847,
      "step": 3933
    },
    {
      "epoch": 0.81,
      "grad_norm": 0.9559547901153564,
      "learning_rate": 1.1946294967715489e-05,
      "loss": 0.492,
      "step": 3934
    },
    {
      "epoch": 0.81,
      "grad_norm": 0.983088493347168,
      "learning_rate": 1.194424515732295e-05,
      "loss": 0.3453,
      "step": 3935
    },
    {
      "epoch": 0.81,
      "grad_norm": 1.5568214654922485,
      "learning_rate": 1.194219534693041e-05,
      "loss": 0.4633,
      "step": 3936
    },
    {
      "epoch": 0.81,
      "grad_norm": 1.0484188795089722,
      "learning_rate": 1.1940145536537871e-05,
      "loss": 0.4078,
      "step": 3937
    },
    {
      "epoch": 0.81,
      "grad_norm": 1.3962312936782837,
      "learning_rate": 1.1938095726145333e-05,
      "loss": 0.4286,
      "step": 3938
    },
    {
      "epoch": 0.81,
      "grad_norm": 1.4905116558074951,
      "learning_rate": 1.1936045915752795e-05,
      "loss": 0.3068,
      "step": 3939
    },
    {
      "epoch": 0.81,
      "grad_norm": 1.5319201946258545,
      "learning_rate": 1.1933996105360255e-05,
      "loss": 0.4452,
      "step": 3940
    },
    {
      "epoch": 0.81,
      "grad_norm": 1.6112319231033325,
      "learning_rate": 1.1931946294967715e-05,
      "loss": 0.3917,
      "step": 3941
    },
    {
      "epoch": 0.81,
      "grad_norm": 1.2322875261306763,
      "learning_rate": 1.1929896484575179e-05,
      "loss": 0.5234,
      "step": 3942
    },
    {
      "epoch": 0.81,
      "grad_norm": 1.0564441680908203,
      "learning_rate": 1.1927846674182639e-05,
      "loss": 0.4762,
      "step": 3943
    },
    {
      "epoch": 0.81,
      "grad_norm": 1.6911813020706177,
      "learning_rate": 1.1925796863790101e-05,
      "loss": 0.4622,
      "step": 3944
    },
    {
      "epoch": 0.81,
      "grad_norm": 0.7647544145584106,
      "learning_rate": 1.1923747053397561e-05,
      "loss": 0.3396,
      "step": 3945
    },
    {
      "epoch": 0.81,
      "grad_norm": 0.7870773673057556,
      "learning_rate": 1.1921697243005023e-05,
      "loss": 0.3235,
      "step": 3946
    },
    {
      "epoch": 0.81,
      "grad_norm": 1.671711802482605,
      "learning_rate": 1.1919647432612485e-05,
      "loss": 0.4635,
      "step": 3947
    },
    {
      "epoch": 0.81,
      "grad_norm": 1.3386174440383911,
      "learning_rate": 1.1917597622219945e-05,
      "loss": 0.3584,
      "step": 3948
    },
    {
      "epoch": 0.81,
      "grad_norm": 0.8042774796485901,
      "learning_rate": 1.1915547811827407e-05,
      "loss": 0.3407,
      "step": 3949
    },
    {
      "epoch": 0.81,
      "grad_norm": 1.8778610229492188,
      "learning_rate": 1.1913498001434869e-05,
      "loss": 0.3261,
      "step": 3950
    },
    {
      "epoch": 0.81,
      "grad_norm": 0.8522258400917053,
      "learning_rate": 1.191144819104233e-05,
      "loss": 0.3524,
      "step": 3951
    },
    {
      "epoch": 0.81,
      "grad_norm": 1.128000020980835,
      "learning_rate": 1.190939838064979e-05,
      "loss": 0.5167,
      "step": 3952
    },
    {
      "epoch": 0.81,
      "grad_norm": 1.2366459369659424,
      "learning_rate": 1.190734857025725e-05,
      "loss": 0.5155,
      "step": 3953
    },
    {
      "epoch": 0.81,
      "grad_norm": 0.988642156124115,
      "learning_rate": 1.1905298759864714e-05,
      "loss": 0.4236,
      "step": 3954
    },
    {
      "epoch": 0.81,
      "grad_norm": 1.2668719291687012,
      "learning_rate": 1.1903248949472175e-05,
      "loss": 0.3292,
      "step": 3955
    },
    {
      "epoch": 0.81,
      "grad_norm": 2.73313045501709,
      "learning_rate": 1.1901199139079636e-05,
      "loss": 0.5901,
      "step": 3956
    },
    {
      "epoch": 0.81,
      "grad_norm": 1.4536843299865723,
      "learning_rate": 1.1899149328687098e-05,
      "loss": 0.4008,
      "step": 3957
    },
    {
      "epoch": 0.81,
      "grad_norm": 2.5658271312713623,
      "learning_rate": 1.1897099518294558e-05,
      "loss": 0.4584,
      "step": 3958
    },
    {
      "epoch": 0.81,
      "grad_norm": 1.7866297960281372,
      "learning_rate": 1.189504970790202e-05,
      "loss": 0.3764,
      "step": 3959
    },
    {
      "epoch": 0.81,
      "grad_norm": 1.4810311794281006,
      "learning_rate": 1.189299989750948e-05,
      "loss": 0.4243,
      "step": 3960
    },
    {
      "epoch": 0.81,
      "grad_norm": 1.090477466583252,
      "learning_rate": 1.1890950087116944e-05,
      "loss": 0.3941,
      "step": 3961
    },
    {
      "epoch": 0.81,
      "grad_norm": 1.58047616481781,
      "learning_rate": 1.1888900276724404e-05,
      "loss": 0.3515,
      "step": 3962
    },
    {
      "epoch": 0.81,
      "grad_norm": 1.1897011995315552,
      "learning_rate": 1.1886850466331864e-05,
      "loss": 0.3741,
      "step": 3963
    },
    {
      "epoch": 0.81,
      "grad_norm": 0.9744850397109985,
      "learning_rate": 1.1884800655939326e-05,
      "loss": 0.5317,
      "step": 3964
    },
    {
      "epoch": 0.81,
      "grad_norm": 1.285138726234436,
      "learning_rate": 1.1882750845546788e-05,
      "loss": 0.4039,
      "step": 3965
    },
    {
      "epoch": 0.81,
      "grad_norm": 1.2184345722198486,
      "learning_rate": 1.188070103515425e-05,
      "loss": 0.3136,
      "step": 3966
    },
    {
      "epoch": 0.81,
      "grad_norm": 1.4217787981033325,
      "learning_rate": 1.187865122476171e-05,
      "loss": 0.4344,
      "step": 3967
    },
    {
      "epoch": 0.81,
      "grad_norm": 1.3451632261276245,
      "learning_rate": 1.187660141436917e-05,
      "loss": 0.5294,
      "step": 3968
    },
    {
      "epoch": 0.81,
      "grad_norm": 1.1386325359344482,
      "learning_rate": 1.1874551603976634e-05,
      "loss": 0.3211,
      "step": 3969
    },
    {
      "epoch": 0.81,
      "grad_norm": 0.983944833278656,
      "learning_rate": 1.1872501793584094e-05,
      "loss": 0.6148,
      "step": 3970
    },
    {
      "epoch": 0.81,
      "grad_norm": 2.1539294719696045,
      "learning_rate": 1.1870451983191556e-05,
      "loss": 0.4617,
      "step": 3971
    },
    {
      "epoch": 0.81,
      "grad_norm": 1.3487625122070312,
      "learning_rate": 1.1868402172799016e-05,
      "loss": 0.4291,
      "step": 3972
    },
    {
      "epoch": 0.81,
      "grad_norm": 1.8363910913467407,
      "learning_rate": 1.186635236240648e-05,
      "loss": 0.4556,
      "step": 3973
    },
    {
      "epoch": 0.81,
      "grad_norm": 1.0187715291976929,
      "learning_rate": 1.186430255201394e-05,
      "loss": 0.5346,
      "step": 3974
    },
    {
      "epoch": 0.81,
      "grad_norm": 1.4624989032745361,
      "learning_rate": 1.18622527416214e-05,
      "loss": 0.4183,
      "step": 3975
    },
    {
      "epoch": 0.81,
      "grad_norm": 1.859980583190918,
      "learning_rate": 1.1860202931228862e-05,
      "loss": 0.4495,
      "step": 3976
    },
    {
      "epoch": 0.81,
      "grad_norm": 1.170952320098877,
      "learning_rate": 1.1858153120836323e-05,
      "loss": 0.3929,
      "step": 3977
    },
    {
      "epoch": 0.81,
      "grad_norm": 1.659723162651062,
      "learning_rate": 1.1856103310443785e-05,
      "loss": 0.4137,
      "step": 3978
    },
    {
      "epoch": 0.82,
      "grad_norm": 1.707330584526062,
      "learning_rate": 1.1854053500051246e-05,
      "loss": 0.4981,
      "step": 3979
    },
    {
      "epoch": 0.82,
      "grad_norm": 1.0423033237457275,
      "learning_rate": 1.1852003689658706e-05,
      "loss": 0.415,
      "step": 3980
    },
    {
      "epoch": 0.82,
      "grad_norm": 0.9614962339401245,
      "learning_rate": 1.184995387926617e-05,
      "loss": 0.3601,
      "step": 3981
    },
    {
      "epoch": 0.82,
      "grad_norm": 1.5010101795196533,
      "learning_rate": 1.184790406887363e-05,
      "loss": 0.4095,
      "step": 3982
    },
    {
      "epoch": 0.82,
      "grad_norm": 1.7859537601470947,
      "learning_rate": 1.1845854258481091e-05,
      "loss": 0.3228,
      "step": 3983
    },
    {
      "epoch": 0.82,
      "grad_norm": 1.2605459690093994,
      "learning_rate": 1.1843804448088551e-05,
      "loss": 0.4345,
      "step": 3984
    },
    {
      "epoch": 0.82,
      "grad_norm": 3.9502782821655273,
      "learning_rate": 1.1841754637696015e-05,
      "loss": 0.3831,
      "step": 3985
    },
    {
      "epoch": 0.82,
      "grad_norm": 2.30086612701416,
      "learning_rate": 1.1839704827303475e-05,
      "loss": 0.4349,
      "step": 3986
    },
    {
      "epoch": 0.82,
      "grad_norm": 2.6241352558135986,
      "learning_rate": 1.1837655016910935e-05,
      "loss": 0.3676,
      "step": 3987
    },
    {
      "epoch": 0.82,
      "grad_norm": 1.065387487411499,
      "learning_rate": 1.1835605206518399e-05,
      "loss": 0.3604,
      "step": 3988
    },
    {
      "epoch": 0.82,
      "grad_norm": 1.5174282789230347,
      "learning_rate": 1.1833555396125859e-05,
      "loss": 0.3826,
      "step": 3989
    },
    {
      "epoch": 0.82,
      "grad_norm": 3.3971173763275146,
      "learning_rate": 1.1831505585733321e-05,
      "loss": 0.4592,
      "step": 3990
    },
    {
      "epoch": 0.82,
      "grad_norm": 1.2514057159423828,
      "learning_rate": 1.1829455775340781e-05,
      "loss": 0.4219,
      "step": 3991
    },
    {
      "epoch": 0.82,
      "grad_norm": 1.3260669708251953,
      "learning_rate": 1.1827405964948245e-05,
      "loss": 0.3979,
      "step": 3992
    },
    {
      "epoch": 0.82,
      "grad_norm": 2.1559486389160156,
      "learning_rate": 1.1825356154555705e-05,
      "loss": 0.5111,
      "step": 3993
    },
    {
      "epoch": 0.82,
      "grad_norm": 1.0933324098587036,
      "learning_rate": 1.1823306344163165e-05,
      "loss": 0.3002,
      "step": 3994
    },
    {
      "epoch": 0.82,
      "grad_norm": 1.2925715446472168,
      "learning_rate": 1.1821256533770627e-05,
      "loss": 0.3696,
      "step": 3995
    },
    {
      "epoch": 0.82,
      "grad_norm": 0.9199633002281189,
      "learning_rate": 1.1819206723378089e-05,
      "loss": 0.3636,
      "step": 3996
    },
    {
      "epoch": 0.82,
      "grad_norm": 0.9403592944145203,
      "learning_rate": 1.181715691298555e-05,
      "loss": 0.3317,
      "step": 3997
    },
    {
      "epoch": 0.82,
      "grad_norm": 1.0943082571029663,
      "learning_rate": 1.181510710259301e-05,
      "loss": 0.1717,
      "step": 3998
    },
    {
      "epoch": 0.82,
      "grad_norm": 1.0612707138061523,
      "learning_rate": 1.181305729220047e-05,
      "loss": 0.4248,
      "step": 3999
    },
    {
      "epoch": 0.82,
      "grad_norm": 1.7051435708999634,
      "learning_rate": 1.1811007481807934e-05,
      "loss": 0.4216,
      "step": 4000
    },
    {
      "epoch": 0.82,
      "eval_loss": 0.40144407749176025,
      "eval_runtime": 668.2009,
      "eval_samples_per_second": 14.966,
      "eval_steps_per_second": 1.871,
      "step": 4000
    },
    {
      "epoch": 0.82,
      "grad_norm": 0.8436797857284546,
      "learning_rate": 1.1808957671415394e-05,
      "loss": 0.3947,
      "step": 4001
    },
    {
      "epoch": 0.82,
      "grad_norm": 1.402997612953186,
      "learning_rate": 1.1806907861022856e-05,
      "loss": 0.1905,
      "step": 4002
    },
    {
      "epoch": 0.82,
      "grad_norm": 1.154161810874939,
      "learning_rate": 1.1804858050630317e-05,
      "loss": 0.3916,
      "step": 4003
    },
    {
      "epoch": 0.82,
      "grad_norm": 0.9684524536132812,
      "learning_rate": 1.180280824023778e-05,
      "loss": 0.3876,
      "step": 4004
    },
    {
      "epoch": 0.82,
      "grad_norm": 2.393454074859619,
      "learning_rate": 1.180075842984524e-05,
      "loss": 0.4879,
      "step": 4005
    },
    {
      "epoch": 0.82,
      "grad_norm": 1.293215036392212,
      "learning_rate": 1.17987086194527e-05,
      "loss": 0.5823,
      "step": 4006
    },
    {
      "epoch": 0.82,
      "grad_norm": 1.655931830406189,
      "learning_rate": 1.1796658809060162e-05,
      "loss": 0.4743,
      "step": 4007
    },
    {
      "epoch": 0.82,
      "grad_norm": 1.2563107013702393,
      "learning_rate": 1.1794608998667624e-05,
      "loss": 0.4019,
      "step": 4008
    },
    {
      "epoch": 0.82,
      "grad_norm": 1.0966426134109497,
      "learning_rate": 1.1792559188275086e-05,
      "loss": 0.281,
      "step": 4009
    },
    {
      "epoch": 0.82,
      "grad_norm": 1.430294156074524,
      "learning_rate": 1.1790509377882546e-05,
      "loss": 0.2901,
      "step": 4010
    },
    {
      "epoch": 0.82,
      "grad_norm": 1.176145076751709,
      "learning_rate": 1.1788459567490006e-05,
      "loss": 0.3447,
      "step": 4011
    },
    {
      "epoch": 0.82,
      "grad_norm": 1.1820493936538696,
      "learning_rate": 1.178640975709747e-05,
      "loss": 0.4178,
      "step": 4012
    },
    {
      "epoch": 0.82,
      "grad_norm": 0.8130080103874207,
      "learning_rate": 1.178435994670493e-05,
      "loss": 0.4103,
      "step": 4013
    },
    {
      "epoch": 0.82,
      "grad_norm": 1.9341410398483276,
      "learning_rate": 1.1782310136312392e-05,
      "loss": 0.4047,
      "step": 4014
    },
    {
      "epoch": 0.82,
      "grad_norm": 1.1812279224395752,
      "learning_rate": 1.1780260325919854e-05,
      "loss": 0.2821,
      "step": 4015
    },
    {
      "epoch": 0.82,
      "grad_norm": 1.199110746383667,
      "learning_rate": 1.1778210515527316e-05,
      "loss": 0.4424,
      "step": 4016
    },
    {
      "epoch": 0.82,
      "grad_norm": 1.1527023315429688,
      "learning_rate": 1.1776160705134776e-05,
      "loss": 0.4014,
      "step": 4017
    },
    {
      "epoch": 0.82,
      "grad_norm": 1.4458930492401123,
      "learning_rate": 1.1774110894742236e-05,
      "loss": 0.4752,
      "step": 4018
    },
    {
      "epoch": 0.82,
      "grad_norm": 1.223958969116211,
      "learning_rate": 1.17720610843497e-05,
      "loss": 0.4969,
      "step": 4019
    },
    {
      "epoch": 0.82,
      "grad_norm": 1.1127959489822388,
      "learning_rate": 1.177001127395716e-05,
      "loss": 0.4152,
      "step": 4020
    },
    {
      "epoch": 0.82,
      "grad_norm": 1.3857593536376953,
      "learning_rate": 1.1767961463564621e-05,
      "loss": 0.3547,
      "step": 4021
    },
    {
      "epoch": 0.82,
      "grad_norm": 0.9366532564163208,
      "learning_rate": 1.1765911653172082e-05,
      "loss": 0.3238,
      "step": 4022
    },
    {
      "epoch": 0.82,
      "grad_norm": 1.8386529684066772,
      "learning_rate": 1.1763861842779545e-05,
      "loss": 0.3465,
      "step": 4023
    },
    {
      "epoch": 0.82,
      "grad_norm": 1.0294852256774902,
      "learning_rate": 1.1761812032387005e-05,
      "loss": 0.454,
      "step": 4024
    },
    {
      "epoch": 0.82,
      "grad_norm": 1.0175917148590088,
      "learning_rate": 1.1759762221994466e-05,
      "loss": 0.3554,
      "step": 4025
    },
    {
      "epoch": 0.82,
      "grad_norm": 1.23789644241333,
      "learning_rate": 1.1757712411601927e-05,
      "loss": 0.337,
      "step": 4026
    },
    {
      "epoch": 0.83,
      "grad_norm": 1.1946039199829102,
      "learning_rate": 1.175566260120939e-05,
      "loss": 0.3613,
      "step": 4027
    },
    {
      "epoch": 0.83,
      "grad_norm": 1.2240054607391357,
      "learning_rate": 1.1753612790816851e-05,
      "loss": 0.375,
      "step": 4028
    },
    {
      "epoch": 0.83,
      "grad_norm": 0.8411372303962708,
      "learning_rate": 1.1751562980424311e-05,
      "loss": 0.4359,
      "step": 4029
    },
    {
      "epoch": 0.83,
      "grad_norm": 1.8235290050506592,
      "learning_rate": 1.1749513170031771e-05,
      "loss": 0.2576,
      "step": 4030
    },
    {
      "epoch": 0.83,
      "grad_norm": 3.253159523010254,
      "learning_rate": 1.1747463359639235e-05,
      "loss": 0.4776,
      "step": 4031
    },
    {
      "epoch": 0.83,
      "grad_norm": 1.2624083757400513,
      "learning_rate": 1.1745413549246695e-05,
      "loss": 0.4976,
      "step": 4032
    },
    {
      "epoch": 0.83,
      "grad_norm": 1.1925554275512695,
      "learning_rate": 1.1743363738854157e-05,
      "loss": 0.5377,
      "step": 4033
    },
    {
      "epoch": 0.83,
      "grad_norm": 1.784279465675354,
      "learning_rate": 1.1741313928461617e-05,
      "loss": 0.4652,
      "step": 4034
    },
    {
      "epoch": 0.83,
      "grad_norm": 2.1274774074554443,
      "learning_rate": 1.173926411806908e-05,
      "loss": 0.3593,
      "step": 4035
    },
    {
      "epoch": 0.83,
      "grad_norm": 1.465438961982727,
      "learning_rate": 1.173721430767654e-05,
      "loss": 0.5128,
      "step": 4036
    },
    {
      "epoch": 0.83,
      "grad_norm": 1.0726613998413086,
      "learning_rate": 1.1735164497284001e-05,
      "loss": 0.3024,
      "step": 4037
    },
    {
      "epoch": 0.83,
      "grad_norm": 1.439640760421753,
      "learning_rate": 1.1733114686891463e-05,
      "loss": 0.3686,
      "step": 4038
    },
    {
      "epoch": 0.83,
      "grad_norm": 1.4480844736099243,
      "learning_rate": 1.1731064876498925e-05,
      "loss": 0.386,
      "step": 4039
    },
    {
      "epoch": 0.83,
      "grad_norm": 1.3489948511123657,
      "learning_rate": 1.1729015066106387e-05,
      "loss": 0.3721,
      "step": 4040
    },
    {
      "epoch": 0.83,
      "grad_norm": 1.2514581680297852,
      "learning_rate": 1.1726965255713847e-05,
      "loss": 0.5115,
      "step": 4041
    },
    {
      "epoch": 0.83,
      "grad_norm": 2.8979313373565674,
      "learning_rate": 1.1724915445321307e-05,
      "loss": 0.3412,
      "step": 4042
    },
    {
      "epoch": 0.83,
      "grad_norm": 1.0347442626953125,
      "learning_rate": 1.172286563492877e-05,
      "loss": 0.3844,
      "step": 4043
    },
    {
      "epoch": 0.83,
      "grad_norm": 0.9925616979598999,
      "learning_rate": 1.172081582453623e-05,
      "loss": 0.4065,
      "step": 4044
    },
    {
      "epoch": 0.83,
      "grad_norm": 1.6376986503601074,
      "learning_rate": 1.1718766014143692e-05,
      "loss": 0.3481,
      "step": 4045
    },
    {
      "epoch": 0.83,
      "grad_norm": 0.7673976421356201,
      "learning_rate": 1.1716716203751154e-05,
      "loss": 0.3276,
      "step": 4046
    },
    {
      "epoch": 0.83,
      "grad_norm": 1.1349358558654785,
      "learning_rate": 1.1714666393358616e-05,
      "loss": 0.3702,
      "step": 4047
    },
    {
      "epoch": 0.83,
      "grad_norm": 2.129143476486206,
      "learning_rate": 1.1712616582966076e-05,
      "loss": 0.2634,
      "step": 4048
    },
    {
      "epoch": 0.83,
      "grad_norm": 1.8008525371551514,
      "learning_rate": 1.1710566772573537e-05,
      "loss": 0.3545,
      "step": 4049
    },
    {
      "epoch": 0.83,
      "grad_norm": 1.0686975717544556,
      "learning_rate": 1.1708516962181e-05,
      "loss": 0.3668,
      "step": 4050
    },
    {
      "epoch": 0.83,
      "grad_norm": 1.2184261083602905,
      "learning_rate": 1.170646715178846e-05,
      "loss": 0.3658,
      "step": 4051
    },
    {
      "epoch": 0.83,
      "grad_norm": 1.9484922885894775,
      "learning_rate": 1.1704417341395922e-05,
      "loss": 0.496,
      "step": 4052
    },
    {
      "epoch": 0.83,
      "grad_norm": 1.1041539907455444,
      "learning_rate": 1.1702367531003382e-05,
      "loss": 0.513,
      "step": 4053
    },
    {
      "epoch": 0.83,
      "grad_norm": 0.6711283326148987,
      "learning_rate": 1.1700317720610846e-05,
      "loss": 0.4198,
      "step": 4054
    },
    {
      "epoch": 0.83,
      "grad_norm": 1.6583656072616577,
      "learning_rate": 1.1698267910218306e-05,
      "loss": 0.3407,
      "step": 4055
    },
    {
      "epoch": 0.83,
      "grad_norm": 1.083431363105774,
      "learning_rate": 1.1696218099825766e-05,
      "loss": 0.6374,
      "step": 4056
    },
    {
      "epoch": 0.83,
      "grad_norm": 1.5789228677749634,
      "learning_rate": 1.1694168289433228e-05,
      "loss": 0.3844,
      "step": 4057
    },
    {
      "epoch": 0.83,
      "grad_norm": 1.9036588668823242,
      "learning_rate": 1.169211847904069e-05,
      "loss": 0.5153,
      "step": 4058
    },
    {
      "epoch": 0.83,
      "grad_norm": 1.333260416984558,
      "learning_rate": 1.1690068668648152e-05,
      "loss": 0.4894,
      "step": 4059
    },
    {
      "epoch": 0.83,
      "grad_norm": 0.9703813195228577,
      "learning_rate": 1.1688018858255612e-05,
      "loss": 0.4374,
      "step": 4060
    },
    {
      "epoch": 0.83,
      "grad_norm": 2.025216579437256,
      "learning_rate": 1.1685969047863072e-05,
      "loss": 0.3565,
      "step": 4061
    },
    {
      "epoch": 0.83,
      "grad_norm": 1.250200867652893,
      "learning_rate": 1.1683919237470536e-05,
      "loss": 0.427,
      "step": 4062
    },
    {
      "epoch": 0.83,
      "grad_norm": 0.9132251143455505,
      "learning_rate": 1.1681869427077996e-05,
      "loss": 0.4033,
      "step": 4063
    },
    {
      "epoch": 0.83,
      "grad_norm": 2.4604597091674805,
      "learning_rate": 1.1679819616685458e-05,
      "loss": 0.2978,
      "step": 4064
    },
    {
      "epoch": 0.83,
      "grad_norm": 1.4280751943588257,
      "learning_rate": 1.1677769806292918e-05,
      "loss": 0.3086,
      "step": 4065
    },
    {
      "epoch": 0.83,
      "grad_norm": 0.9282175898551941,
      "learning_rate": 1.1675719995900381e-05,
      "loss": 0.3766,
      "step": 4066
    },
    {
      "epoch": 0.83,
      "grad_norm": 2.3529276847839355,
      "learning_rate": 1.1673670185507841e-05,
      "loss": 0.3939,
      "step": 4067
    },
    {
      "epoch": 0.83,
      "grad_norm": 4.42480993270874,
      "learning_rate": 1.1671620375115302e-05,
      "loss": 0.3378,
      "step": 4068
    },
    {
      "epoch": 0.83,
      "grad_norm": 1.9557212591171265,
      "learning_rate": 1.1669570564722763e-05,
      "loss": 0.3858,
      "step": 4069
    },
    {
      "epoch": 0.83,
      "grad_norm": 2.084519624710083,
      "learning_rate": 1.1667520754330225e-05,
      "loss": 0.4512,
      "step": 4070
    },
    {
      "epoch": 0.83,
      "grad_norm": 1.2068288326263428,
      "learning_rate": 1.1665470943937687e-05,
      "loss": 0.4487,
      "step": 4071
    },
    {
      "epoch": 0.83,
      "grad_norm": 2.279254913330078,
      "learning_rate": 1.1663421133545147e-05,
      "loss": 0.3296,
      "step": 4072
    },
    {
      "epoch": 0.83,
      "grad_norm": 1.0493825674057007,
      "learning_rate": 1.1661371323152611e-05,
      "loss": 0.4551,
      "step": 4073
    },
    {
      "epoch": 0.83,
      "grad_norm": 1.1856610774993896,
      "learning_rate": 1.1659321512760071e-05,
      "loss": 0.3665,
      "step": 4074
    },
    {
      "epoch": 0.83,
      "grad_norm": 2.689138174057007,
      "learning_rate": 1.1657271702367531e-05,
      "loss": 0.2643,
      "step": 4075
    },
    {
      "epoch": 0.84,
      "grad_norm": 1.0088437795639038,
      "learning_rate": 1.1655221891974993e-05,
      "loss": 0.4442,
      "step": 4076
    },
    {
      "epoch": 0.84,
      "grad_norm": 3.298673391342163,
      "learning_rate": 1.1653172081582455e-05,
      "loss": 0.3222,
      "step": 4077
    },
    {
      "epoch": 0.84,
      "grad_norm": 2.152740001678467,
      "learning_rate": 1.1651122271189917e-05,
      "loss": 0.4142,
      "step": 4078
    },
    {
      "epoch": 0.84,
      "grad_norm": 2.566007614135742,
      "learning_rate": 1.1649072460797377e-05,
      "loss": 0.3941,
      "step": 4079
    },
    {
      "epoch": 0.84,
      "grad_norm": 0.6489132642745972,
      "learning_rate": 1.1647022650404837e-05,
      "loss": 0.3082,
      "step": 4080
    },
    {
      "epoch": 0.84,
      "grad_norm": 3.917001962661743,
      "learning_rate": 1.16449728400123e-05,
      "loss": 0.4862,
      "step": 4081
    },
    {
      "epoch": 0.84,
      "grad_norm": 3.127086639404297,
      "learning_rate": 1.164292302961976e-05,
      "loss": 0.3518,
      "step": 4082
    },
    {
      "epoch": 0.84,
      "grad_norm": 1.0780043601989746,
      "learning_rate": 1.1640873219227223e-05,
      "loss": 0.3499,
      "step": 4083
    },
    {
      "epoch": 0.84,
      "grad_norm": 0.8652812242507935,
      "learning_rate": 1.1638823408834683e-05,
      "loss": 0.3141,
      "step": 4084
    },
    {
      "epoch": 0.84,
      "grad_norm": 1.7356524467468262,
      "learning_rate": 1.1636773598442146e-05,
      "loss": 0.3422,
      "step": 4085
    },
    {
      "epoch": 0.84,
      "grad_norm": 1.8359748125076294,
      "learning_rate": 1.1634723788049607e-05,
      "loss": 0.5193,
      "step": 4086
    },
    {
      "epoch": 0.84,
      "grad_norm": 1.4764350652694702,
      "learning_rate": 1.1632673977657067e-05,
      "loss": 0.4257,
      "step": 4087
    },
    {
      "epoch": 0.84,
      "grad_norm": 1.5499054193496704,
      "learning_rate": 1.1630624167264529e-05,
      "loss": 0.3957,
      "step": 4088
    },
    {
      "epoch": 0.84,
      "grad_norm": 1.0217781066894531,
      "learning_rate": 1.162857435687199e-05,
      "loss": 0.4071,
      "step": 4089
    },
    {
      "epoch": 0.84,
      "grad_norm": 0.7094206809997559,
      "learning_rate": 1.1626524546479452e-05,
      "loss": 0.3562,
      "step": 4090
    },
    {
      "epoch": 0.84,
      "grad_norm": 1.544045329093933,
      "learning_rate": 1.1624474736086912e-05,
      "loss": 0.352,
      "step": 4091
    },
    {
      "epoch": 0.84,
      "grad_norm": 1.5979666709899902,
      "learning_rate": 1.1622424925694373e-05,
      "loss": 0.4223,
      "step": 4092
    },
    {
      "epoch": 0.84,
      "grad_norm": 1.551705241203308,
      "learning_rate": 1.1620375115301836e-05,
      "loss": 0.4917,
      "step": 4093
    },
    {
      "epoch": 0.84,
      "grad_norm": 2.4002435207366943,
      "learning_rate": 1.1618325304909296e-05,
      "loss": 0.3291,
      "step": 4094
    },
    {
      "epoch": 0.84,
      "grad_norm": 1.6320655345916748,
      "learning_rate": 1.1616275494516758e-05,
      "loss": 0.4207,
      "step": 4095
    },
    {
      "epoch": 0.84,
      "grad_norm": 4.140797138214111,
      "learning_rate": 1.1614225684124218e-05,
      "loss": 0.2937,
      "step": 4096
    },
    {
      "epoch": 0.84,
      "grad_norm": 1.4180222749710083,
      "learning_rate": 1.1612175873731682e-05,
      "loss": 0.284,
      "step": 4097
    },
    {
      "epoch": 0.84,
      "grad_norm": 1.7627865076065063,
      "learning_rate": 1.1610126063339142e-05,
      "loss": 0.4909,
      "step": 4098
    },
    {
      "epoch": 0.84,
      "grad_norm": 2.262714147567749,
      "learning_rate": 1.1608076252946602e-05,
      "loss": 0.3993,
      "step": 4099
    },
    {
      "epoch": 0.84,
      "grad_norm": 1.1281324625015259,
      "learning_rate": 1.1606026442554064e-05,
      "loss": 0.2921,
      "step": 4100
    },
    {
      "epoch": 0.84,
      "grad_norm": 1.73540461063385,
      "learning_rate": 1.1603976632161526e-05,
      "loss": 0.3453,
      "step": 4101
    },
    {
      "epoch": 0.84,
      "grad_norm": 2.1156163215637207,
      "learning_rate": 1.1601926821768988e-05,
      "loss": 0.3948,
      "step": 4102
    },
    {
      "epoch": 0.84,
      "grad_norm": 0.9830648303031921,
      "learning_rate": 1.1599877011376448e-05,
      "loss": 0.3283,
      "step": 4103
    },
    {
      "epoch": 0.84,
      "grad_norm": 1.193088173866272,
      "learning_rate": 1.1597827200983911e-05,
      "loss": 0.3027,
      "step": 4104
    },
    {
      "epoch": 0.84,
      "grad_norm": 1.3115205764770508,
      "learning_rate": 1.1595777390591372e-05,
      "loss": 0.5112,
      "step": 4105
    },
    {
      "epoch": 0.84,
      "grad_norm": 1.3974337577819824,
      "learning_rate": 1.1593727580198832e-05,
      "loss": 0.3258,
      "step": 4106
    },
    {
      "epoch": 0.84,
      "grad_norm": 1.7618685960769653,
      "learning_rate": 1.1591677769806294e-05,
      "loss": 0.2743,
      "step": 4107
    },
    {
      "epoch": 0.84,
      "grad_norm": 1.5268175601959229,
      "learning_rate": 1.1589627959413756e-05,
      "loss": 0.4382,
      "step": 4108
    },
    {
      "epoch": 0.84,
      "grad_norm": 1.515258550643921,
      "learning_rate": 1.1587578149021217e-05,
      "loss": 0.4185,
      "step": 4109
    },
    {
      "epoch": 0.84,
      "grad_norm": 1.6958892345428467,
      "learning_rate": 1.1585528338628678e-05,
      "loss": 0.4728,
      "step": 4110
    },
    {
      "epoch": 0.84,
      "grad_norm": 1.0720221996307373,
      "learning_rate": 1.1583478528236138e-05,
      "loss": 0.5162,
      "step": 4111
    },
    {
      "epoch": 0.84,
      "grad_norm": 1.115807056427002,
      "learning_rate": 1.1581428717843601e-05,
      "loss": 0.3894,
      "step": 4112
    },
    {
      "epoch": 0.84,
      "grad_norm": 2.012317657470703,
      "learning_rate": 1.1579378907451061e-05,
      "loss": 0.2515,
      "step": 4113
    },
    {
      "epoch": 0.84,
      "grad_norm": 0.9883923530578613,
      "learning_rate": 1.1577329097058523e-05,
      "loss": 0.4422,
      "step": 4114
    },
    {
      "epoch": 0.84,
      "grad_norm": 1.0141500234603882,
      "learning_rate": 1.1575279286665983e-05,
      "loss": 0.2773,
      "step": 4115
    },
    {
      "epoch": 0.84,
      "grad_norm": 1.238797664642334,
      "learning_rate": 1.1573229476273447e-05,
      "loss": 0.3609,
      "step": 4116
    },
    {
      "epoch": 0.84,
      "grad_norm": 1.400823950767517,
      "learning_rate": 1.1571179665880907e-05,
      "loss": 0.3739,
      "step": 4117
    },
    {
      "epoch": 0.84,
      "grad_norm": 1.153718113899231,
      "learning_rate": 1.1569129855488367e-05,
      "loss": 0.2271,
      "step": 4118
    },
    {
      "epoch": 0.84,
      "grad_norm": 2.2765629291534424,
      "learning_rate": 1.156708004509583e-05,
      "loss": 0.2872,
      "step": 4119
    },
    {
      "epoch": 0.84,
      "grad_norm": 0.8564644455909729,
      "learning_rate": 1.1565030234703291e-05,
      "loss": 0.3345,
      "step": 4120
    },
    {
      "epoch": 0.84,
      "grad_norm": 0.8478949666023254,
      "learning_rate": 1.1562980424310753e-05,
      "loss": 0.3642,
      "step": 4121
    },
    {
      "epoch": 0.84,
      "grad_norm": 0.8189977407455444,
      "learning_rate": 1.1560930613918213e-05,
      "loss": 0.3256,
      "step": 4122
    },
    {
      "epoch": 0.84,
      "grad_norm": 0.8159515857696533,
      "learning_rate": 1.1558880803525673e-05,
      "loss": 0.4212,
      "step": 4123
    },
    {
      "epoch": 0.84,
      "grad_norm": 0.9545471668243408,
      "learning_rate": 1.1556830993133137e-05,
      "loss": 0.3709,
      "step": 4124
    },
    {
      "epoch": 0.85,
      "grad_norm": 1.3891570568084717,
      "learning_rate": 1.1554781182740597e-05,
      "loss": 0.3715,
      "step": 4125
    },
    {
      "epoch": 0.85,
      "grad_norm": 1.2163171768188477,
      "learning_rate": 1.1552731372348059e-05,
      "loss": 0.4967,
      "step": 4126
    },
    {
      "epoch": 0.85,
      "grad_norm": 1.3344449996948242,
      "learning_rate": 1.1550681561955519e-05,
      "loss": 0.4405,
      "step": 4127
    },
    {
      "epoch": 0.85,
      "grad_norm": 1.130409598350525,
      "learning_rate": 1.1548631751562983e-05,
      "loss": 0.3508,
      "step": 4128
    },
    {
      "epoch": 0.85,
      "grad_norm": 1.054843783378601,
      "learning_rate": 1.1546581941170443e-05,
      "loss": 0.5506,
      "step": 4129
    },
    {
      "epoch": 0.85,
      "grad_norm": 1.081945776939392,
      "learning_rate": 1.1544532130777903e-05,
      "loss": 0.2425,
      "step": 4130
    },
    {
      "epoch": 0.85,
      "grad_norm": 1.2752320766448975,
      "learning_rate": 1.1542482320385365e-05,
      "loss": 0.2095,
      "step": 4131
    },
    {
      "epoch": 0.85,
      "grad_norm": 1.2820754051208496,
      "learning_rate": 1.1540432509992827e-05,
      "loss": 0.4964,
      "step": 4132
    },
    {
      "epoch": 0.85,
      "grad_norm": 0.8691174983978271,
      "learning_rate": 1.1538382699600288e-05,
      "loss": 0.5229,
      "step": 4133
    },
    {
      "epoch": 0.85,
      "grad_norm": 2.2788054943084717,
      "learning_rate": 1.1536332889207749e-05,
      "loss": 0.3693,
      "step": 4134
    },
    {
      "epoch": 0.85,
      "grad_norm": 0.8169610500335693,
      "learning_rate": 1.1534283078815212e-05,
      "loss": 0.3142,
      "step": 4135
    },
    {
      "epoch": 0.85,
      "grad_norm": 1.4606844186782837,
      "learning_rate": 1.1532233268422672e-05,
      "loss": 0.3266,
      "step": 4136
    },
    {
      "epoch": 0.85,
      "grad_norm": 0.9455342888832092,
      "learning_rate": 1.1530183458030132e-05,
      "loss": 0.4048,
      "step": 4137
    },
    {
      "epoch": 0.85,
      "grad_norm": 0.9710613489151001,
      "learning_rate": 1.1528133647637594e-05,
      "loss": 0.3033,
      "step": 4138
    },
    {
      "epoch": 0.85,
      "grad_norm": 1.0615649223327637,
      "learning_rate": 1.1526083837245056e-05,
      "loss": 0.4708,
      "step": 4139
    },
    {
      "epoch": 0.85,
      "grad_norm": 1.1338772773742676,
      "learning_rate": 1.1524034026852518e-05,
      "loss": 0.3123,
      "step": 4140
    },
    {
      "epoch": 0.85,
      "grad_norm": 1.0585745573043823,
      "learning_rate": 1.1521984216459978e-05,
      "loss": 0.4728,
      "step": 4141
    },
    {
      "epoch": 0.85,
      "grad_norm": 0.7932665944099426,
      "learning_rate": 1.1519934406067438e-05,
      "loss": 0.4515,
      "step": 4142
    },
    {
      "epoch": 0.85,
      "grad_norm": 1.1265958547592163,
      "learning_rate": 1.1517884595674902e-05,
      "loss": 0.5178,
      "step": 4143
    },
    {
      "epoch": 0.85,
      "grad_norm": 1.3937162160873413,
      "learning_rate": 1.1515834785282362e-05,
      "loss": 0.3948,
      "step": 4144
    },
    {
      "epoch": 0.85,
      "grad_norm": 1.1327060461044312,
      "learning_rate": 1.1513784974889824e-05,
      "loss": 0.4428,
      "step": 4145
    },
    {
      "epoch": 0.85,
      "grad_norm": 1.4850740432739258,
      "learning_rate": 1.1511735164497284e-05,
      "loss": 0.476,
      "step": 4146
    },
    {
      "epoch": 0.85,
      "grad_norm": 1.7693665027618408,
      "learning_rate": 1.1509685354104748e-05,
      "loss": 0.3373,
      "step": 4147
    },
    {
      "epoch": 0.85,
      "grad_norm": 1.296278953552246,
      "learning_rate": 1.1507635543712208e-05,
      "loss": 0.3469,
      "step": 4148
    },
    {
      "epoch": 0.85,
      "grad_norm": 1.2279295921325684,
      "learning_rate": 1.1505585733319668e-05,
      "loss": 0.4693,
      "step": 4149
    },
    {
      "epoch": 0.85,
      "grad_norm": 2.1348092555999756,
      "learning_rate": 1.150353592292713e-05,
      "loss": 0.4541,
      "step": 4150
    },
    {
      "epoch": 0.85,
      "grad_norm": 1.3985515832901,
      "learning_rate": 1.1501486112534592e-05,
      "loss": 0.4264,
      "step": 4151
    },
    {
      "epoch": 0.85,
      "grad_norm": 0.8458012342453003,
      "learning_rate": 1.1499436302142054e-05,
      "loss": 0.3672,
      "step": 4152
    },
    {
      "epoch": 0.85,
      "grad_norm": 2.830554485321045,
      "learning_rate": 1.1497386491749514e-05,
      "loss": 0.3844,
      "step": 4153
    },
    {
      "epoch": 0.85,
      "grad_norm": 0.9932125210762024,
      "learning_rate": 1.1495336681356974e-05,
      "loss": 0.3366,
      "step": 4154
    },
    {
      "epoch": 0.85,
      "grad_norm": 1.3769042491912842,
      "learning_rate": 1.1493286870964437e-05,
      "loss": 0.4307,
      "step": 4155
    },
    {
      "epoch": 0.85,
      "grad_norm": 1.3722060918807983,
      "learning_rate": 1.1491237060571898e-05,
      "loss": 0.3724,
      "step": 4156
    },
    {
      "epoch": 0.85,
      "grad_norm": 0.7859123945236206,
      "learning_rate": 1.148918725017936e-05,
      "loss": 0.5018,
      "step": 4157
    },
    {
      "epoch": 0.85,
      "grad_norm": 1.2190309762954712,
      "learning_rate": 1.148713743978682e-05,
      "loss": 0.3648,
      "step": 4158
    },
    {
      "epoch": 0.85,
      "grad_norm": 2.2910637855529785,
      "learning_rate": 1.1485087629394283e-05,
      "loss": 0.3533,
      "step": 4159
    },
    {
      "epoch": 0.85,
      "grad_norm": 1.1521192789077759,
      "learning_rate": 1.1483037819001743e-05,
      "loss": 0.4051,
      "step": 4160
    },
    {
      "epoch": 0.85,
      "grad_norm": 2.8114030361175537,
      "learning_rate": 1.1480988008609203e-05,
      "loss": 0.308,
      "step": 4161
    },
    {
      "epoch": 0.85,
      "grad_norm": 1.2940925359725952,
      "learning_rate": 1.1478938198216667e-05,
      "loss": 0.4178,
      "step": 4162
    },
    {
      "epoch": 0.85,
      "grad_norm": 1.5166584253311157,
      "learning_rate": 1.1476888387824127e-05,
      "loss": 0.457,
      "step": 4163
    },
    {
      "epoch": 0.85,
      "grad_norm": 1.5623979568481445,
      "learning_rate": 1.1474838577431589e-05,
      "loss": 0.2457,
      "step": 4164
    },
    {
      "epoch": 0.85,
      "grad_norm": 1.002244472503662,
      "learning_rate": 1.147278876703905e-05,
      "loss": 0.4335,
      "step": 4165
    },
    {
      "epoch": 0.85,
      "grad_norm": 1.9685813188552856,
      "learning_rate": 1.1470738956646513e-05,
      "loss": 0.4414,
      "step": 4166
    },
    {
      "epoch": 0.85,
      "grad_norm": 1.5968273878097534,
      "learning_rate": 1.1468689146253973e-05,
      "loss": 0.2978,
      "step": 4167
    },
    {
      "epoch": 0.85,
      "grad_norm": 1.1326487064361572,
      "learning_rate": 1.1466639335861433e-05,
      "loss": 0.3187,
      "step": 4168
    },
    {
      "epoch": 0.85,
      "grad_norm": 1.0196892023086548,
      "learning_rate": 1.1464589525468895e-05,
      "loss": 0.4974,
      "step": 4169
    },
    {
      "epoch": 0.85,
      "grad_norm": 3.9246509075164795,
      "learning_rate": 1.1462539715076357e-05,
      "loss": 0.3989,
      "step": 4170
    },
    {
      "epoch": 0.85,
      "grad_norm": 2.0191848278045654,
      "learning_rate": 1.1460489904683819e-05,
      "loss": 0.5141,
      "step": 4171
    },
    {
      "epoch": 0.85,
      "grad_norm": 1.0645289421081543,
      "learning_rate": 1.1458440094291279e-05,
      "loss": 0.5852,
      "step": 4172
    },
    {
      "epoch": 0.85,
      "grad_norm": 1.4436720609664917,
      "learning_rate": 1.1456390283898739e-05,
      "loss": 0.3918,
      "step": 4173
    },
    {
      "epoch": 0.86,
      "grad_norm": 1.800522804260254,
      "learning_rate": 1.1454340473506202e-05,
      "loss": 0.5305,
      "step": 4174
    },
    {
      "epoch": 0.86,
      "grad_norm": 1.0263936519622803,
      "learning_rate": 1.1452290663113663e-05,
      "loss": 0.5105,
      "step": 4175
    },
    {
      "epoch": 0.86,
      "grad_norm": 1.011675238609314,
      "learning_rate": 1.1450240852721125e-05,
      "loss": 0.5532,
      "step": 4176
    },
    {
      "epoch": 0.86,
      "grad_norm": 1.1864597797393799,
      "learning_rate": 1.1448191042328585e-05,
      "loss": 0.3785,
      "step": 4177
    },
    {
      "epoch": 0.86,
      "grad_norm": 1.2259654998779297,
      "learning_rate": 1.1446141231936048e-05,
      "loss": 0.4638,
      "step": 4178
    },
    {
      "epoch": 0.86,
      "grad_norm": 1.347428798675537,
      "learning_rate": 1.1444091421543508e-05,
      "loss": 0.427,
      "step": 4179
    },
    {
      "epoch": 0.86,
      "grad_norm": 1.072411298751831,
      "learning_rate": 1.1442041611150969e-05,
      "loss": 0.4212,
      "step": 4180
    },
    {
      "epoch": 0.86,
      "grad_norm": 1.9628007411956787,
      "learning_rate": 1.143999180075843e-05,
      "loss": 0.4333,
      "step": 4181
    },
    {
      "epoch": 0.86,
      "grad_norm": 1.465140700340271,
      "learning_rate": 1.1437941990365892e-05,
      "loss": 0.4139,
      "step": 4182
    },
    {
      "epoch": 0.86,
      "grad_norm": 1.3403728008270264,
      "learning_rate": 1.1435892179973354e-05,
      "loss": 0.4645,
      "step": 4183
    },
    {
      "epoch": 0.86,
      "grad_norm": 2.1431000232696533,
      "learning_rate": 1.1433842369580814e-05,
      "loss": 0.3716,
      "step": 4184
    },
    {
      "epoch": 0.86,
      "grad_norm": 2.5548839569091797,
      "learning_rate": 1.1431792559188274e-05,
      "loss": 0.4322,
      "step": 4185
    },
    {
      "epoch": 0.86,
      "grad_norm": 1.4156891107559204,
      "learning_rate": 1.1429742748795738e-05,
      "loss": 0.3844,
      "step": 4186
    },
    {
      "epoch": 0.86,
      "grad_norm": 2.697502374649048,
      "learning_rate": 1.1427692938403198e-05,
      "loss": 0.3943,
      "step": 4187
    },
    {
      "epoch": 0.86,
      "grad_norm": 1.814555048942566,
      "learning_rate": 1.142564312801066e-05,
      "loss": 0.3204,
      "step": 4188
    },
    {
      "epoch": 0.86,
      "grad_norm": 1.363420009613037,
      "learning_rate": 1.142359331761812e-05,
      "loss": 0.3631,
      "step": 4189
    },
    {
      "epoch": 0.86,
      "grad_norm": 1.4201993942260742,
      "learning_rate": 1.1421543507225584e-05,
      "loss": 0.3372,
      "step": 4190
    },
    {
      "epoch": 0.86,
      "grad_norm": 0.8885387778282166,
      "learning_rate": 1.1419493696833044e-05,
      "loss": 0.5268,
      "step": 4191
    },
    {
      "epoch": 0.86,
      "grad_norm": 1.956339955329895,
      "learning_rate": 1.1417443886440504e-05,
      "loss": 0.5161,
      "step": 4192
    },
    {
      "epoch": 0.86,
      "grad_norm": 3.1406025886535645,
      "learning_rate": 1.1415394076047968e-05,
      "loss": 0.3607,
      "step": 4193
    },
    {
      "epoch": 0.86,
      "grad_norm": 1.4748094081878662,
      "learning_rate": 1.1413344265655428e-05,
      "loss": 0.4448,
      "step": 4194
    },
    {
      "epoch": 0.86,
      "grad_norm": 2.2855958938598633,
      "learning_rate": 1.141129445526289e-05,
      "loss": 0.3163,
      "step": 4195
    },
    {
      "epoch": 0.86,
      "grad_norm": 1.6585079431533813,
      "learning_rate": 1.140924464487035e-05,
      "loss": 0.4325,
      "step": 4196
    },
    {
      "epoch": 0.86,
      "grad_norm": 1.3360060453414917,
      "learning_rate": 1.1407194834477813e-05,
      "loss": 0.416,
      "step": 4197
    },
    {
      "epoch": 0.86,
      "grad_norm": 1.6921626329421997,
      "learning_rate": 1.1405145024085273e-05,
      "loss": 0.3579,
      "step": 4198
    },
    {
      "epoch": 0.86,
      "grad_norm": 4.920496940612793,
      "learning_rate": 1.1403095213692734e-05,
      "loss": 0.3313,
      "step": 4199
    },
    {
      "epoch": 0.86,
      "grad_norm": 2.033604145050049,
      "learning_rate": 1.1401045403300196e-05,
      "loss": 0.3743,
      "step": 4200
    },
    {
      "epoch": 0.86,
      "grad_norm": 1.3224202394485474,
      "learning_rate": 1.1398995592907657e-05,
      "loss": 0.338,
      "step": 4201
    },
    {
      "epoch": 0.86,
      "grad_norm": 0.887026309967041,
      "learning_rate": 1.139694578251512e-05,
      "loss": 0.2926,
      "step": 4202
    },
    {
      "epoch": 0.86,
      "grad_norm": 1.450658917427063,
      "learning_rate": 1.139489597212258e-05,
      "loss": 0.4349,
      "step": 4203
    },
    {
      "epoch": 0.86,
      "grad_norm": 1.2351131439208984,
      "learning_rate": 1.139284616173004e-05,
      "loss": 0.355,
      "step": 4204
    },
    {
      "epoch": 0.86,
      "grad_norm": 0.9520105123519897,
      "learning_rate": 1.1390796351337503e-05,
      "loss": 0.4262,
      "step": 4205
    },
    {
      "epoch": 0.86,
      "grad_norm": 2.6472907066345215,
      "learning_rate": 1.1388746540944963e-05,
      "loss": 0.4463,
      "step": 4206
    },
    {
      "epoch": 0.86,
      "grad_norm": 1.4495223760604858,
      "learning_rate": 1.1386696730552425e-05,
      "loss": 0.42,
      "step": 4207
    },
    {
      "epoch": 0.86,
      "grad_norm": 2.0034518241882324,
      "learning_rate": 1.1384646920159885e-05,
      "loss": 0.3369,
      "step": 4208
    },
    {
      "epoch": 0.86,
      "grad_norm": 1.1320635080337524,
      "learning_rate": 1.1382597109767349e-05,
      "loss": 0.3663,
      "step": 4209
    },
    {
      "epoch": 0.86,
      "grad_norm": 1.2305455207824707,
      "learning_rate": 1.1380547299374809e-05,
      "loss": 0.3171,
      "step": 4210
    },
    {
      "epoch": 0.86,
      "grad_norm": 0.8146041035652161,
      "learning_rate": 1.1378497488982269e-05,
      "loss": 0.4185,
      "step": 4211
    },
    {
      "epoch": 0.86,
      "grad_norm": 2.606621026992798,
      "learning_rate": 1.1376447678589731e-05,
      "loss": 0.49,
      "step": 4212
    },
    {
      "epoch": 0.86,
      "grad_norm": 2.345045328140259,
      "learning_rate": 1.1374397868197193e-05,
      "loss": 0.3012,
      "step": 4213
    },
    {
      "epoch": 0.86,
      "grad_norm": 1.1674472093582153,
      "learning_rate": 1.1372348057804655e-05,
      "loss": 0.4063,
      "step": 4214
    },
    {
      "epoch": 0.86,
      "grad_norm": 2.5669667720794678,
      "learning_rate": 1.1370298247412115e-05,
      "loss": 0.4121,
      "step": 4215
    },
    {
      "epoch": 0.86,
      "grad_norm": 2.399960517883301,
      "learning_rate": 1.1368248437019575e-05,
      "loss": 0.327,
      "step": 4216
    },
    {
      "epoch": 0.86,
      "grad_norm": 1.4028481245040894,
      "learning_rate": 1.1366198626627039e-05,
      "loss": 0.448,
      "step": 4217
    },
    {
      "epoch": 0.86,
      "grad_norm": 1.2282134294509888,
      "learning_rate": 1.1364148816234499e-05,
      "loss": 0.3837,
      "step": 4218
    },
    {
      "epoch": 0.86,
      "grad_norm": 1.3047246932983398,
      "learning_rate": 1.136209900584196e-05,
      "loss": 0.5237,
      "step": 4219
    },
    {
      "epoch": 0.86,
      "grad_norm": 1.419037938117981,
      "learning_rate": 1.136004919544942e-05,
      "loss": 0.298,
      "step": 4220
    },
    {
      "epoch": 0.86,
      "grad_norm": 1.6660906076431274,
      "learning_rate": 1.1357999385056884e-05,
      "loss": 0.3816,
      "step": 4221
    },
    {
      "epoch": 0.86,
      "grad_norm": 1.8094699382781982,
      "learning_rate": 1.1355949574664344e-05,
      "loss": 0.4296,
      "step": 4222
    },
    {
      "epoch": 0.87,
      "grad_norm": 0.9815214276313782,
      "learning_rate": 1.1353899764271805e-05,
      "loss": 0.477,
      "step": 4223
    },
    {
      "epoch": 0.87,
      "grad_norm": 0.85430508852005,
      "learning_rate": 1.1351849953879268e-05,
      "loss": 0.5155,
      "step": 4224
    },
    {
      "epoch": 0.87,
      "grad_norm": 1.332963228225708,
      "learning_rate": 1.1349800143486728e-05,
      "loss": 0.3589,
      "step": 4225
    },
    {
      "epoch": 0.87,
      "grad_norm": 0.9138806462287903,
      "learning_rate": 1.134775033309419e-05,
      "loss": 0.5063,
      "step": 4226
    },
    {
      "epoch": 0.87,
      "grad_norm": 1.4150471687316895,
      "learning_rate": 1.134570052270165e-05,
      "loss": 0.3329,
      "step": 4227
    },
    {
      "epoch": 0.87,
      "grad_norm": 1.9549020528793335,
      "learning_rate": 1.1343650712309114e-05,
      "loss": 0.5831,
      "step": 4228
    },
    {
      "epoch": 0.87,
      "grad_norm": 1.1214438676834106,
      "learning_rate": 1.1341600901916574e-05,
      "loss": 0.4209,
      "step": 4229
    },
    {
      "epoch": 0.87,
      "grad_norm": 1.293986201286316,
      "learning_rate": 1.1339551091524034e-05,
      "loss": 0.3491,
      "step": 4230
    },
    {
      "epoch": 0.87,
      "grad_norm": 0.9890806078910828,
      "learning_rate": 1.1337501281131496e-05,
      "loss": 0.3734,
      "step": 4231
    },
    {
      "epoch": 0.87,
      "grad_norm": 1.454783320426941,
      "learning_rate": 1.1335451470738958e-05,
      "loss": 0.3815,
      "step": 4232
    },
    {
      "epoch": 0.87,
      "grad_norm": 1.6033763885498047,
      "learning_rate": 1.133340166034642e-05,
      "loss": 0.3106,
      "step": 4233
    },
    {
      "epoch": 0.87,
      "grad_norm": 1.133012056350708,
      "learning_rate": 1.133135184995388e-05,
      "loss": 0.5365,
      "step": 4234
    },
    {
      "epoch": 0.87,
      "grad_norm": 1.4141147136688232,
      "learning_rate": 1.132930203956134e-05,
      "loss": 0.3283,
      "step": 4235
    },
    {
      "epoch": 0.87,
      "grad_norm": 1.7231227159500122,
      "learning_rate": 1.1327252229168804e-05,
      "loss": 0.4284,
      "step": 4236
    },
    {
      "epoch": 0.87,
      "grad_norm": 1.6123102903366089,
      "learning_rate": 1.1325202418776264e-05,
      "loss": 0.3876,
      "step": 4237
    },
    {
      "epoch": 0.87,
      "grad_norm": 1.042793869972229,
      "learning_rate": 1.1323152608383726e-05,
      "loss": 0.3447,
      "step": 4238
    },
    {
      "epoch": 0.87,
      "grad_norm": 1.8163561820983887,
      "learning_rate": 1.1321102797991186e-05,
      "loss": 0.4688,
      "step": 4239
    },
    {
      "epoch": 0.87,
      "grad_norm": 3.466566801071167,
      "learning_rate": 1.131905298759865e-05,
      "loss": 0.445,
      "step": 4240
    },
    {
      "epoch": 0.87,
      "grad_norm": 1.4619059562683105,
      "learning_rate": 1.131700317720611e-05,
      "loss": 0.3809,
      "step": 4241
    },
    {
      "epoch": 0.87,
      "grad_norm": 1.4669616222381592,
      "learning_rate": 1.131495336681357e-05,
      "loss": 0.5338,
      "step": 4242
    },
    {
      "epoch": 0.87,
      "grad_norm": 2.1450769901275635,
      "learning_rate": 1.1312903556421032e-05,
      "loss": 0.319,
      "step": 4243
    },
    {
      "epoch": 0.87,
      "grad_norm": 0.984049379825592,
      "learning_rate": 1.1310853746028493e-05,
      "loss": 0.4474,
      "step": 4244
    },
    {
      "epoch": 0.87,
      "grad_norm": 1.102245569229126,
      "learning_rate": 1.1308803935635955e-05,
      "loss": 0.4556,
      "step": 4245
    },
    {
      "epoch": 0.87,
      "grad_norm": 1.1967705488204956,
      "learning_rate": 1.1306754125243415e-05,
      "loss": 0.5462,
      "step": 4246
    },
    {
      "epoch": 0.87,
      "grad_norm": 1.2669789791107178,
      "learning_rate": 1.1304704314850876e-05,
      "loss": 0.2895,
      "step": 4247
    },
    {
      "epoch": 0.87,
      "grad_norm": 1.520289421081543,
      "learning_rate": 1.130265450445834e-05,
      "loss": 0.3745,
      "step": 4248
    },
    {
      "epoch": 0.87,
      "grad_norm": 1.3929239511489868,
      "learning_rate": 1.13006046940658e-05,
      "loss": 0.2882,
      "step": 4249
    },
    {
      "epoch": 0.87,
      "grad_norm": 1.9971576929092407,
      "learning_rate": 1.1298554883673261e-05,
      "loss": 0.3935,
      "step": 4250
    },
    {
      "epoch": 0.87,
      "grad_norm": 1.284874439239502,
      "learning_rate": 1.1296505073280723e-05,
      "loss": 0.3085,
      "step": 4251
    },
    {
      "epoch": 0.87,
      "grad_norm": 1.3656262159347534,
      "learning_rate": 1.1294455262888185e-05,
      "loss": 0.4339,
      "step": 4252
    },
    {
      "epoch": 0.87,
      "grad_norm": 1.203776478767395,
      "learning_rate": 1.1292405452495645e-05,
      "loss": 0.4015,
      "step": 4253
    },
    {
      "epoch": 0.87,
      "grad_norm": 1.139491081237793,
      "learning_rate": 1.1290355642103105e-05,
      "loss": 0.4344,
      "step": 4254
    },
    {
      "epoch": 0.87,
      "grad_norm": 1.3731533288955688,
      "learning_rate": 1.1288305831710569e-05,
      "loss": 0.5513,
      "step": 4255
    },
    {
      "epoch": 0.87,
      "grad_norm": 0.8950809836387634,
      "learning_rate": 1.1286256021318029e-05,
      "loss": 0.4135,
      "step": 4256
    },
    {
      "epoch": 0.87,
      "grad_norm": 1.088836431503296,
      "learning_rate": 1.128420621092549e-05,
      "loss": 0.5121,
      "step": 4257
    },
    {
      "epoch": 0.87,
      "grad_norm": 0.9299361705780029,
      "learning_rate": 1.1282156400532951e-05,
      "loss": 0.354,
      "step": 4258
    },
    {
      "epoch": 0.87,
      "grad_norm": 2.0083248615264893,
      "learning_rate": 1.1280106590140415e-05,
      "loss": 0.4288,
      "step": 4259
    },
    {
      "epoch": 0.87,
      "grad_norm": 0.8762795925140381,
      "learning_rate": 1.1278056779747875e-05,
      "loss": 0.2455,
      "step": 4260
    },
    {
      "epoch": 0.87,
      "grad_norm": 1.4916845560073853,
      "learning_rate": 1.1276006969355335e-05,
      "loss": 0.3148,
      "step": 4261
    },
    {
      "epoch": 0.87,
      "grad_norm": 1.1521450281143188,
      "learning_rate": 1.1273957158962797e-05,
      "loss": 0.2996,
      "step": 4262
    },
    {
      "epoch": 0.87,
      "grad_norm": 0.8906106948852539,
      "learning_rate": 1.1271907348570259e-05,
      "loss": 0.364,
      "step": 4263
    },
    {
      "epoch": 0.87,
      "grad_norm": 0.9688189625740051,
      "learning_rate": 1.126985753817772e-05,
      "loss": 0.4461,
      "step": 4264
    },
    {
      "epoch": 0.87,
      "grad_norm": 1.2364658117294312,
      "learning_rate": 1.126780772778518e-05,
      "loss": 0.3537,
      "step": 4265
    },
    {
      "epoch": 0.87,
      "grad_norm": 1.1645594835281372,
      "learning_rate": 1.126575791739264e-05,
      "loss": 0.4628,
      "step": 4266
    },
    {
      "epoch": 0.87,
      "grad_norm": 1.0005615949630737,
      "learning_rate": 1.1263708107000104e-05,
      "loss": 0.3924,
      "step": 4267
    },
    {
      "epoch": 0.87,
      "grad_norm": 1.4717583656311035,
      "learning_rate": 1.1261658296607564e-05,
      "loss": 0.3997,
      "step": 4268
    },
    {
      "epoch": 0.87,
      "grad_norm": 1.2118624448776245,
      "learning_rate": 1.1259608486215026e-05,
      "loss": 0.4451,
      "step": 4269
    },
    {
      "epoch": 0.87,
      "grad_norm": 0.7711514830589294,
      "learning_rate": 1.1257558675822486e-05,
      "loss": 0.3192,
      "step": 4270
    },
    {
      "epoch": 0.88,
      "grad_norm": 2.341444492340088,
      "learning_rate": 1.125550886542995e-05,
      "loss": 0.3466,
      "step": 4271
    },
    {
      "epoch": 0.88,
      "grad_norm": 0.9258382320404053,
      "learning_rate": 1.125345905503741e-05,
      "loss": 0.3148,
      "step": 4272
    },
    {
      "epoch": 0.88,
      "grad_norm": 0.7466933727264404,
      "learning_rate": 1.125140924464487e-05,
      "loss": 0.3494,
      "step": 4273
    },
    {
      "epoch": 0.88,
      "grad_norm": 1.314205527305603,
      "learning_rate": 1.1249359434252332e-05,
      "loss": 0.4422,
      "step": 4274
    },
    {
      "epoch": 0.88,
      "grad_norm": 2.3322954177856445,
      "learning_rate": 1.1247309623859794e-05,
      "loss": 0.361,
      "step": 4275
    },
    {
      "epoch": 0.88,
      "grad_norm": 1.03439199924469,
      "learning_rate": 1.1245259813467256e-05,
      "loss": 0.4968,
      "step": 4276
    },
    {
      "epoch": 0.88,
      "grad_norm": 1.1232264041900635,
      "learning_rate": 1.1243210003074716e-05,
      "loss": 0.3398,
      "step": 4277
    },
    {
      "epoch": 0.88,
      "grad_norm": 1.186004400253296,
      "learning_rate": 1.1241160192682176e-05,
      "loss": 0.2517,
      "step": 4278
    },
    {
      "epoch": 0.88,
      "grad_norm": 2.043369770050049,
      "learning_rate": 1.123911038228964e-05,
      "loss": 0.3496,
      "step": 4279
    },
    {
      "epoch": 0.88,
      "grad_norm": 1.9114344120025635,
      "learning_rate": 1.12370605718971e-05,
      "loss": 0.3213,
      "step": 4280
    },
    {
      "epoch": 0.88,
      "grad_norm": 2.205462694168091,
      "learning_rate": 1.1235010761504562e-05,
      "loss": 0.5064,
      "step": 4281
    },
    {
      "epoch": 0.88,
      "grad_norm": 1.2895581722259521,
      "learning_rate": 1.1232960951112024e-05,
      "loss": 0.3769,
      "step": 4282
    },
    {
      "epoch": 0.88,
      "grad_norm": 1.3709778785705566,
      "learning_rate": 1.1230911140719486e-05,
      "loss": 0.3958,
      "step": 4283
    },
    {
      "epoch": 0.88,
      "grad_norm": 2.6624724864959717,
      "learning_rate": 1.1228861330326946e-05,
      "loss": 0.2881,
      "step": 4284
    },
    {
      "epoch": 0.88,
      "grad_norm": 1.2156089544296265,
      "learning_rate": 1.1226811519934406e-05,
      "loss": 0.3807,
      "step": 4285
    },
    {
      "epoch": 0.88,
      "grad_norm": 1.0025511980056763,
      "learning_rate": 1.122476170954187e-05,
      "loss": 0.597,
      "step": 4286
    },
    {
      "epoch": 0.88,
      "grad_norm": 1.2033488750457764,
      "learning_rate": 1.122271189914933e-05,
      "loss": 0.4204,
      "step": 4287
    },
    {
      "epoch": 0.88,
      "grad_norm": 1.062626600265503,
      "learning_rate": 1.1220662088756791e-05,
      "loss": 0.4495,
      "step": 4288
    },
    {
      "epoch": 0.88,
      "grad_norm": 1.0703645944595337,
      "learning_rate": 1.1218612278364252e-05,
      "loss": 0.3506,
      "step": 4289
    },
    {
      "epoch": 0.88,
      "grad_norm": 1.3027676343917847,
      "learning_rate": 1.1216562467971715e-05,
      "loss": 0.3665,
      "step": 4290
    },
    {
      "epoch": 0.88,
      "grad_norm": 1.1527669429779053,
      "learning_rate": 1.1214512657579175e-05,
      "loss": 0.4224,
      "step": 4291
    },
    {
      "epoch": 0.88,
      "grad_norm": 1.2566733360290527,
      "learning_rate": 1.1212462847186635e-05,
      "loss": 0.3553,
      "step": 4292
    },
    {
      "epoch": 0.88,
      "grad_norm": 1.310585618019104,
      "learning_rate": 1.1210413036794097e-05,
      "loss": 0.2908,
      "step": 4293
    },
    {
      "epoch": 0.88,
      "grad_norm": 1.8795738220214844,
      "learning_rate": 1.120836322640156e-05,
      "loss": 0.4326,
      "step": 4294
    },
    {
      "epoch": 0.88,
      "grad_norm": 0.7801071405410767,
      "learning_rate": 1.1206313416009021e-05,
      "loss": 0.438,
      "step": 4295
    },
    {
      "epoch": 0.88,
      "grad_norm": 1.4668235778808594,
      "learning_rate": 1.1204263605616481e-05,
      "loss": 0.4568,
      "step": 4296
    },
    {
      "epoch": 0.88,
      "grad_norm": 2.3077354431152344,
      "learning_rate": 1.1202213795223941e-05,
      "loss": 0.3453,
      "step": 4297
    },
    {
      "epoch": 0.88,
      "grad_norm": 1.4196852445602417,
      "learning_rate": 1.1200163984831405e-05,
      "loss": 0.2962,
      "step": 4298
    },
    {
      "epoch": 0.88,
      "grad_norm": 1.340651512145996,
      "learning_rate": 1.1198114174438865e-05,
      "loss": 0.3642,
      "step": 4299
    },
    {
      "epoch": 0.88,
      "grad_norm": 1.5057750940322876,
      "learning_rate": 1.1196064364046327e-05,
      "loss": 0.3466,
      "step": 4300
    },
    {
      "epoch": 0.88,
      "grad_norm": 1.8815760612487793,
      "learning_rate": 1.1194014553653787e-05,
      "loss": 0.3881,
      "step": 4301
    },
    {
      "epoch": 0.88,
      "grad_norm": 1.2278530597686768,
      "learning_rate": 1.119196474326125e-05,
      "loss": 0.4364,
      "step": 4302
    },
    {
      "epoch": 0.88,
      "grad_norm": 1.3757470846176147,
      "learning_rate": 1.118991493286871e-05,
      "loss": 0.496,
      "step": 4303
    },
    {
      "epoch": 0.88,
      "grad_norm": 2.373422145843506,
      "learning_rate": 1.1187865122476171e-05,
      "loss": 0.3409,
      "step": 4304
    },
    {
      "epoch": 0.88,
      "grad_norm": 1.0631952285766602,
      "learning_rate": 1.1185815312083633e-05,
      "loss": 0.3249,
      "step": 4305
    },
    {
      "epoch": 0.88,
      "grad_norm": 1.4599525928497314,
      "learning_rate": 1.1183765501691095e-05,
      "loss": 0.4185,
      "step": 4306
    },
    {
      "epoch": 0.88,
      "grad_norm": 1.8575284481048584,
      "learning_rate": 1.1181715691298557e-05,
      "loss": 0.3009,
      "step": 4307
    },
    {
      "epoch": 0.88,
      "grad_norm": 1.1966519355773926,
      "learning_rate": 1.1179665880906017e-05,
      "loss": 0.2955,
      "step": 4308
    },
    {
      "epoch": 0.88,
      "grad_norm": 1.1944595575332642,
      "learning_rate": 1.117761607051348e-05,
      "loss": 0.3227,
      "step": 4309
    },
    {
      "epoch": 0.88,
      "grad_norm": 1.49472975730896,
      "learning_rate": 1.117556626012094e-05,
      "loss": 0.3495,
      "step": 4310
    },
    {
      "epoch": 0.88,
      "grad_norm": 2.302534341812134,
      "learning_rate": 1.11735164497284e-05,
      "loss": 0.3571,
      "step": 4311
    },
    {
      "epoch": 0.88,
      "grad_norm": 1.0437179803848267,
      "learning_rate": 1.1171466639335862e-05,
      "loss": 0.3044,
      "step": 4312
    },
    {
      "epoch": 0.88,
      "grad_norm": 1.2291487455368042,
      "learning_rate": 1.1169416828943324e-05,
      "loss": 0.5667,
      "step": 4313
    },
    {
      "epoch": 0.88,
      "grad_norm": 1.2119090557098389,
      "learning_rate": 1.1167367018550786e-05,
      "loss": 0.286,
      "step": 4314
    },
    {
      "epoch": 0.88,
      "grad_norm": 1.057436227798462,
      "learning_rate": 1.1165317208158246e-05,
      "loss": 0.2964,
      "step": 4315
    },
    {
      "epoch": 0.88,
      "grad_norm": 1.1668466329574585,
      "learning_rate": 1.1163267397765706e-05,
      "loss": 0.4361,
      "step": 4316
    },
    {
      "epoch": 0.88,
      "grad_norm": 1.0895956754684448,
      "learning_rate": 1.116121758737317e-05,
      "loss": 0.5146,
      "step": 4317
    },
    {
      "epoch": 0.88,
      "grad_norm": 1.5659865140914917,
      "learning_rate": 1.115916777698063e-05,
      "loss": 0.3833,
      "step": 4318
    },
    {
      "epoch": 0.88,
      "grad_norm": 1.4372726678848267,
      "learning_rate": 1.1157117966588092e-05,
      "loss": 0.3227,
      "step": 4319
    },
    {
      "epoch": 0.89,
      "grad_norm": 0.936303436756134,
      "learning_rate": 1.1155068156195552e-05,
      "loss": 0.5086,
      "step": 4320
    },
    {
      "epoch": 0.89,
      "grad_norm": 0.9172969460487366,
      "learning_rate": 1.1153018345803016e-05,
      "loss": 0.3368,
      "step": 4321
    },
    {
      "epoch": 0.89,
      "grad_norm": 1.6221067905426025,
      "learning_rate": 1.1150968535410476e-05,
      "loss": 0.3235,
      "step": 4322
    },
    {
      "epoch": 0.89,
      "grad_norm": 1.2925945520401,
      "learning_rate": 1.1148918725017936e-05,
      "loss": 0.5083,
      "step": 4323
    },
    {
      "epoch": 0.89,
      "grad_norm": 1.164437174797058,
      "learning_rate": 1.1146868914625398e-05,
      "loss": 0.3472,
      "step": 4324
    },
    {
      "epoch": 0.89,
      "grad_norm": 2.3195831775665283,
      "learning_rate": 1.114481910423286e-05,
      "loss": 0.2982,
      "step": 4325
    },
    {
      "epoch": 0.89,
      "grad_norm": 0.9481234550476074,
      "learning_rate": 1.1142769293840322e-05,
      "loss": 0.3064,
      "step": 4326
    },
    {
      "epoch": 0.89,
      "grad_norm": 1.557728886604309,
      "learning_rate": 1.1140719483447782e-05,
      "loss": 0.3995,
      "step": 4327
    },
    {
      "epoch": 0.89,
      "grad_norm": 0.8870514631271362,
      "learning_rate": 1.1138669673055242e-05,
      "loss": 0.2468,
      "step": 4328
    },
    {
      "epoch": 0.89,
      "grad_norm": 2.4546992778778076,
      "learning_rate": 1.1136619862662706e-05,
      "loss": 0.328,
      "step": 4329
    },
    {
      "epoch": 0.89,
      "grad_norm": 1.068838119506836,
      "learning_rate": 1.1134570052270166e-05,
      "loss": 0.5456,
      "step": 4330
    },
    {
      "epoch": 0.89,
      "grad_norm": 1.4636112451553345,
      "learning_rate": 1.1132520241877628e-05,
      "loss": 0.4823,
      "step": 4331
    },
    {
      "epoch": 0.89,
      "grad_norm": 0.9778579473495483,
      "learning_rate": 1.1130470431485088e-05,
      "loss": 0.4298,
      "step": 4332
    },
    {
      "epoch": 0.89,
      "grad_norm": 1.6922844648361206,
      "learning_rate": 1.1128420621092551e-05,
      "loss": 0.286,
      "step": 4333
    },
    {
      "epoch": 0.89,
      "grad_norm": 0.8077926635742188,
      "learning_rate": 1.1126370810700011e-05,
      "loss": 0.3648,
      "step": 4334
    },
    {
      "epoch": 0.89,
      "grad_norm": 1.4485982656478882,
      "learning_rate": 1.1124321000307472e-05,
      "loss": 0.4162,
      "step": 4335
    },
    {
      "epoch": 0.89,
      "grad_norm": 1.0819331407546997,
      "learning_rate": 1.1122271189914933e-05,
      "loss": 0.3629,
      "step": 4336
    },
    {
      "epoch": 0.89,
      "grad_norm": 0.9941723346710205,
      "learning_rate": 1.1120221379522395e-05,
      "loss": 0.3672,
      "step": 4337
    },
    {
      "epoch": 0.89,
      "grad_norm": 0.9650956988334656,
      "learning_rate": 1.1118171569129857e-05,
      "loss": 0.3292,
      "step": 4338
    },
    {
      "epoch": 0.89,
      "grad_norm": 2.745061159133911,
      "learning_rate": 1.1116121758737317e-05,
      "loss": 0.4308,
      "step": 4339
    },
    {
      "epoch": 0.89,
      "grad_norm": 2.217057466506958,
      "learning_rate": 1.1114071948344781e-05,
      "loss": 0.3749,
      "step": 4340
    },
    {
      "epoch": 0.89,
      "grad_norm": 1.7000150680541992,
      "learning_rate": 1.1112022137952241e-05,
      "loss": 0.4617,
      "step": 4341
    },
    {
      "epoch": 0.89,
      "grad_norm": 1.38167142868042,
      "learning_rate": 1.1109972327559701e-05,
      "loss": 0.3553,
      "step": 4342
    },
    {
      "epoch": 0.89,
      "grad_norm": 1.2534972429275513,
      "learning_rate": 1.1107922517167163e-05,
      "loss": 0.3134,
      "step": 4343
    },
    {
      "epoch": 0.89,
      "grad_norm": 1.0495374202728271,
      "learning_rate": 1.1105872706774625e-05,
      "loss": 0.4149,
      "step": 4344
    },
    {
      "epoch": 0.89,
      "grad_norm": 1.4493019580841064,
      "learning_rate": 1.1103822896382087e-05,
      "loss": 0.267,
      "step": 4345
    },
    {
      "epoch": 0.89,
      "grad_norm": 1.0716664791107178,
      "learning_rate": 1.1101773085989547e-05,
      "loss": 0.394,
      "step": 4346
    },
    {
      "epoch": 0.89,
      "grad_norm": 1.2478433847427368,
      "learning_rate": 1.1099723275597007e-05,
      "loss": 0.3483,
      "step": 4347
    },
    {
      "epoch": 0.89,
      "grad_norm": 1.253670334815979,
      "learning_rate": 1.109767346520447e-05,
      "loss": 0.4268,
      "step": 4348
    },
    {
      "epoch": 0.89,
      "grad_norm": 1.6822816133499146,
      "learning_rate": 1.109562365481193e-05,
      "loss": 0.3538,
      "step": 4349
    },
    {
      "epoch": 0.89,
      "grad_norm": 0.948588490486145,
      "learning_rate": 1.1093573844419393e-05,
      "loss": 0.2034,
      "step": 4350
    },
    {
      "epoch": 0.89,
      "grad_norm": 0.747913122177124,
      "learning_rate": 1.1091524034026853e-05,
      "loss": 0.3406,
      "step": 4351
    },
    {
      "epoch": 0.89,
      "grad_norm": 1.176619529724121,
      "learning_rate": 1.1089474223634316e-05,
      "loss": 0.4275,
      "step": 4352
    },
    {
      "epoch": 0.89,
      "grad_norm": 1.3780268430709839,
      "learning_rate": 1.1087424413241777e-05,
      "loss": 0.337,
      "step": 4353
    },
    {
      "epoch": 0.89,
      "grad_norm": 1.4396259784698486,
      "learning_rate": 1.1085374602849237e-05,
      "loss": 0.494,
      "step": 4354
    },
    {
      "epoch": 0.89,
      "grad_norm": 2.2246310710906982,
      "learning_rate": 1.1083324792456699e-05,
      "loss": 0.4231,
      "step": 4355
    },
    {
      "epoch": 0.89,
      "grad_norm": 1.458333969116211,
      "learning_rate": 1.108127498206416e-05,
      "loss": 0.3798,
      "step": 4356
    },
    {
      "epoch": 0.89,
      "grad_norm": 1.470787525177002,
      "learning_rate": 1.1079225171671622e-05,
      "loss": 0.5334,
      "step": 4357
    },
    {
      "epoch": 0.89,
      "grad_norm": 1.1314932107925415,
      "learning_rate": 1.1077175361279082e-05,
      "loss": 0.5583,
      "step": 4358
    },
    {
      "epoch": 0.89,
      "grad_norm": 1.0080642700195312,
      "learning_rate": 1.1075125550886543e-05,
      "loss": 0.3253,
      "step": 4359
    },
    {
      "epoch": 0.89,
      "grad_norm": 1.6124790906906128,
      "learning_rate": 1.1073075740494006e-05,
      "loss": 0.4479,
      "step": 4360
    },
    {
      "epoch": 0.89,
      "grad_norm": 0.7186933755874634,
      "learning_rate": 1.1071025930101466e-05,
      "loss": 0.3065,
      "step": 4361
    },
    {
      "epoch": 0.89,
      "grad_norm": 1.0357134342193604,
      "learning_rate": 1.1068976119708928e-05,
      "loss": 0.2256,
      "step": 4362
    },
    {
      "epoch": 0.89,
      "grad_norm": 1.0786067247390747,
      "learning_rate": 1.1066926309316388e-05,
      "loss": 0.4657,
      "step": 4363
    },
    {
      "epoch": 0.89,
      "grad_norm": 0.8141231536865234,
      "learning_rate": 1.1064876498923852e-05,
      "loss": 0.4218,
      "step": 4364
    },
    {
      "epoch": 0.89,
      "grad_norm": 0.9325032830238342,
      "learning_rate": 1.1062826688531312e-05,
      "loss": 0.4569,
      "step": 4365
    },
    {
      "epoch": 0.89,
      "grad_norm": 1.5232720375061035,
      "learning_rate": 1.1060776878138772e-05,
      "loss": 0.4508,
      "step": 4366
    },
    {
      "epoch": 0.89,
      "grad_norm": 1.2556958198547363,
      "learning_rate": 1.1058727067746234e-05,
      "loss": 0.4184,
      "step": 4367
    },
    {
      "epoch": 0.89,
      "grad_norm": 0.7447523474693298,
      "learning_rate": 1.1056677257353696e-05,
      "loss": 0.4598,
      "step": 4368
    },
    {
      "epoch": 0.9,
      "grad_norm": 0.8771785497665405,
      "learning_rate": 1.1054627446961158e-05,
      "loss": 0.3332,
      "step": 4369
    },
    {
      "epoch": 0.9,
      "grad_norm": 1.5769670009613037,
      "learning_rate": 1.1052577636568618e-05,
      "loss": 0.4421,
      "step": 4370
    },
    {
      "epoch": 0.9,
      "grad_norm": 1.5556854009628296,
      "learning_rate": 1.1050527826176081e-05,
      "loss": 0.3049,
      "step": 4371
    },
    {
      "epoch": 0.9,
      "grad_norm": 0.935059666633606,
      "learning_rate": 1.1048478015783542e-05,
      "loss": 0.3131,
      "step": 4372
    },
    {
      "epoch": 0.9,
      "grad_norm": 1.4465252161026,
      "learning_rate": 1.1046428205391002e-05,
      "loss": 0.4435,
      "step": 4373
    },
    {
      "epoch": 0.9,
      "grad_norm": 0.9941191077232361,
      "learning_rate": 1.1044378394998464e-05,
      "loss": 0.3941,
      "step": 4374
    },
    {
      "epoch": 0.9,
      "grad_norm": 1.232738971710205,
      "learning_rate": 1.1042328584605926e-05,
      "loss": 0.2181,
      "step": 4375
    },
    {
      "epoch": 0.9,
      "grad_norm": 0.5557137727737427,
      "learning_rate": 1.1040278774213387e-05,
      "loss": 0.2198,
      "step": 4376
    },
    {
      "epoch": 0.9,
      "grad_norm": 0.8709990978240967,
      "learning_rate": 1.1038228963820848e-05,
      "loss": 0.3015,
      "step": 4377
    },
    {
      "epoch": 0.9,
      "grad_norm": 1.0804264545440674,
      "learning_rate": 1.1036179153428308e-05,
      "loss": 0.3901,
      "step": 4378
    },
    {
      "epoch": 0.9,
      "grad_norm": 1.1904277801513672,
      "learning_rate": 1.1034129343035771e-05,
      "loss": 0.3857,
      "step": 4379
    },
    {
      "epoch": 0.9,
      "grad_norm": 1.18610417842865,
      "learning_rate": 1.1032079532643231e-05,
      "loss": 0.5191,
      "step": 4380
    },
    {
      "epoch": 0.9,
      "grad_norm": 1.2877447605133057,
      "learning_rate": 1.1030029722250693e-05,
      "loss": 0.259,
      "step": 4381
    },
    {
      "epoch": 0.9,
      "grad_norm": 1.024787425994873,
      "learning_rate": 1.1027979911858153e-05,
      "loss": 0.2991,
      "step": 4382
    },
    {
      "epoch": 0.9,
      "grad_norm": 1.2029210329055786,
      "learning_rate": 1.1025930101465617e-05,
      "loss": 0.4013,
      "step": 4383
    },
    {
      "epoch": 0.9,
      "grad_norm": 0.8667818903923035,
      "learning_rate": 1.1023880291073077e-05,
      "loss": 0.4334,
      "step": 4384
    },
    {
      "epoch": 0.9,
      "grad_norm": 2.160763740539551,
      "learning_rate": 1.1021830480680537e-05,
      "loss": 0.3252,
      "step": 4385
    },
    {
      "epoch": 0.9,
      "grad_norm": 1.247025489807129,
      "learning_rate": 1.1019780670287999e-05,
      "loss": 0.3697,
      "step": 4386
    },
    {
      "epoch": 0.9,
      "grad_norm": 1.171655297279358,
      "learning_rate": 1.1017730859895461e-05,
      "loss": 0.3771,
      "step": 4387
    },
    {
      "epoch": 0.9,
      "grad_norm": 1.0938379764556885,
      "learning_rate": 1.1015681049502923e-05,
      "loss": 0.4152,
      "step": 4388
    },
    {
      "epoch": 0.9,
      "grad_norm": 0.690769374370575,
      "learning_rate": 1.1013631239110383e-05,
      "loss": 0.3621,
      "step": 4389
    },
    {
      "epoch": 0.9,
      "grad_norm": 1.5952157974243164,
      "learning_rate": 1.1011581428717843e-05,
      "loss": 0.4309,
      "step": 4390
    },
    {
      "epoch": 0.9,
      "grad_norm": 1.1853734254837036,
      "learning_rate": 1.1009531618325307e-05,
      "loss": 0.3303,
      "step": 4391
    },
    {
      "epoch": 0.9,
      "grad_norm": 1.1364432573318481,
      "learning_rate": 1.1007481807932767e-05,
      "loss": 0.2652,
      "step": 4392
    },
    {
      "epoch": 0.9,
      "grad_norm": 1.3018035888671875,
      "learning_rate": 1.1005431997540229e-05,
      "loss": 0.5586,
      "step": 4393
    },
    {
      "epoch": 0.9,
      "grad_norm": 1.2076241970062256,
      "learning_rate": 1.1003382187147689e-05,
      "loss": 0.4698,
      "step": 4394
    },
    {
      "epoch": 0.9,
      "grad_norm": 0.9885700345039368,
      "learning_rate": 1.1001332376755152e-05,
      "loss": 0.5005,
      "step": 4395
    },
    {
      "epoch": 0.9,
      "grad_norm": 1.308667540550232,
      "learning_rate": 1.0999282566362613e-05,
      "loss": 0.396,
      "step": 4396
    },
    {
      "epoch": 0.9,
      "grad_norm": 1.6081769466400146,
      "learning_rate": 1.0997232755970073e-05,
      "loss": 0.347,
      "step": 4397
    },
    {
      "epoch": 0.9,
      "grad_norm": 0.9889606237411499,
      "learning_rate": 1.0995182945577536e-05,
      "loss": 0.3983,
      "step": 4398
    },
    {
      "epoch": 0.9,
      "grad_norm": 1.398722767829895,
      "learning_rate": 1.0993133135184997e-05,
      "loss": 0.3644,
      "step": 4399
    },
    {
      "epoch": 0.9,
      "grad_norm": 1.2816026210784912,
      "learning_rate": 1.0991083324792458e-05,
      "loss": 0.3972,
      "step": 4400
    },
    {
      "epoch": 0.9,
      "grad_norm": 1.058870792388916,
      "learning_rate": 1.0989033514399919e-05,
      "loss": 0.5187,
      "step": 4401
    },
    {
      "epoch": 0.9,
      "grad_norm": 1.3165448904037476,
      "learning_rate": 1.0986983704007382e-05,
      "loss": 0.4283,
      "step": 4402
    },
    {
      "epoch": 0.9,
      "grad_norm": 0.9551041722297668,
      "learning_rate": 1.0984933893614842e-05,
      "loss": 0.3863,
      "step": 4403
    },
    {
      "epoch": 0.9,
      "grad_norm": 1.06923508644104,
      "learning_rate": 1.0982884083222302e-05,
      "loss": 0.5536,
      "step": 4404
    },
    {
      "epoch": 0.9,
      "grad_norm": 1.5396322011947632,
      "learning_rate": 1.0980834272829764e-05,
      "loss": 0.384,
      "step": 4405
    },
    {
      "epoch": 0.9,
      "grad_norm": 1.7729674577713013,
      "learning_rate": 1.0978784462437226e-05,
      "loss": 0.3418,
      "step": 4406
    },
    {
      "epoch": 0.9,
      "grad_norm": 1.5209466218948364,
      "learning_rate": 1.0976734652044688e-05,
      "loss": 0.3606,
      "step": 4407
    },
    {
      "epoch": 0.9,
      "grad_norm": 0.9482343196868896,
      "learning_rate": 1.0974684841652148e-05,
      "loss": 0.3777,
      "step": 4408
    },
    {
      "epoch": 0.9,
      "grad_norm": 0.9142643213272095,
      "learning_rate": 1.0972635031259608e-05,
      "loss": 0.3692,
      "step": 4409
    },
    {
      "epoch": 0.9,
      "grad_norm": 1.0490820407867432,
      "learning_rate": 1.0970585220867072e-05,
      "loss": 0.318,
      "step": 4410
    },
    {
      "epoch": 0.9,
      "grad_norm": 2.2745509147644043,
      "learning_rate": 1.0968535410474532e-05,
      "loss": 0.4766,
      "step": 4411
    },
    {
      "epoch": 0.9,
      "grad_norm": 1.6425179243087769,
      "learning_rate": 1.0966485600081994e-05,
      "loss": 0.3757,
      "step": 4412
    },
    {
      "epoch": 0.9,
      "grad_norm": 1.095414161682129,
      "learning_rate": 1.0964435789689454e-05,
      "loss": 0.3344,
      "step": 4413
    },
    {
      "epoch": 0.9,
      "grad_norm": 2.1255979537963867,
      "learning_rate": 1.0962385979296916e-05,
      "loss": 0.4919,
      "step": 4414
    },
    {
      "epoch": 0.9,
      "grad_norm": 1.8994519710540771,
      "learning_rate": 1.0960336168904378e-05,
      "loss": 0.3147,
      "step": 4415
    },
    {
      "epoch": 0.9,
      "grad_norm": 1.3612489700317383,
      "learning_rate": 1.0958286358511838e-05,
      "loss": 0.4211,
      "step": 4416
    },
    {
      "epoch": 0.9,
      "grad_norm": 1.4154130220413208,
      "learning_rate": 1.09562365481193e-05,
      "loss": 0.455,
      "step": 4417
    },
    {
      "epoch": 0.91,
      "grad_norm": 1.2440941333770752,
      "learning_rate": 1.0954186737726762e-05,
      "loss": 0.4542,
      "step": 4418
    },
    {
      "epoch": 0.91,
      "grad_norm": 1.3822904825210571,
      "learning_rate": 1.0952136927334222e-05,
      "loss": 0.2759,
      "step": 4419
    },
    {
      "epoch": 0.91,
      "grad_norm": 1.4740935564041138,
      "learning_rate": 1.0950087116941684e-05,
      "loss": 0.3178,
      "step": 4420
    },
    {
      "epoch": 0.91,
      "grad_norm": 1.3482367992401123,
      "learning_rate": 1.0948037306549144e-05,
      "loss": 0.3645,
      "step": 4421
    },
    {
      "epoch": 0.91,
      "grad_norm": 1.2440472841262817,
      "learning_rate": 1.0945987496156607e-05,
      "loss": 0.3645,
      "step": 4422
    },
    {
      "epoch": 0.91,
      "grad_norm": 0.7673025727272034,
      "learning_rate": 1.0943937685764068e-05,
      "loss": 0.4068,
      "step": 4423
    },
    {
      "epoch": 0.91,
      "grad_norm": 2.09679913520813,
      "learning_rate": 1.094188787537153e-05,
      "loss": 0.3704,
      "step": 4424
    },
    {
      "epoch": 0.91,
      "grad_norm": 2.2766013145446777,
      "learning_rate": 1.093983806497899e-05,
      "loss": 0.2918,
      "step": 4425
    },
    {
      "epoch": 0.91,
      "grad_norm": 0.8573858141899109,
      "learning_rate": 1.0937788254586451e-05,
      "loss": 0.4577,
      "step": 4426
    },
    {
      "epoch": 0.91,
      "grad_norm": 1.6226532459259033,
      "learning_rate": 1.0935738444193913e-05,
      "loss": 0.5471,
      "step": 4427
    },
    {
      "epoch": 0.91,
      "grad_norm": 1.6911991834640503,
      "learning_rate": 1.0933688633801373e-05,
      "loss": 0.4904,
      "step": 4428
    },
    {
      "epoch": 0.91,
      "grad_norm": 0.898155152797699,
      "learning_rate": 1.0931638823408837e-05,
      "loss": 0.2629,
      "step": 4429
    },
    {
      "epoch": 0.91,
      "grad_norm": 1.2607768774032593,
      "learning_rate": 1.0929589013016297e-05,
      "loss": 0.4386,
      "step": 4430
    },
    {
      "epoch": 0.91,
      "grad_norm": 2.1426444053649902,
      "learning_rate": 1.0927539202623757e-05,
      "loss": 0.4883,
      "step": 4431
    },
    {
      "epoch": 0.91,
      "grad_norm": 1.0990798473358154,
      "learning_rate": 1.0925489392231219e-05,
      "loss": 0.3424,
      "step": 4432
    },
    {
      "epoch": 0.91,
      "grad_norm": 1.1734954118728638,
      "learning_rate": 1.0923439581838681e-05,
      "loss": 0.4782,
      "step": 4433
    },
    {
      "epoch": 0.91,
      "grad_norm": 0.9925129413604736,
      "learning_rate": 1.0921389771446143e-05,
      "loss": 0.3813,
      "step": 4434
    },
    {
      "epoch": 0.91,
      "grad_norm": 0.9538601636886597,
      "learning_rate": 1.0919339961053603e-05,
      "loss": 0.3992,
      "step": 4435
    },
    {
      "epoch": 0.91,
      "grad_norm": 1.0730702877044678,
      "learning_rate": 1.0917290150661063e-05,
      "loss": 0.4736,
      "step": 4436
    },
    {
      "epoch": 0.91,
      "grad_norm": 2.145970582962036,
      "learning_rate": 1.0915240340268527e-05,
      "loss": 0.3997,
      "step": 4437
    },
    {
      "epoch": 0.91,
      "grad_norm": 1.1292530298233032,
      "learning_rate": 1.0913190529875987e-05,
      "loss": 0.3859,
      "step": 4438
    },
    {
      "epoch": 0.91,
      "grad_norm": 2.359806776046753,
      "learning_rate": 1.0911140719483449e-05,
      "loss": 0.4066,
      "step": 4439
    },
    {
      "epoch": 0.91,
      "grad_norm": 0.9405481815338135,
      "learning_rate": 1.0909090909090909e-05,
      "loss": 0.4486,
      "step": 4440
    },
    {
      "epoch": 0.91,
      "grad_norm": 1.1605446338653564,
      "learning_rate": 1.0907041098698372e-05,
      "loss": 0.3874,
      "step": 4441
    },
    {
      "epoch": 0.91,
      "grad_norm": 2.4600276947021484,
      "learning_rate": 1.0904991288305833e-05,
      "loss": 0.4108,
      "step": 4442
    },
    {
      "epoch": 0.91,
      "grad_norm": 1.682633399963379,
      "learning_rate": 1.0902941477913293e-05,
      "loss": 0.3069,
      "step": 4443
    },
    {
      "epoch": 0.91,
      "grad_norm": 1.714287281036377,
      "learning_rate": 1.0900891667520755e-05,
      "loss": 0.3969,
      "step": 4444
    },
    {
      "epoch": 0.91,
      "grad_norm": 0.8140469193458557,
      "learning_rate": 1.0898841857128216e-05,
      "loss": 0.3261,
      "step": 4445
    },
    {
      "epoch": 0.91,
      "grad_norm": 2.258327007293701,
      "learning_rate": 1.0896792046735678e-05,
      "loss": 0.3755,
      "step": 4446
    },
    {
      "epoch": 0.91,
      "grad_norm": 1.4260683059692383,
      "learning_rate": 1.0894742236343139e-05,
      "loss": 0.4642,
      "step": 4447
    },
    {
      "epoch": 0.91,
      "grad_norm": 2.0220084190368652,
      "learning_rate": 1.0892692425950599e-05,
      "loss": 0.2555,
      "step": 4448
    },
    {
      "epoch": 0.91,
      "grad_norm": 1.757979154586792,
      "learning_rate": 1.0890642615558062e-05,
      "loss": 0.3847,
      "step": 4449
    },
    {
      "epoch": 0.91,
      "grad_norm": 1.7460969686508179,
      "learning_rate": 1.0888592805165522e-05,
      "loss": 0.562,
      "step": 4450
    },
    {
      "epoch": 0.91,
      "grad_norm": 4.277390003204346,
      "learning_rate": 1.0886542994772984e-05,
      "loss": 0.3381,
      "step": 4451
    },
    {
      "epoch": 0.91,
      "grad_norm": 1.4146629571914673,
      "learning_rate": 1.0884493184380444e-05,
      "loss": 0.3466,
      "step": 4452
    },
    {
      "epoch": 0.91,
      "grad_norm": 1.7219494581222534,
      "learning_rate": 1.0882443373987908e-05,
      "loss": 0.2459,
      "step": 4453
    },
    {
      "epoch": 0.91,
      "grad_norm": 2.639146089553833,
      "learning_rate": 1.0880393563595368e-05,
      "loss": 0.4302,
      "step": 4454
    },
    {
      "epoch": 0.91,
      "grad_norm": 2.7193872928619385,
      "learning_rate": 1.0878343753202828e-05,
      "loss": 0.362,
      "step": 4455
    },
    {
      "epoch": 0.91,
      "grad_norm": 1.4322209358215332,
      "learning_rate": 1.087629394281029e-05,
      "loss": 0.4421,
      "step": 4456
    },
    {
      "epoch": 0.91,
      "grad_norm": 1.5518230199813843,
      "learning_rate": 1.0874244132417752e-05,
      "loss": 0.507,
      "step": 4457
    },
    {
      "epoch": 0.91,
      "grad_norm": 2.0038938522338867,
      "learning_rate": 1.0872194322025214e-05,
      "loss": 0.4524,
      "step": 4458
    },
    {
      "epoch": 0.91,
      "grad_norm": 2.050208568572998,
      "learning_rate": 1.0870144511632674e-05,
      "loss": 0.4544,
      "step": 4459
    },
    {
      "epoch": 0.91,
      "grad_norm": 1.1009997129440308,
      "learning_rate": 1.0868094701240138e-05,
      "loss": 0.4239,
      "step": 4460
    },
    {
      "epoch": 0.91,
      "grad_norm": 0.905090868473053,
      "learning_rate": 1.0866044890847598e-05,
      "loss": 0.3678,
      "step": 4461
    },
    {
      "epoch": 0.91,
      "grad_norm": 2.7761635780334473,
      "learning_rate": 1.0863995080455058e-05,
      "loss": 0.4083,
      "step": 4462
    },
    {
      "epoch": 0.91,
      "grad_norm": 2.1292502880096436,
      "learning_rate": 1.086194527006252e-05,
      "loss": 0.4279,
      "step": 4463
    },
    {
      "epoch": 0.91,
      "grad_norm": 1.4220027923583984,
      "learning_rate": 1.0859895459669982e-05,
      "loss": 0.432,
      "step": 4464
    },
    {
      "epoch": 0.91,
      "grad_norm": 3.5016984939575195,
      "learning_rate": 1.0857845649277443e-05,
      "loss": 0.3795,
      "step": 4465
    },
    {
      "epoch": 0.91,
      "grad_norm": 1.229535698890686,
      "learning_rate": 1.0855795838884904e-05,
      "loss": 0.3837,
      "step": 4466
    },
    {
      "epoch": 0.92,
      "grad_norm": 1.8527858257293701,
      "learning_rate": 1.0853746028492364e-05,
      "loss": 0.4382,
      "step": 4467
    },
    {
      "epoch": 0.92,
      "grad_norm": 0.8964061737060547,
      "learning_rate": 1.0851696218099827e-05,
      "loss": 0.3314,
      "step": 4468
    },
    {
      "epoch": 0.92,
      "grad_norm": 2.060389280319214,
      "learning_rate": 1.0849646407707287e-05,
      "loss": 0.4007,
      "step": 4469
    },
    {
      "epoch": 0.92,
      "grad_norm": 1.185780644416809,
      "learning_rate": 1.084759659731475e-05,
      "loss": 0.4945,
      "step": 4470
    },
    {
      "epoch": 0.92,
      "grad_norm": 1.1338547468185425,
      "learning_rate": 1.084554678692221e-05,
      "loss": 0.3103,
      "step": 4471
    },
    {
      "epoch": 0.92,
      "grad_norm": 1.013396143913269,
      "learning_rate": 1.0843496976529673e-05,
      "loss": 0.3497,
      "step": 4472
    },
    {
      "epoch": 0.92,
      "grad_norm": 0.8928062915802002,
      "learning_rate": 1.0841447166137133e-05,
      "loss": 0.2934,
      "step": 4473
    },
    {
      "epoch": 0.92,
      "grad_norm": 1.0326838493347168,
      "learning_rate": 1.0839397355744593e-05,
      "loss": 0.3917,
      "step": 4474
    },
    {
      "epoch": 0.92,
      "grad_norm": 1.2933971881866455,
      "learning_rate": 1.0837347545352055e-05,
      "loss": 0.3225,
      "step": 4475
    },
    {
      "epoch": 0.92,
      "grad_norm": 0.8381249308586121,
      "learning_rate": 1.0835297734959517e-05,
      "loss": 0.1983,
      "step": 4476
    },
    {
      "epoch": 0.92,
      "grad_norm": 1.1593395471572876,
      "learning_rate": 1.0833247924566979e-05,
      "loss": 0.2945,
      "step": 4477
    },
    {
      "epoch": 0.92,
      "grad_norm": 1.240929126739502,
      "learning_rate": 1.0831198114174439e-05,
      "loss": 0.4836,
      "step": 4478
    },
    {
      "epoch": 0.92,
      "grad_norm": 2.2360305786132812,
      "learning_rate": 1.08291483037819e-05,
      "loss": 0.4086,
      "step": 4479
    },
    {
      "epoch": 0.92,
      "grad_norm": 2.3585171699523926,
      "learning_rate": 1.0827098493389363e-05,
      "loss": 0.4135,
      "step": 4480
    },
    {
      "epoch": 0.92,
      "grad_norm": 1.591324806213379,
      "learning_rate": 1.0825048682996823e-05,
      "loss": 0.4385,
      "step": 4481
    },
    {
      "epoch": 0.92,
      "grad_norm": 2.808053731918335,
      "learning_rate": 1.0822998872604285e-05,
      "loss": 0.4606,
      "step": 4482
    },
    {
      "epoch": 0.92,
      "grad_norm": 1.1837115287780762,
      "learning_rate": 1.0820949062211745e-05,
      "loss": 0.3319,
      "step": 4483
    },
    {
      "epoch": 0.92,
      "grad_norm": 1.4083988666534424,
      "learning_rate": 1.0818899251819209e-05,
      "loss": 0.3955,
      "step": 4484
    },
    {
      "epoch": 0.92,
      "grad_norm": 2.2429494857788086,
      "learning_rate": 1.0816849441426669e-05,
      "loss": 0.4284,
      "step": 4485
    },
    {
      "epoch": 0.92,
      "grad_norm": 1.031496524810791,
      "learning_rate": 1.0814799631034129e-05,
      "loss": 0.4515,
      "step": 4486
    },
    {
      "epoch": 0.92,
      "grad_norm": 1.0452353954315186,
      "learning_rate": 1.0812749820641592e-05,
      "loss": 0.3936,
      "step": 4487
    },
    {
      "epoch": 0.92,
      "grad_norm": 1.4210543632507324,
      "learning_rate": 1.0810700010249053e-05,
      "loss": 0.3794,
      "step": 4488
    },
    {
      "epoch": 0.92,
      "grad_norm": 1.5921525955200195,
      "learning_rate": 1.0808650199856514e-05,
      "loss": 0.3301,
      "step": 4489
    },
    {
      "epoch": 0.92,
      "grad_norm": 2.2497470378875732,
      "learning_rate": 1.0806600389463975e-05,
      "loss": 0.5815,
      "step": 4490
    },
    {
      "epoch": 0.92,
      "grad_norm": 1.2162888050079346,
      "learning_rate": 1.0804550579071438e-05,
      "loss": 0.4881,
      "step": 4491
    },
    {
      "epoch": 0.92,
      "grad_norm": 3.064568042755127,
      "learning_rate": 1.0802500768678898e-05,
      "loss": 0.491,
      "step": 4492
    },
    {
      "epoch": 0.92,
      "grad_norm": 1.225062370300293,
      "learning_rate": 1.0800450958286358e-05,
      "loss": 0.4001,
      "step": 4493
    },
    {
      "epoch": 0.92,
      "grad_norm": 2.88405442237854,
      "learning_rate": 1.079840114789382e-05,
      "loss": 0.3187,
      "step": 4494
    },
    {
      "epoch": 0.92,
      "grad_norm": 0.8706159591674805,
      "learning_rate": 1.0796351337501282e-05,
      "loss": 0.3631,
      "step": 4495
    },
    {
      "epoch": 0.92,
      "grad_norm": 2.2702629566192627,
      "learning_rate": 1.0794301527108744e-05,
      "loss": 0.4229,
      "step": 4496
    },
    {
      "epoch": 0.92,
      "grad_norm": 2.1310110092163086,
      "learning_rate": 1.0792251716716204e-05,
      "loss": 0.3226,
      "step": 4497
    },
    {
      "epoch": 0.92,
      "grad_norm": 2.156107187271118,
      "learning_rate": 1.0790201906323664e-05,
      "loss": 0.43,
      "step": 4498
    },
    {
      "epoch": 0.92,
      "grad_norm": 1.2061558961868286,
      "learning_rate": 1.0788152095931128e-05,
      "loss": 0.4515,
      "step": 4499
    },
    {
      "epoch": 0.92,
      "grad_norm": 1.3653221130371094,
      "learning_rate": 1.0786102285538588e-05,
      "loss": 0.4342,
      "step": 4500
    },
    {
      "epoch": 0.92,
      "grad_norm": 1.8231356143951416,
      "learning_rate": 1.078405247514605e-05,
      "loss": 0.543,
      "step": 4501
    },
    {
      "epoch": 0.92,
      "grad_norm": 1.8867532014846802,
      "learning_rate": 1.078200266475351e-05,
      "loss": 0.3128,
      "step": 4502
    },
    {
      "epoch": 0.92,
      "grad_norm": 0.8833730220794678,
      "learning_rate": 1.0779952854360974e-05,
      "loss": 0.3588,
      "step": 4503
    },
    {
      "epoch": 0.92,
      "grad_norm": 1.594881534576416,
      "learning_rate": 1.0777903043968434e-05,
      "loss": 0.576,
      "step": 4504
    },
    {
      "epoch": 0.92,
      "grad_norm": 2.6084179878234863,
      "learning_rate": 1.0775853233575894e-05,
      "loss": 0.5135,
      "step": 4505
    },
    {
      "epoch": 0.92,
      "grad_norm": 1.5036547183990479,
      "learning_rate": 1.0773803423183356e-05,
      "loss": 0.4253,
      "step": 4506
    },
    {
      "epoch": 0.92,
      "grad_norm": 1.8019598722457886,
      "learning_rate": 1.0771753612790818e-05,
      "loss": 0.5004,
      "step": 4507
    },
    {
      "epoch": 0.92,
      "grad_norm": 0.9572566151618958,
      "learning_rate": 1.076970380239828e-05,
      "loss": 0.2562,
      "step": 4508
    },
    {
      "epoch": 0.92,
      "grad_norm": 1.0540482997894287,
      "learning_rate": 1.076765399200574e-05,
      "loss": 0.3363,
      "step": 4509
    },
    {
      "epoch": 0.92,
      "grad_norm": 1.109815239906311,
      "learning_rate": 1.07656041816132e-05,
      "loss": 0.3703,
      "step": 4510
    },
    {
      "epoch": 0.92,
      "grad_norm": 1.6485179662704468,
      "learning_rate": 1.0763554371220663e-05,
      "loss": 0.3957,
      "step": 4511
    },
    {
      "epoch": 0.92,
      "grad_norm": 1.0591901540756226,
      "learning_rate": 1.0761504560828124e-05,
      "loss": 0.3559,
      "step": 4512
    },
    {
      "epoch": 0.92,
      "grad_norm": 0.9069542288780212,
      "learning_rate": 1.0759454750435585e-05,
      "loss": 0.3435,
      "step": 4513
    },
    {
      "epoch": 0.92,
      "grad_norm": 1.4372857809066772,
      "learning_rate": 1.0757404940043046e-05,
      "loss": 0.3752,
      "step": 4514
    },
    {
      "epoch": 0.93,
      "grad_norm": 1.8636579513549805,
      "learning_rate": 1.075535512965051e-05,
      "loss": 0.3474,
      "step": 4515
    },
    {
      "epoch": 0.93,
      "grad_norm": 1.2129952907562256,
      "learning_rate": 1.075330531925797e-05,
      "loss": 0.5135,
      "step": 4516
    },
    {
      "epoch": 0.93,
      "grad_norm": 1.35732901096344,
      "learning_rate": 1.075125550886543e-05,
      "loss": 0.4022,
      "step": 4517
    },
    {
      "epoch": 0.93,
      "grad_norm": 1.7144322395324707,
      "learning_rate": 1.0749205698472893e-05,
      "loss": 0.4566,
      "step": 4518
    },
    {
      "epoch": 0.93,
      "grad_norm": 2.112483263015747,
      "learning_rate": 1.0747155888080353e-05,
      "loss": 0.3593,
      "step": 4519
    },
    {
      "epoch": 0.93,
      "grad_norm": 0.9259324669837952,
      "learning_rate": 1.0745106077687815e-05,
      "loss": 0.3064,
      "step": 4520
    },
    {
      "epoch": 0.93,
      "grad_norm": 1.132306694984436,
      "learning_rate": 1.0743056267295275e-05,
      "loss": 0.413,
      "step": 4521
    },
    {
      "epoch": 0.93,
      "grad_norm": 2.4635350704193115,
      "learning_rate": 1.0741006456902739e-05,
      "loss": 0.2792,
      "step": 4522
    },
    {
      "epoch": 0.93,
      "grad_norm": 1.7332078218460083,
      "learning_rate": 1.0738956646510199e-05,
      "loss": 0.4846,
      "step": 4523
    },
    {
      "epoch": 0.93,
      "grad_norm": 0.986463725566864,
      "learning_rate": 1.0736906836117659e-05,
      "loss": 0.4978,
      "step": 4524
    },
    {
      "epoch": 0.93,
      "grad_norm": 1.278408169746399,
      "learning_rate": 1.0734857025725121e-05,
      "loss": 0.4508,
      "step": 4525
    },
    {
      "epoch": 0.93,
      "grad_norm": 1.5742754936218262,
      "learning_rate": 1.0732807215332583e-05,
      "loss": 0.4647,
      "step": 4526
    },
    {
      "epoch": 0.93,
      "grad_norm": 1.0605013370513916,
      "learning_rate": 1.0730757404940045e-05,
      "loss": 0.4404,
      "step": 4527
    },
    {
      "epoch": 0.93,
      "grad_norm": 1.186865210533142,
      "learning_rate": 1.0728707594547505e-05,
      "loss": 0.3667,
      "step": 4528
    },
    {
      "epoch": 0.93,
      "grad_norm": 0.8860734701156616,
      "learning_rate": 1.0726657784154965e-05,
      "loss": 0.3805,
      "step": 4529
    },
    {
      "epoch": 0.93,
      "grad_norm": 2.7468690872192383,
      "learning_rate": 1.0724607973762429e-05,
      "loss": 0.3636,
      "step": 4530
    },
    {
      "epoch": 0.93,
      "grad_norm": 1.3484212160110474,
      "learning_rate": 1.0722558163369889e-05,
      "loss": 0.4592,
      "step": 4531
    },
    {
      "epoch": 0.93,
      "grad_norm": 1.320716142654419,
      "learning_rate": 1.072050835297735e-05,
      "loss": 0.4146,
      "step": 4532
    },
    {
      "epoch": 0.93,
      "grad_norm": 1.0227937698364258,
      "learning_rate": 1.071845854258481e-05,
      "loss": 0.305,
      "step": 4533
    },
    {
      "epoch": 0.93,
      "grad_norm": 1.2159762382507324,
      "learning_rate": 1.0716408732192274e-05,
      "loss": 0.4895,
      "step": 4534
    },
    {
      "epoch": 0.93,
      "grad_norm": 0.9432414770126343,
      "learning_rate": 1.0714358921799734e-05,
      "loss": 0.3548,
      "step": 4535
    },
    {
      "epoch": 0.93,
      "grad_norm": 1.0816270112991333,
      "learning_rate": 1.0712309111407195e-05,
      "loss": 0.3128,
      "step": 4536
    },
    {
      "epoch": 0.93,
      "grad_norm": 1.232609748840332,
      "learning_rate": 1.0710259301014656e-05,
      "loss": 0.5905,
      "step": 4537
    },
    {
      "epoch": 0.93,
      "grad_norm": 0.9629917740821838,
      "learning_rate": 1.0708209490622118e-05,
      "loss": 0.3381,
      "step": 4538
    },
    {
      "epoch": 0.93,
      "grad_norm": 1.2116739749908447,
      "learning_rate": 1.070615968022958e-05,
      "loss": 0.4243,
      "step": 4539
    },
    {
      "epoch": 0.93,
      "grad_norm": 1.0072981119155884,
      "learning_rate": 1.070410986983704e-05,
      "loss": 0.4275,
      "step": 4540
    },
    {
      "epoch": 0.93,
      "grad_norm": 1.19407320022583,
      "learning_rate": 1.07020600594445e-05,
      "loss": 0.4162,
      "step": 4541
    },
    {
      "epoch": 0.93,
      "grad_norm": 1.0289511680603027,
      "learning_rate": 1.0700010249051964e-05,
      "loss": 0.3693,
      "step": 4542
    },
    {
      "epoch": 0.93,
      "grad_norm": 0.8313674926757812,
      "learning_rate": 1.0697960438659424e-05,
      "loss": 0.3635,
      "step": 4543
    },
    {
      "epoch": 0.93,
      "grad_norm": 0.8967030048370361,
      "learning_rate": 1.0695910628266886e-05,
      "loss": 0.2811,
      "step": 4544
    },
    {
      "epoch": 0.93,
      "grad_norm": 1.1326305866241455,
      "learning_rate": 1.0693860817874348e-05,
      "loss": 0.2807,
      "step": 4545
    },
    {
      "epoch": 0.93,
      "grad_norm": 0.9901710748672485,
      "learning_rate": 1.069181100748181e-05,
      "loss": 0.3731,
      "step": 4546
    },
    {
      "epoch": 0.93,
      "grad_norm": 1.2989156246185303,
      "learning_rate": 1.068976119708927e-05,
      "loss": 0.4858,
      "step": 4547
    },
    {
      "epoch": 0.93,
      "grad_norm": 1.958454966545105,
      "learning_rate": 1.068771138669673e-05,
      "loss": 0.4744,
      "step": 4548
    },
    {
      "epoch": 0.93,
      "grad_norm": 1.1198300123214722,
      "learning_rate": 1.0685661576304194e-05,
      "loss": 0.4415,
      "step": 4549
    },
    {
      "epoch": 0.93,
      "grad_norm": 1.3913482427597046,
      "learning_rate": 1.0683611765911654e-05,
      "loss": 0.4345,
      "step": 4550
    },
    {
      "epoch": 0.93,
      "grad_norm": 1.4237860441207886,
      "learning_rate": 1.0681561955519116e-05,
      "loss": 0.4583,
      "step": 4551
    },
    {
      "epoch": 0.93,
      "grad_norm": 1.0935018062591553,
      "learning_rate": 1.0679512145126576e-05,
      "loss": 0.3791,
      "step": 4552
    },
    {
      "epoch": 0.93,
      "grad_norm": 1.501466155052185,
      "learning_rate": 1.067746233473404e-05,
      "loss": 0.3592,
      "step": 4553
    },
    {
      "epoch": 0.93,
      "grad_norm": 3.004021167755127,
      "learning_rate": 1.06754125243415e-05,
      "loss": 0.3158,
      "step": 4554
    },
    {
      "epoch": 0.93,
      "grad_norm": 1.4968376159667969,
      "learning_rate": 1.067336271394896e-05,
      "loss": 0.4408,
      "step": 4555
    },
    {
      "epoch": 0.93,
      "grad_norm": 1.3484903573989868,
      "learning_rate": 1.0671312903556422e-05,
      "loss": 0.3088,
      "step": 4556
    },
    {
      "epoch": 0.93,
      "grad_norm": 2.775636672973633,
      "learning_rate": 1.0669263093163883e-05,
      "loss": 0.3555,
      "step": 4557
    },
    {
      "epoch": 0.93,
      "grad_norm": 1.8758764266967773,
      "learning_rate": 1.0667213282771345e-05,
      "loss": 0.3132,
      "step": 4558
    },
    {
      "epoch": 0.93,
      "grad_norm": 1.8654801845550537,
      "learning_rate": 1.0665163472378805e-05,
      "loss": 0.3391,
      "step": 4559
    },
    {
      "epoch": 0.93,
      "grad_norm": 1.916786789894104,
      "learning_rate": 1.0663113661986266e-05,
      "loss": 0.3337,
      "step": 4560
    },
    {
      "epoch": 0.93,
      "grad_norm": 5.990647792816162,
      "learning_rate": 1.066106385159373e-05,
      "loss": 0.4002,
      "step": 4561
    },
    {
      "epoch": 0.93,
      "grad_norm": 1.2024320363998413,
      "learning_rate": 1.065901404120119e-05,
      "loss": 0.394,
      "step": 4562
    },
    {
      "epoch": 0.93,
      "grad_norm": 1.0455015897750854,
      "learning_rate": 1.0656964230808651e-05,
      "loss": 0.3816,
      "step": 4563
    },
    {
      "epoch": 0.94,
      "grad_norm": 1.6435072422027588,
      "learning_rate": 1.0654914420416111e-05,
      "loss": 0.3855,
      "step": 4564
    },
    {
      "epoch": 0.94,
      "grad_norm": 2.3233890533447266,
      "learning_rate": 1.0652864610023575e-05,
      "loss": 0.4558,
      "step": 4565
    },
    {
      "epoch": 0.94,
      "grad_norm": 2.0672495365142822,
      "learning_rate": 1.0650814799631035e-05,
      "loss": 0.4948,
      "step": 4566
    },
    {
      "epoch": 0.94,
      "grad_norm": 0.8129491806030273,
      "learning_rate": 1.0648764989238495e-05,
      "loss": 0.3081,
      "step": 4567
    },
    {
      "epoch": 0.94,
      "grad_norm": 1.2175686359405518,
      "learning_rate": 1.0646715178845957e-05,
      "loss": 0.3474,
      "step": 4568
    },
    {
      "epoch": 0.94,
      "grad_norm": 3.8129491806030273,
      "learning_rate": 1.0644665368453419e-05,
      "loss": 0.4296,
      "step": 4569
    },
    {
      "epoch": 0.94,
      "grad_norm": 1.4334850311279297,
      "learning_rate": 1.064261555806088e-05,
      "loss": 0.3313,
      "step": 4570
    },
    {
      "epoch": 0.94,
      "grad_norm": 1.0533289909362793,
      "learning_rate": 1.0640565747668341e-05,
      "loss": 0.4638,
      "step": 4571
    },
    {
      "epoch": 0.94,
      "grad_norm": 1.6547648906707764,
      "learning_rate": 1.0638515937275801e-05,
      "loss": 0.3571,
      "step": 4572
    },
    {
      "epoch": 0.94,
      "grad_norm": 1.4063903093338013,
      "learning_rate": 1.0636466126883265e-05,
      "loss": 0.2638,
      "step": 4573
    },
    {
      "epoch": 0.94,
      "grad_norm": 1.3296931982040405,
      "learning_rate": 1.0634416316490725e-05,
      "loss": 0.5015,
      "step": 4574
    },
    {
      "epoch": 0.94,
      "grad_norm": 1.113021969795227,
      "learning_rate": 1.0632366506098187e-05,
      "loss": 0.4411,
      "step": 4575
    },
    {
      "epoch": 0.94,
      "grad_norm": 1.259238839149475,
      "learning_rate": 1.0630316695705649e-05,
      "loss": 0.4581,
      "step": 4576
    },
    {
      "epoch": 0.94,
      "grad_norm": 1.4206830263137817,
      "learning_rate": 1.062826688531311e-05,
      "loss": 0.5139,
      "step": 4577
    },
    {
      "epoch": 0.94,
      "grad_norm": 0.8138440847396851,
      "learning_rate": 1.062621707492057e-05,
      "loss": 0.4276,
      "step": 4578
    },
    {
      "epoch": 0.94,
      "grad_norm": 1.4995372295379639,
      "learning_rate": 1.062416726452803e-05,
      "loss": 0.4158,
      "step": 4579
    },
    {
      "epoch": 0.94,
      "grad_norm": 1.3147951364517212,
      "learning_rate": 1.0622117454135494e-05,
      "loss": 0.3801,
      "step": 4580
    },
    {
      "epoch": 0.94,
      "grad_norm": 1.7070099115371704,
      "learning_rate": 1.0620067643742954e-05,
      "loss": 0.3795,
      "step": 4581
    },
    {
      "epoch": 0.94,
      "grad_norm": 1.8529361486434937,
      "learning_rate": 1.0618017833350416e-05,
      "loss": 0.3654,
      "step": 4582
    },
    {
      "epoch": 0.94,
      "grad_norm": 1.2172261476516724,
      "learning_rate": 1.0615968022957876e-05,
      "loss": 0.2879,
      "step": 4583
    },
    {
      "epoch": 0.94,
      "grad_norm": 2.1695070266723633,
      "learning_rate": 1.061391821256534e-05,
      "loss": 0.4263,
      "step": 4584
    },
    {
      "epoch": 0.94,
      "grad_norm": 1.8346000909805298,
      "learning_rate": 1.06118684021728e-05,
      "loss": 0.6028,
      "step": 4585
    },
    {
      "epoch": 0.94,
      "grad_norm": 1.1092287302017212,
      "learning_rate": 1.060981859178026e-05,
      "loss": 0.4583,
      "step": 4586
    },
    {
      "epoch": 0.94,
      "grad_norm": 0.8869577646255493,
      "learning_rate": 1.0607768781387722e-05,
      "loss": 0.3836,
      "step": 4587
    },
    {
      "epoch": 0.94,
      "grad_norm": 1.2484619617462158,
      "learning_rate": 1.0605718970995184e-05,
      "loss": 0.4551,
      "step": 4588
    },
    {
      "epoch": 0.94,
      "grad_norm": 1.0069999694824219,
      "learning_rate": 1.0603669160602646e-05,
      "loss": 0.3976,
      "step": 4589
    },
    {
      "epoch": 0.94,
      "grad_norm": 0.9819819331169128,
      "learning_rate": 1.0601619350210106e-05,
      "loss": 0.3225,
      "step": 4590
    },
    {
      "epoch": 0.94,
      "grad_norm": 1.164384126663208,
      "learning_rate": 1.0599569539817566e-05,
      "loss": 0.4483,
      "step": 4591
    },
    {
      "epoch": 0.94,
      "grad_norm": 0.7842147350311279,
      "learning_rate": 1.059751972942503e-05,
      "loss": 0.3506,
      "step": 4592
    },
    {
      "epoch": 0.94,
      "grad_norm": 1.2746864557266235,
      "learning_rate": 1.059546991903249e-05,
      "loss": 0.4166,
      "step": 4593
    },
    {
      "epoch": 0.94,
      "grad_norm": 0.9476361870765686,
      "learning_rate": 1.0593420108639952e-05,
      "loss": 0.3938,
      "step": 4594
    },
    {
      "epoch": 0.94,
      "grad_norm": 2.7341086864471436,
      "learning_rate": 1.0591370298247412e-05,
      "loss": 0.2892,
      "step": 4595
    },
    {
      "epoch": 0.94,
      "grad_norm": 1.4749488830566406,
      "learning_rate": 1.0589320487854875e-05,
      "loss": 0.4532,
      "step": 4596
    },
    {
      "epoch": 0.94,
      "grad_norm": 1.019311547279358,
      "learning_rate": 1.0587270677462336e-05,
      "loss": 0.3139,
      "step": 4597
    },
    {
      "epoch": 0.94,
      "grad_norm": 1.497238039970398,
      "learning_rate": 1.0585220867069796e-05,
      "loss": 0.416,
      "step": 4598
    },
    {
      "epoch": 0.94,
      "grad_norm": 1.0643255710601807,
      "learning_rate": 1.0583171056677258e-05,
      "loss": 0.2612,
      "step": 4599
    },
    {
      "epoch": 0.94,
      "grad_norm": 0.9868800044059753,
      "learning_rate": 1.058112124628472e-05,
      "loss": 0.3043,
      "step": 4600
    },
    {
      "epoch": 0.94,
      "grad_norm": 1.1179611682891846,
      "learning_rate": 1.0579071435892181e-05,
      "loss": 0.4423,
      "step": 4601
    },
    {
      "epoch": 0.94,
      "grad_norm": 1.683259129524231,
      "learning_rate": 1.0577021625499642e-05,
      "loss": 0.352,
      "step": 4602
    },
    {
      "epoch": 0.94,
      "grad_norm": 2.831148624420166,
      "learning_rate": 1.0574971815107102e-05,
      "loss": 0.5137,
      "step": 4603
    },
    {
      "epoch": 0.94,
      "grad_norm": 1.0220062732696533,
      "learning_rate": 1.0572922004714565e-05,
      "loss": 0.2356,
      "step": 4604
    },
    {
      "epoch": 0.94,
      "grad_norm": 0.6731340289115906,
      "learning_rate": 1.0570872194322025e-05,
      "loss": 0.3209,
      "step": 4605
    },
    {
      "epoch": 0.94,
      "grad_norm": 1.0135074853897095,
      "learning_rate": 1.0568822383929487e-05,
      "loss": 0.3891,
      "step": 4606
    },
    {
      "epoch": 0.94,
      "grad_norm": 1.1108720302581787,
      "learning_rate": 1.0566772573536949e-05,
      "loss": 0.5277,
      "step": 4607
    },
    {
      "epoch": 0.94,
      "grad_norm": 0.7731739282608032,
      "learning_rate": 1.0564722763144411e-05,
      "loss": 0.2341,
      "step": 4608
    },
    {
      "epoch": 0.94,
      "grad_norm": 1.7082195281982422,
      "learning_rate": 1.0562672952751871e-05,
      "loss": 0.4242,
      "step": 4609
    },
    {
      "epoch": 0.94,
      "grad_norm": 1.4851129055023193,
      "learning_rate": 1.0560623142359331e-05,
      "loss": 0.3874,
      "step": 4610
    },
    {
      "epoch": 0.94,
      "grad_norm": 1.7133194208145142,
      "learning_rate": 1.0558573331966795e-05,
      "loss": 0.5231,
      "step": 4611
    },
    {
      "epoch": 0.94,
      "grad_norm": 1.2329117059707642,
      "learning_rate": 1.0556523521574255e-05,
      "loss": 0.4079,
      "step": 4612
    },
    {
      "epoch": 0.95,
      "grad_norm": 0.8845753073692322,
      "learning_rate": 1.0554473711181717e-05,
      "loss": 0.3409,
      "step": 4613
    },
    {
      "epoch": 0.95,
      "grad_norm": 1.3126412630081177,
      "learning_rate": 1.0552423900789177e-05,
      "loss": 0.3714,
      "step": 4614
    },
    {
      "epoch": 0.95,
      "grad_norm": 1.0040651559829712,
      "learning_rate": 1.055037409039664e-05,
      "loss": 0.4615,
      "step": 4615
    },
    {
      "epoch": 0.95,
      "grad_norm": 1.540372371673584,
      "learning_rate": 1.05483242800041e-05,
      "loss": 0.3115,
      "step": 4616
    },
    {
      "epoch": 0.95,
      "grad_norm": 1.070016860961914,
      "learning_rate": 1.0546274469611561e-05,
      "loss": 0.2484,
      "step": 4617
    },
    {
      "epoch": 0.95,
      "grad_norm": 1.2818931341171265,
      "learning_rate": 1.0544224659219023e-05,
      "loss": 0.4337,
      "step": 4618
    },
    {
      "epoch": 0.95,
      "grad_norm": 1.307708501815796,
      "learning_rate": 1.0542174848826485e-05,
      "loss": 0.4148,
      "step": 4619
    },
    {
      "epoch": 0.95,
      "grad_norm": 1.266527533531189,
      "learning_rate": 1.0540125038433946e-05,
      "loss": 0.3225,
      "step": 4620
    },
    {
      "epoch": 0.95,
      "grad_norm": 1.7632368803024292,
      "learning_rate": 1.0538075228041407e-05,
      "loss": 0.3648,
      "step": 4621
    },
    {
      "epoch": 0.95,
      "grad_norm": 0.8356927633285522,
      "learning_rate": 1.0536025417648867e-05,
      "loss": 0.4718,
      "step": 4622
    },
    {
      "epoch": 0.95,
      "grad_norm": 1.063151240348816,
      "learning_rate": 1.053397560725633e-05,
      "loss": 0.3271,
      "step": 4623
    },
    {
      "epoch": 0.95,
      "grad_norm": 1.3940057754516602,
      "learning_rate": 1.053192579686379e-05,
      "loss": 0.5302,
      "step": 4624
    },
    {
      "epoch": 0.95,
      "grad_norm": 1.3382526636123657,
      "learning_rate": 1.0529875986471252e-05,
      "loss": 0.3613,
      "step": 4625
    },
    {
      "epoch": 0.95,
      "grad_norm": 0.9629470705986023,
      "learning_rate": 1.0527826176078713e-05,
      "loss": 0.4032,
      "step": 4626
    },
    {
      "epoch": 0.95,
      "grad_norm": 1.3125401735305786,
      "learning_rate": 1.0525776365686176e-05,
      "loss": 0.4427,
      "step": 4627
    },
    {
      "epoch": 0.95,
      "grad_norm": 1.3554842472076416,
      "learning_rate": 1.0523726555293636e-05,
      "loss": 0.4248,
      "step": 4628
    },
    {
      "epoch": 0.95,
      "grad_norm": 1.07865571975708,
      "learning_rate": 1.0521676744901096e-05,
      "loss": 0.4303,
      "step": 4629
    },
    {
      "epoch": 0.95,
      "grad_norm": 1.0401560068130493,
      "learning_rate": 1.0519626934508558e-05,
      "loss": 0.5081,
      "step": 4630
    },
    {
      "epoch": 0.95,
      "grad_norm": 1.1214901208877563,
      "learning_rate": 1.051757712411602e-05,
      "loss": 0.3191,
      "step": 4631
    },
    {
      "epoch": 0.95,
      "grad_norm": 2.0573325157165527,
      "learning_rate": 1.0515527313723482e-05,
      "loss": 0.4874,
      "step": 4632
    },
    {
      "epoch": 0.95,
      "grad_norm": 1.0700693130493164,
      "learning_rate": 1.0513477503330942e-05,
      "loss": 0.4697,
      "step": 4633
    },
    {
      "epoch": 0.95,
      "grad_norm": 1.7562803030014038,
      "learning_rate": 1.0511427692938406e-05,
      "loss": 0.5804,
      "step": 4634
    },
    {
      "epoch": 0.95,
      "grad_norm": 3.399091958999634,
      "learning_rate": 1.0509377882545866e-05,
      "loss": 0.3696,
      "step": 4635
    },
    {
      "epoch": 0.95,
      "grad_norm": 1.560746431350708,
      "learning_rate": 1.0507328072153326e-05,
      "loss": 0.3599,
      "step": 4636
    },
    {
      "epoch": 0.95,
      "grad_norm": 1.246412754058838,
      "learning_rate": 1.0505278261760788e-05,
      "loss": 0.484,
      "step": 4637
    },
    {
      "epoch": 0.95,
      "grad_norm": 2.305880546569824,
      "learning_rate": 1.050322845136825e-05,
      "loss": 0.29,
      "step": 4638
    },
    {
      "epoch": 0.95,
      "grad_norm": 1.5794668197631836,
      "learning_rate": 1.0501178640975712e-05,
      "loss": 0.3088,
      "step": 4639
    },
    {
      "epoch": 0.95,
      "grad_norm": 1.5579701662063599,
      "learning_rate": 1.0499128830583172e-05,
      "loss": 0.4781,
      "step": 4640
    },
    {
      "epoch": 0.95,
      "grad_norm": 1.1449085474014282,
      "learning_rate": 1.0497079020190632e-05,
      "loss": 0.352,
      "step": 4641
    },
    {
      "epoch": 0.95,
      "grad_norm": 2.5451252460479736,
      "learning_rate": 1.0495029209798095e-05,
      "loss": 0.3839,
      "step": 4642
    },
    {
      "epoch": 0.95,
      "grad_norm": 1.1597423553466797,
      "learning_rate": 1.0492979399405556e-05,
      "loss": 0.4955,
      "step": 4643
    },
    {
      "epoch": 0.95,
      "grad_norm": 0.9335319995880127,
      "learning_rate": 1.0490929589013017e-05,
      "loss": 0.3122,
      "step": 4644
    },
    {
      "epoch": 0.95,
      "grad_norm": 1.8309649229049683,
      "learning_rate": 1.0488879778620478e-05,
      "loss": 0.3472,
      "step": 4645
    },
    {
      "epoch": 0.95,
      "grad_norm": 0.9755045175552368,
      "learning_rate": 1.0486829968227941e-05,
      "loss": 0.2971,
      "step": 4646
    },
    {
      "epoch": 0.95,
      "grad_norm": 3.2254230976104736,
      "learning_rate": 1.0484780157835401e-05,
      "loss": 0.2636,
      "step": 4647
    },
    {
      "epoch": 0.95,
      "grad_norm": 1.6205710172653198,
      "learning_rate": 1.0482730347442862e-05,
      "loss": 0.4515,
      "step": 4648
    },
    {
      "epoch": 0.95,
      "grad_norm": 2.357692003250122,
      "learning_rate": 1.0480680537050323e-05,
      "loss": 0.3394,
      "step": 4649
    },
    {
      "epoch": 0.95,
      "grad_norm": 1.0041614770889282,
      "learning_rate": 1.0478630726657785e-05,
      "loss": 0.48,
      "step": 4650
    },
    {
      "epoch": 0.95,
      "grad_norm": 1.840161681175232,
      "learning_rate": 1.0476580916265247e-05,
      "loss": 0.4905,
      "step": 4651
    },
    {
      "epoch": 0.95,
      "grad_norm": 2.058755397796631,
      "learning_rate": 1.0474531105872707e-05,
      "loss": 0.4137,
      "step": 4652
    },
    {
      "epoch": 0.95,
      "grad_norm": 1.622046947479248,
      "learning_rate": 1.0472481295480167e-05,
      "loss": 0.357,
      "step": 4653
    },
    {
      "epoch": 0.95,
      "grad_norm": 0.8946687579154968,
      "learning_rate": 1.0470431485087631e-05,
      "loss": 0.2573,
      "step": 4654
    },
    {
      "epoch": 0.95,
      "grad_norm": 2.749098777770996,
      "learning_rate": 1.0468381674695091e-05,
      "loss": 0.3898,
      "step": 4655
    },
    {
      "epoch": 0.95,
      "grad_norm": 2.3434300422668457,
      "learning_rate": 1.0466331864302553e-05,
      "loss": 0.2359,
      "step": 4656
    },
    {
      "epoch": 0.95,
      "grad_norm": 1.9197145700454712,
      "learning_rate": 1.0464282053910013e-05,
      "loss": 0.3746,
      "step": 4657
    },
    {
      "epoch": 0.95,
      "grad_norm": 1.457160472869873,
      "learning_rate": 1.0462232243517477e-05,
      "loss": 0.3648,
      "step": 4658
    },
    {
      "epoch": 0.95,
      "grad_norm": 1.09019935131073,
      "learning_rate": 1.0460182433124937e-05,
      "loss": 0.3781,
      "step": 4659
    },
    {
      "epoch": 0.95,
      "grad_norm": 1.5108559131622314,
      "learning_rate": 1.0458132622732397e-05,
      "loss": 0.3242,
      "step": 4660
    },
    {
      "epoch": 0.95,
      "grad_norm": 0.8683121800422668,
      "learning_rate": 1.0456082812339859e-05,
      "loss": 0.2941,
      "step": 4661
    },
    {
      "epoch": 0.96,
      "grad_norm": 1.6208471059799194,
      "learning_rate": 1.045403300194732e-05,
      "loss": 0.4883,
      "step": 4662
    },
    {
      "epoch": 0.96,
      "grad_norm": 1.1499725580215454,
      "learning_rate": 1.0451983191554783e-05,
      "loss": 0.2914,
      "step": 4663
    },
    {
      "epoch": 0.96,
      "grad_norm": 2.637647867202759,
      "learning_rate": 1.0449933381162243e-05,
      "loss": 0.4159,
      "step": 4664
    },
    {
      "epoch": 0.96,
      "grad_norm": 1.4688024520874023,
      "learning_rate": 1.0447883570769706e-05,
      "loss": 0.4466,
      "step": 4665
    },
    {
      "epoch": 0.96,
      "grad_norm": 1.171146273612976,
      "learning_rate": 1.0445833760377166e-05,
      "loss": 0.4119,
      "step": 4666
    },
    {
      "epoch": 0.96,
      "grad_norm": 1.378808856010437,
      "learning_rate": 1.0443783949984627e-05,
      "loss": 0.4733,
      "step": 4667
    },
    {
      "epoch": 0.96,
      "grad_norm": 1.4686760902404785,
      "learning_rate": 1.0441734139592088e-05,
      "loss": 0.483,
      "step": 4668
    },
    {
      "epoch": 0.96,
      "grad_norm": 1.3256103992462158,
      "learning_rate": 1.043968432919955e-05,
      "loss": 0.416,
      "step": 4669
    },
    {
      "epoch": 0.96,
      "grad_norm": 1.0650635957717896,
      "learning_rate": 1.0437634518807012e-05,
      "loss": 0.3855,
      "step": 4670
    },
    {
      "epoch": 0.96,
      "grad_norm": 1.225875735282898,
      "learning_rate": 1.0435584708414472e-05,
      "loss": 0.3249,
      "step": 4671
    },
    {
      "epoch": 0.96,
      "grad_norm": 1.5105137825012207,
      "learning_rate": 1.0433534898021933e-05,
      "loss": 0.2377,
      "step": 4672
    },
    {
      "epoch": 0.96,
      "grad_norm": 1.2258801460266113,
      "learning_rate": 1.0431485087629396e-05,
      "loss": 0.2747,
      "step": 4673
    },
    {
      "epoch": 0.96,
      "grad_norm": 1.4887255430221558,
      "learning_rate": 1.0429435277236856e-05,
      "loss": 0.3513,
      "step": 4674
    },
    {
      "epoch": 0.96,
      "grad_norm": 1.3271002769470215,
      "learning_rate": 1.0427385466844318e-05,
      "loss": 0.4024,
      "step": 4675
    },
    {
      "epoch": 0.96,
      "grad_norm": 1.240715742111206,
      "learning_rate": 1.0425335656451778e-05,
      "loss": 0.5272,
      "step": 4676
    },
    {
      "epoch": 0.96,
      "grad_norm": 1.217507243156433,
      "learning_rate": 1.0423285846059242e-05,
      "loss": 0.3281,
      "step": 4677
    },
    {
      "epoch": 0.96,
      "grad_norm": 1.3282676935195923,
      "learning_rate": 1.0421236035666702e-05,
      "loss": 0.3962,
      "step": 4678
    },
    {
      "epoch": 0.96,
      "grad_norm": 0.9735891819000244,
      "learning_rate": 1.0419186225274162e-05,
      "loss": 0.4436,
      "step": 4679
    },
    {
      "epoch": 0.96,
      "grad_norm": 1.3266335725784302,
      "learning_rate": 1.0417136414881624e-05,
      "loss": 0.5012,
      "step": 4680
    },
    {
      "epoch": 0.96,
      "grad_norm": 1.3032221794128418,
      "learning_rate": 1.0415086604489086e-05,
      "loss": 0.4199,
      "step": 4681
    },
    {
      "epoch": 0.96,
      "grad_norm": 1.3135470151901245,
      "learning_rate": 1.0413036794096548e-05,
      "loss": 0.3067,
      "step": 4682
    },
    {
      "epoch": 0.96,
      "grad_norm": 0.9203290343284607,
      "learning_rate": 1.0410986983704008e-05,
      "loss": 0.5165,
      "step": 4683
    },
    {
      "epoch": 0.96,
      "grad_norm": 1.3135597705841064,
      "learning_rate": 1.0408937173311468e-05,
      "loss": 0.4813,
      "step": 4684
    },
    {
      "epoch": 0.96,
      "grad_norm": 2.528510570526123,
      "learning_rate": 1.0406887362918932e-05,
      "loss": 0.3479,
      "step": 4685
    },
    {
      "epoch": 0.96,
      "grad_norm": 1.4878594875335693,
      "learning_rate": 1.0404837552526392e-05,
      "loss": 0.3801,
      "step": 4686
    },
    {
      "epoch": 0.96,
      "grad_norm": 1.6965293884277344,
      "learning_rate": 1.0402787742133854e-05,
      "loss": 0.2711,
      "step": 4687
    },
    {
      "epoch": 0.96,
      "grad_norm": 0.9258142709732056,
      "learning_rate": 1.0400737931741314e-05,
      "loss": 0.4157,
      "step": 4688
    },
    {
      "epoch": 0.96,
      "grad_norm": 1.1274957656860352,
      "learning_rate": 1.0398688121348777e-05,
      "loss": 0.5425,
      "step": 4689
    },
    {
      "epoch": 0.96,
      "grad_norm": 1.3808977603912354,
      "learning_rate": 1.0396638310956237e-05,
      "loss": 0.3029,
      "step": 4690
    },
    {
      "epoch": 0.96,
      "grad_norm": 1.2407399415969849,
      "learning_rate": 1.0394588500563698e-05,
      "loss": 0.3641,
      "step": 4691
    },
    {
      "epoch": 0.96,
      "grad_norm": 1.297539472579956,
      "learning_rate": 1.0392538690171161e-05,
      "loss": 0.3008,
      "step": 4692
    },
    {
      "epoch": 0.96,
      "grad_norm": 2.0383236408233643,
      "learning_rate": 1.0390488879778621e-05,
      "loss": 0.3791,
      "step": 4693
    },
    {
      "epoch": 0.96,
      "grad_norm": 1.2545799016952515,
      "learning_rate": 1.0388439069386083e-05,
      "loss": 0.3568,
      "step": 4694
    },
    {
      "epoch": 0.96,
      "grad_norm": 1.4395158290863037,
      "learning_rate": 1.0386389258993543e-05,
      "loss": 0.4019,
      "step": 4695
    },
    {
      "epoch": 0.96,
      "grad_norm": 2.349911689758301,
      "learning_rate": 1.0384339448601007e-05,
      "loss": 0.3876,
      "step": 4696
    },
    {
      "epoch": 0.96,
      "grad_norm": 0.8755351305007935,
      "learning_rate": 1.0382289638208467e-05,
      "loss": 0.3371,
      "step": 4697
    },
    {
      "epoch": 0.96,
      "grad_norm": 1.149551510810852,
      "learning_rate": 1.0380239827815927e-05,
      "loss": 0.3753,
      "step": 4698
    },
    {
      "epoch": 0.96,
      "grad_norm": 1.3487533330917358,
      "learning_rate": 1.0378190017423389e-05,
      "loss": 0.4056,
      "step": 4699
    },
    {
      "epoch": 0.96,
      "grad_norm": 1.1654905080795288,
      "learning_rate": 1.0376140207030851e-05,
      "loss": 0.5203,
      "step": 4700
    },
    {
      "epoch": 0.96,
      "grad_norm": 1.7804861068725586,
      "learning_rate": 1.0374090396638313e-05,
      "loss": 0.5064,
      "step": 4701
    },
    {
      "epoch": 0.96,
      "grad_norm": 0.8911133408546448,
      "learning_rate": 1.0372040586245773e-05,
      "loss": 0.3279,
      "step": 4702
    },
    {
      "epoch": 0.96,
      "grad_norm": 1.1180368661880493,
      "learning_rate": 1.0369990775853233e-05,
      "loss": 0.2714,
      "step": 4703
    },
    {
      "epoch": 0.96,
      "grad_norm": 0.9255823493003845,
      "learning_rate": 1.0367940965460697e-05,
      "loss": 0.3308,
      "step": 4704
    },
    {
      "epoch": 0.96,
      "grad_norm": 1.8318032026290894,
      "learning_rate": 1.0365891155068157e-05,
      "loss": 0.3642,
      "step": 4705
    },
    {
      "epoch": 0.96,
      "grad_norm": 1.1611658334732056,
      "learning_rate": 1.0363841344675619e-05,
      "loss": 0.3827,
      "step": 4706
    },
    {
      "epoch": 0.96,
      "grad_norm": 1.959973692893982,
      "learning_rate": 1.0361791534283079e-05,
      "loss": 0.4145,
      "step": 4707
    },
    {
      "epoch": 0.96,
      "grad_norm": 1.518244743347168,
      "learning_rate": 1.0359741723890542e-05,
      "loss": 0.3413,
      "step": 4708
    },
    {
      "epoch": 0.96,
      "grad_norm": 1.5623769760131836,
      "learning_rate": 1.0357691913498003e-05,
      "loss": 0.3485,
      "step": 4709
    },
    {
      "epoch": 0.96,
      "grad_norm": 1.4021952152252197,
      "learning_rate": 1.0355642103105463e-05,
      "loss": 0.4013,
      "step": 4710
    },
    {
      "epoch": 0.97,
      "grad_norm": 0.6880077719688416,
      "learning_rate": 1.0353592292712925e-05,
      "loss": 0.3878,
      "step": 4711
    },
    {
      "epoch": 0.97,
      "grad_norm": 1.7636545896530151,
      "learning_rate": 1.0351542482320386e-05,
      "loss": 0.3223,
      "step": 4712
    },
    {
      "epoch": 0.97,
      "grad_norm": 0.9884512424468994,
      "learning_rate": 1.0349492671927848e-05,
      "loss": 0.4472,
      "step": 4713
    },
    {
      "epoch": 0.97,
      "grad_norm": 1.6329869031906128,
      "learning_rate": 1.0347442861535308e-05,
      "loss": 0.4969,
      "step": 4714
    },
    {
      "epoch": 0.97,
      "grad_norm": 0.9097015261650085,
      "learning_rate": 1.0345393051142769e-05,
      "loss": 0.2984,
      "step": 4715
    },
    {
      "epoch": 0.97,
      "grad_norm": 1.6811130046844482,
      "learning_rate": 1.0343343240750232e-05,
      "loss": 0.3622,
      "step": 4716
    },
    {
      "epoch": 0.97,
      "grad_norm": 1.299885630607605,
      "learning_rate": 1.0341293430357692e-05,
      "loss": 0.3716,
      "step": 4717
    },
    {
      "epoch": 0.97,
      "grad_norm": 1.7652761936187744,
      "learning_rate": 1.0339243619965154e-05,
      "loss": 0.3682,
      "step": 4718
    },
    {
      "epoch": 0.97,
      "grad_norm": 1.9773648977279663,
      "learning_rate": 1.0337193809572614e-05,
      "loss": 0.3919,
      "step": 4719
    },
    {
      "epoch": 0.97,
      "grad_norm": 1.0624510049819946,
      "learning_rate": 1.0335143999180078e-05,
      "loss": 0.3712,
      "step": 4720
    },
    {
      "epoch": 0.97,
      "grad_norm": 0.9436257481575012,
      "learning_rate": 1.0333094188787538e-05,
      "loss": 0.3176,
      "step": 4721
    },
    {
      "epoch": 0.97,
      "grad_norm": 2.100224018096924,
      "learning_rate": 1.0331044378394998e-05,
      "loss": 0.3617,
      "step": 4722
    },
    {
      "epoch": 0.97,
      "grad_norm": 1.086012840270996,
      "learning_rate": 1.0328994568002462e-05,
      "loss": 0.4105,
      "step": 4723
    },
    {
      "epoch": 0.97,
      "grad_norm": 1.2817054986953735,
      "learning_rate": 1.0326944757609922e-05,
      "loss": 0.5155,
      "step": 4724
    },
    {
      "epoch": 0.97,
      "grad_norm": 1.137294054031372,
      "learning_rate": 1.0324894947217384e-05,
      "loss": 0.3581,
      "step": 4725
    },
    {
      "epoch": 0.97,
      "grad_norm": 1.116685152053833,
      "learning_rate": 1.0322845136824844e-05,
      "loss": 0.3938,
      "step": 4726
    },
    {
      "epoch": 0.97,
      "grad_norm": 1.5994704961776733,
      "learning_rate": 1.0320795326432308e-05,
      "loss": 0.4133,
      "step": 4727
    },
    {
      "epoch": 0.97,
      "grad_norm": 1.1190234422683716,
      "learning_rate": 1.0318745516039768e-05,
      "loss": 0.324,
      "step": 4728
    },
    {
      "epoch": 0.97,
      "grad_norm": 1.0389721393585205,
      "learning_rate": 1.0316695705647228e-05,
      "loss": 0.3465,
      "step": 4729
    },
    {
      "epoch": 0.97,
      "grad_norm": 1.337423324584961,
      "learning_rate": 1.031464589525469e-05,
      "loss": 0.3144,
      "step": 4730
    },
    {
      "epoch": 0.97,
      "grad_norm": 1.4999620914459229,
      "learning_rate": 1.0312596084862152e-05,
      "loss": 0.3882,
      "step": 4731
    },
    {
      "epoch": 0.97,
      "grad_norm": 1.058883786201477,
      "learning_rate": 1.0310546274469613e-05,
      "loss": 0.3927,
      "step": 4732
    },
    {
      "epoch": 0.97,
      "grad_norm": 1.077745795249939,
      "learning_rate": 1.0308496464077074e-05,
      "loss": 0.3341,
      "step": 4733
    },
    {
      "epoch": 0.97,
      "grad_norm": 1.1378295421600342,
      "learning_rate": 1.0306446653684534e-05,
      "loss": 0.4627,
      "step": 4734
    },
    {
      "epoch": 0.97,
      "grad_norm": 1.2660897970199585,
      "learning_rate": 1.0304396843291997e-05,
      "loss": 0.4178,
      "step": 4735
    },
    {
      "epoch": 0.97,
      "grad_norm": 2.9615001678466797,
      "learning_rate": 1.0302347032899457e-05,
      "loss": 0.3035,
      "step": 4736
    },
    {
      "epoch": 0.97,
      "grad_norm": 1.7235701084136963,
      "learning_rate": 1.030029722250692e-05,
      "loss": 0.4497,
      "step": 4737
    },
    {
      "epoch": 0.97,
      "grad_norm": 2.2861766815185547,
      "learning_rate": 1.029824741211438e-05,
      "loss": 0.4124,
      "step": 4738
    },
    {
      "epoch": 0.97,
      "grad_norm": 3.211367607116699,
      "learning_rate": 1.0296197601721843e-05,
      "loss": 0.306,
      "step": 4739
    },
    {
      "epoch": 0.97,
      "grad_norm": 1.8691240549087524,
      "learning_rate": 1.0294147791329303e-05,
      "loss": 0.4078,
      "step": 4740
    },
    {
      "epoch": 0.97,
      "grad_norm": 1.1792399883270264,
      "learning_rate": 1.0292097980936763e-05,
      "loss": 0.3478,
      "step": 4741
    },
    {
      "epoch": 0.97,
      "grad_norm": 2.539577007293701,
      "learning_rate": 1.0290048170544225e-05,
      "loss": 0.4037,
      "step": 4742
    },
    {
      "epoch": 0.97,
      "grad_norm": 1.8343782424926758,
      "learning_rate": 1.0287998360151687e-05,
      "loss": 0.275,
      "step": 4743
    },
    {
      "epoch": 0.97,
      "grad_norm": 1.1081777811050415,
      "learning_rate": 1.0285948549759149e-05,
      "loss": 0.3719,
      "step": 4744
    },
    {
      "epoch": 0.97,
      "grad_norm": 1.9103904962539673,
      "learning_rate": 1.0283898739366609e-05,
      "loss": 0.2058,
      "step": 4745
    },
    {
      "epoch": 0.97,
      "grad_norm": 1.6383799314498901,
      "learning_rate": 1.028184892897407e-05,
      "loss": 0.3266,
      "step": 4746
    },
    {
      "epoch": 0.97,
      "grad_norm": 1.9506659507751465,
      "learning_rate": 1.0279799118581533e-05,
      "loss": 0.402,
      "step": 4747
    },
    {
      "epoch": 0.97,
      "grad_norm": 1.7892979383468628,
      "learning_rate": 1.0277749308188993e-05,
      "loss": 0.5462,
      "step": 4748
    },
    {
      "epoch": 0.97,
      "grad_norm": 1.0074992179870605,
      "learning_rate": 1.0275699497796455e-05,
      "loss": 0.3059,
      "step": 4749
    },
    {
      "epoch": 0.97,
      "grad_norm": 1.5708281993865967,
      "learning_rate": 1.0273649687403915e-05,
      "loss": 0.2874,
      "step": 4750
    },
    {
      "epoch": 0.97,
      "grad_norm": 2.2911062240600586,
      "learning_rate": 1.0271599877011379e-05,
      "loss": 0.4643,
      "step": 4751
    },
    {
      "epoch": 0.97,
      "grad_norm": 1.6634784936904907,
      "learning_rate": 1.0269550066618839e-05,
      "loss": 0.2624,
      "step": 4752
    },
    {
      "epoch": 0.97,
      "grad_norm": 0.815280020236969,
      "learning_rate": 1.0267500256226299e-05,
      "loss": 0.2475,
      "step": 4753
    },
    {
      "epoch": 0.97,
      "grad_norm": 1.7747349739074707,
      "learning_rate": 1.0265450445833762e-05,
      "loss": 0.4456,
      "step": 4754
    },
    {
      "epoch": 0.97,
      "grad_norm": 1.3005062341690063,
      "learning_rate": 1.0263400635441223e-05,
      "loss": 0.3561,
      "step": 4755
    },
    {
      "epoch": 0.97,
      "grad_norm": 0.8592973947525024,
      "learning_rate": 1.0261350825048684e-05,
      "loss": 0.3527,
      "step": 4756
    },
    {
      "epoch": 0.97,
      "grad_norm": 0.7896450757980347,
      "learning_rate": 1.0259301014656145e-05,
      "loss": 0.3489,
      "step": 4757
    },
    {
      "epoch": 0.97,
      "grad_norm": 1.41012704372406,
      "learning_rate": 1.0257251204263608e-05,
      "loss": 0.4603,
      "step": 4758
    },
    {
      "epoch": 0.98,
      "grad_norm": 1.407403588294983,
      "learning_rate": 1.0255201393871068e-05,
      "loss": 0.266,
      "step": 4759
    },
    {
      "epoch": 0.98,
      "grad_norm": 1.205641269683838,
      "learning_rate": 1.0253151583478528e-05,
      "loss": 0.4022,
      "step": 4760
    },
    {
      "epoch": 0.98,
      "grad_norm": 0.9529339671134949,
      "learning_rate": 1.025110177308599e-05,
      "loss": 0.3524,
      "step": 4761
    },
    {
      "epoch": 0.98,
      "grad_norm": 1.681655764579773,
      "learning_rate": 1.0249051962693452e-05,
      "loss": 0.4757,
      "step": 4762
    },
    {
      "epoch": 0.98,
      "grad_norm": 2.308317184448242,
      "learning_rate": 1.0247002152300914e-05,
      "loss": 0.3335,
      "step": 4763
    },
    {
      "epoch": 0.98,
      "grad_norm": 1.9067591428756714,
      "learning_rate": 1.0244952341908374e-05,
      "loss": 0.5633,
      "step": 4764
    },
    {
      "epoch": 0.98,
      "grad_norm": 1.7446507215499878,
      "learning_rate": 1.0242902531515834e-05,
      "loss": 0.4159,
      "step": 4765
    },
    {
      "epoch": 0.98,
      "grad_norm": 0.888601541519165,
      "learning_rate": 1.0240852721123298e-05,
      "loss": 0.2313,
      "step": 4766
    },
    {
      "epoch": 0.98,
      "grad_norm": 1.3001964092254639,
      "learning_rate": 1.0238802910730758e-05,
      "loss": 0.3973,
      "step": 4767
    },
    {
      "epoch": 0.98,
      "grad_norm": 0.8818100094795227,
      "learning_rate": 1.023675310033822e-05,
      "loss": 0.3036,
      "step": 4768
    },
    {
      "epoch": 0.98,
      "grad_norm": 1.2975410223007202,
      "learning_rate": 1.023470328994568e-05,
      "loss": 0.5068,
      "step": 4769
    },
    {
      "epoch": 0.98,
      "grad_norm": 1.3570400476455688,
      "learning_rate": 1.0232653479553144e-05,
      "loss": 0.4191,
      "step": 4770
    },
    {
      "epoch": 0.98,
      "grad_norm": 1.4464049339294434,
      "learning_rate": 1.0230603669160604e-05,
      "loss": 0.3222,
      "step": 4771
    },
    {
      "epoch": 0.98,
      "grad_norm": 1.129111647605896,
      "learning_rate": 1.0228553858768064e-05,
      "loss": 0.4287,
      "step": 4772
    },
    {
      "epoch": 0.98,
      "grad_norm": 1.902663230895996,
      "learning_rate": 1.0226504048375526e-05,
      "loss": 0.4545,
      "step": 4773
    },
    {
      "epoch": 0.98,
      "grad_norm": 1.1133397817611694,
      "learning_rate": 1.0224454237982988e-05,
      "loss": 0.4256,
      "step": 4774
    },
    {
      "epoch": 0.98,
      "grad_norm": 0.8423953652381897,
      "learning_rate": 1.022240442759045e-05,
      "loss": 0.3316,
      "step": 4775
    },
    {
      "epoch": 0.98,
      "grad_norm": 0.8671063780784607,
      "learning_rate": 1.022035461719791e-05,
      "loss": 0.3139,
      "step": 4776
    },
    {
      "epoch": 0.98,
      "grad_norm": 1.0756580829620361,
      "learning_rate": 1.021830480680537e-05,
      "loss": 0.3255,
      "step": 4777
    },
    {
      "epoch": 0.98,
      "grad_norm": 1.2424083948135376,
      "learning_rate": 1.0216254996412833e-05,
      "loss": 0.4131,
      "step": 4778
    },
    {
      "epoch": 0.98,
      "grad_norm": 0.9595470428466797,
      "learning_rate": 1.0214205186020294e-05,
      "loss": 0.4674,
      "step": 4779
    },
    {
      "epoch": 0.98,
      "grad_norm": 1.234296441078186,
      "learning_rate": 1.0212155375627755e-05,
      "loss": 0.3543,
      "step": 4780
    },
    {
      "epoch": 0.98,
      "grad_norm": 1.0634671449661255,
      "learning_rate": 1.0210105565235217e-05,
      "loss": 0.4595,
      "step": 4781
    },
    {
      "epoch": 0.98,
      "grad_norm": 0.839154839515686,
      "learning_rate": 1.0208055754842679e-05,
      "loss": 0.3176,
      "step": 4782
    },
    {
      "epoch": 0.98,
      "grad_norm": 1.2207995653152466,
      "learning_rate": 1.020600594445014e-05,
      "loss": 0.6049,
      "step": 4783
    },
    {
      "epoch": 0.98,
      "grad_norm": 1.5121785402297974,
      "learning_rate": 1.02039561340576e-05,
      "loss": 0.3953,
      "step": 4784
    },
    {
      "epoch": 0.98,
      "grad_norm": 2.035203218460083,
      "learning_rate": 1.0201906323665063e-05,
      "loss": 0.326,
      "step": 4785
    },
    {
      "epoch": 0.98,
      "grad_norm": 1.7782763242721558,
      "learning_rate": 1.0199856513272523e-05,
      "loss": 0.3656,
      "step": 4786
    },
    {
      "epoch": 0.98,
      "grad_norm": 1.012368083000183,
      "learning_rate": 1.0197806702879985e-05,
      "loss": 0.3715,
      "step": 4787
    },
    {
      "epoch": 0.98,
      "grad_norm": 1.3028315305709839,
      "learning_rate": 1.0195756892487445e-05,
      "loss": 0.397,
      "step": 4788
    },
    {
      "epoch": 0.98,
      "grad_norm": 1.4666461944580078,
      "learning_rate": 1.0193707082094909e-05,
      "loss": 0.3042,
      "step": 4789
    },
    {
      "epoch": 0.98,
      "grad_norm": 1.4483321905136108,
      "learning_rate": 1.0191657271702369e-05,
      "loss": 0.4516,
      "step": 4790
    },
    {
      "epoch": 0.98,
      "grad_norm": 1.0499823093414307,
      "learning_rate": 1.0189607461309829e-05,
      "loss": 0.3012,
      "step": 4791
    },
    {
      "epoch": 0.98,
      "grad_norm": 1.1744168996810913,
      "learning_rate": 1.0187557650917291e-05,
      "loss": 0.3646,
      "step": 4792
    },
    {
      "epoch": 0.98,
      "grad_norm": 1.1894961595535278,
      "learning_rate": 1.0185507840524753e-05,
      "loss": 0.3476,
      "step": 4793
    },
    {
      "epoch": 0.98,
      "grad_norm": 1.1010264158248901,
      "learning_rate": 1.0183458030132215e-05,
      "loss": 0.4281,
      "step": 4794
    },
    {
      "epoch": 0.98,
      "grad_norm": 1.5500961542129517,
      "learning_rate": 1.0181408219739675e-05,
      "loss": 0.2722,
      "step": 4795
    },
    {
      "epoch": 0.98,
      "grad_norm": 0.7981236577033997,
      "learning_rate": 1.0179358409347135e-05,
      "loss": 0.3421,
      "step": 4796
    },
    {
      "epoch": 0.98,
      "grad_norm": 1.0775675773620605,
      "learning_rate": 1.0177308598954599e-05,
      "loss": 0.2518,
      "step": 4797
    },
    {
      "epoch": 0.98,
      "grad_norm": 0.9953214526176453,
      "learning_rate": 1.0175258788562059e-05,
      "loss": 0.3666,
      "step": 4798
    },
    {
      "epoch": 0.98,
      "grad_norm": 1.1405118703842163,
      "learning_rate": 1.017320897816952e-05,
      "loss": 0.406,
      "step": 4799
    },
    {
      "epoch": 0.98,
      "grad_norm": 1.1938018798828125,
      "learning_rate": 1.017115916777698e-05,
      "loss": 0.5161,
      "step": 4800
    },
    {
      "epoch": 0.98,
      "grad_norm": 1.105165958404541,
      "learning_rate": 1.0169109357384444e-05,
      "loss": 0.3447,
      "step": 4801
    },
    {
      "epoch": 0.98,
      "grad_norm": 0.7459461092948914,
      "learning_rate": 1.0167059546991904e-05,
      "loss": 0.3601,
      "step": 4802
    },
    {
      "epoch": 0.98,
      "grad_norm": 1.6276636123657227,
      "learning_rate": 1.0165009736599365e-05,
      "loss": 0.4104,
      "step": 4803
    },
    {
      "epoch": 0.98,
      "grad_norm": 1.0377768278121948,
      "learning_rate": 1.0162959926206826e-05,
      "loss": 0.2309,
      "step": 4804
    },
    {
      "epoch": 0.98,
      "grad_norm": 1.0793282985687256,
      "learning_rate": 1.0160910115814288e-05,
      "loss": 0.4904,
      "step": 4805
    },
    {
      "epoch": 0.98,
      "grad_norm": 1.450120449066162,
      "learning_rate": 1.015886030542175e-05,
      "loss": 0.4501,
      "step": 4806
    },
    {
      "epoch": 0.98,
      "grad_norm": 1.4587799310684204,
      "learning_rate": 1.015681049502921e-05,
      "loss": 0.3588,
      "step": 4807
    },
    {
      "epoch": 0.99,
      "grad_norm": 1.4035967588424683,
      "learning_rate": 1.015476068463667e-05,
      "loss": 0.3305,
      "step": 4808
    },
    {
      "epoch": 0.99,
      "grad_norm": 1.444778561592102,
      "learning_rate": 1.0152710874244134e-05,
      "loss": 0.3055,
      "step": 4809
    },
    {
      "epoch": 0.99,
      "grad_norm": 1.2839717864990234,
      "learning_rate": 1.0150661063851594e-05,
      "loss": 0.2555,
      "step": 4810
    },
    {
      "epoch": 0.99,
      "grad_norm": 1.3863462209701538,
      "learning_rate": 1.0148611253459056e-05,
      "loss": 0.3874,
      "step": 4811
    },
    {
      "epoch": 0.99,
      "grad_norm": 1.201309323310852,
      "learning_rate": 1.0146561443066518e-05,
      "loss": 0.432,
      "step": 4812
    },
    {
      "epoch": 0.99,
      "grad_norm": 2.5227468013763428,
      "learning_rate": 1.014451163267398e-05,
      "loss": 0.2007,
      "step": 4813
    },
    {
      "epoch": 0.99,
      "grad_norm": 1.1285321712493896,
      "learning_rate": 1.014246182228144e-05,
      "loss": 0.4754,
      "step": 4814
    },
    {
      "epoch": 0.99,
      "grad_norm": 2.008849620819092,
      "learning_rate": 1.01404120118889e-05,
      "loss": 0.3671,
      "step": 4815
    },
    {
      "epoch": 0.99,
      "grad_norm": 1.2643300294876099,
      "learning_rate": 1.0138362201496364e-05,
      "loss": 0.3926,
      "step": 4816
    },
    {
      "epoch": 0.99,
      "grad_norm": 0.9729251861572266,
      "learning_rate": 1.0136312391103824e-05,
      "loss": 0.4315,
      "step": 4817
    },
    {
      "epoch": 0.99,
      "grad_norm": 1.2614495754241943,
      "learning_rate": 1.0134262580711286e-05,
      "loss": 0.3152,
      "step": 4818
    },
    {
      "epoch": 0.99,
      "grad_norm": 1.1588239669799805,
      "learning_rate": 1.0132212770318746e-05,
      "loss": 0.2675,
      "step": 4819
    },
    {
      "epoch": 0.99,
      "grad_norm": 1.38546621799469,
      "learning_rate": 1.013016295992621e-05,
      "loss": 0.495,
      "step": 4820
    },
    {
      "epoch": 0.99,
      "grad_norm": 1.1807456016540527,
      "learning_rate": 1.012811314953367e-05,
      "loss": 0.5131,
      "step": 4821
    },
    {
      "epoch": 0.99,
      "grad_norm": 1.2711840867996216,
      "learning_rate": 1.012606333914113e-05,
      "loss": 0.3167,
      "step": 4822
    },
    {
      "epoch": 0.99,
      "grad_norm": 0.9367479681968689,
      "learning_rate": 1.0124013528748592e-05,
      "loss": 0.4618,
      "step": 4823
    },
    {
      "epoch": 0.99,
      "grad_norm": 0.9150292277336121,
      "learning_rate": 1.0121963718356053e-05,
      "loss": 0.3102,
      "step": 4824
    },
    {
      "epoch": 0.99,
      "grad_norm": 1.4563748836517334,
      "learning_rate": 1.0119913907963515e-05,
      "loss": 0.4545,
      "step": 4825
    },
    {
      "epoch": 0.99,
      "grad_norm": 1.4084287881851196,
      "learning_rate": 1.0117864097570975e-05,
      "loss": 0.608,
      "step": 4826
    },
    {
      "epoch": 0.99,
      "grad_norm": 2.1746227741241455,
      "learning_rate": 1.0115814287178436e-05,
      "loss": 0.2959,
      "step": 4827
    },
    {
      "epoch": 0.99,
      "grad_norm": 0.9771335124969482,
      "learning_rate": 1.0113764476785899e-05,
      "loss": 0.3079,
      "step": 4828
    },
    {
      "epoch": 0.99,
      "grad_norm": 0.9159827828407288,
      "learning_rate": 1.011171466639336e-05,
      "loss": 0.3891,
      "step": 4829
    },
    {
      "epoch": 0.99,
      "grad_norm": 0.9176535606384277,
      "learning_rate": 1.0109664856000821e-05,
      "loss": 0.4689,
      "step": 4830
    },
    {
      "epoch": 0.99,
      "grad_norm": 2.680962085723877,
      "learning_rate": 1.0107615045608281e-05,
      "loss": 0.5347,
      "step": 4831
    },
    {
      "epoch": 0.99,
      "grad_norm": 1.3948962688446045,
      "learning_rate": 1.0105565235215745e-05,
      "loss": 0.3147,
      "step": 4832
    },
    {
      "epoch": 0.99,
      "grad_norm": 1.1205832958221436,
      "learning_rate": 1.0103515424823205e-05,
      "loss": 0.3539,
      "step": 4833
    },
    {
      "epoch": 0.99,
      "grad_norm": 1.914348840713501,
      "learning_rate": 1.0101465614430665e-05,
      "loss": 0.5426,
      "step": 4834
    },
    {
      "epoch": 0.99,
      "grad_norm": 0.7667924761772156,
      "learning_rate": 1.0099415804038127e-05,
      "loss": 0.3526,
      "step": 4835
    },
    {
      "epoch": 0.99,
      "grad_norm": 0.7832313776016235,
      "learning_rate": 1.0097365993645589e-05,
      "loss": 0.2245,
      "step": 4836
    },
    {
      "epoch": 0.99,
      "grad_norm": 1.6084750890731812,
      "learning_rate": 1.009531618325305e-05,
      "loss": 0.2763,
      "step": 4837
    },
    {
      "epoch": 0.99,
      "grad_norm": 0.790282666683197,
      "learning_rate": 1.0093266372860511e-05,
      "loss": 0.3407,
      "step": 4838
    },
    {
      "epoch": 0.99,
      "grad_norm": 1.2929450273513794,
      "learning_rate": 1.0091216562467971e-05,
      "loss": 0.4685,
      "step": 4839
    },
    {
      "epoch": 0.99,
      "grad_norm": 0.9833725094795227,
      "learning_rate": 1.0089166752075435e-05,
      "loss": 0.3896,
      "step": 4840
    },
    {
      "epoch": 0.99,
      "grad_norm": 1.176794171333313,
      "learning_rate": 1.0087116941682895e-05,
      "loss": 0.2612,
      "step": 4841
    },
    {
      "epoch": 0.99,
      "grad_norm": 1.011525273323059,
      "learning_rate": 1.0085067131290357e-05,
      "loss": 0.4289,
      "step": 4842
    },
    {
      "epoch": 0.99,
      "grad_norm": 0.9896533489227295,
      "learning_rate": 1.0083017320897819e-05,
      "loss": 0.4911,
      "step": 4843
    },
    {
      "epoch": 0.99,
      "grad_norm": 0.8617740273475647,
      "learning_rate": 1.008096751050528e-05,
      "loss": 0.3834,
      "step": 4844
    },
    {
      "epoch": 0.99,
      "grad_norm": 1.2046033143997192,
      "learning_rate": 1.007891770011274e-05,
      "loss": 0.4311,
      "step": 4845
    },
    {
      "epoch": 0.99,
      "grad_norm": 1.2891039848327637,
      "learning_rate": 1.00768678897202e-05,
      "loss": 0.4924,
      "step": 4846
    },
    {
      "epoch": 0.99,
      "grad_norm": 1.3067221641540527,
      "learning_rate": 1.0074818079327664e-05,
      "loss": 0.4658,
      "step": 4847
    },
    {
      "epoch": 0.99,
      "grad_norm": 1.3370031118392944,
      "learning_rate": 1.0072768268935124e-05,
      "loss": 0.2715,
      "step": 4848
    },
    {
      "epoch": 0.99,
      "grad_norm": 1.1335033178329468,
      "learning_rate": 1.0070718458542586e-05,
      "loss": 0.3936,
      "step": 4849
    },
    {
      "epoch": 0.99,
      "grad_norm": 1.2283936738967896,
      "learning_rate": 1.0068668648150046e-05,
      "loss": 0.4025,
      "step": 4850
    },
    {
      "epoch": 0.99,
      "grad_norm": 2.0328433513641357,
      "learning_rate": 1.006661883775751e-05,
      "loss": 0.4619,
      "step": 4851
    },
    {
      "epoch": 0.99,
      "grad_norm": 1.0336893796920776,
      "learning_rate": 1.006456902736497e-05,
      "loss": 0.2041,
      "step": 4852
    },
    {
      "epoch": 0.99,
      "grad_norm": 1.3222838640213013,
      "learning_rate": 1.006251921697243e-05,
      "loss": 0.4399,
      "step": 4853
    },
    {
      "epoch": 0.99,
      "grad_norm": 1.230034589767456,
      "learning_rate": 1.0060469406579892e-05,
      "loss": 0.5336,
      "step": 4854
    },
    {
      "epoch": 0.99,
      "grad_norm": 1.765737771987915,
      "learning_rate": 1.0058419596187354e-05,
      "loss": 0.4109,
      "step": 4855
    },
    {
      "epoch": 0.99,
      "grad_norm": 1.1382936239242554,
      "learning_rate": 1.0056369785794816e-05,
      "loss": 0.4058,
      "step": 4856
    },
    {
      "epoch": 1.0,
      "grad_norm": 2.323601722717285,
      "learning_rate": 1.0054319975402276e-05,
      "loss": 0.4391,
      "step": 4857
    },
    {
      "epoch": 1.0,
      "grad_norm": 0.8000975251197815,
      "learning_rate": 1.0052270165009736e-05,
      "loss": 0.4814,
      "step": 4858
    },
    {
      "epoch": 1.0,
      "grad_norm": 1.2276347875595093,
      "learning_rate": 1.00502203546172e-05,
      "loss": 0.5098,
      "step": 4859
    },
    {
      "epoch": 1.0,
      "grad_norm": 1.1720105409622192,
      "learning_rate": 1.004817054422466e-05,
      "loss": 0.2663,
      "step": 4860
    },
    {
      "epoch": 1.0,
      "grad_norm": 2.7155613899230957,
      "learning_rate": 1.0046120733832122e-05,
      "loss": 0.3306,
      "step": 4861
    },
    {
      "epoch": 1.0,
      "grad_norm": 1.0479804277420044,
      "learning_rate": 1.0044070923439582e-05,
      "loss": 0.4056,
      "step": 4862
    },
    {
      "epoch": 1.0,
      "grad_norm": 1.0997421741485596,
      "learning_rate": 1.0042021113047045e-05,
      "loss": 0.4823,
      "step": 4863
    },
    {
      "epoch": 1.0,
      "grad_norm": 2.0155189037323,
      "learning_rate": 1.0039971302654506e-05,
      "loss": 0.3716,
      "step": 4864
    },
    {
      "epoch": 1.0,
      "grad_norm": 1.4157871007919312,
      "learning_rate": 1.0037921492261966e-05,
      "loss": 0.5049,
      "step": 4865
    },
    {
      "epoch": 1.0,
      "grad_norm": 1.7281221151351929,
      "learning_rate": 1.0035871681869428e-05,
      "loss": 0.3609,
      "step": 4866
    },
    {
      "epoch": 1.0,
      "grad_norm": 1.0976812839508057,
      "learning_rate": 1.003382187147689e-05,
      "loss": 0.4072,
      "step": 4867
    },
    {
      "epoch": 1.0,
      "grad_norm": 1.203079342842102,
      "learning_rate": 1.0031772061084351e-05,
      "loss": 0.461,
      "step": 4868
    },
    {
      "epoch": 1.0,
      "grad_norm": 1.0000700950622559,
      "learning_rate": 1.0029722250691812e-05,
      "loss": 0.3327,
      "step": 4869
    },
    {
      "epoch": 1.0,
      "grad_norm": 1.1168429851531982,
      "learning_rate": 1.0027672440299273e-05,
      "loss": 0.3737,
      "step": 4870
    },
    {
      "epoch": 1.0,
      "grad_norm": 1.3755556344985962,
      "learning_rate": 1.0025622629906735e-05,
      "loss": 0.2585,
      "step": 4871
    },
    {
      "epoch": 1.0,
      "grad_norm": 1.056441307067871,
      "learning_rate": 1.0023572819514195e-05,
      "loss": 0.5393,
      "step": 4872
    },
    {
      "epoch": 1.0,
      "grad_norm": 1.8303457498550415,
      "learning_rate": 1.0021523009121657e-05,
      "loss": 0.2935,
      "step": 4873
    },
    {
      "epoch": 1.0,
      "grad_norm": 1.0686222314834595,
      "learning_rate": 1.0019473198729119e-05,
      "loss": 0.5301,
      "step": 4874
    },
    {
      "epoch": 1.0,
      "grad_norm": 1.7958101034164429,
      "learning_rate": 1.0017423388336581e-05,
      "loss": 0.33,
      "step": 4875
    },
    {
      "epoch": 1.0,
      "grad_norm": 2.1845903396606445,
      "learning_rate": 1.0015373577944041e-05,
      "loss": 0.4657,
      "step": 4876
    },
    {
      "epoch": 1.0,
      "grad_norm": 1.022426724433899,
      "learning_rate": 1.0013323767551501e-05,
      "loss": 0.5023,
      "step": 4877
    },
    {
      "epoch": 1.0,
      "grad_norm": 0.8899657726287842,
      "learning_rate": 1.0011273957158965e-05,
      "loss": 0.2561,
      "step": 4878
    },
    {
      "epoch": 1.0,
      "grad_norm": 1.0385613441467285,
      "learning_rate": 1.0009224146766425e-05,
      "loss": 0.3438,
      "step": 4879
    },
    {
      "epoch": 1.0,
      "grad_norm": 2.7498958110809326,
      "learning_rate": 1.0007174336373887e-05,
      "loss": 0.344,
      "step": 4880
    },
    {
      "epoch": 1.0,
      "grad_norm": 1.001101016998291,
      "learning_rate": 1.0005124525981347e-05,
      "loss": 0.3509,
      "step": 4881
    },
    {
      "epoch": 1.0,
      "grad_norm": 1.1589840650558472,
      "learning_rate": 1.0003074715588809e-05,
      "loss": 0.2606,
      "step": 4882
    },
    {
      "epoch": 1.0,
      "grad_norm": 1.213821530342102,
      "learning_rate": 1.000102490519627e-05,
      "loss": 0.5224,
      "step": 4883
    },
    {
      "epoch": 1.0,
      "grad_norm": 1.502663254737854,
      "learning_rate": 9.998975094803731e-06,
      "loss": 0.3067,
      "step": 4884
    },
    {
      "epoch": 1.0,
      "grad_norm": 1.3546357154846191,
      "learning_rate": 9.996925284411193e-06,
      "loss": 0.4081,
      "step": 4885
    },
    {
      "epoch": 1.0,
      "grad_norm": 1.247498869895935,
      "learning_rate": 9.994875474018655e-06,
      "loss": 0.4363,
      "step": 4886
    },
    {
      "epoch": 1.0,
      "grad_norm": 2.1972808837890625,
      "learning_rate": 9.992825663626115e-06,
      "loss": 0.4396,
      "step": 4887
    },
    {
      "epoch": 1.0,
      "grad_norm": 1.0580673217773438,
      "learning_rate": 9.990775853233577e-06,
      "loss": 0.5175,
      "step": 4888
    },
    {
      "epoch": 1.0,
      "grad_norm": 1.9402294158935547,
      "learning_rate": 9.988726042841038e-06,
      "loss": 0.3994,
      "step": 4889
    },
    {
      "epoch": 1.0,
      "grad_norm": 0.8844422698020935,
      "learning_rate": 9.986676232448499e-06,
      "loss": 0.4636,
      "step": 4890
    },
    {
      "epoch": 1.0,
      "grad_norm": 0.7763133645057678,
      "learning_rate": 9.98462642205596e-06,
      "loss": 0.337,
      "step": 4891
    },
    {
      "epoch": 1.0,
      "grad_norm": 3.612623453140259,
      "learning_rate": 9.98257661166342e-06,
      "loss": 0.2632,
      "step": 4892
    },
    {
      "epoch": 1.0,
      "grad_norm": 1.0973893404006958,
      "learning_rate": 9.980526801270883e-06,
      "loss": 0.3745,
      "step": 4893
    },
    {
      "epoch": 1.0,
      "grad_norm": 0.8469696640968323,
      "learning_rate": 9.978476990878344e-06,
      "loss": 0.2916,
      "step": 4894
    },
    {
      "epoch": 1.0,
      "grad_norm": 1.224104642868042,
      "learning_rate": 9.976427180485806e-06,
      "loss": 0.3861,
      "step": 4895
    },
    {
      "epoch": 1.0,
      "grad_norm": 1.018389105796814,
      "learning_rate": 9.974377370093266e-06,
      "loss": 0.3375,
      "step": 4896
    },
    {
      "epoch": 1.0,
      "grad_norm": 1.3784210681915283,
      "learning_rate": 9.972327559700728e-06,
      "loss": 0.3919,
      "step": 4897
    },
    {
      "epoch": 1.0,
      "grad_norm": 1.391122817993164,
      "learning_rate": 9.970277749308188e-06,
      "loss": 0.3708,
      "step": 4898
    },
    {
      "epoch": 1.0,
      "grad_norm": 1.1972646713256836,
      "learning_rate": 9.96822793891565e-06,
      "loss": 0.3687,
      "step": 4899
    },
    {
      "epoch": 1.0,
      "grad_norm": 2.4548864364624023,
      "learning_rate": 9.966178128523112e-06,
      "loss": 0.3851,
      "step": 4900
    },
    {
      "epoch": 1.0,
      "grad_norm": 1.766090750694275,
      "learning_rate": 9.964128318130574e-06,
      "loss": 0.3903,
      "step": 4901
    },
    {
      "epoch": 1.0,
      "grad_norm": 1.5257257223129272,
      "learning_rate": 9.962078507738036e-06,
      "loss": 0.2663,
      "step": 4902
    },
    {
      "epoch": 1.0,
      "grad_norm": 2.779749631881714,
      "learning_rate": 9.960028697345496e-06,
      "loss": 0.4137,
      "step": 4903
    },
    {
      "epoch": 1.0,
      "grad_norm": 4.397765636444092,
      "learning_rate": 9.957978886952958e-06,
      "loss": 0.4178,
      "step": 4904
    },
    {
      "epoch": 1.0,
      "grad_norm": 2.1055173873901367,
      "learning_rate": 9.955929076560418e-06,
      "loss": 0.374,
      "step": 4905
    },
    {
      "epoch": 1.01,
      "grad_norm": 2.3640410900115967,
      "learning_rate": 9.95387926616788e-06,
      "loss": 0.3039,
      "step": 4906
    },
    {
      "epoch": 1.01,
      "grad_norm": 1.5677069425582886,
      "learning_rate": 9.951829455775342e-06,
      "loss": 0.3147,
      "step": 4907
    },
    {
      "epoch": 1.01,
      "grad_norm": 2.6183342933654785,
      "learning_rate": 9.949779645382804e-06,
      "loss": 0.2359,
      "step": 4908
    },
    {
      "epoch": 1.01,
      "grad_norm": 1.802001714706421,
      "learning_rate": 9.947729834990264e-06,
      "loss": 0.3637,
      "step": 4909
    },
    {
      "epoch": 1.01,
      "grad_norm": 1.6256240606307983,
      "learning_rate": 9.945680024597726e-06,
      "loss": 0.3194,
      "step": 4910
    },
    {
      "epoch": 1.01,
      "grad_norm": 2.1068668365478516,
      "learning_rate": 9.943630214205186e-06,
      "loss": 0.3017,
      "step": 4911
    },
    {
      "epoch": 1.01,
      "grad_norm": 2.4482240676879883,
      "learning_rate": 9.941580403812648e-06,
      "loss": 0.4423,
      "step": 4912
    },
    {
      "epoch": 1.01,
      "grad_norm": 1.939966082572937,
      "learning_rate": 9.93953059342011e-06,
      "loss": 0.4179,
      "step": 4913
    },
    {
      "epoch": 1.01,
      "grad_norm": 1.2325347661972046,
      "learning_rate": 9.937480783027571e-06,
      "loss": 0.3309,
      "step": 4914
    },
    {
      "epoch": 1.01,
      "grad_norm": 1.835005283355713,
      "learning_rate": 9.935430972635032e-06,
      "loss": 0.4913,
      "step": 4915
    },
    {
      "epoch": 1.01,
      "grad_norm": 3.127713918685913,
      "learning_rate": 9.933381162242493e-06,
      "loss": 0.4573,
      "step": 4916
    },
    {
      "epoch": 1.01,
      "grad_norm": 1.726901888847351,
      "learning_rate": 9.931331351849954e-06,
      "loss": 0.2939,
      "step": 4917
    },
    {
      "epoch": 1.01,
      "grad_norm": 1.1590602397918701,
      "learning_rate": 9.929281541457415e-06,
      "loss": 0.3256,
      "step": 4918
    },
    {
      "epoch": 1.01,
      "grad_norm": 1.0949941873550415,
      "learning_rate": 9.927231731064877e-06,
      "loss": 0.3469,
      "step": 4919
    },
    {
      "epoch": 1.01,
      "grad_norm": 1.555491328239441,
      "learning_rate": 9.925181920672339e-06,
      "loss": 0.4467,
      "step": 4920
    },
    {
      "epoch": 1.01,
      "grad_norm": 0.9276222586631775,
      "learning_rate": 9.9231321102798e-06,
      "loss": 0.3723,
      "step": 4921
    },
    {
      "epoch": 1.01,
      "grad_norm": 1.9788991212844849,
      "learning_rate": 9.921082299887261e-06,
      "loss": 0.372,
      "step": 4922
    },
    {
      "epoch": 1.01,
      "grad_norm": 1.3091955184936523,
      "learning_rate": 9.919032489494721e-06,
      "loss": 0.4534,
      "step": 4923
    },
    {
      "epoch": 1.01,
      "grad_norm": 0.8265174627304077,
      "learning_rate": 9.916982679102183e-06,
      "loss": 0.4426,
      "step": 4924
    },
    {
      "epoch": 1.01,
      "grad_norm": 1.6335786581039429,
      "learning_rate": 9.914932868709645e-06,
      "loss": 0.4599,
      "step": 4925
    },
    {
      "epoch": 1.01,
      "grad_norm": 1.7997725009918213,
      "learning_rate": 9.912883058317107e-06,
      "loss": 0.453,
      "step": 4926
    },
    {
      "epoch": 1.01,
      "grad_norm": 3.6450753211975098,
      "learning_rate": 9.910833247924567e-06,
      "loss": 0.2575,
      "step": 4927
    },
    {
      "epoch": 1.01,
      "grad_norm": 2.3537676334381104,
      "learning_rate": 9.908783437532029e-06,
      "loss": 0.3136,
      "step": 4928
    },
    {
      "epoch": 1.01,
      "grad_norm": 0.8635093569755554,
      "learning_rate": 9.90673362713949e-06,
      "loss": 0.3507,
      "step": 4929
    },
    {
      "epoch": 1.01,
      "grad_norm": 2.618244171142578,
      "learning_rate": 9.904683816746951e-06,
      "loss": 0.4511,
      "step": 4930
    },
    {
      "epoch": 1.01,
      "grad_norm": 4.641287803649902,
      "learning_rate": 9.902634006354413e-06,
      "loss": 0.2836,
      "step": 4931
    },
    {
      "epoch": 1.01,
      "grad_norm": 2.2315995693206787,
      "learning_rate": 9.900584195961875e-06,
      "loss": 0.382,
      "step": 4932
    },
    {
      "epoch": 1.01,
      "grad_norm": 1.8026869297027588,
      "learning_rate": 9.898534385569336e-06,
      "loss": 0.416,
      "step": 4933
    },
    {
      "epoch": 1.01,
      "grad_norm": 2.3567821979522705,
      "learning_rate": 9.896484575176797e-06,
      "loss": 0.4413,
      "step": 4934
    },
    {
      "epoch": 1.01,
      "grad_norm": 3.8067967891693115,
      "learning_rate": 9.894434764784258e-06,
      "loss": 0.4207,
      "step": 4935
    },
    {
      "epoch": 1.01,
      "grad_norm": 4.060136318206787,
      "learning_rate": 9.892384954391719e-06,
      "loss": 0.4464,
      "step": 4936
    },
    {
      "epoch": 1.01,
      "grad_norm": 1.2484383583068848,
      "learning_rate": 9.89033514399918e-06,
      "loss": 0.4261,
      "step": 4937
    },
    {
      "epoch": 1.01,
      "grad_norm": 1.5440394878387451,
      "learning_rate": 9.888285333606642e-06,
      "loss": 0.2352,
      "step": 4938
    },
    {
      "epoch": 1.01,
      "grad_norm": 2.2248852252960205,
      "learning_rate": 9.886235523214104e-06,
      "loss": 0.4042,
      "step": 4939
    },
    {
      "epoch": 1.01,
      "grad_norm": 0.9141248464584351,
      "learning_rate": 9.884185712821564e-06,
      "loss": 0.1949,
      "step": 4940
    },
    {
      "epoch": 1.01,
      "grad_norm": 1.6690741777420044,
      "learning_rate": 9.882135902429026e-06,
      "loss": 0.3516,
      "step": 4941
    },
    {
      "epoch": 1.01,
      "grad_norm": 1.7398251295089722,
      "learning_rate": 9.880086092036486e-06,
      "loss": 0.4293,
      "step": 4942
    },
    {
      "epoch": 1.01,
      "grad_norm": 1.1693637371063232,
      "learning_rate": 9.878036281643948e-06,
      "loss": 0.4681,
      "step": 4943
    },
    {
      "epoch": 1.01,
      "grad_norm": 1.5742580890655518,
      "learning_rate": 9.87598647125141e-06,
      "loss": 0.4158,
      "step": 4944
    },
    {
      "epoch": 1.01,
      "grad_norm": 1.3976296186447144,
      "learning_rate": 9.873936660858872e-06,
      "loss": 0.4774,
      "step": 4945
    },
    {
      "epoch": 1.01,
      "grad_norm": 1.0383304357528687,
      "learning_rate": 9.871886850466332e-06,
      "loss": 0.4278,
      "step": 4946
    },
    {
      "epoch": 1.01,
      "grad_norm": 1.1521639823913574,
      "learning_rate": 9.869837040073794e-06,
      "loss": 0.2931,
      "step": 4947
    },
    {
      "epoch": 1.01,
      "grad_norm": 0.8336406946182251,
      "learning_rate": 9.867787229681254e-06,
      "loss": 0.4953,
      "step": 4948
    },
    {
      "epoch": 1.01,
      "grad_norm": 1.2696990966796875,
      "learning_rate": 9.865737419288716e-06,
      "loss": 0.4319,
      "step": 4949
    },
    {
      "epoch": 1.01,
      "grad_norm": 0.8479085564613342,
      "learning_rate": 9.863687608896178e-06,
      "loss": 0.4306,
      "step": 4950
    },
    {
      "epoch": 1.01,
      "grad_norm": 1.0698894262313843,
      "learning_rate": 9.86163779850364e-06,
      "loss": 0.4458,
      "step": 4951
    },
    {
      "epoch": 1.01,
      "grad_norm": 0.8271989822387695,
      "learning_rate": 9.8595879881111e-06,
      "loss": 0.2912,
      "step": 4952
    },
    {
      "epoch": 1.01,
      "grad_norm": 1.4522417783737183,
      "learning_rate": 9.857538177718562e-06,
      "loss": 0.41,
      "step": 4953
    },
    {
      "epoch": 1.01,
      "grad_norm": 1.178993582725525,
      "learning_rate": 9.855488367326022e-06,
      "loss": 0.5102,
      "step": 4954
    },
    {
      "epoch": 1.02,
      "grad_norm": 0.9621181488037109,
      "learning_rate": 9.853438556933484e-06,
      "loss": 0.3391,
      "step": 4955
    },
    {
      "epoch": 1.02,
      "grad_norm": 1.735835075378418,
      "learning_rate": 9.851388746540946e-06,
      "loss": 0.2963,
      "step": 4956
    },
    {
      "epoch": 1.02,
      "grad_norm": 0.8688756227493286,
      "learning_rate": 9.849338936148407e-06,
      "loss": 0.4903,
      "step": 4957
    },
    {
      "epoch": 1.02,
      "grad_norm": 1.0409842729568481,
      "learning_rate": 9.84728912575587e-06,
      "loss": 0.4991,
      "step": 4958
    },
    {
      "epoch": 1.02,
      "grad_norm": 1.431946039199829,
      "learning_rate": 9.84523931536333e-06,
      "loss": 0.384,
      "step": 4959
    },
    {
      "epoch": 1.02,
      "grad_norm": 1.4575601816177368,
      "learning_rate": 9.843189504970791e-06,
      "loss": 0.3298,
      "step": 4960
    },
    {
      "epoch": 1.02,
      "grad_norm": 1.2024880647659302,
      "learning_rate": 9.841139694578251e-06,
      "loss": 0.3445,
      "step": 4961
    },
    {
      "epoch": 1.02,
      "grad_norm": 1.1800788640975952,
      "learning_rate": 9.839089884185713e-06,
      "loss": 0.3201,
      "step": 4962
    },
    {
      "epoch": 1.02,
      "grad_norm": 0.8617342114448547,
      "learning_rate": 9.837040073793175e-06,
      "loss": 0.3308,
      "step": 4963
    },
    {
      "epoch": 1.02,
      "grad_norm": 1.913167953491211,
      "learning_rate": 9.834990263400637e-06,
      "loss": 0.4039,
      "step": 4964
    },
    {
      "epoch": 1.02,
      "grad_norm": 1.2622236013412476,
      "learning_rate": 9.832940453008097e-06,
      "loss": 0.3653,
      "step": 4965
    },
    {
      "epoch": 1.02,
      "grad_norm": 1.1682970523834229,
      "learning_rate": 9.830890642615559e-06,
      "loss": 0.3529,
      "step": 4966
    },
    {
      "epoch": 1.02,
      "grad_norm": 1.6218361854553223,
      "learning_rate": 9.82884083222302e-06,
      "loss": 0.3868,
      "step": 4967
    },
    {
      "epoch": 1.02,
      "grad_norm": 1.1681095361709595,
      "learning_rate": 9.826791021830481e-06,
      "loss": 0.3655,
      "step": 4968
    },
    {
      "epoch": 1.02,
      "grad_norm": 1.0259532928466797,
      "learning_rate": 9.824741211437943e-06,
      "loss": 0.3156,
      "step": 4969
    },
    {
      "epoch": 1.02,
      "grad_norm": 2.7226264476776123,
      "learning_rate": 9.822691401045405e-06,
      "loss": 0.4118,
      "step": 4970
    },
    {
      "epoch": 1.02,
      "grad_norm": 1.7378544807434082,
      "learning_rate": 9.820641590652865e-06,
      "loss": 0.4093,
      "step": 4971
    },
    {
      "epoch": 1.02,
      "grad_norm": 2.2421658039093018,
      "learning_rate": 9.818591780260327e-06,
      "loss": 0.3395,
      "step": 4972
    },
    {
      "epoch": 1.02,
      "grad_norm": 1.8406785726547241,
      "learning_rate": 9.816541969867787e-06,
      "loss": 0.4367,
      "step": 4973
    },
    {
      "epoch": 1.02,
      "grad_norm": 1.1816059350967407,
      "learning_rate": 9.814492159475249e-06,
      "loss": 0.4114,
      "step": 4974
    },
    {
      "epoch": 1.02,
      "grad_norm": 1.2752017974853516,
      "learning_rate": 9.81244234908271e-06,
      "loss": 0.316,
      "step": 4975
    },
    {
      "epoch": 1.02,
      "grad_norm": 1.3010905981063843,
      "learning_rate": 9.810392538690173e-06,
      "loss": 0.3699,
      "step": 4976
    },
    {
      "epoch": 1.02,
      "grad_norm": 1.1309140920639038,
      "learning_rate": 9.808342728297633e-06,
      "loss": 0.2642,
      "step": 4977
    },
    {
      "epoch": 1.02,
      "grad_norm": 1.4729334115982056,
      "learning_rate": 9.806292917905095e-06,
      "loss": 0.3466,
      "step": 4978
    },
    {
      "epoch": 1.02,
      "grad_norm": 1.8095639944076538,
      "learning_rate": 9.804243107512555e-06,
      "loss": 0.3485,
      "step": 4979
    },
    {
      "epoch": 1.02,
      "grad_norm": 1.3412082195281982,
      "learning_rate": 9.802193297120017e-06,
      "loss": 0.4062,
      "step": 4980
    },
    {
      "epoch": 1.02,
      "grad_norm": 1.1054716110229492,
      "learning_rate": 9.800143486727478e-06,
      "loss": 0.3841,
      "step": 4981
    },
    {
      "epoch": 1.02,
      "grad_norm": 1.2260637283325195,
      "learning_rate": 9.79809367633494e-06,
      "loss": 0.3995,
      "step": 4982
    },
    {
      "epoch": 1.02,
      "grad_norm": 1.238572597503662,
      "learning_rate": 9.7960438659424e-06,
      "loss": 0.3731,
      "step": 4983
    },
    {
      "epoch": 1.02,
      "grad_norm": 1.3990051746368408,
      "learning_rate": 9.793994055549862e-06,
      "loss": 0.5176,
      "step": 4984
    },
    {
      "epoch": 1.02,
      "grad_norm": 1.1568963527679443,
      "learning_rate": 9.791944245157322e-06,
      "loss": 0.27,
      "step": 4985
    },
    {
      "epoch": 1.02,
      "grad_norm": 0.9285327196121216,
      "learning_rate": 9.789894434764784e-06,
      "loss": 0.3552,
      "step": 4986
    },
    {
      "epoch": 1.02,
      "grad_norm": 1.0389575958251953,
      "learning_rate": 9.787844624372246e-06,
      "loss": 0.3738,
      "step": 4987
    },
    {
      "epoch": 1.02,
      "grad_norm": 1.1618603467941284,
      "learning_rate": 9.785794813979708e-06,
      "loss": 0.412,
      "step": 4988
    },
    {
      "epoch": 1.02,
      "grad_norm": 0.8142200708389282,
      "learning_rate": 9.78374500358717e-06,
      "loss": 0.2997,
      "step": 4989
    },
    {
      "epoch": 1.02,
      "grad_norm": 0.8210780024528503,
      "learning_rate": 9.78169519319463e-06,
      "loss": 0.3801,
      "step": 4990
    },
    {
      "epoch": 1.02,
      "grad_norm": 1.123596429824829,
      "learning_rate": 9.779645382802092e-06,
      "loss": 0.3505,
      "step": 4991
    },
    {
      "epoch": 1.02,
      "grad_norm": 1.2499457597732544,
      "learning_rate": 9.777595572409552e-06,
      "loss": 0.3429,
      "step": 4992
    },
    {
      "epoch": 1.02,
      "grad_norm": 1.0912591218948364,
      "learning_rate": 9.775545762017014e-06,
      "loss": 0.3159,
      "step": 4993
    },
    {
      "epoch": 1.02,
      "grad_norm": 1.4400835037231445,
      "learning_rate": 9.773495951624476e-06,
      "loss": 0.3177,
      "step": 4994
    },
    {
      "epoch": 1.02,
      "grad_norm": 1.620078444480896,
      "learning_rate": 9.771446141231938e-06,
      "loss": 0.3685,
      "step": 4995
    },
    {
      "epoch": 1.02,
      "grad_norm": 1.5991524457931519,
      "learning_rate": 9.769396330839398e-06,
      "loss": 0.2839,
      "step": 4996
    },
    {
      "epoch": 1.02,
      "grad_norm": 1.3872843980789185,
      "learning_rate": 9.76734652044686e-06,
      "loss": 0.3511,
      "step": 4997
    },
    {
      "epoch": 1.02,
      "grad_norm": 2.5154712200164795,
      "learning_rate": 9.76529671005432e-06,
      "loss": 0.3927,
      "step": 4998
    },
    {
      "epoch": 1.02,
      "grad_norm": 0.7432418465614319,
      "learning_rate": 9.763246899661782e-06,
      "loss": 0.4,
      "step": 4999
    },
    {
      "epoch": 1.02,
      "grad_norm": 3.896984577178955,
      "learning_rate": 9.761197089269244e-06,
      "loss": 0.24,
      "step": 5000
    },
    {
      "epoch": 1.02,
      "eval_loss": 0.37790560722351074,
      "eval_runtime": 663.6007,
      "eval_samples_per_second": 15.069,
      "eval_steps_per_second": 1.884,
      "step": 5000
    },
    {
      "epoch": 1.02,
      "grad_norm": 1.6994571685791016,
      "learning_rate": 9.759147278876705e-06,
      "loss": 0.2797,
      "step": 5001
    },
    {
      "epoch": 1.02,
      "grad_norm": 0.9852463006973267,
      "learning_rate": 9.757097468484166e-06,
      "loss": 0.5359,
      "step": 5002
    },
    {
      "epoch": 1.02,
      "grad_norm": 1.3820210695266724,
      "learning_rate": 9.755047658091627e-06,
      "loss": 0.3472,
      "step": 5003
    },
    {
      "epoch": 1.03,
      "grad_norm": 2.295337438583374,
      "learning_rate": 9.752997847699088e-06,
      "loss": 0.3142,
      "step": 5004
    },
    {
      "epoch": 1.03,
      "grad_norm": 1.150633454322815,
      "learning_rate": 9.75094803730655e-06,
      "loss": 0.4386,
      "step": 5005
    },
    {
      "epoch": 1.03,
      "grad_norm": 1.0242109298706055,
      "learning_rate": 9.748898226914011e-06,
      "loss": 0.3814,
      "step": 5006
    },
    {
      "epoch": 1.03,
      "grad_norm": 0.8074360489845276,
      "learning_rate": 9.746848416521473e-06,
      "loss": 0.2784,
      "step": 5007
    },
    {
      "epoch": 1.03,
      "grad_norm": 1.350307822227478,
      "learning_rate": 9.744798606128933e-06,
      "loss": 0.4205,
      "step": 5008
    },
    {
      "epoch": 1.03,
      "grad_norm": 1.738419532775879,
      "learning_rate": 9.742748795736395e-06,
      "loss": 0.2308,
      "step": 5009
    },
    {
      "epoch": 1.03,
      "grad_norm": 1.1130472421646118,
      "learning_rate": 9.740698985343855e-06,
      "loss": 0.3,
      "step": 5010
    },
    {
      "epoch": 1.03,
      "grad_norm": 2.187103748321533,
      "learning_rate": 9.738649174951317e-06,
      "loss": 0.3541,
      "step": 5011
    },
    {
      "epoch": 1.03,
      "grad_norm": 1.1295748949050903,
      "learning_rate": 9.736599364558779e-06,
      "loss": 0.3573,
      "step": 5012
    },
    {
      "epoch": 1.03,
      "grad_norm": 1.2440506219863892,
      "learning_rate": 9.734549554166241e-06,
      "loss": 0.2797,
      "step": 5013
    },
    {
      "epoch": 1.03,
      "grad_norm": 0.9256919026374817,
      "learning_rate": 9.732499743773701e-06,
      "loss": 0.3667,
      "step": 5014
    },
    {
      "epoch": 1.03,
      "grad_norm": 1.1880180835723877,
      "learning_rate": 9.730449933381163e-06,
      "loss": 0.4817,
      "step": 5015
    },
    {
      "epoch": 1.03,
      "grad_norm": 2.1633079051971436,
      "learning_rate": 9.728400122988623e-06,
      "loss": 0.366,
      "step": 5016
    },
    {
      "epoch": 1.03,
      "grad_norm": 1.0608830451965332,
      "learning_rate": 9.726350312596085e-06,
      "loss": 0.2929,
      "step": 5017
    },
    {
      "epoch": 1.03,
      "grad_norm": 1.6475344896316528,
      "learning_rate": 9.724300502203547e-06,
      "loss": 0.3145,
      "step": 5018
    },
    {
      "epoch": 1.03,
      "grad_norm": 1.1422022581100464,
      "learning_rate": 9.722250691811009e-06,
      "loss": 0.4708,
      "step": 5019
    },
    {
      "epoch": 1.03,
      "grad_norm": 1.0830814838409424,
      "learning_rate": 9.72020088141847e-06,
      "loss": 0.2899,
      "step": 5020
    },
    {
      "epoch": 1.03,
      "grad_norm": 0.9496896266937256,
      "learning_rate": 9.71815107102593e-06,
      "loss": 0.531,
      "step": 5021
    },
    {
      "epoch": 1.03,
      "grad_norm": 0.9972265958786011,
      "learning_rate": 9.716101260633393e-06,
      "loss": 0.4782,
      "step": 5022
    },
    {
      "epoch": 1.03,
      "grad_norm": 1.159127116203308,
      "learning_rate": 9.714051450240853e-06,
      "loss": 0.3112,
      "step": 5023
    },
    {
      "epoch": 1.03,
      "grad_norm": 1.4896044731140137,
      "learning_rate": 9.712001639848315e-06,
      "loss": 0.5155,
      "step": 5024
    },
    {
      "epoch": 1.03,
      "grad_norm": 1.1121726036071777,
      "learning_rate": 9.709951829455776e-06,
      "loss": 0.4479,
      "step": 5025
    },
    {
      "epoch": 1.03,
      "grad_norm": 1.383800983428955,
      "learning_rate": 9.707902019063238e-06,
      "loss": 0.2687,
      "step": 5026
    },
    {
      "epoch": 1.03,
      "grad_norm": 2.2200992107391357,
      "learning_rate": 9.705852208670698e-06,
      "loss": 0.314,
      "step": 5027
    },
    {
      "epoch": 1.03,
      "grad_norm": 1.4250143766403198,
      "learning_rate": 9.70380239827816e-06,
      "loss": 0.3421,
      "step": 5028
    },
    {
      "epoch": 1.03,
      "grad_norm": 1.2243314981460571,
      "learning_rate": 9.70175258788562e-06,
      "loss": 0.4013,
      "step": 5029
    },
    {
      "epoch": 1.03,
      "grad_norm": 1.4550280570983887,
      "learning_rate": 9.699702777493082e-06,
      "loss": 0.2456,
      "step": 5030
    },
    {
      "epoch": 1.03,
      "grad_norm": 1.7839477062225342,
      "learning_rate": 9.697652967100544e-06,
      "loss": 0.3938,
      "step": 5031
    },
    {
      "epoch": 1.03,
      "grad_norm": 0.6946855187416077,
      "learning_rate": 9.695603156708006e-06,
      "loss": 0.1573,
      "step": 5032
    },
    {
      "epoch": 1.03,
      "grad_norm": 0.7299742102622986,
      "learning_rate": 9.693553346315466e-06,
      "loss": 0.5259,
      "step": 5033
    },
    {
      "epoch": 1.03,
      "grad_norm": 1.2821675539016724,
      "learning_rate": 9.691503535922928e-06,
      "loss": 0.4054,
      "step": 5034
    },
    {
      "epoch": 1.03,
      "grad_norm": 1.4223237037658691,
      "learning_rate": 9.689453725530388e-06,
      "loss": 0.4563,
      "step": 5035
    },
    {
      "epoch": 1.03,
      "grad_norm": 2.391761302947998,
      "learning_rate": 9.68740391513785e-06,
      "loss": 0.4096,
      "step": 5036
    },
    {
      "epoch": 1.03,
      "grad_norm": 1.3900467157363892,
      "learning_rate": 9.685354104745312e-06,
      "loss": 0.4407,
      "step": 5037
    },
    {
      "epoch": 1.03,
      "grad_norm": 1.090932846069336,
      "learning_rate": 9.683304294352774e-06,
      "loss": 0.3941,
      "step": 5038
    },
    {
      "epoch": 1.03,
      "grad_norm": 2.144766330718994,
      "learning_rate": 9.681254483960234e-06,
      "loss": 0.3603,
      "step": 5039
    },
    {
      "epoch": 1.03,
      "grad_norm": 1.040893793106079,
      "learning_rate": 9.679204673567696e-06,
      "loss": 0.2195,
      "step": 5040
    },
    {
      "epoch": 1.03,
      "grad_norm": 1.239895224571228,
      "learning_rate": 9.677154863175156e-06,
      "loss": 0.3948,
      "step": 5041
    },
    {
      "epoch": 1.03,
      "grad_norm": 1.48698890209198,
      "learning_rate": 9.675105052782618e-06,
      "loss": 0.5184,
      "step": 5042
    },
    {
      "epoch": 1.03,
      "grad_norm": 0.8550350666046143,
      "learning_rate": 9.67305524239008e-06,
      "loss": 0.3433,
      "step": 5043
    },
    {
      "epoch": 1.03,
      "grad_norm": 1.2972745895385742,
      "learning_rate": 9.671005431997542e-06,
      "loss": 0.3884,
      "step": 5044
    },
    {
      "epoch": 1.03,
      "grad_norm": 1.1837875843048096,
      "learning_rate": 9.668955621605002e-06,
      "loss": 0.4611,
      "step": 5045
    },
    {
      "epoch": 1.03,
      "grad_norm": 1.4394190311431885,
      "learning_rate": 9.666905811212464e-06,
      "loss": 0.4362,
      "step": 5046
    },
    {
      "epoch": 1.03,
      "grad_norm": 1.172838807106018,
      "learning_rate": 9.664856000819925e-06,
      "loss": 0.4008,
      "step": 5047
    },
    {
      "epoch": 1.03,
      "grad_norm": 1.0558750629425049,
      "learning_rate": 9.662806190427386e-06,
      "loss": 0.3741,
      "step": 5048
    },
    {
      "epoch": 1.03,
      "grad_norm": 0.8365474939346313,
      "learning_rate": 9.660756380034847e-06,
      "loss": 0.4587,
      "step": 5049
    },
    {
      "epoch": 1.03,
      "grad_norm": 1.5199625492095947,
      "learning_rate": 9.65870656964231e-06,
      "loss": 0.3811,
      "step": 5050
    },
    {
      "epoch": 1.03,
      "grad_norm": 1.213032841682434,
      "learning_rate": 9.656656759249771e-06,
      "loss": 0.2872,
      "step": 5051
    },
    {
      "epoch": 1.04,
      "grad_norm": 0.8185086846351624,
      "learning_rate": 9.654606948857231e-06,
      "loss": 0.3301,
      "step": 5052
    },
    {
      "epoch": 1.04,
      "grad_norm": 0.9597133994102478,
      "learning_rate": 9.652557138464693e-06,
      "loss": 0.36,
      "step": 5053
    },
    {
      "epoch": 1.04,
      "grad_norm": 1.0156210660934448,
      "learning_rate": 9.650507328072153e-06,
      "loss": 0.4513,
      "step": 5054
    },
    {
      "epoch": 1.04,
      "grad_norm": 1.435778260231018,
      "learning_rate": 9.648457517679615e-06,
      "loss": 0.3226,
      "step": 5055
    },
    {
      "epoch": 1.04,
      "grad_norm": 1.364670753479004,
      "learning_rate": 9.646407707287077e-06,
      "loss": 0.3305,
      "step": 5056
    },
    {
      "epoch": 1.04,
      "grad_norm": 1.2424561977386475,
      "learning_rate": 9.644357896894539e-06,
      "loss": 0.4312,
      "step": 5057
    },
    {
      "epoch": 1.04,
      "grad_norm": 1.1814385652542114,
      "learning_rate": 9.642308086501999e-06,
      "loss": 0.5423,
      "step": 5058
    },
    {
      "epoch": 1.04,
      "grad_norm": 0.9389705657958984,
      "learning_rate": 9.640258276109461e-06,
      "loss": 0.2726,
      "step": 5059
    },
    {
      "epoch": 1.04,
      "grad_norm": 2.491302967071533,
      "learning_rate": 9.638208465716921e-06,
      "loss": 0.3535,
      "step": 5060
    },
    {
      "epoch": 1.04,
      "grad_norm": 1.3120307922363281,
      "learning_rate": 9.636158655324383e-06,
      "loss": 0.419,
      "step": 5061
    },
    {
      "epoch": 1.04,
      "grad_norm": 0.9532415866851807,
      "learning_rate": 9.634108844931845e-06,
      "loss": 0.3404,
      "step": 5062
    },
    {
      "epoch": 1.04,
      "grad_norm": 1.246200442314148,
      "learning_rate": 9.632059034539307e-06,
      "loss": 0.43,
      "step": 5063
    },
    {
      "epoch": 1.04,
      "grad_norm": 1.981935977935791,
      "learning_rate": 9.630009224146767e-06,
      "loss": 0.4889,
      "step": 5064
    },
    {
      "epoch": 1.04,
      "grad_norm": 0.9579466581344604,
      "learning_rate": 9.627959413754229e-06,
      "loss": 0.4105,
      "step": 5065
    },
    {
      "epoch": 1.04,
      "grad_norm": 1.6980278491973877,
      "learning_rate": 9.625909603361689e-06,
      "loss": 0.2984,
      "step": 5066
    },
    {
      "epoch": 1.04,
      "grad_norm": 1.950053334236145,
      "learning_rate": 9.62385979296915e-06,
      "loss": 0.3598,
      "step": 5067
    },
    {
      "epoch": 1.04,
      "grad_norm": 2.1082382202148438,
      "learning_rate": 9.621809982576613e-06,
      "loss": 0.5602,
      "step": 5068
    },
    {
      "epoch": 1.04,
      "grad_norm": 2.965956211090088,
      "learning_rate": 9.619760172184074e-06,
      "loss": 0.3401,
      "step": 5069
    },
    {
      "epoch": 1.04,
      "grad_norm": 2.4747769832611084,
      "learning_rate": 9.617710361791535e-06,
      "loss": 0.4033,
      "step": 5070
    },
    {
      "epoch": 1.04,
      "grad_norm": 2.7150185108184814,
      "learning_rate": 9.615660551398996e-06,
      "loss": 0.3709,
      "step": 5071
    },
    {
      "epoch": 1.04,
      "grad_norm": 1.7683241367340088,
      "learning_rate": 9.613610741006457e-06,
      "loss": 0.3522,
      "step": 5072
    },
    {
      "epoch": 1.04,
      "grad_norm": 1.135467529296875,
      "learning_rate": 9.611560930613918e-06,
      "loss": 0.3307,
      "step": 5073
    },
    {
      "epoch": 1.04,
      "grad_norm": 1.2797986268997192,
      "learning_rate": 9.60951112022138e-06,
      "loss": 0.3198,
      "step": 5074
    },
    {
      "epoch": 1.04,
      "grad_norm": 1.2267534732818604,
      "learning_rate": 9.607461309828842e-06,
      "loss": 0.4436,
      "step": 5075
    },
    {
      "epoch": 1.04,
      "grad_norm": 0.7341127395629883,
      "learning_rate": 9.605411499436304e-06,
      "loss": 0.2369,
      "step": 5076
    },
    {
      "epoch": 1.04,
      "grad_norm": 1.2508116960525513,
      "learning_rate": 9.603361689043764e-06,
      "loss": 0.248,
      "step": 5077
    },
    {
      "epoch": 1.04,
      "grad_norm": 1.2610266208648682,
      "learning_rate": 9.601311878651226e-06,
      "loss": 0.3481,
      "step": 5078
    },
    {
      "epoch": 1.04,
      "grad_norm": 1.1970840692520142,
      "learning_rate": 9.599262068258686e-06,
      "loss": 0.3225,
      "step": 5079
    },
    {
      "epoch": 1.04,
      "grad_norm": 1.0870916843414307,
      "learning_rate": 9.597212257866148e-06,
      "loss": 0.4337,
      "step": 5080
    },
    {
      "epoch": 1.04,
      "grad_norm": 0.8154357671737671,
      "learning_rate": 9.59516244747361e-06,
      "loss": 0.3284,
      "step": 5081
    },
    {
      "epoch": 1.04,
      "grad_norm": 0.9800032377243042,
      "learning_rate": 9.593112637081072e-06,
      "loss": 0.4145,
      "step": 5082
    },
    {
      "epoch": 1.04,
      "grad_norm": 1.0025904178619385,
      "learning_rate": 9.591062826688532e-06,
      "loss": 0.4153,
      "step": 5083
    },
    {
      "epoch": 1.04,
      "grad_norm": 1.5384671688079834,
      "learning_rate": 9.589013016295994e-06,
      "loss": 0.2531,
      "step": 5084
    },
    {
      "epoch": 1.04,
      "grad_norm": 1.5194203853607178,
      "learning_rate": 9.586963205903454e-06,
      "loss": 0.3459,
      "step": 5085
    },
    {
      "epoch": 1.04,
      "grad_norm": 1.0382717847824097,
      "learning_rate": 9.584913395510916e-06,
      "loss": 0.4058,
      "step": 5086
    },
    {
      "epoch": 1.04,
      "grad_norm": 1.126806616783142,
      "learning_rate": 9.582863585118378e-06,
      "loss": 0.3774,
      "step": 5087
    },
    {
      "epoch": 1.04,
      "grad_norm": 1.342903971672058,
      "learning_rate": 9.58081377472584e-06,
      "loss": 0.3745,
      "step": 5088
    },
    {
      "epoch": 1.04,
      "grad_norm": 1.4420478343963623,
      "learning_rate": 9.5787639643333e-06,
      "loss": 0.5354,
      "step": 5089
    },
    {
      "epoch": 1.04,
      "grad_norm": 1.3548897504806519,
      "learning_rate": 9.576714153940762e-06,
      "loss": 0.4089,
      "step": 5090
    },
    {
      "epoch": 1.04,
      "grad_norm": 1.4483221769332886,
      "learning_rate": 9.574664343548222e-06,
      "loss": 0.4928,
      "step": 5091
    },
    {
      "epoch": 1.04,
      "grad_norm": 1.4805259704589844,
      "learning_rate": 9.572614533155684e-06,
      "loss": 0.3082,
      "step": 5092
    },
    {
      "epoch": 1.04,
      "grad_norm": 2.1799302101135254,
      "learning_rate": 9.570564722763145e-06,
      "loss": 0.392,
      "step": 5093
    },
    {
      "epoch": 1.04,
      "grad_norm": 0.857342004776001,
      "learning_rate": 9.568514912370607e-06,
      "loss": 0.3099,
      "step": 5094
    },
    {
      "epoch": 1.04,
      "grad_norm": 0.8953371644020081,
      "learning_rate": 9.566465101978067e-06,
      "loss": 0.4907,
      "step": 5095
    },
    {
      "epoch": 1.04,
      "grad_norm": 2.7492477893829346,
      "learning_rate": 9.56441529158553e-06,
      "loss": 0.3835,
      "step": 5096
    },
    {
      "epoch": 1.04,
      "grad_norm": 2.3640973567962646,
      "learning_rate": 9.56236548119299e-06,
      "loss": 0.4143,
      "step": 5097
    },
    {
      "epoch": 1.04,
      "grad_norm": 1.5367145538330078,
      "learning_rate": 9.560315670800451e-06,
      "loss": 0.3767,
      "step": 5098
    },
    {
      "epoch": 1.04,
      "grad_norm": 2.337486743927002,
      "learning_rate": 9.558265860407913e-06,
      "loss": 0.3817,
      "step": 5099
    },
    {
      "epoch": 1.04,
      "grad_norm": 2.869624137878418,
      "learning_rate": 9.556216050015375e-06,
      "loss": 0.407,
      "step": 5100
    },
    {
      "epoch": 1.05,
      "grad_norm": 1.2613840103149414,
      "learning_rate": 9.554166239622835e-06,
      "loss": 0.414,
      "step": 5101
    },
    {
      "epoch": 1.05,
      "grad_norm": 1.2801796197891235,
      "learning_rate": 9.552116429230297e-06,
      "loss": 0.3548,
      "step": 5102
    },
    {
      "epoch": 1.05,
      "grad_norm": 2.3323545455932617,
      "learning_rate": 9.550066618837757e-06,
      "loss": 0.3699,
      "step": 5103
    },
    {
      "epoch": 1.05,
      "grad_norm": 1.7226847410202026,
      "learning_rate": 9.548016808445219e-06,
      "loss": 0.302,
      "step": 5104
    },
    {
      "epoch": 1.05,
      "grad_norm": 1.6407384872436523,
      "learning_rate": 9.545966998052681e-06,
      "loss": 0.5011,
      "step": 5105
    },
    {
      "epoch": 1.05,
      "grad_norm": 1.156119465827942,
      "learning_rate": 9.543917187660143e-06,
      "loss": 0.3699,
      "step": 5106
    },
    {
      "epoch": 1.05,
      "grad_norm": 0.9586964249610901,
      "learning_rate": 9.541867377267605e-06,
      "loss": 0.2537,
      "step": 5107
    },
    {
      "epoch": 1.05,
      "grad_norm": 0.8251621723175049,
      "learning_rate": 9.539817566875065e-06,
      "loss": 0.3414,
      "step": 5108
    },
    {
      "epoch": 1.05,
      "grad_norm": 0.799405574798584,
      "learning_rate": 9.537767756482527e-06,
      "loss": 0.3108,
      "step": 5109
    },
    {
      "epoch": 1.05,
      "grad_norm": 1.2792203426361084,
      "learning_rate": 9.535717946089987e-06,
      "loss": 0.3605,
      "step": 5110
    },
    {
      "epoch": 1.05,
      "grad_norm": 1.0380157232284546,
      "learning_rate": 9.533668135697449e-06,
      "loss": 0.417,
      "step": 5111
    },
    {
      "epoch": 1.05,
      "grad_norm": 1.1651887893676758,
      "learning_rate": 9.53161832530491e-06,
      "loss": 0.4741,
      "step": 5112
    },
    {
      "epoch": 1.05,
      "grad_norm": 1.4038258790969849,
      "learning_rate": 9.529568514912372e-06,
      "loss": 0.3029,
      "step": 5113
    },
    {
      "epoch": 1.05,
      "grad_norm": 1.702415108680725,
      "learning_rate": 9.527518704519833e-06,
      "loss": 0.3848,
      "step": 5114
    },
    {
      "epoch": 1.05,
      "grad_norm": 0.8457038402557373,
      "learning_rate": 9.525468894127294e-06,
      "loss": 0.2345,
      "step": 5115
    },
    {
      "epoch": 1.05,
      "grad_norm": 1.227651596069336,
      "learning_rate": 9.523419083734755e-06,
      "loss": 0.3873,
      "step": 5116
    },
    {
      "epoch": 1.05,
      "grad_norm": 1.1121915578842163,
      "learning_rate": 9.521369273342216e-06,
      "loss": 0.5764,
      "step": 5117
    },
    {
      "epoch": 1.05,
      "grad_norm": 1.1240772008895874,
      "learning_rate": 9.519319462949678e-06,
      "loss": 0.3887,
      "step": 5118
    },
    {
      "epoch": 1.05,
      "grad_norm": 1.0688594579696655,
      "learning_rate": 9.51726965255714e-06,
      "loss": 0.4535,
      "step": 5119
    },
    {
      "epoch": 1.05,
      "grad_norm": 1.6714667081832886,
      "learning_rate": 9.5152198421646e-06,
      "loss": 0.3502,
      "step": 5120
    },
    {
      "epoch": 1.05,
      "grad_norm": 2.0645363330841064,
      "learning_rate": 9.513170031772062e-06,
      "loss": 0.2739,
      "step": 5121
    },
    {
      "epoch": 1.05,
      "grad_norm": 0.8693837523460388,
      "learning_rate": 9.511120221379522e-06,
      "loss": 0.363,
      "step": 5122
    },
    {
      "epoch": 1.05,
      "grad_norm": 1.6859272718429565,
      "learning_rate": 9.509070410986984e-06,
      "loss": 0.1822,
      "step": 5123
    },
    {
      "epoch": 1.05,
      "grad_norm": 1.675168514251709,
      "learning_rate": 9.507020600594446e-06,
      "loss": 0.3375,
      "step": 5124
    },
    {
      "epoch": 1.05,
      "grad_norm": 0.8047938346862793,
      "learning_rate": 9.504970790201908e-06,
      "loss": 0.345,
      "step": 5125
    },
    {
      "epoch": 1.05,
      "grad_norm": 1.0238211154937744,
      "learning_rate": 9.502920979809368e-06,
      "loss": 0.3858,
      "step": 5126
    },
    {
      "epoch": 1.05,
      "grad_norm": 1.52183997631073,
      "learning_rate": 9.50087116941683e-06,
      "loss": 0.429,
      "step": 5127
    },
    {
      "epoch": 1.05,
      "grad_norm": 0.9401686787605286,
      "learning_rate": 9.49882135902429e-06,
      "loss": 0.3334,
      "step": 5128
    },
    {
      "epoch": 1.05,
      "grad_norm": 0.9339427351951599,
      "learning_rate": 9.496771548631752e-06,
      "loss": 0.4467,
      "step": 5129
    },
    {
      "epoch": 1.05,
      "grad_norm": 1.4202079772949219,
      "learning_rate": 9.494721738239214e-06,
      "loss": 0.389,
      "step": 5130
    },
    {
      "epoch": 1.05,
      "grad_norm": 0.8298852443695068,
      "learning_rate": 9.492671927846676e-06,
      "loss": 0.3636,
      "step": 5131
    },
    {
      "epoch": 1.05,
      "grad_norm": 1.1732016801834106,
      "learning_rate": 9.490622117454136e-06,
      "loss": 0.438,
      "step": 5132
    },
    {
      "epoch": 1.05,
      "grad_norm": 1.2912955284118652,
      "learning_rate": 9.488572307061598e-06,
      "loss": 0.2857,
      "step": 5133
    },
    {
      "epoch": 1.05,
      "grad_norm": 1.6225659847259521,
      "learning_rate": 9.486522496669058e-06,
      "loss": 0.4436,
      "step": 5134
    },
    {
      "epoch": 1.05,
      "grad_norm": 1.3383291959762573,
      "learning_rate": 9.48447268627652e-06,
      "loss": 0.5131,
      "step": 5135
    },
    {
      "epoch": 1.05,
      "grad_norm": 0.956227719783783,
      "learning_rate": 9.482422875883981e-06,
      "loss": 0.3512,
      "step": 5136
    },
    {
      "epoch": 1.05,
      "grad_norm": 3.0779945850372314,
      "learning_rate": 9.480373065491443e-06,
      "loss": 0.3001,
      "step": 5137
    },
    {
      "epoch": 1.05,
      "grad_norm": 1.1686639785766602,
      "learning_rate": 9.478323255098905e-06,
      "loss": 0.3855,
      "step": 5138
    },
    {
      "epoch": 1.05,
      "grad_norm": 1.1265102624893188,
      "learning_rate": 9.476273444706365e-06,
      "loss": 0.3372,
      "step": 5139
    },
    {
      "epoch": 1.05,
      "grad_norm": 2.052536964416504,
      "learning_rate": 9.474223634313827e-06,
      "loss": 0.4488,
      "step": 5140
    },
    {
      "epoch": 1.05,
      "grad_norm": 1.9654453992843628,
      "learning_rate": 9.472173823921287e-06,
      "loss": 0.2983,
      "step": 5141
    },
    {
      "epoch": 1.05,
      "grad_norm": 1.5421143770217896,
      "learning_rate": 9.47012401352875e-06,
      "loss": 0.5485,
      "step": 5142
    },
    {
      "epoch": 1.05,
      "grad_norm": 1.6980332136154175,
      "learning_rate": 9.468074203136211e-06,
      "loss": 0.3313,
      "step": 5143
    },
    {
      "epoch": 1.05,
      "grad_norm": 2.029707431793213,
      "learning_rate": 9.466024392743673e-06,
      "loss": 0.3585,
      "step": 5144
    },
    {
      "epoch": 1.05,
      "grad_norm": 1.4055804014205933,
      "learning_rate": 9.463974582351133e-06,
      "loss": 0.4177,
      "step": 5145
    },
    {
      "epoch": 1.05,
      "grad_norm": 1.527223825454712,
      "learning_rate": 9.461924771958595e-06,
      "loss": 0.4387,
      "step": 5146
    },
    {
      "epoch": 1.05,
      "grad_norm": 1.1481106281280518,
      "learning_rate": 9.459874961566055e-06,
      "loss": 0.286,
      "step": 5147
    },
    {
      "epoch": 1.05,
      "grad_norm": 2.7958126068115234,
      "learning_rate": 9.457825151173517e-06,
      "loss": 0.3508,
      "step": 5148
    },
    {
      "epoch": 1.05,
      "grad_norm": 0.8953293561935425,
      "learning_rate": 9.455775340780979e-06,
      "loss": 0.3717,
      "step": 5149
    },
    {
      "epoch": 1.06,
      "grad_norm": 1.2428420782089233,
      "learning_rate": 9.45372553038844e-06,
      "loss": 0.4254,
      "step": 5150
    },
    {
      "epoch": 1.06,
      "grad_norm": 3.5929062366485596,
      "learning_rate": 9.451675719995901e-06,
      "loss": 0.3328,
      "step": 5151
    },
    {
      "epoch": 1.06,
      "grad_norm": 1.111372470855713,
      "learning_rate": 9.449625909603363e-06,
      "loss": 0.3104,
      "step": 5152
    },
    {
      "epoch": 1.06,
      "grad_norm": 1.28646981716156,
      "learning_rate": 9.447576099210823e-06,
      "loss": 0.3109,
      "step": 5153
    },
    {
      "epoch": 1.06,
      "grad_norm": 1.264303207397461,
      "learning_rate": 9.445526288818285e-06,
      "loss": 0.4162,
      "step": 5154
    },
    {
      "epoch": 1.06,
      "grad_norm": 1.065494418144226,
      "learning_rate": 9.443476478425747e-06,
      "loss": 0.4329,
      "step": 5155
    },
    {
      "epoch": 1.06,
      "grad_norm": 1.8715581893920898,
      "learning_rate": 9.441426668033208e-06,
      "loss": 0.5336,
      "step": 5156
    },
    {
      "epoch": 1.06,
      "grad_norm": 1.7037705183029175,
      "learning_rate": 9.439376857640669e-06,
      "loss": 0.4247,
      "step": 5157
    },
    {
      "epoch": 1.06,
      "grad_norm": 0.9411700367927551,
      "learning_rate": 9.43732704724813e-06,
      "loss": 0.5013,
      "step": 5158
    },
    {
      "epoch": 1.06,
      "grad_norm": 1.0958945751190186,
      "learning_rate": 9.43527723685559e-06,
      "loss": 0.4328,
      "step": 5159
    },
    {
      "epoch": 1.06,
      "grad_norm": 1.459241271018982,
      "learning_rate": 9.433227426463052e-06,
      "loss": 0.3447,
      "step": 5160
    },
    {
      "epoch": 1.06,
      "grad_norm": 1.2836321592330933,
      "learning_rate": 9.431177616070514e-06,
      "loss": 0.3165,
      "step": 5161
    },
    {
      "epoch": 1.06,
      "grad_norm": 2.1606743335723877,
      "learning_rate": 9.429127805677976e-06,
      "loss": 0.3143,
      "step": 5162
    },
    {
      "epoch": 1.06,
      "grad_norm": 1.4897304773330688,
      "learning_rate": 9.427077995285436e-06,
      "loss": 0.4075,
      "step": 5163
    },
    {
      "epoch": 1.06,
      "grad_norm": 0.9534682631492615,
      "learning_rate": 9.425028184892898e-06,
      "loss": 0.2612,
      "step": 5164
    },
    {
      "epoch": 1.06,
      "grad_norm": 1.7332775592803955,
      "learning_rate": 9.42297837450036e-06,
      "loss": 0.2901,
      "step": 5165
    },
    {
      "epoch": 1.06,
      "grad_norm": 1.046736717224121,
      "learning_rate": 9.42092856410782e-06,
      "loss": 0.3826,
      "step": 5166
    },
    {
      "epoch": 1.06,
      "grad_norm": 1.487596035003662,
      "learning_rate": 9.418878753715282e-06,
      "loss": 0.3389,
      "step": 5167
    },
    {
      "epoch": 1.06,
      "grad_norm": 1.2411577701568604,
      "learning_rate": 9.416828943322744e-06,
      "loss": 0.3124,
      "step": 5168
    },
    {
      "epoch": 1.06,
      "grad_norm": 1.506824254989624,
      "learning_rate": 9.414779132930206e-06,
      "loss": 0.2715,
      "step": 5169
    },
    {
      "epoch": 1.06,
      "grad_norm": 1.785913109779358,
      "learning_rate": 9.412729322537666e-06,
      "loss": 0.402,
      "step": 5170
    },
    {
      "epoch": 1.06,
      "grad_norm": 1.8810714483261108,
      "learning_rate": 9.410679512145128e-06,
      "loss": 0.3627,
      "step": 5171
    },
    {
      "epoch": 1.06,
      "grad_norm": 2.2404420375823975,
      "learning_rate": 9.408629701752588e-06,
      "loss": 0.2695,
      "step": 5172
    },
    {
      "epoch": 1.06,
      "grad_norm": 2.224513292312622,
      "learning_rate": 9.40657989136005e-06,
      "loss": 0.397,
      "step": 5173
    },
    {
      "epoch": 1.06,
      "grad_norm": 1.5149388313293457,
      "learning_rate": 9.404530080967512e-06,
      "loss": 0.3216,
      "step": 5174
    },
    {
      "epoch": 1.06,
      "grad_norm": 1.3443092107772827,
      "learning_rate": 9.402480270574974e-06,
      "loss": 0.357,
      "step": 5175
    },
    {
      "epoch": 1.06,
      "grad_norm": 1.6892375946044922,
      "learning_rate": 9.400430460182434e-06,
      "loss": 0.3907,
      "step": 5176
    },
    {
      "epoch": 1.06,
      "grad_norm": 1.6517921686172485,
      "learning_rate": 9.398380649789896e-06,
      "loss": 0.4132,
      "step": 5177
    },
    {
      "epoch": 1.06,
      "grad_norm": 1.1247035264968872,
      "learning_rate": 9.396330839397356e-06,
      "loss": 0.3718,
      "step": 5178
    },
    {
      "epoch": 1.06,
      "grad_norm": 1.5859408378601074,
      "learning_rate": 9.394281029004818e-06,
      "loss": 0.3072,
      "step": 5179
    },
    {
      "epoch": 1.06,
      "grad_norm": 0.8703363537788391,
      "learning_rate": 9.39223121861228e-06,
      "loss": 0.3065,
      "step": 5180
    },
    {
      "epoch": 1.06,
      "grad_norm": 1.0257583856582642,
      "learning_rate": 9.390181408219741e-06,
      "loss": 0.4254,
      "step": 5181
    },
    {
      "epoch": 1.06,
      "grad_norm": 1.5991361141204834,
      "learning_rate": 9.388131597827201e-06,
      "loss": 0.4984,
      "step": 5182
    },
    {
      "epoch": 1.06,
      "grad_norm": 1.4746567010879517,
      "learning_rate": 9.386081787434663e-06,
      "loss": 0.4428,
      "step": 5183
    },
    {
      "epoch": 1.06,
      "grad_norm": 1.407999038696289,
      "learning_rate": 9.384031977042123e-06,
      "loss": 0.4228,
      "step": 5184
    },
    {
      "epoch": 1.06,
      "grad_norm": 0.8031652569770813,
      "learning_rate": 9.381982166649585e-06,
      "loss": 0.3527,
      "step": 5185
    },
    {
      "epoch": 1.06,
      "grad_norm": 1.3023818731307983,
      "learning_rate": 9.379932356257047e-06,
      "loss": 0.4932,
      "step": 5186
    },
    {
      "epoch": 1.06,
      "grad_norm": 1.1449474096298218,
      "learning_rate": 9.377882545864509e-06,
      "loss": 0.2501,
      "step": 5187
    },
    {
      "epoch": 1.06,
      "grad_norm": 1.7732115983963013,
      "learning_rate": 9.37583273547197e-06,
      "loss": 0.4027,
      "step": 5188
    },
    {
      "epoch": 1.06,
      "grad_norm": 1.0068825483322144,
      "learning_rate": 9.373782925079431e-06,
      "loss": 0.3962,
      "step": 5189
    },
    {
      "epoch": 1.06,
      "grad_norm": 0.9726455807685852,
      "learning_rate": 9.371733114686891e-06,
      "loss": 0.4018,
      "step": 5190
    },
    {
      "epoch": 1.06,
      "grad_norm": 1.1237221956253052,
      "learning_rate": 9.369683304294353e-06,
      "loss": 0.4309,
      "step": 5191
    },
    {
      "epoch": 1.06,
      "grad_norm": 1.1747812032699585,
      "learning_rate": 9.367633493901815e-06,
      "loss": 0.3312,
      "step": 5192
    },
    {
      "epoch": 1.06,
      "grad_norm": 1.4048751592636108,
      "learning_rate": 9.365583683509277e-06,
      "loss": 0.2604,
      "step": 5193
    },
    {
      "epoch": 1.06,
      "grad_norm": 0.99985271692276,
      "learning_rate": 9.363533873116739e-06,
      "loss": 0.3586,
      "step": 5194
    },
    {
      "epoch": 1.06,
      "grad_norm": 1.3880088329315186,
      "learning_rate": 9.361484062724199e-06,
      "loss": 0.551,
      "step": 5195
    },
    {
      "epoch": 1.06,
      "grad_norm": 0.9556317925453186,
      "learning_rate": 9.35943425233166e-06,
      "loss": 0.314,
      "step": 5196
    },
    {
      "epoch": 1.06,
      "grad_norm": 1.9344723224639893,
      "learning_rate": 9.357384441939121e-06,
      "loss": 0.3892,
      "step": 5197
    },
    {
      "epoch": 1.06,
      "grad_norm": 0.9338480234146118,
      "learning_rate": 9.355334631546583e-06,
      "loss": 0.3739,
      "step": 5198
    },
    {
      "epoch": 1.07,
      "grad_norm": 1.2709457874298096,
      "learning_rate": 9.353284821154045e-06,
      "loss": 0.325,
      "step": 5199
    },
    {
      "epoch": 1.07,
      "grad_norm": 1.2994087934494019,
      "learning_rate": 9.351235010761506e-06,
      "loss": 0.3672,
      "step": 5200
    },
    {
      "epoch": 1.07,
      "grad_norm": 1.2093541622161865,
      "learning_rate": 9.349185200368967e-06,
      "loss": 0.3927,
      "step": 5201
    },
    {
      "epoch": 1.07,
      "grad_norm": 1.207167625427246,
      "learning_rate": 9.347135389976428e-06,
      "loss": 0.2799,
      "step": 5202
    },
    {
      "epoch": 1.07,
      "grad_norm": 1.223215937614441,
      "learning_rate": 9.345085579583889e-06,
      "loss": 0.5175,
      "step": 5203
    },
    {
      "epoch": 1.07,
      "grad_norm": 0.991693377494812,
      "learning_rate": 9.34303576919135e-06,
      "loss": 0.4333,
      "step": 5204
    },
    {
      "epoch": 1.07,
      "grad_norm": 1.3787873983383179,
      "learning_rate": 9.340985958798812e-06,
      "loss": 0.384,
      "step": 5205
    },
    {
      "epoch": 1.07,
      "grad_norm": 0.7654988169670105,
      "learning_rate": 9.338936148406274e-06,
      "loss": 0.4193,
      "step": 5206
    },
    {
      "epoch": 1.07,
      "grad_norm": 1.5578820705413818,
      "learning_rate": 9.336886338013734e-06,
      "loss": 0.4021,
      "step": 5207
    },
    {
      "epoch": 1.07,
      "grad_norm": 1.7043601274490356,
      "learning_rate": 9.334836527621196e-06,
      "loss": 0.4218,
      "step": 5208
    },
    {
      "epoch": 1.07,
      "grad_norm": 1.36136794090271,
      "learning_rate": 9.332786717228656e-06,
      "loss": 0.3536,
      "step": 5209
    },
    {
      "epoch": 1.07,
      "grad_norm": 1.3620023727416992,
      "learning_rate": 9.330736906836118e-06,
      "loss": 0.507,
      "step": 5210
    },
    {
      "epoch": 1.07,
      "grad_norm": 3.381113052368164,
      "learning_rate": 9.32868709644358e-06,
      "loss": 0.3473,
      "step": 5211
    },
    {
      "epoch": 1.07,
      "grad_norm": 2.3139142990112305,
      "learning_rate": 9.326637286051042e-06,
      "loss": 0.2819,
      "step": 5212
    },
    {
      "epoch": 1.07,
      "grad_norm": 1.2593189477920532,
      "learning_rate": 9.324587475658502e-06,
      "loss": 0.4444,
      "step": 5213
    },
    {
      "epoch": 1.07,
      "grad_norm": 3.241725206375122,
      "learning_rate": 9.322537665265964e-06,
      "loss": 0.3532,
      "step": 5214
    },
    {
      "epoch": 1.07,
      "grad_norm": 2.713658094406128,
      "learning_rate": 9.320487854873424e-06,
      "loss": 0.2702,
      "step": 5215
    },
    {
      "epoch": 1.07,
      "grad_norm": 1.848044991493225,
      "learning_rate": 9.318438044480886e-06,
      "loss": 0.2965,
      "step": 5216
    },
    {
      "epoch": 1.07,
      "grad_norm": 1.0146335363388062,
      "learning_rate": 9.316388234088348e-06,
      "loss": 0.401,
      "step": 5217
    },
    {
      "epoch": 1.07,
      "grad_norm": 2.1416409015655518,
      "learning_rate": 9.31433842369581e-06,
      "loss": 0.3373,
      "step": 5218
    },
    {
      "epoch": 1.07,
      "grad_norm": 1.856888771057129,
      "learning_rate": 9.31228861330327e-06,
      "loss": 0.4087,
      "step": 5219
    },
    {
      "epoch": 1.07,
      "grad_norm": 0.7747472524642944,
      "learning_rate": 9.310238802910732e-06,
      "loss": 0.2732,
      "step": 5220
    },
    {
      "epoch": 1.07,
      "grad_norm": 1.6003634929656982,
      "learning_rate": 9.308188992518192e-06,
      "loss": 0.4817,
      "step": 5221
    },
    {
      "epoch": 1.07,
      "grad_norm": 1.465995192527771,
      "learning_rate": 9.306139182125654e-06,
      "loss": 0.2928,
      "step": 5222
    },
    {
      "epoch": 1.07,
      "grad_norm": 0.9160084128379822,
      "learning_rate": 9.304089371733116e-06,
      "loss": 0.3253,
      "step": 5223
    },
    {
      "epoch": 1.07,
      "grad_norm": 0.8986130356788635,
      "learning_rate": 9.302039561340577e-06,
      "loss": 0.267,
      "step": 5224
    },
    {
      "epoch": 1.07,
      "grad_norm": 0.7516369819641113,
      "learning_rate": 9.29998975094804e-06,
      "loss": 0.325,
      "step": 5225
    },
    {
      "epoch": 1.07,
      "grad_norm": 1.2283234596252441,
      "learning_rate": 9.2979399405555e-06,
      "loss": 0.3871,
      "step": 5226
    },
    {
      "epoch": 1.07,
      "grad_norm": 2.3177151679992676,
      "learning_rate": 9.295890130162961e-06,
      "loss": 0.4753,
      "step": 5227
    },
    {
      "epoch": 1.07,
      "grad_norm": 1.2458044290542603,
      "learning_rate": 9.293840319770421e-06,
      "loss": 0.2742,
      "step": 5228
    },
    {
      "epoch": 1.07,
      "grad_norm": 1.0682278871536255,
      "learning_rate": 9.291790509377883e-06,
      "loss": 0.5232,
      "step": 5229
    },
    {
      "epoch": 1.07,
      "grad_norm": 1.780558705329895,
      "learning_rate": 9.289740698985345e-06,
      "loss": 0.4267,
      "step": 5230
    },
    {
      "epoch": 1.07,
      "grad_norm": 1.7195302248001099,
      "learning_rate": 9.287690888592807e-06,
      "loss": 0.3531,
      "step": 5231
    },
    {
      "epoch": 1.07,
      "grad_norm": 1.4419381618499756,
      "learning_rate": 9.285641078200267e-06,
      "loss": 0.4333,
      "step": 5232
    },
    {
      "epoch": 1.07,
      "grad_norm": 2.230966806411743,
      "learning_rate": 9.283591267807729e-06,
      "loss": 0.2716,
      "step": 5233
    },
    {
      "epoch": 1.07,
      "grad_norm": 0.8323211073875427,
      "learning_rate": 9.28154145741519e-06,
      "loss": 0.2972,
      "step": 5234
    },
    {
      "epoch": 1.07,
      "grad_norm": 0.8307211995124817,
      "learning_rate": 9.279491647022651e-06,
      "loss": 0.3406,
      "step": 5235
    },
    {
      "epoch": 1.07,
      "grad_norm": 1.4311333894729614,
      "learning_rate": 9.277441836630113e-06,
      "loss": 0.3907,
      "step": 5236
    },
    {
      "epoch": 1.07,
      "grad_norm": 1.8097070455551147,
      "learning_rate": 9.275392026237575e-06,
      "loss": 0.3778,
      "step": 5237
    },
    {
      "epoch": 1.07,
      "grad_norm": 1.794068455696106,
      "learning_rate": 9.273342215845035e-06,
      "loss": 0.5233,
      "step": 5238
    },
    {
      "epoch": 1.07,
      "grad_norm": 1.363971471786499,
      "learning_rate": 9.271292405452497e-06,
      "loss": 0.4748,
      "step": 5239
    },
    {
      "epoch": 1.07,
      "grad_norm": 1.3961012363433838,
      "learning_rate": 9.269242595059957e-06,
      "loss": 0.3233,
      "step": 5240
    },
    {
      "epoch": 1.07,
      "grad_norm": 1.083160400390625,
      "learning_rate": 9.267192784667419e-06,
      "loss": 0.3974,
      "step": 5241
    },
    {
      "epoch": 1.07,
      "grad_norm": 1.2349474430084229,
      "learning_rate": 9.26514297427488e-06,
      "loss": 0.4865,
      "step": 5242
    },
    {
      "epoch": 1.07,
      "grad_norm": 1.2065781354904175,
      "learning_rate": 9.263093163882343e-06,
      "loss": 0.2566,
      "step": 5243
    },
    {
      "epoch": 1.07,
      "grad_norm": 1.7258001565933228,
      "learning_rate": 9.261043353489803e-06,
      "loss": 0.3226,
      "step": 5244
    },
    {
      "epoch": 1.07,
      "grad_norm": 0.8253034949302673,
      "learning_rate": 9.258993543097265e-06,
      "loss": 0.387,
      "step": 5245
    },
    {
      "epoch": 1.07,
      "grad_norm": 2.0191168785095215,
      "learning_rate": 9.256943732704725e-06,
      "loss": 0.4451,
      "step": 5246
    },
    {
      "epoch": 1.07,
      "grad_norm": 1.370650053024292,
      "learning_rate": 9.254893922312187e-06,
      "loss": 0.3332,
      "step": 5247
    },
    {
      "epoch": 1.08,
      "grad_norm": 1.0358332395553589,
      "learning_rate": 9.252844111919648e-06,
      "loss": 0.2864,
      "step": 5248
    },
    {
      "epoch": 1.08,
      "grad_norm": 1.3211590051651,
      "learning_rate": 9.25079430152711e-06,
      "loss": 0.294,
      "step": 5249
    },
    {
      "epoch": 1.08,
      "grad_norm": 1.5846385955810547,
      "learning_rate": 9.24874449113457e-06,
      "loss": 0.3758,
      "step": 5250
    },
    {
      "epoch": 1.08,
      "grad_norm": 1.6308963298797607,
      "learning_rate": 9.246694680742032e-06,
      "loss": 0.3595,
      "step": 5251
    },
    {
      "epoch": 1.08,
      "grad_norm": 2.275830030441284,
      "learning_rate": 9.244644870349494e-06,
      "loss": 0.3295,
      "step": 5252
    },
    {
      "epoch": 1.08,
      "grad_norm": 2.3446905612945557,
      "learning_rate": 9.242595059956954e-06,
      "loss": 0.5021,
      "step": 5253
    },
    {
      "epoch": 1.08,
      "grad_norm": 1.4215279817581177,
      "learning_rate": 9.240545249564416e-06,
      "loss": 0.338,
      "step": 5254
    },
    {
      "epoch": 1.08,
      "grad_norm": 0.843303918838501,
      "learning_rate": 9.238495439171878e-06,
      "loss": 0.3371,
      "step": 5255
    },
    {
      "epoch": 1.08,
      "grad_norm": 2.6280879974365234,
      "learning_rate": 9.23644562877934e-06,
      "loss": 0.2554,
      "step": 5256
    },
    {
      "epoch": 1.08,
      "grad_norm": 1.1490575075149536,
      "learning_rate": 9.2343958183868e-06,
      "loss": 0.4743,
      "step": 5257
    },
    {
      "epoch": 1.08,
      "grad_norm": 1.1147589683532715,
      "learning_rate": 9.232346007994262e-06,
      "loss": 0.3652,
      "step": 5258
    },
    {
      "epoch": 1.08,
      "grad_norm": 1.348110556602478,
      "learning_rate": 9.230296197601722e-06,
      "loss": 0.4068,
      "step": 5259
    },
    {
      "epoch": 1.08,
      "grad_norm": 1.409690499305725,
      "learning_rate": 9.228246387209184e-06,
      "loss": 0.3925,
      "step": 5260
    },
    {
      "epoch": 1.08,
      "grad_norm": 0.9410330057144165,
      "learning_rate": 9.226196576816646e-06,
      "loss": 0.3266,
      "step": 5261
    },
    {
      "epoch": 1.08,
      "grad_norm": 1.299345850944519,
      "learning_rate": 9.224146766424108e-06,
      "loss": 0.3136,
      "step": 5262
    },
    {
      "epoch": 1.08,
      "grad_norm": 1.5101107358932495,
      "learning_rate": 9.222096956031568e-06,
      "loss": 0.3577,
      "step": 5263
    },
    {
      "epoch": 1.08,
      "grad_norm": 1.093544363975525,
      "learning_rate": 9.22004714563903e-06,
      "loss": 0.2379,
      "step": 5264
    },
    {
      "epoch": 1.08,
      "grad_norm": 1.2575016021728516,
      "learning_rate": 9.21799733524649e-06,
      "loss": 0.3829,
      "step": 5265
    },
    {
      "epoch": 1.08,
      "grad_norm": 1.1547411680221558,
      "learning_rate": 9.215947524853952e-06,
      "loss": 0.3825,
      "step": 5266
    },
    {
      "epoch": 1.08,
      "grad_norm": 2.6263561248779297,
      "learning_rate": 9.213897714461414e-06,
      "loss": 0.2636,
      "step": 5267
    },
    {
      "epoch": 1.08,
      "grad_norm": 3.2967002391815186,
      "learning_rate": 9.211847904068875e-06,
      "loss": 0.3608,
      "step": 5268
    },
    {
      "epoch": 1.08,
      "grad_norm": 2.057732343673706,
      "learning_rate": 9.209798093676336e-06,
      "loss": 0.3283,
      "step": 5269
    },
    {
      "epoch": 1.08,
      "grad_norm": 1.106483817100525,
      "learning_rate": 9.207748283283797e-06,
      "loss": 0.4192,
      "step": 5270
    },
    {
      "epoch": 1.08,
      "grad_norm": 2.1754603385925293,
      "learning_rate": 9.205698472891258e-06,
      "loss": 0.3107,
      "step": 5271
    },
    {
      "epoch": 1.08,
      "grad_norm": 1.8968864679336548,
      "learning_rate": 9.20364866249872e-06,
      "loss": 0.3459,
      "step": 5272
    },
    {
      "epoch": 1.08,
      "grad_norm": 1.4674009084701538,
      "learning_rate": 9.201598852106181e-06,
      "loss": 0.4125,
      "step": 5273
    },
    {
      "epoch": 1.08,
      "grad_norm": 1.2847399711608887,
      "learning_rate": 9.199549041713643e-06,
      "loss": 0.4657,
      "step": 5274
    },
    {
      "epoch": 1.08,
      "grad_norm": 1.155954122543335,
      "learning_rate": 9.197499231321103e-06,
      "loss": 0.5307,
      "step": 5275
    },
    {
      "epoch": 1.08,
      "grad_norm": 1.4229722023010254,
      "learning_rate": 9.195449420928565e-06,
      "loss": 0.3282,
      "step": 5276
    },
    {
      "epoch": 1.08,
      "grad_norm": 1.4753727912902832,
      "learning_rate": 9.193399610536025e-06,
      "loss": 0.2197,
      "step": 5277
    },
    {
      "epoch": 1.08,
      "grad_norm": 1.705296277999878,
      "learning_rate": 9.191349800143487e-06,
      "loss": 0.2759,
      "step": 5278
    },
    {
      "epoch": 1.08,
      "grad_norm": 0.8198864459991455,
      "learning_rate": 9.189299989750949e-06,
      "loss": 0.4105,
      "step": 5279
    },
    {
      "epoch": 1.08,
      "grad_norm": 1.492366909980774,
      "learning_rate": 9.187250179358411e-06,
      "loss": 0.2327,
      "step": 5280
    },
    {
      "epoch": 1.08,
      "grad_norm": 1.1206190586090088,
      "learning_rate": 9.185200368965871e-06,
      "loss": 0.373,
      "step": 5281
    },
    {
      "epoch": 1.08,
      "grad_norm": 1.919454574584961,
      "learning_rate": 9.183150558573333e-06,
      "loss": 0.2408,
      "step": 5282
    },
    {
      "epoch": 1.08,
      "grad_norm": 1.630811095237732,
      "learning_rate": 9.181100748180795e-06,
      "loss": 0.3454,
      "step": 5283
    },
    {
      "epoch": 1.08,
      "grad_norm": 1.6251044273376465,
      "learning_rate": 9.179050937788255e-06,
      "loss": 0.2828,
      "step": 5284
    },
    {
      "epoch": 1.08,
      "grad_norm": 1.009106993675232,
      "learning_rate": 9.177001127395717e-06,
      "loss": 0.2911,
      "step": 5285
    },
    {
      "epoch": 1.08,
      "grad_norm": 0.9856387972831726,
      "learning_rate": 9.174951317003179e-06,
      "loss": 0.399,
      "step": 5286
    },
    {
      "epoch": 1.08,
      "grad_norm": 1.5742894411087036,
      "learning_rate": 9.17290150661064e-06,
      "loss": 0.3442,
      "step": 5287
    },
    {
      "epoch": 1.08,
      "grad_norm": 0.9352991580963135,
      "learning_rate": 9.1708516962181e-06,
      "loss": 0.3818,
      "step": 5288
    },
    {
      "epoch": 1.08,
      "grad_norm": 2.3132734298706055,
      "learning_rate": 9.168801885825563e-06,
      "loss": 0.3213,
      "step": 5289
    },
    {
      "epoch": 1.08,
      "grad_norm": 1.3218168020248413,
      "learning_rate": 9.166752075433023e-06,
      "loss": 0.3948,
      "step": 5290
    },
    {
      "epoch": 1.08,
      "grad_norm": 1.9859925508499146,
      "learning_rate": 9.164702265040485e-06,
      "loss": 0.4419,
      "step": 5291
    },
    {
      "epoch": 1.08,
      "grad_norm": 1.3831621408462524,
      "learning_rate": 9.162652454647946e-06,
      "loss": 0.3824,
      "step": 5292
    },
    {
      "epoch": 1.08,
      "grad_norm": 0.9792860150337219,
      "learning_rate": 9.160602644255408e-06,
      "loss": 0.3093,
      "step": 5293
    },
    {
      "epoch": 1.08,
      "grad_norm": 1.38754141330719,
      "learning_rate": 9.158552833862868e-06,
      "loss": 0.4226,
      "step": 5294
    },
    {
      "epoch": 1.08,
      "grad_norm": 1.3839459419250488,
      "learning_rate": 9.15650302347033e-06,
      "loss": 0.3844,
      "step": 5295
    },
    {
      "epoch": 1.09,
      "grad_norm": 0.988681435585022,
      "learning_rate": 9.15445321307779e-06,
      "loss": 0.3625,
      "step": 5296
    },
    {
      "epoch": 1.09,
      "grad_norm": 1.2843389511108398,
      "learning_rate": 9.152403402685252e-06,
      "loss": 0.5888,
      "step": 5297
    },
    {
      "epoch": 1.09,
      "grad_norm": 1.8899379968643188,
      "learning_rate": 9.150353592292714e-06,
      "loss": 0.5332,
      "step": 5298
    },
    {
      "epoch": 1.09,
      "grad_norm": 1.5273927450180054,
      "learning_rate": 9.148303781900176e-06,
      "loss": 0.3681,
      "step": 5299
    },
    {
      "epoch": 1.09,
      "grad_norm": 1.85776686668396,
      "learning_rate": 9.146253971507636e-06,
      "loss": 0.4199,
      "step": 5300
    },
    {
      "epoch": 1.09,
      "grad_norm": 0.8555405139923096,
      "learning_rate": 9.144204161115098e-06,
      "loss": 0.3929,
      "step": 5301
    },
    {
      "epoch": 1.09,
      "grad_norm": 2.120060920715332,
      "learning_rate": 9.142154350722558e-06,
      "loss": 0.3707,
      "step": 5302
    },
    {
      "epoch": 1.09,
      "grad_norm": 1.17274808883667,
      "learning_rate": 9.14010454033002e-06,
      "loss": 0.3191,
      "step": 5303
    },
    {
      "epoch": 1.09,
      "grad_norm": 1.7129729986190796,
      "learning_rate": 9.138054729937482e-06,
      "loss": 0.4413,
      "step": 5304
    },
    {
      "epoch": 1.09,
      "grad_norm": 0.8851607441902161,
      "learning_rate": 9.136004919544944e-06,
      "loss": 0.2756,
      "step": 5305
    },
    {
      "epoch": 1.09,
      "grad_norm": 1.0842047929763794,
      "learning_rate": 9.133955109152404e-06,
      "loss": 0.3739,
      "step": 5306
    },
    {
      "epoch": 1.09,
      "grad_norm": 1.6783097982406616,
      "learning_rate": 9.131905298759866e-06,
      "loss": 0.4843,
      "step": 5307
    },
    {
      "epoch": 1.09,
      "grad_norm": 1.9810261726379395,
      "learning_rate": 9.129855488367326e-06,
      "loss": 0.3101,
      "step": 5308
    },
    {
      "epoch": 1.09,
      "grad_norm": 0.9664841294288635,
      "learning_rate": 9.127805677974788e-06,
      "loss": 0.3083,
      "step": 5309
    },
    {
      "epoch": 1.09,
      "grad_norm": 1.3449815511703491,
      "learning_rate": 9.12575586758225e-06,
      "loss": 0.3978,
      "step": 5310
    },
    {
      "epoch": 1.09,
      "grad_norm": 1.015048861503601,
      "learning_rate": 9.123706057189711e-06,
      "loss": 0.4332,
      "step": 5311
    },
    {
      "epoch": 1.09,
      "grad_norm": 0.987155556678772,
      "learning_rate": 9.121656246797173e-06,
      "loss": 0.2937,
      "step": 5312
    },
    {
      "epoch": 1.09,
      "grad_norm": 1.2003337144851685,
      "learning_rate": 9.119606436404634e-06,
      "loss": 0.4605,
      "step": 5313
    },
    {
      "epoch": 1.09,
      "grad_norm": 1.0634410381317139,
      "learning_rate": 9.117556626012095e-06,
      "loss": 0.3737,
      "step": 5314
    },
    {
      "epoch": 1.09,
      "grad_norm": 1.0109056234359741,
      "learning_rate": 9.115506815619556e-06,
      "loss": 0.2322,
      "step": 5315
    },
    {
      "epoch": 1.09,
      "grad_norm": 0.9751250743865967,
      "learning_rate": 9.113457005227017e-06,
      "loss": 0.4757,
      "step": 5316
    },
    {
      "epoch": 1.09,
      "grad_norm": 0.9213088750839233,
      "learning_rate": 9.11140719483448e-06,
      "loss": 0.3897,
      "step": 5317
    },
    {
      "epoch": 1.09,
      "grad_norm": 2.21465802192688,
      "learning_rate": 9.109357384441941e-06,
      "loss": 0.4934,
      "step": 5318
    },
    {
      "epoch": 1.09,
      "grad_norm": 1.6604108810424805,
      "learning_rate": 9.107307574049401e-06,
      "loss": 0.4375,
      "step": 5319
    },
    {
      "epoch": 1.09,
      "grad_norm": 0.9322565793991089,
      "learning_rate": 9.105257763656863e-06,
      "loss": 0.3425,
      "step": 5320
    },
    {
      "epoch": 1.09,
      "grad_norm": 1.1693140268325806,
      "learning_rate": 9.103207953264323e-06,
      "loss": 0.4102,
      "step": 5321
    },
    {
      "epoch": 1.09,
      "grad_norm": 1.274314522743225,
      "learning_rate": 9.101158142871785e-06,
      "loss": 0.5152,
      "step": 5322
    },
    {
      "epoch": 1.09,
      "grad_norm": 1.6974236965179443,
      "learning_rate": 9.099108332479247e-06,
      "loss": 0.4189,
      "step": 5323
    },
    {
      "epoch": 1.09,
      "grad_norm": 1.1418200731277466,
      "learning_rate": 9.097058522086709e-06,
      "loss": 0.5583,
      "step": 5324
    },
    {
      "epoch": 1.09,
      "grad_norm": 1.2541800737380981,
      "learning_rate": 9.095008711694169e-06,
      "loss": 0.2886,
      "step": 5325
    },
    {
      "epoch": 1.09,
      "grad_norm": 1.2456583976745605,
      "learning_rate": 9.092958901301631e-06,
      "loss": 0.3814,
      "step": 5326
    },
    {
      "epoch": 1.09,
      "grad_norm": 1.1385400295257568,
      "learning_rate": 9.090909090909091e-06,
      "loss": 0.5508,
      "step": 5327
    },
    {
      "epoch": 1.09,
      "grad_norm": 3.1431212425231934,
      "learning_rate": 9.088859280516553e-06,
      "loss": 0.4492,
      "step": 5328
    },
    {
      "epoch": 1.09,
      "grad_norm": 1.840837001800537,
      "learning_rate": 9.086809470124015e-06,
      "loss": 0.4204,
      "step": 5329
    },
    {
      "epoch": 1.09,
      "grad_norm": 1.7942726612091064,
      "learning_rate": 9.084759659731477e-06,
      "loss": 0.3711,
      "step": 5330
    },
    {
      "epoch": 1.09,
      "grad_norm": 2.226733922958374,
      "learning_rate": 9.082709849338937e-06,
      "loss": 0.4815,
      "step": 5331
    },
    {
      "epoch": 1.09,
      "grad_norm": 2.3888609409332275,
      "learning_rate": 9.080660038946399e-06,
      "loss": 0.4252,
      "step": 5332
    },
    {
      "epoch": 1.09,
      "grad_norm": 1.1904017925262451,
      "learning_rate": 9.078610228553859e-06,
      "loss": 0.5342,
      "step": 5333
    },
    {
      "epoch": 1.09,
      "grad_norm": 1.4090499877929688,
      "learning_rate": 9.07656041816132e-06,
      "loss": 0.3423,
      "step": 5334
    },
    {
      "epoch": 1.09,
      "grad_norm": 1.5660871267318726,
      "learning_rate": 9.074510607768782e-06,
      "loss": 0.3196,
      "step": 5335
    },
    {
      "epoch": 1.09,
      "grad_norm": 2.055534839630127,
      "learning_rate": 9.072460797376244e-06,
      "loss": 0.3319,
      "step": 5336
    },
    {
      "epoch": 1.09,
      "grad_norm": 1.0487254858016968,
      "learning_rate": 9.070410986983705e-06,
      "loss": 0.3702,
      "step": 5337
    },
    {
      "epoch": 1.09,
      "grad_norm": 1.090025544166565,
      "learning_rate": 9.068361176591166e-06,
      "loss": 0.3781,
      "step": 5338
    },
    {
      "epoch": 1.09,
      "grad_norm": 1.650610089302063,
      "learning_rate": 9.066311366198627e-06,
      "loss": 0.4494,
      "step": 5339
    },
    {
      "epoch": 1.09,
      "grad_norm": 0.9116500020027161,
      "learning_rate": 9.064261555806088e-06,
      "loss": 0.3141,
      "step": 5340
    },
    {
      "epoch": 1.09,
      "grad_norm": 0.9971908330917358,
      "learning_rate": 9.06221174541355e-06,
      "loss": 0.3621,
      "step": 5341
    },
    {
      "epoch": 1.09,
      "grad_norm": 1.699680209159851,
      "learning_rate": 9.060161935021012e-06,
      "loss": 0.3049,
      "step": 5342
    },
    {
      "epoch": 1.09,
      "grad_norm": 0.6949090361595154,
      "learning_rate": 9.058112124628472e-06,
      "loss": 0.3903,
      "step": 5343
    },
    {
      "epoch": 1.09,
      "grad_norm": 1.23211669921875,
      "learning_rate": 9.056062314235934e-06,
      "loss": 0.4884,
      "step": 5344
    },
    {
      "epoch": 1.1,
      "grad_norm": 0.8988739848136902,
      "learning_rate": 9.054012503843396e-06,
      "loss": 0.2328,
      "step": 5345
    },
    {
      "epoch": 1.1,
      "grad_norm": 1.1719964742660522,
      "learning_rate": 9.051962693450856e-06,
      "loss": 0.473,
      "step": 5346
    },
    {
      "epoch": 1.1,
      "grad_norm": 0.8736479878425598,
      "learning_rate": 9.049912883058318e-06,
      "loss": 0.2814,
      "step": 5347
    },
    {
      "epoch": 1.1,
      "grad_norm": 1.6076087951660156,
      "learning_rate": 9.04786307266578e-06,
      "loss": 0.3829,
      "step": 5348
    },
    {
      "epoch": 1.1,
      "grad_norm": 1.1041887998580933,
      "learning_rate": 9.04581326227324e-06,
      "loss": 0.3145,
      "step": 5349
    },
    {
      "epoch": 1.1,
      "grad_norm": 1.0428025722503662,
      "learning_rate": 9.043763451880702e-06,
      "loss": 0.3864,
      "step": 5350
    },
    {
      "epoch": 1.1,
      "grad_norm": 1.3437408208847046,
      "learning_rate": 9.041713641488164e-06,
      "loss": 0.324,
      "step": 5351
    },
    {
      "epoch": 1.1,
      "grad_norm": 1.202266812324524,
      "learning_rate": 9.039663831095624e-06,
      "loss": 0.3788,
      "step": 5352
    },
    {
      "epoch": 1.1,
      "grad_norm": 2.0544955730438232,
      "learning_rate": 9.037614020703086e-06,
      "loss": 0.2326,
      "step": 5353
    },
    {
      "epoch": 1.1,
      "grad_norm": 2.0557475090026855,
      "learning_rate": 9.035564210310546e-06,
      "loss": 0.3339,
      "step": 5354
    },
    {
      "epoch": 1.1,
      "grad_norm": 1.0006836652755737,
      "learning_rate": 9.033514399918008e-06,
      "loss": 0.3572,
      "step": 5355
    },
    {
      "epoch": 1.1,
      "grad_norm": 1.771369218826294,
      "learning_rate": 9.03146458952547e-06,
      "loss": 0.3812,
      "step": 5356
    },
    {
      "epoch": 1.1,
      "grad_norm": 2.0148582458496094,
      "learning_rate": 9.029414779132931e-06,
      "loss": 0.4249,
      "step": 5357
    },
    {
      "epoch": 1.1,
      "grad_norm": 0.8794457912445068,
      "learning_rate": 9.027364968740392e-06,
      "loss": 0.222,
      "step": 5358
    },
    {
      "epoch": 1.1,
      "grad_norm": 1.1676743030548096,
      "learning_rate": 9.025315158347854e-06,
      "loss": 0.3888,
      "step": 5359
    },
    {
      "epoch": 1.1,
      "grad_norm": 1.3731049299240112,
      "learning_rate": 9.023265347955314e-06,
      "loss": 0.3728,
      "step": 5360
    },
    {
      "epoch": 1.1,
      "grad_norm": 2.002305507659912,
      "learning_rate": 9.021215537562776e-06,
      "loss": 0.2893,
      "step": 5361
    },
    {
      "epoch": 1.1,
      "grad_norm": 1.490627408027649,
      "learning_rate": 9.019165727170237e-06,
      "loss": 0.4419,
      "step": 5362
    },
    {
      "epoch": 1.1,
      "grad_norm": 1.0935736894607544,
      "learning_rate": 9.0171159167777e-06,
      "loss": 0.2279,
      "step": 5363
    },
    {
      "epoch": 1.1,
      "grad_norm": 2.717578172683716,
      "learning_rate": 9.01506610638516e-06,
      "loss": 0.5158,
      "step": 5364
    },
    {
      "epoch": 1.1,
      "grad_norm": 2.822033643722534,
      "learning_rate": 9.013016295992621e-06,
      "loss": 0.4098,
      "step": 5365
    },
    {
      "epoch": 1.1,
      "grad_norm": 2.107738733291626,
      "learning_rate": 9.010966485600081e-06,
      "loss": 0.4057,
      "step": 5366
    },
    {
      "epoch": 1.1,
      "grad_norm": 1.4672181606292725,
      "learning_rate": 9.008916675207543e-06,
      "loss": 0.4256,
      "step": 5367
    },
    {
      "epoch": 1.1,
      "grad_norm": 3.7418947219848633,
      "learning_rate": 9.006866864815005e-06,
      "loss": 0.3107,
      "step": 5368
    },
    {
      "epoch": 1.1,
      "grad_norm": 2.995803117752075,
      "learning_rate": 9.004817054422467e-06,
      "loss": 0.3781,
      "step": 5369
    },
    {
      "epoch": 1.1,
      "grad_norm": 1.837653398513794,
      "learning_rate": 9.002767244029929e-06,
      "loss": 0.2892,
      "step": 5370
    },
    {
      "epoch": 1.1,
      "grad_norm": 1.897159457206726,
      "learning_rate": 9.000717433637389e-06,
      "loss": 0.5046,
      "step": 5371
    },
    {
      "epoch": 1.1,
      "grad_norm": 1.8882861137390137,
      "learning_rate": 8.998667623244851e-06,
      "loss": 0.3813,
      "step": 5372
    },
    {
      "epoch": 1.1,
      "grad_norm": 2.219101667404175,
      "learning_rate": 8.996617812852311e-06,
      "loss": 0.2679,
      "step": 5373
    },
    {
      "epoch": 1.1,
      "grad_norm": 1.696659803390503,
      "learning_rate": 8.994568002459773e-06,
      "loss": 0.4305,
      "step": 5374
    },
    {
      "epoch": 1.1,
      "grad_norm": 1.9952008724212646,
      "learning_rate": 8.992518192067235e-06,
      "loss": 0.2158,
      "step": 5375
    },
    {
      "epoch": 1.1,
      "grad_norm": 2.336606502532959,
      "learning_rate": 8.990468381674697e-06,
      "loss": 0.3385,
      "step": 5376
    },
    {
      "epoch": 1.1,
      "grad_norm": 2.4328668117523193,
      "learning_rate": 8.988418571282157e-06,
      "loss": 0.4016,
      "step": 5377
    },
    {
      "epoch": 1.1,
      "grad_norm": 1.4111541509628296,
      "learning_rate": 8.986368760889619e-06,
      "loss": 0.3138,
      "step": 5378
    },
    {
      "epoch": 1.1,
      "grad_norm": 1.39220130443573,
      "learning_rate": 8.984318950497079e-06,
      "loss": 0.2449,
      "step": 5379
    },
    {
      "epoch": 1.1,
      "grad_norm": 1.0955878496170044,
      "learning_rate": 8.98226914010454e-06,
      "loss": 0.437,
      "step": 5380
    },
    {
      "epoch": 1.1,
      "grad_norm": 2.273754119873047,
      "learning_rate": 8.980219329712002e-06,
      "loss": 0.2891,
      "step": 5381
    },
    {
      "epoch": 1.1,
      "grad_norm": 1.0289210081100464,
      "learning_rate": 8.978169519319464e-06,
      "loss": 0.2845,
      "step": 5382
    },
    {
      "epoch": 1.1,
      "grad_norm": 1.2963424921035767,
      "learning_rate": 8.976119708926925e-06,
      "loss": 0.2159,
      "step": 5383
    },
    {
      "epoch": 1.1,
      "grad_norm": 2.0612905025482178,
      "learning_rate": 8.974069898534386e-06,
      "loss": 0.4078,
      "step": 5384
    },
    {
      "epoch": 1.1,
      "grad_norm": 1.2149144411087036,
      "learning_rate": 8.972020088141847e-06,
      "loss": 0.4081,
      "step": 5385
    },
    {
      "epoch": 1.1,
      "grad_norm": 0.9749161005020142,
      "learning_rate": 8.969970277749308e-06,
      "loss": 0.2918,
      "step": 5386
    },
    {
      "epoch": 1.1,
      "grad_norm": 1.268168568611145,
      "learning_rate": 8.96792046735677e-06,
      "loss": 0.3274,
      "step": 5387
    },
    {
      "epoch": 1.1,
      "grad_norm": 1.3543925285339355,
      "learning_rate": 8.965870656964232e-06,
      "loss": 0.2183,
      "step": 5388
    },
    {
      "epoch": 1.1,
      "grad_norm": 1.0566622018814087,
      "learning_rate": 8.963820846571692e-06,
      "loss": 0.5665,
      "step": 5389
    },
    {
      "epoch": 1.1,
      "grad_norm": 0.8869978189468384,
      "learning_rate": 8.961771036179154e-06,
      "loss": 0.288,
      "step": 5390
    },
    {
      "epoch": 1.1,
      "grad_norm": 1.3648289442062378,
      "learning_rate": 8.959721225786614e-06,
      "loss": 0.3992,
      "step": 5391
    },
    {
      "epoch": 1.1,
      "grad_norm": 1.24214768409729,
      "learning_rate": 8.957671415394076e-06,
      "loss": 0.2204,
      "step": 5392
    },
    {
      "epoch": 1.1,
      "grad_norm": 1.3644201755523682,
      "learning_rate": 8.955621605001538e-06,
      "loss": 0.4052,
      "step": 5393
    },
    {
      "epoch": 1.11,
      "grad_norm": 1.251762866973877,
      "learning_rate": 8.953571794609e-06,
      "loss": 0.4693,
      "step": 5394
    },
    {
      "epoch": 1.11,
      "grad_norm": 1.0711567401885986,
      "learning_rate": 8.95152198421646e-06,
      "loss": 0.4662,
      "step": 5395
    },
    {
      "epoch": 1.11,
      "grad_norm": 1.1202951669692993,
      "learning_rate": 8.949472173823922e-06,
      "loss": 0.4166,
      "step": 5396
    },
    {
      "epoch": 1.11,
      "grad_norm": 1.3236966133117676,
      "learning_rate": 8.947422363431382e-06,
      "loss": 0.3812,
      "step": 5397
    },
    {
      "epoch": 1.11,
      "grad_norm": 1.3013778924942017,
      "learning_rate": 8.945372553038844e-06,
      "loss": 0.245,
      "step": 5398
    },
    {
      "epoch": 1.11,
      "grad_norm": 0.8990997672080994,
      "learning_rate": 8.943322742646306e-06,
      "loss": 0.2767,
      "step": 5399
    },
    {
      "epoch": 1.11,
      "grad_norm": 1.1962894201278687,
      "learning_rate": 8.941272932253768e-06,
      "loss": 0.3647,
      "step": 5400
    },
    {
      "epoch": 1.11,
      "grad_norm": 1.4285082817077637,
      "learning_rate": 8.93922312186123e-06,
      "loss": 0.5726,
      "step": 5401
    },
    {
      "epoch": 1.11,
      "grad_norm": 1.3000584840774536,
      "learning_rate": 8.93717331146869e-06,
      "loss": 0.3676,
      "step": 5402
    },
    {
      "epoch": 1.11,
      "grad_norm": 0.916266143321991,
      "learning_rate": 8.935123501076151e-06,
      "loss": 0.2793,
      "step": 5403
    },
    {
      "epoch": 1.11,
      "grad_norm": 1.7344071865081787,
      "learning_rate": 8.933073690683612e-06,
      "loss": 0.2626,
      "step": 5404
    },
    {
      "epoch": 1.11,
      "grad_norm": 2.585155487060547,
      "learning_rate": 8.931023880291073e-06,
      "loss": 0.3424,
      "step": 5405
    },
    {
      "epoch": 1.11,
      "grad_norm": 1.2466602325439453,
      "learning_rate": 8.928974069898535e-06,
      "loss": 0.3676,
      "step": 5406
    },
    {
      "epoch": 1.11,
      "grad_norm": 1.366823673248291,
      "learning_rate": 8.926924259505997e-06,
      "loss": 0.4274,
      "step": 5407
    },
    {
      "epoch": 1.11,
      "grad_norm": 2.0730762481689453,
      "learning_rate": 8.924874449113457e-06,
      "loss": 0.5469,
      "step": 5408
    },
    {
      "epoch": 1.11,
      "grad_norm": 1.643125057220459,
      "learning_rate": 8.92282463872092e-06,
      "loss": 0.2177,
      "step": 5409
    },
    {
      "epoch": 1.11,
      "grad_norm": 1.1648142337799072,
      "learning_rate": 8.92077482832838e-06,
      "loss": 0.4475,
      "step": 5410
    },
    {
      "epoch": 1.11,
      "grad_norm": 1.399093747138977,
      "learning_rate": 8.918725017935841e-06,
      "loss": 0.3972,
      "step": 5411
    },
    {
      "epoch": 1.11,
      "grad_norm": 0.650490939617157,
      "learning_rate": 8.916675207543303e-06,
      "loss": 0.2431,
      "step": 5412
    },
    {
      "epoch": 1.11,
      "grad_norm": 1.7284489870071411,
      "learning_rate": 8.914625397150765e-06,
      "loss": 0.3071,
      "step": 5413
    },
    {
      "epoch": 1.11,
      "grad_norm": 1.1613868474960327,
      "learning_rate": 8.912575586758225e-06,
      "loss": 0.3202,
      "step": 5414
    },
    {
      "epoch": 1.11,
      "grad_norm": 1.7108510732650757,
      "learning_rate": 8.910525776365687e-06,
      "loss": 0.3965,
      "step": 5415
    },
    {
      "epoch": 1.11,
      "grad_norm": 0.8711456060409546,
      "learning_rate": 8.908475965973147e-06,
      "loss": 0.3813,
      "step": 5416
    },
    {
      "epoch": 1.11,
      "grad_norm": 1.2361654043197632,
      "learning_rate": 8.906426155580609e-06,
      "loss": 0.3108,
      "step": 5417
    },
    {
      "epoch": 1.11,
      "grad_norm": 0.9721918106079102,
      "learning_rate": 8.90437634518807e-06,
      "loss": 0.2553,
      "step": 5418
    },
    {
      "epoch": 1.11,
      "grad_norm": 1.3460849523544312,
      "learning_rate": 8.902326534795533e-06,
      "loss": 0.3715,
      "step": 5419
    },
    {
      "epoch": 1.11,
      "grad_norm": 1.4488317966461182,
      "learning_rate": 8.900276724402993e-06,
      "loss": 0.5542,
      "step": 5420
    },
    {
      "epoch": 1.11,
      "grad_norm": 0.9778124690055847,
      "learning_rate": 8.898226914010455e-06,
      "loss": 0.3507,
      "step": 5421
    },
    {
      "epoch": 1.11,
      "grad_norm": 0.9878735542297363,
      "learning_rate": 8.896177103617915e-06,
      "loss": 0.2485,
      "step": 5422
    },
    {
      "epoch": 1.11,
      "grad_norm": 1.1725612878799438,
      "learning_rate": 8.894127293225377e-06,
      "loss": 0.2803,
      "step": 5423
    },
    {
      "epoch": 1.11,
      "grad_norm": 1.0833616256713867,
      "learning_rate": 8.892077482832839e-06,
      "loss": 0.3665,
      "step": 5424
    },
    {
      "epoch": 1.11,
      "grad_norm": 1.4072808027267456,
      "learning_rate": 8.8900276724403e-06,
      "loss": 0.2627,
      "step": 5425
    },
    {
      "epoch": 1.11,
      "grad_norm": 1.2946337461471558,
      "learning_rate": 8.88797786204776e-06,
      "loss": 0.5102,
      "step": 5426
    },
    {
      "epoch": 1.11,
      "grad_norm": 1.9863272905349731,
      "learning_rate": 8.885928051655222e-06,
      "loss": 0.4916,
      "step": 5427
    },
    {
      "epoch": 1.11,
      "grad_norm": 2.2300095558166504,
      "learning_rate": 8.883878241262683e-06,
      "loss": 0.3824,
      "step": 5428
    },
    {
      "epoch": 1.11,
      "grad_norm": 3.0413060188293457,
      "learning_rate": 8.881828430870144e-06,
      "loss": 0.3978,
      "step": 5429
    },
    {
      "epoch": 1.11,
      "grad_norm": 1.2904044389724731,
      "learning_rate": 8.879778620477606e-06,
      "loss": 0.3484,
      "step": 5430
    },
    {
      "epoch": 1.11,
      "grad_norm": 1.412697196006775,
      "learning_rate": 8.877728810085068e-06,
      "loss": 0.3388,
      "step": 5431
    },
    {
      "epoch": 1.11,
      "grad_norm": 1.4391438961029053,
      "learning_rate": 8.87567899969253e-06,
      "loss": 0.3378,
      "step": 5432
    },
    {
      "epoch": 1.11,
      "grad_norm": 1.3950974941253662,
      "learning_rate": 8.87362918929999e-06,
      "loss": 0.492,
      "step": 5433
    },
    {
      "epoch": 1.11,
      "grad_norm": 2.469759464263916,
      "learning_rate": 8.871579378907452e-06,
      "loss": 0.3676,
      "step": 5434
    },
    {
      "epoch": 1.11,
      "grad_norm": 1.7854084968566895,
      "learning_rate": 8.869529568514912e-06,
      "loss": 0.3959,
      "step": 5435
    },
    {
      "epoch": 1.11,
      "grad_norm": 1.8419069051742554,
      "learning_rate": 8.867479758122374e-06,
      "loss": 0.5041,
      "step": 5436
    },
    {
      "epoch": 1.11,
      "grad_norm": 2.9932003021240234,
      "learning_rate": 8.865429947729836e-06,
      "loss": 0.3512,
      "step": 5437
    },
    {
      "epoch": 1.11,
      "grad_norm": 1.0649831295013428,
      "learning_rate": 8.863380137337298e-06,
      "loss": 0.4806,
      "step": 5438
    },
    {
      "epoch": 1.11,
      "grad_norm": 1.9157848358154297,
      "learning_rate": 8.861330326944758e-06,
      "loss": 0.3787,
      "step": 5439
    },
    {
      "epoch": 1.11,
      "grad_norm": 2.998796224594116,
      "learning_rate": 8.85928051655222e-06,
      "loss": 0.3852,
      "step": 5440
    },
    {
      "epoch": 1.11,
      "grad_norm": 0.8375831246376038,
      "learning_rate": 8.85723070615968e-06,
      "loss": 0.2377,
      "step": 5441
    },
    {
      "epoch": 1.11,
      "grad_norm": 1.2695924043655396,
      "learning_rate": 8.855180895767142e-06,
      "loss": 0.4013,
      "step": 5442
    },
    {
      "epoch": 1.12,
      "grad_norm": 1.9880948066711426,
      "learning_rate": 8.853131085374604e-06,
      "loss": 0.4369,
      "step": 5443
    },
    {
      "epoch": 1.12,
      "grad_norm": 2.9409267902374268,
      "learning_rate": 8.851081274982066e-06,
      "loss": 0.3451,
      "step": 5444
    },
    {
      "epoch": 1.12,
      "grad_norm": 1.064389705657959,
      "learning_rate": 8.849031464589526e-06,
      "loss": 0.4693,
      "step": 5445
    },
    {
      "epoch": 1.12,
      "grad_norm": 1.166906476020813,
      "learning_rate": 8.846981654196988e-06,
      "loss": 0.2937,
      "step": 5446
    },
    {
      "epoch": 1.12,
      "grad_norm": 1.1817764043807983,
      "learning_rate": 8.844931843804448e-06,
      "loss": 0.3952,
      "step": 5447
    },
    {
      "epoch": 1.12,
      "grad_norm": 1.068212866783142,
      "learning_rate": 8.84288203341191e-06,
      "loss": 0.3564,
      "step": 5448
    },
    {
      "epoch": 1.12,
      "grad_norm": 2.317389726638794,
      "learning_rate": 8.840832223019371e-06,
      "loss": 0.5651,
      "step": 5449
    },
    {
      "epoch": 1.12,
      "grad_norm": 1.1146349906921387,
      "learning_rate": 8.838782412626833e-06,
      "loss": 0.2498,
      "step": 5450
    },
    {
      "epoch": 1.12,
      "grad_norm": 0.9344548583030701,
      "learning_rate": 8.836732602234293e-06,
      "loss": 0.3537,
      "step": 5451
    },
    {
      "epoch": 1.12,
      "grad_norm": 1.6785753965377808,
      "learning_rate": 8.834682791841755e-06,
      "loss": 0.2635,
      "step": 5452
    },
    {
      "epoch": 1.12,
      "grad_norm": 1.242612600326538,
      "learning_rate": 8.832632981449215e-06,
      "loss": 0.3157,
      "step": 5453
    },
    {
      "epoch": 1.12,
      "grad_norm": 1.0205873250961304,
      "learning_rate": 8.830583171056677e-06,
      "loss": 0.3132,
      "step": 5454
    },
    {
      "epoch": 1.12,
      "grad_norm": 1.332593321800232,
      "learning_rate": 8.82853336066414e-06,
      "loss": 0.3536,
      "step": 5455
    },
    {
      "epoch": 1.12,
      "grad_norm": 2.1082372665405273,
      "learning_rate": 8.826483550271601e-06,
      "loss": 0.5193,
      "step": 5456
    },
    {
      "epoch": 1.12,
      "grad_norm": 1.321079134941101,
      "learning_rate": 8.824433739879061e-06,
      "loss": 0.3129,
      "step": 5457
    },
    {
      "epoch": 1.12,
      "grad_norm": 1.2602260112762451,
      "learning_rate": 8.822383929486523e-06,
      "loss": 0.4279,
      "step": 5458
    },
    {
      "epoch": 1.12,
      "grad_norm": 1.839367151260376,
      "learning_rate": 8.820334119093985e-06,
      "loss": 0.2976,
      "step": 5459
    },
    {
      "epoch": 1.12,
      "grad_norm": 1.7281700372695923,
      "learning_rate": 8.818284308701445e-06,
      "loss": 0.1992,
      "step": 5460
    },
    {
      "epoch": 1.12,
      "grad_norm": 0.9830224514007568,
      "learning_rate": 8.816234498308907e-06,
      "loss": 0.2957,
      "step": 5461
    },
    {
      "epoch": 1.12,
      "grad_norm": 2.755762815475464,
      "learning_rate": 8.814184687916369e-06,
      "loss": 0.308,
      "step": 5462
    },
    {
      "epoch": 1.12,
      "grad_norm": 1.4455286264419556,
      "learning_rate": 8.81213487752383e-06,
      "loss": 0.3305,
      "step": 5463
    },
    {
      "epoch": 1.12,
      "grad_norm": 1.734383225440979,
      "learning_rate": 8.81008506713129e-06,
      "loss": 0.3352,
      "step": 5464
    },
    {
      "epoch": 1.12,
      "grad_norm": 1.8351356983184814,
      "learning_rate": 8.808035256738753e-06,
      "loss": 0.4244,
      "step": 5465
    },
    {
      "epoch": 1.12,
      "grad_norm": 2.259612798690796,
      "learning_rate": 8.805985446346213e-06,
      "loss": 0.4036,
      "step": 5466
    },
    {
      "epoch": 1.12,
      "grad_norm": 1.2265117168426514,
      "learning_rate": 8.803935635953675e-06,
      "loss": 0.394,
      "step": 5467
    },
    {
      "epoch": 1.12,
      "grad_norm": 0.837955117225647,
      "learning_rate": 8.801885825561137e-06,
      "loss": 0.4003,
      "step": 5468
    },
    {
      "epoch": 1.12,
      "grad_norm": 1.2225313186645508,
      "learning_rate": 8.799836015168598e-06,
      "loss": 0.35,
      "step": 5469
    },
    {
      "epoch": 1.12,
      "grad_norm": 1.852886438369751,
      "learning_rate": 8.797786204776059e-06,
      "loss": 0.3339,
      "step": 5470
    },
    {
      "epoch": 1.12,
      "grad_norm": 1.4222956895828247,
      "learning_rate": 8.79573639438352e-06,
      "loss": 0.4539,
      "step": 5471
    },
    {
      "epoch": 1.12,
      "grad_norm": 1.7948901653289795,
      "learning_rate": 8.79368658399098e-06,
      "loss": 0.5191,
      "step": 5472
    },
    {
      "epoch": 1.12,
      "grad_norm": 0.9089756011962891,
      "learning_rate": 8.791636773598442e-06,
      "loss": 0.4717,
      "step": 5473
    },
    {
      "epoch": 1.12,
      "grad_norm": 0.8027331233024597,
      "learning_rate": 8.789586963205904e-06,
      "loss": 0.2833,
      "step": 5474
    },
    {
      "epoch": 1.12,
      "grad_norm": 2.40297532081604,
      "learning_rate": 8.787537152813366e-06,
      "loss": 0.3065,
      "step": 5475
    },
    {
      "epoch": 1.12,
      "grad_norm": 1.1553878784179688,
      "learning_rate": 8.785487342420826e-06,
      "loss": 0.1844,
      "step": 5476
    },
    {
      "epoch": 1.12,
      "grad_norm": 1.1918901205062866,
      "learning_rate": 8.783437532028288e-06,
      "loss": 0.4834,
      "step": 5477
    },
    {
      "epoch": 1.12,
      "grad_norm": 2.238084554672241,
      "learning_rate": 8.781387721635748e-06,
      "loss": 0.3605,
      "step": 5478
    },
    {
      "epoch": 1.12,
      "grad_norm": 1.3015090227127075,
      "learning_rate": 8.77933791124321e-06,
      "loss": 0.1905,
      "step": 5479
    },
    {
      "epoch": 1.12,
      "grad_norm": 0.9586412906646729,
      "learning_rate": 8.777288100850672e-06,
      "loss": 0.42,
      "step": 5480
    },
    {
      "epoch": 1.12,
      "grad_norm": 3.4676992893218994,
      "learning_rate": 8.775238290458134e-06,
      "loss": 0.3622,
      "step": 5481
    },
    {
      "epoch": 1.12,
      "grad_norm": 1.3931044340133667,
      "learning_rate": 8.773188480065594e-06,
      "loss": 0.3077,
      "step": 5482
    },
    {
      "epoch": 1.12,
      "grad_norm": 1.7388746738433838,
      "learning_rate": 8.771138669673056e-06,
      "loss": 0.3673,
      "step": 5483
    },
    {
      "epoch": 1.12,
      "grad_norm": 1.3476827144622803,
      "learning_rate": 8.769088859280516e-06,
      "loss": 0.2192,
      "step": 5484
    },
    {
      "epoch": 1.12,
      "grad_norm": 1.6787959337234497,
      "learning_rate": 8.767039048887978e-06,
      "loss": 0.415,
      "step": 5485
    },
    {
      "epoch": 1.12,
      "grad_norm": 1.9420064687728882,
      "learning_rate": 8.76498923849544e-06,
      "loss": 0.4147,
      "step": 5486
    },
    {
      "epoch": 1.12,
      "grad_norm": 2.1924610137939453,
      "learning_rate": 8.762939428102902e-06,
      "loss": 0.3124,
      "step": 5487
    },
    {
      "epoch": 1.12,
      "grad_norm": 1.2426910400390625,
      "learning_rate": 8.760889617710364e-06,
      "loss": 0.498,
      "step": 5488
    },
    {
      "epoch": 1.12,
      "grad_norm": 1.6789923906326294,
      "learning_rate": 8.758839807317824e-06,
      "loss": 0.4378,
      "step": 5489
    },
    {
      "epoch": 1.12,
      "grad_norm": 1.2881139516830444,
      "learning_rate": 8.756789996925286e-06,
      "loss": 0.4087,
      "step": 5490
    },
    {
      "epoch": 1.12,
      "grad_norm": 1.047239899635315,
      "learning_rate": 8.754740186532746e-06,
      "loss": 0.4663,
      "step": 5491
    },
    {
      "epoch": 1.13,
      "grad_norm": 1.2125967741012573,
      "learning_rate": 8.752690376140208e-06,
      "loss": 0.3824,
      "step": 5492
    },
    {
      "epoch": 1.13,
      "grad_norm": 3.169837236404419,
      "learning_rate": 8.75064056574767e-06,
      "loss": 0.392,
      "step": 5493
    },
    {
      "epoch": 1.13,
      "grad_norm": 1.8927421569824219,
      "learning_rate": 8.748590755355131e-06,
      "loss": 0.3235,
      "step": 5494
    },
    {
      "epoch": 1.13,
      "grad_norm": 1.3545925617218018,
      "learning_rate": 8.746540944962591e-06,
      "loss": 0.4549,
      "step": 5495
    },
    {
      "epoch": 1.13,
      "grad_norm": 3.5553414821624756,
      "learning_rate": 8.744491134570053e-06,
      "loss": 0.2827,
      "step": 5496
    },
    {
      "epoch": 1.13,
      "grad_norm": 2.3879218101501465,
      "learning_rate": 8.742441324177513e-06,
      "loss": 0.2868,
      "step": 5497
    },
    {
      "epoch": 1.13,
      "grad_norm": 2.9812734127044678,
      "learning_rate": 8.740391513784975e-06,
      "loss": 0.2643,
      "step": 5498
    },
    {
      "epoch": 1.13,
      "grad_norm": 0.7705603241920471,
      "learning_rate": 8.738341703392437e-06,
      "loss": 0.2563,
      "step": 5499
    },
    {
      "epoch": 1.13,
      "grad_norm": 1.7809383869171143,
      "learning_rate": 8.736291892999899e-06,
      "loss": 0.2388,
      "step": 5500
    },
    {
      "epoch": 1.13,
      "grad_norm": 1.823790192604065,
      "learning_rate": 8.73424208260736e-06,
      "loss": 0.2884,
      "step": 5501
    },
    {
      "epoch": 1.13,
      "grad_norm": 1.4381886720657349,
      "learning_rate": 8.732192272214821e-06,
      "loss": 0.3858,
      "step": 5502
    },
    {
      "epoch": 1.13,
      "grad_norm": 0.9117255806922913,
      "learning_rate": 8.730142461822281e-06,
      "loss": 0.3819,
      "step": 5503
    },
    {
      "epoch": 1.13,
      "grad_norm": 1.2492403984069824,
      "learning_rate": 8.728092651429743e-06,
      "loss": 0.4008,
      "step": 5504
    },
    {
      "epoch": 1.13,
      "grad_norm": 1.0334410667419434,
      "learning_rate": 8.726042841037205e-06,
      "loss": 0.4882,
      "step": 5505
    },
    {
      "epoch": 1.13,
      "grad_norm": 1.054518699645996,
      "learning_rate": 8.723993030644667e-06,
      "loss": 0.2354,
      "step": 5506
    },
    {
      "epoch": 1.13,
      "grad_norm": 1.4884005784988403,
      "learning_rate": 8.721943220252127e-06,
      "loss": 0.4577,
      "step": 5507
    },
    {
      "epoch": 1.13,
      "grad_norm": 1.2470051050186157,
      "learning_rate": 8.719893409859589e-06,
      "loss": 0.4102,
      "step": 5508
    },
    {
      "epoch": 1.13,
      "grad_norm": 1.4086625576019287,
      "learning_rate": 8.717843599467049e-06,
      "loss": 0.3896,
      "step": 5509
    },
    {
      "epoch": 1.13,
      "grad_norm": 1.8742948770523071,
      "learning_rate": 8.71579378907451e-06,
      "loss": 0.5031,
      "step": 5510
    },
    {
      "epoch": 1.13,
      "grad_norm": 0.9385780096054077,
      "learning_rate": 8.713743978681973e-06,
      "loss": 0.4478,
      "step": 5511
    },
    {
      "epoch": 1.13,
      "grad_norm": 1.4039770364761353,
      "learning_rate": 8.711694168289435e-06,
      "loss": 0.3191,
      "step": 5512
    },
    {
      "epoch": 1.13,
      "grad_norm": 1.3689179420471191,
      "learning_rate": 8.709644357896895e-06,
      "loss": 0.2969,
      "step": 5513
    },
    {
      "epoch": 1.13,
      "grad_norm": 2.2083802223205566,
      "learning_rate": 8.707594547504357e-06,
      "loss": 0.2847,
      "step": 5514
    },
    {
      "epoch": 1.13,
      "grad_norm": 1.0165683031082153,
      "learning_rate": 8.705544737111817e-06,
      "loss": 0.267,
      "step": 5515
    },
    {
      "epoch": 1.13,
      "grad_norm": 2.4002158641815186,
      "learning_rate": 8.703494926719279e-06,
      "loss": 0.313,
      "step": 5516
    },
    {
      "epoch": 1.13,
      "grad_norm": 1.847699761390686,
      "learning_rate": 8.70144511632674e-06,
      "loss": 0.465,
      "step": 5517
    },
    {
      "epoch": 1.13,
      "grad_norm": 0.9962397813796997,
      "learning_rate": 8.699395305934202e-06,
      "loss": 0.214,
      "step": 5518
    },
    {
      "epoch": 1.13,
      "grad_norm": 1.2224736213684082,
      "learning_rate": 8.697345495541664e-06,
      "loss": 0.5371,
      "step": 5519
    },
    {
      "epoch": 1.13,
      "grad_norm": 3.2852349281311035,
      "learning_rate": 8.695295685149124e-06,
      "loss": 0.3912,
      "step": 5520
    },
    {
      "epoch": 1.13,
      "grad_norm": 1.2195333242416382,
      "learning_rate": 8.693245874756586e-06,
      "loss": 0.5085,
      "step": 5521
    },
    {
      "epoch": 1.13,
      "grad_norm": 1.7369816303253174,
      "learning_rate": 8.691196064364046e-06,
      "loss": 0.4111,
      "step": 5522
    },
    {
      "epoch": 1.13,
      "grad_norm": 1.1040658950805664,
      "learning_rate": 8.689146253971508e-06,
      "loss": 0.4545,
      "step": 5523
    },
    {
      "epoch": 1.13,
      "grad_norm": 1.0771212577819824,
      "learning_rate": 8.68709644357897e-06,
      "loss": 0.2872,
      "step": 5524
    },
    {
      "epoch": 1.13,
      "grad_norm": 2.0890886783599854,
      "learning_rate": 8.685046633186432e-06,
      "loss": 0.2396,
      "step": 5525
    },
    {
      "epoch": 1.13,
      "grad_norm": 0.9830480217933655,
      "learning_rate": 8.682996822793892e-06,
      "loss": 0.2359,
      "step": 5526
    },
    {
      "epoch": 1.13,
      "grad_norm": 1.19728684425354,
      "learning_rate": 8.680947012401354e-06,
      "loss": 0.422,
      "step": 5527
    },
    {
      "epoch": 1.13,
      "grad_norm": 1.7247563600540161,
      "learning_rate": 8.678897202008814e-06,
      "loss": 0.4028,
      "step": 5528
    },
    {
      "epoch": 1.13,
      "grad_norm": 2.0765323638916016,
      "learning_rate": 8.676847391616276e-06,
      "loss": 0.4265,
      "step": 5529
    },
    {
      "epoch": 1.13,
      "grad_norm": 1.1476728916168213,
      "learning_rate": 8.674797581223738e-06,
      "loss": 0.4024,
      "step": 5530
    },
    {
      "epoch": 1.13,
      "grad_norm": 1.0955493450164795,
      "learning_rate": 8.6727477708312e-06,
      "loss": 0.1699,
      "step": 5531
    },
    {
      "epoch": 1.13,
      "grad_norm": 1.8754916191101074,
      "learning_rate": 8.67069796043866e-06,
      "loss": 0.3929,
      "step": 5532
    },
    {
      "epoch": 1.13,
      "grad_norm": 1.1548587083816528,
      "learning_rate": 8.668648150046122e-06,
      "loss": 0.3517,
      "step": 5533
    },
    {
      "epoch": 1.13,
      "grad_norm": 0.937273383140564,
      "learning_rate": 8.666598339653582e-06,
      "loss": 0.4148,
      "step": 5534
    },
    {
      "epoch": 1.13,
      "grad_norm": 1.5542759895324707,
      "learning_rate": 8.664548529261044e-06,
      "loss": 0.4279,
      "step": 5535
    },
    {
      "epoch": 1.13,
      "grad_norm": 0.9832344651222229,
      "learning_rate": 8.662498718868506e-06,
      "loss": 0.2759,
      "step": 5536
    },
    {
      "epoch": 1.13,
      "grad_norm": 1.4499199390411377,
      "learning_rate": 8.660448908475967e-06,
      "loss": 0.3283,
      "step": 5537
    },
    {
      "epoch": 1.13,
      "grad_norm": 1.1964117288589478,
      "learning_rate": 8.658399098083428e-06,
      "loss": 0.2551,
      "step": 5538
    },
    {
      "epoch": 1.13,
      "grad_norm": 1.9359294176101685,
      "learning_rate": 8.65634928769089e-06,
      "loss": 0.3543,
      "step": 5539
    },
    {
      "epoch": 1.14,
      "grad_norm": 1.4716877937316895,
      "learning_rate": 8.65429947729835e-06,
      "loss": 0.2465,
      "step": 5540
    },
    {
      "epoch": 1.14,
      "grad_norm": 1.120816707611084,
      "learning_rate": 8.652249666905811e-06,
      "loss": 0.3878,
      "step": 5541
    },
    {
      "epoch": 1.14,
      "grad_norm": 1.0262266397476196,
      "learning_rate": 8.650199856513273e-06,
      "loss": 0.461,
      "step": 5542
    },
    {
      "epoch": 1.14,
      "grad_norm": 1.2507529258728027,
      "learning_rate": 8.648150046120735e-06,
      "loss": 0.2294,
      "step": 5543
    },
    {
      "epoch": 1.14,
      "grad_norm": 1.154183030128479,
      "learning_rate": 8.646100235728195e-06,
      "loss": 0.4241,
      "step": 5544
    },
    {
      "epoch": 1.14,
      "grad_norm": 1.2197279930114746,
      "learning_rate": 8.644050425335657e-06,
      "loss": 0.3285,
      "step": 5545
    },
    {
      "epoch": 1.14,
      "grad_norm": 1.4639229774475098,
      "learning_rate": 8.642000614943117e-06,
      "loss": 0.4444,
      "step": 5546
    },
    {
      "epoch": 1.14,
      "grad_norm": 1.0677520036697388,
      "learning_rate": 8.63995080455058e-06,
      "loss": 0.3545,
      "step": 5547
    },
    {
      "epoch": 1.14,
      "grad_norm": 1.3242660760879517,
      "learning_rate": 8.637900994158041e-06,
      "loss": 0.3632,
      "step": 5548
    },
    {
      "epoch": 1.14,
      "grad_norm": 1.3363937139511108,
      "learning_rate": 8.635851183765503e-06,
      "loss": 0.3148,
      "step": 5549
    },
    {
      "epoch": 1.14,
      "grad_norm": 0.8965305685997009,
      "learning_rate": 8.633801373372965e-06,
      "loss": 0.2558,
      "step": 5550
    },
    {
      "epoch": 1.14,
      "grad_norm": 1.071207880973816,
      "learning_rate": 8.631751562980425e-06,
      "loss": 0.3741,
      "step": 5551
    },
    {
      "epoch": 1.14,
      "grad_norm": 1.9016666412353516,
      "learning_rate": 8.629701752587887e-06,
      "loss": 0.4873,
      "step": 5552
    },
    {
      "epoch": 1.14,
      "grad_norm": 1.2402604818344116,
      "learning_rate": 8.627651942195347e-06,
      "loss": 0.3357,
      "step": 5553
    },
    {
      "epoch": 1.14,
      "grad_norm": 0.981562614440918,
      "learning_rate": 8.625602131802809e-06,
      "loss": 0.3161,
      "step": 5554
    },
    {
      "epoch": 1.14,
      "grad_norm": 1.6754294633865356,
      "learning_rate": 8.62355232141027e-06,
      "loss": 0.2846,
      "step": 5555
    },
    {
      "epoch": 1.14,
      "grad_norm": 0.8018062710762024,
      "learning_rate": 8.621502511017732e-06,
      "loss": 0.3973,
      "step": 5556
    },
    {
      "epoch": 1.14,
      "grad_norm": 0.961147665977478,
      "learning_rate": 8.619452700625193e-06,
      "loss": 0.3466,
      "step": 5557
    },
    {
      "epoch": 1.14,
      "grad_norm": 1.0664176940917969,
      "learning_rate": 8.617402890232655e-06,
      "loss": 0.2181,
      "step": 5558
    },
    {
      "epoch": 1.14,
      "grad_norm": 1.581771969795227,
      "learning_rate": 8.615353079840115e-06,
      "loss": 0.3504,
      "step": 5559
    },
    {
      "epoch": 1.14,
      "grad_norm": 1.7181512117385864,
      "learning_rate": 8.613303269447577e-06,
      "loss": 0.3714,
      "step": 5560
    },
    {
      "epoch": 1.14,
      "grad_norm": 1.115473985671997,
      "learning_rate": 8.611253459055038e-06,
      "loss": 0.4052,
      "step": 5561
    },
    {
      "epoch": 1.14,
      "grad_norm": 2.084759473800659,
      "learning_rate": 8.6092036486625e-06,
      "loss": 0.4151,
      "step": 5562
    },
    {
      "epoch": 1.14,
      "grad_norm": 0.9036343693733215,
      "learning_rate": 8.60715383826996e-06,
      "loss": 0.3526,
      "step": 5563
    },
    {
      "epoch": 1.14,
      "grad_norm": 4.218792915344238,
      "learning_rate": 8.605104027877422e-06,
      "loss": 0.3743,
      "step": 5564
    },
    {
      "epoch": 1.14,
      "grad_norm": 1.7815686464309692,
      "learning_rate": 8.603054217484882e-06,
      "loss": 0.2868,
      "step": 5565
    },
    {
      "epoch": 1.14,
      "grad_norm": 1.1961941719055176,
      "learning_rate": 8.601004407092344e-06,
      "loss": 0.3679,
      "step": 5566
    },
    {
      "epoch": 1.14,
      "grad_norm": 2.103203058242798,
      "learning_rate": 8.598954596699806e-06,
      "loss": 0.3543,
      "step": 5567
    },
    {
      "epoch": 1.14,
      "grad_norm": 3.2596797943115234,
      "learning_rate": 8.596904786307268e-06,
      "loss": 0.3461,
      "step": 5568
    },
    {
      "epoch": 1.14,
      "grad_norm": 1.1129966974258423,
      "learning_rate": 8.594854975914728e-06,
      "loss": 0.4123,
      "step": 5569
    },
    {
      "epoch": 1.14,
      "grad_norm": 1.7298123836517334,
      "learning_rate": 8.59280516552219e-06,
      "loss": 0.4319,
      "step": 5570
    },
    {
      "epoch": 1.14,
      "grad_norm": 1.6668123006820679,
      "learning_rate": 8.59075535512965e-06,
      "loss": 0.334,
      "step": 5571
    },
    {
      "epoch": 1.14,
      "grad_norm": 2.4279472827911377,
      "learning_rate": 8.588705544737112e-06,
      "loss": 0.4372,
      "step": 5572
    },
    {
      "epoch": 1.14,
      "grad_norm": 1.4337012767791748,
      "learning_rate": 8.586655734344574e-06,
      "loss": 0.3691,
      "step": 5573
    },
    {
      "epoch": 1.14,
      "grad_norm": 1.4395982027053833,
      "learning_rate": 8.584605923952036e-06,
      "loss": 0.3137,
      "step": 5574
    },
    {
      "epoch": 1.14,
      "grad_norm": 0.9643992781639099,
      "learning_rate": 8.582556113559496e-06,
      "loss": 0.2889,
      "step": 5575
    },
    {
      "epoch": 1.14,
      "grad_norm": 1.1176722049713135,
      "learning_rate": 8.580506303166958e-06,
      "loss": 0.3956,
      "step": 5576
    },
    {
      "epoch": 1.14,
      "grad_norm": 1.5002906322479248,
      "learning_rate": 8.57845649277442e-06,
      "loss": 0.3211,
      "step": 5577
    },
    {
      "epoch": 1.14,
      "grad_norm": 0.6934036612510681,
      "learning_rate": 8.57640668238188e-06,
      "loss": 0.2737,
      "step": 5578
    },
    {
      "epoch": 1.14,
      "grad_norm": 1.0523183345794678,
      "learning_rate": 8.574356871989342e-06,
      "loss": 0.3913,
      "step": 5579
    },
    {
      "epoch": 1.14,
      "grad_norm": 1.193499207496643,
      "learning_rate": 8.572307061596803e-06,
      "loss": 0.4313,
      "step": 5580
    },
    {
      "epoch": 1.14,
      "grad_norm": 1.887481451034546,
      "learning_rate": 8.570257251204265e-06,
      "loss": 0.4421,
      "step": 5581
    },
    {
      "epoch": 1.14,
      "grad_norm": 1.3026179075241089,
      "learning_rate": 8.568207440811726e-06,
      "loss": 0.2936,
      "step": 5582
    },
    {
      "epoch": 1.14,
      "grad_norm": 1.876971960067749,
      "learning_rate": 8.566157630419187e-06,
      "loss": 0.2571,
      "step": 5583
    },
    {
      "epoch": 1.14,
      "grad_norm": 1.012534260749817,
      "learning_rate": 8.564107820026648e-06,
      "loss": 0.2262,
      "step": 5584
    },
    {
      "epoch": 1.14,
      "grad_norm": 0.6842167973518372,
      "learning_rate": 8.56205800963411e-06,
      "loss": 0.2109,
      "step": 5585
    },
    {
      "epoch": 1.14,
      "grad_norm": 1.7087082862854004,
      "learning_rate": 8.560008199241571e-06,
      "loss": 0.3391,
      "step": 5586
    },
    {
      "epoch": 1.14,
      "grad_norm": 1.3021111488342285,
      "learning_rate": 8.557958388849033e-06,
      "loss": 0.3323,
      "step": 5587
    },
    {
      "epoch": 1.14,
      "grad_norm": 1.3486148118972778,
      "learning_rate": 8.555908578456493e-06,
      "loss": 0.3267,
      "step": 5588
    },
    {
      "epoch": 1.15,
      "grad_norm": 0.7205281853675842,
      "learning_rate": 8.553858768063955e-06,
      "loss": 0.3102,
      "step": 5589
    },
    {
      "epoch": 1.15,
      "grad_norm": 1.033793568611145,
      "learning_rate": 8.551808957671415e-06,
      "loss": 0.3175,
      "step": 5590
    },
    {
      "epoch": 1.15,
      "grad_norm": 0.9369393587112427,
      "learning_rate": 8.549759147278877e-06,
      "loss": 0.4205,
      "step": 5591
    },
    {
      "epoch": 1.15,
      "grad_norm": 1.511271357536316,
      "learning_rate": 8.547709336886339e-06,
      "loss": 0.3595,
      "step": 5592
    },
    {
      "epoch": 1.15,
      "grad_norm": 1.353212594985962,
      "learning_rate": 8.5456595264938e-06,
      "loss": 0.3681,
      "step": 5593
    },
    {
      "epoch": 1.15,
      "grad_norm": 1.6050753593444824,
      "learning_rate": 8.543609716101261e-06,
      "loss": 0.4457,
      "step": 5594
    },
    {
      "epoch": 1.15,
      "grad_norm": 1.0745571851730347,
      "learning_rate": 8.541559905708723e-06,
      "loss": 0.2754,
      "step": 5595
    },
    {
      "epoch": 1.15,
      "grad_norm": 1.257298231124878,
      "learning_rate": 8.539510095316183e-06,
      "loss": 0.4287,
      "step": 5596
    },
    {
      "epoch": 1.15,
      "grad_norm": 1.2518963813781738,
      "learning_rate": 8.537460284923645e-06,
      "loss": 0.222,
      "step": 5597
    },
    {
      "epoch": 1.15,
      "grad_norm": 1.2123456001281738,
      "learning_rate": 8.535410474531107e-06,
      "loss": 0.4807,
      "step": 5598
    },
    {
      "epoch": 1.15,
      "grad_norm": 1.375220537185669,
      "learning_rate": 8.533360664138569e-06,
      "loss": 0.3829,
      "step": 5599
    },
    {
      "epoch": 1.15,
      "grad_norm": 1.5353033542633057,
      "learning_rate": 8.531310853746029e-06,
      "loss": 0.2693,
      "step": 5600
    },
    {
      "epoch": 1.15,
      "grad_norm": 0.9234751462936401,
      "learning_rate": 8.52926104335349e-06,
      "loss": 0.3395,
      "step": 5601
    },
    {
      "epoch": 1.15,
      "grad_norm": 1.5753546953201294,
      "learning_rate": 8.52721123296095e-06,
      "loss": 0.4418,
      "step": 5602
    },
    {
      "epoch": 1.15,
      "grad_norm": 1.0556672811508179,
      "learning_rate": 8.525161422568413e-06,
      "loss": 0.3386,
      "step": 5603
    },
    {
      "epoch": 1.15,
      "grad_norm": 1.0382522344589233,
      "learning_rate": 8.523111612175874e-06,
      "loss": 0.352,
      "step": 5604
    },
    {
      "epoch": 1.15,
      "grad_norm": 0.9616307616233826,
      "learning_rate": 8.521061801783336e-06,
      "loss": 0.3918,
      "step": 5605
    },
    {
      "epoch": 1.15,
      "grad_norm": 1.048301339149475,
      "learning_rate": 8.519011991390798e-06,
      "loss": 0.3595,
      "step": 5606
    },
    {
      "epoch": 1.15,
      "grad_norm": 1.2226555347442627,
      "learning_rate": 8.516962180998258e-06,
      "loss": 0.4141,
      "step": 5607
    },
    {
      "epoch": 1.15,
      "grad_norm": 1.3569004535675049,
      "learning_rate": 8.51491237060572e-06,
      "loss": 0.3836,
      "step": 5608
    },
    {
      "epoch": 1.15,
      "grad_norm": 1.2080937623977661,
      "learning_rate": 8.51286256021318e-06,
      "loss": 0.3061,
      "step": 5609
    },
    {
      "epoch": 1.15,
      "grad_norm": 0.9010663032531738,
      "learning_rate": 8.510812749820642e-06,
      "loss": 0.4376,
      "step": 5610
    },
    {
      "epoch": 1.15,
      "grad_norm": 1.5172451734542847,
      "learning_rate": 8.508762939428104e-06,
      "loss": 0.3971,
      "step": 5611
    },
    {
      "epoch": 1.15,
      "grad_norm": 2.8709609508514404,
      "learning_rate": 8.506713129035566e-06,
      "loss": 0.3336,
      "step": 5612
    },
    {
      "epoch": 1.15,
      "grad_norm": 1.3577532768249512,
      "learning_rate": 8.504663318643026e-06,
      "loss": 0.3251,
      "step": 5613
    },
    {
      "epoch": 1.15,
      "grad_norm": 1.0201698541641235,
      "learning_rate": 8.502613508250488e-06,
      "loss": 0.3592,
      "step": 5614
    },
    {
      "epoch": 1.15,
      "grad_norm": 1.4561740159988403,
      "learning_rate": 8.500563697857948e-06,
      "loss": 0.2773,
      "step": 5615
    },
    {
      "epoch": 1.15,
      "grad_norm": 1.1411733627319336,
      "learning_rate": 8.49851388746541e-06,
      "loss": 0.3212,
      "step": 5616
    },
    {
      "epoch": 1.15,
      "grad_norm": 1.3199783563613892,
      "learning_rate": 8.496464077072872e-06,
      "loss": 0.3428,
      "step": 5617
    },
    {
      "epoch": 1.15,
      "grad_norm": 1.3445987701416016,
      "learning_rate": 8.494414266680334e-06,
      "loss": 0.4027,
      "step": 5618
    },
    {
      "epoch": 1.15,
      "grad_norm": 1.5603845119476318,
      "learning_rate": 8.492364456287794e-06,
      "loss": 0.4445,
      "step": 5619
    },
    {
      "epoch": 1.15,
      "grad_norm": 1.458200216293335,
      "learning_rate": 8.490314645895256e-06,
      "loss": 0.3358,
      "step": 5620
    },
    {
      "epoch": 1.15,
      "grad_norm": 1.349102258682251,
      "learning_rate": 8.488264835502716e-06,
      "loss": 0.3732,
      "step": 5621
    },
    {
      "epoch": 1.15,
      "grad_norm": 1.5439064502716064,
      "learning_rate": 8.486215025110178e-06,
      "loss": 0.361,
      "step": 5622
    },
    {
      "epoch": 1.15,
      "grad_norm": 0.8566880822181702,
      "learning_rate": 8.48416521471764e-06,
      "loss": 0.268,
      "step": 5623
    },
    {
      "epoch": 1.15,
      "grad_norm": 1.7643496990203857,
      "learning_rate": 8.482115404325101e-06,
      "loss": 0.4502,
      "step": 5624
    },
    {
      "epoch": 1.15,
      "grad_norm": 1.7003401517868042,
      "learning_rate": 8.480065593932562e-06,
      "loss": 0.3472,
      "step": 5625
    },
    {
      "epoch": 1.15,
      "grad_norm": 1.0121359825134277,
      "learning_rate": 8.478015783540023e-06,
      "loss": 0.3042,
      "step": 5626
    },
    {
      "epoch": 1.15,
      "grad_norm": 1.0414425134658813,
      "learning_rate": 8.475965973147484e-06,
      "loss": 0.3192,
      "step": 5627
    },
    {
      "epoch": 1.15,
      "grad_norm": 1.0303462743759155,
      "learning_rate": 8.473916162754945e-06,
      "loss": 0.2979,
      "step": 5628
    },
    {
      "epoch": 1.15,
      "grad_norm": 2.0475730895996094,
      "learning_rate": 8.471866352362407e-06,
      "loss": 0.3345,
      "step": 5629
    },
    {
      "epoch": 1.15,
      "grad_norm": 1.621268630027771,
      "learning_rate": 8.46981654196987e-06,
      "loss": 0.3727,
      "step": 5630
    },
    {
      "epoch": 1.15,
      "grad_norm": 1.333681344985962,
      "learning_rate": 8.46776673157733e-06,
      "loss": 0.2651,
      "step": 5631
    },
    {
      "epoch": 1.15,
      "grad_norm": 1.910103678703308,
      "learning_rate": 8.465716921184791e-06,
      "loss": 0.2855,
      "step": 5632
    },
    {
      "epoch": 1.15,
      "grad_norm": 2.1975150108337402,
      "learning_rate": 8.463667110792251e-06,
      "loss": 0.3326,
      "step": 5633
    },
    {
      "epoch": 1.15,
      "grad_norm": 0.7543809413909912,
      "learning_rate": 8.461617300399713e-06,
      "loss": 0.2032,
      "step": 5634
    },
    {
      "epoch": 1.15,
      "grad_norm": 0.9486744999885559,
      "learning_rate": 8.459567490007175e-06,
      "loss": 0.3941,
      "step": 5635
    },
    {
      "epoch": 1.15,
      "grad_norm": 1.564528226852417,
      "learning_rate": 8.457517679614637e-06,
      "loss": 0.5053,
      "step": 5636
    },
    {
      "epoch": 1.15,
      "grad_norm": 2.7313759326934814,
      "learning_rate": 8.455467869222099e-06,
      "loss": 0.367,
      "step": 5637
    },
    {
      "epoch": 1.16,
      "grad_norm": 1.3269004821777344,
      "learning_rate": 8.453418058829559e-06,
      "loss": 0.2816,
      "step": 5638
    },
    {
      "epoch": 1.16,
      "grad_norm": 1.4109129905700684,
      "learning_rate": 8.45136824843702e-06,
      "loss": 0.5069,
      "step": 5639
    },
    {
      "epoch": 1.16,
      "grad_norm": 1.4896883964538574,
      "learning_rate": 8.449318438044481e-06,
      "loss": 0.2587,
      "step": 5640
    },
    {
      "epoch": 1.16,
      "grad_norm": 2.9348180294036865,
      "learning_rate": 8.447268627651943e-06,
      "loss": 0.3816,
      "step": 5641
    },
    {
      "epoch": 1.16,
      "grad_norm": 1.304639458656311,
      "learning_rate": 8.445218817259405e-06,
      "loss": 0.4167,
      "step": 5642
    },
    {
      "epoch": 1.16,
      "grad_norm": 1.7407687902450562,
      "learning_rate": 8.443169006866867e-06,
      "loss": 0.3942,
      "step": 5643
    },
    {
      "epoch": 1.16,
      "grad_norm": 1.8636488914489746,
      "learning_rate": 8.441119196474327e-06,
      "loss": 0.3668,
      "step": 5644
    },
    {
      "epoch": 1.16,
      "grad_norm": 0.9319773316383362,
      "learning_rate": 8.439069386081789e-06,
      "loss": 0.4491,
      "step": 5645
    },
    {
      "epoch": 1.16,
      "grad_norm": 1.375947117805481,
      "learning_rate": 8.437019575689249e-06,
      "loss": 0.3513,
      "step": 5646
    },
    {
      "epoch": 1.16,
      "grad_norm": 1.311894178390503,
      "learning_rate": 8.43496976529671e-06,
      "loss": 0.4065,
      "step": 5647
    },
    {
      "epoch": 1.16,
      "grad_norm": 1.147829294204712,
      "learning_rate": 8.432919954904172e-06,
      "loss": 0.2975,
      "step": 5648
    },
    {
      "epoch": 1.16,
      "grad_norm": 0.8663501143455505,
      "learning_rate": 8.430870144511634e-06,
      "loss": 0.4479,
      "step": 5649
    },
    {
      "epoch": 1.16,
      "grad_norm": 2.0157310962677,
      "learning_rate": 8.428820334119094e-06,
      "loss": 0.2823,
      "step": 5650
    },
    {
      "epoch": 1.16,
      "grad_norm": 1.299617886543274,
      "learning_rate": 8.426770523726556e-06,
      "loss": 0.4401,
      "step": 5651
    },
    {
      "epoch": 1.16,
      "grad_norm": 0.8602480888366699,
      "learning_rate": 8.424720713334016e-06,
      "loss": 0.214,
      "step": 5652
    },
    {
      "epoch": 1.16,
      "grad_norm": 1.1224170923233032,
      "learning_rate": 8.422670902941478e-06,
      "loss": 0.3938,
      "step": 5653
    },
    {
      "epoch": 1.16,
      "grad_norm": 1.1781716346740723,
      "learning_rate": 8.42062109254894e-06,
      "loss": 0.3922,
      "step": 5654
    },
    {
      "epoch": 1.16,
      "grad_norm": 1.0875087976455688,
      "learning_rate": 8.418571282156402e-06,
      "loss": 0.3693,
      "step": 5655
    },
    {
      "epoch": 1.16,
      "grad_norm": 1.065111756324768,
      "learning_rate": 8.416521471763862e-06,
      "loss": 0.3243,
      "step": 5656
    },
    {
      "epoch": 1.16,
      "grad_norm": 0.9501993060112,
      "learning_rate": 8.414471661371324e-06,
      "loss": 0.3515,
      "step": 5657
    },
    {
      "epoch": 1.16,
      "grad_norm": 1.590657353401184,
      "learning_rate": 8.412421850978784e-06,
      "loss": 0.4155,
      "step": 5658
    },
    {
      "epoch": 1.16,
      "grad_norm": 1.167843222618103,
      "learning_rate": 8.410372040586246e-06,
      "loss": 0.4518,
      "step": 5659
    },
    {
      "epoch": 1.16,
      "grad_norm": 1.1307705640792847,
      "learning_rate": 8.408322230193708e-06,
      "loss": 0.3413,
      "step": 5660
    },
    {
      "epoch": 1.16,
      "grad_norm": 2.1328485012054443,
      "learning_rate": 8.40627241980117e-06,
      "loss": 0.4456,
      "step": 5661
    },
    {
      "epoch": 1.16,
      "grad_norm": 1.3096542358398438,
      "learning_rate": 8.40422260940863e-06,
      "loss": 0.3487,
      "step": 5662
    },
    {
      "epoch": 1.16,
      "grad_norm": 1.0117377042770386,
      "learning_rate": 8.402172799016092e-06,
      "loss": 0.3514,
      "step": 5663
    },
    {
      "epoch": 1.16,
      "grad_norm": 1.1231131553649902,
      "learning_rate": 8.400122988623552e-06,
      "loss": 0.2323,
      "step": 5664
    },
    {
      "epoch": 1.16,
      "grad_norm": 1.2585731744766235,
      "learning_rate": 8.398073178231014e-06,
      "loss": 0.2791,
      "step": 5665
    },
    {
      "epoch": 1.16,
      "grad_norm": 1.1554371118545532,
      "learning_rate": 8.396023367838476e-06,
      "loss": 0.3459,
      "step": 5666
    },
    {
      "epoch": 1.16,
      "grad_norm": 1.058924674987793,
      "learning_rate": 8.393973557445938e-06,
      "loss": 0.3118,
      "step": 5667
    },
    {
      "epoch": 1.16,
      "grad_norm": 0.9239153265953064,
      "learning_rate": 8.3919237470534e-06,
      "loss": 0.3442,
      "step": 5668
    },
    {
      "epoch": 1.16,
      "grad_norm": 2.2041056156158447,
      "learning_rate": 8.38987393666086e-06,
      "loss": 0.3766,
      "step": 5669
    },
    {
      "epoch": 1.16,
      "grad_norm": 1.4789360761642456,
      "learning_rate": 8.387824126268321e-06,
      "loss": 0.2568,
      "step": 5670
    },
    {
      "epoch": 1.16,
      "grad_norm": 1.3661035299301147,
      "learning_rate": 8.385774315875782e-06,
      "loss": 0.4119,
      "step": 5671
    },
    {
      "epoch": 1.16,
      "grad_norm": 0.9346221685409546,
      "learning_rate": 8.383724505483243e-06,
      "loss": 0.3843,
      "step": 5672
    },
    {
      "epoch": 1.16,
      "grad_norm": 1.032431721687317,
      "learning_rate": 8.381674695090705e-06,
      "loss": 0.3973,
      "step": 5673
    },
    {
      "epoch": 1.16,
      "grad_norm": 0.9315689206123352,
      "learning_rate": 8.379624884698167e-06,
      "loss": 0.2803,
      "step": 5674
    },
    {
      "epoch": 1.16,
      "grad_norm": 1.2978992462158203,
      "learning_rate": 8.377575074305627e-06,
      "loss": 0.5234,
      "step": 5675
    },
    {
      "epoch": 1.16,
      "grad_norm": 2.3675642013549805,
      "learning_rate": 8.37552526391309e-06,
      "loss": 0.4209,
      "step": 5676
    },
    {
      "epoch": 1.16,
      "grad_norm": 1.2609326839447021,
      "learning_rate": 8.37347545352055e-06,
      "loss": 0.318,
      "step": 5677
    },
    {
      "epoch": 1.16,
      "grad_norm": 1.6009306907653809,
      "learning_rate": 8.371425643128011e-06,
      "loss": 0.3805,
      "step": 5678
    },
    {
      "epoch": 1.16,
      "grad_norm": 1.2391165494918823,
      "learning_rate": 8.369375832735473e-06,
      "loss": 0.4785,
      "step": 5679
    },
    {
      "epoch": 1.16,
      "grad_norm": 0.9401497840881348,
      "learning_rate": 8.367326022342935e-06,
      "loss": 0.3108,
      "step": 5680
    },
    {
      "epoch": 1.16,
      "grad_norm": 1.6667593717575073,
      "learning_rate": 8.365276211950395e-06,
      "loss": 0.3635,
      "step": 5681
    },
    {
      "epoch": 1.16,
      "grad_norm": 1.5009801387786865,
      "learning_rate": 8.363226401557857e-06,
      "loss": 0.4646,
      "step": 5682
    },
    {
      "epoch": 1.16,
      "grad_norm": 0.8818970918655396,
      "learning_rate": 8.361176591165317e-06,
      "loss": 0.3243,
      "step": 5683
    },
    {
      "epoch": 1.16,
      "grad_norm": 1.1955324411392212,
      "learning_rate": 8.359126780772779e-06,
      "loss": 0.3631,
      "step": 5684
    },
    {
      "epoch": 1.16,
      "grad_norm": 3.401628255844116,
      "learning_rate": 8.35707697038024e-06,
      "loss": 0.498,
      "step": 5685
    },
    {
      "epoch": 1.16,
      "grad_norm": 1.51034677028656,
      "learning_rate": 8.355027159987703e-06,
      "loss": 0.362,
      "step": 5686
    },
    {
      "epoch": 1.17,
      "grad_norm": 2.0726113319396973,
      "learning_rate": 8.352977349595163e-06,
      "loss": 0.3843,
      "step": 5687
    },
    {
      "epoch": 1.17,
      "grad_norm": 1.51449453830719,
      "learning_rate": 8.350927539202625e-06,
      "loss": 0.4124,
      "step": 5688
    },
    {
      "epoch": 1.17,
      "grad_norm": 1.7040684223175049,
      "learning_rate": 8.348877728810085e-06,
      "loss": 0.4507,
      "step": 5689
    },
    {
      "epoch": 1.17,
      "grad_norm": 1.8818622827529907,
      "learning_rate": 8.346827918417547e-06,
      "loss": 0.358,
      "step": 5690
    },
    {
      "epoch": 1.17,
      "grad_norm": 1.4897466897964478,
      "learning_rate": 8.344778108025009e-06,
      "loss": 0.412,
      "step": 5691
    },
    {
      "epoch": 1.17,
      "grad_norm": 1.2155096530914307,
      "learning_rate": 8.34272829763247e-06,
      "loss": 0.38,
      "step": 5692
    },
    {
      "epoch": 1.17,
      "grad_norm": 2.8470330238342285,
      "learning_rate": 8.34067848723993e-06,
      "loss": 0.3295,
      "step": 5693
    },
    {
      "epoch": 1.17,
      "grad_norm": 2.0675432682037354,
      "learning_rate": 8.338628676847392e-06,
      "loss": 0.42,
      "step": 5694
    },
    {
      "epoch": 1.17,
      "grad_norm": 1.0726735591888428,
      "learning_rate": 8.336578866454854e-06,
      "loss": 0.4485,
      "step": 5695
    },
    {
      "epoch": 1.17,
      "grad_norm": 1.0229688882827759,
      "learning_rate": 8.334529056062314e-06,
      "loss": 0.2501,
      "step": 5696
    },
    {
      "epoch": 1.17,
      "grad_norm": 1.0699512958526611,
      "learning_rate": 8.332479245669776e-06,
      "loss": 0.4238,
      "step": 5697
    },
    {
      "epoch": 1.17,
      "grad_norm": 1.0945289134979248,
      "learning_rate": 8.330429435277238e-06,
      "loss": 0.4907,
      "step": 5698
    },
    {
      "epoch": 1.17,
      "grad_norm": 1.0590790510177612,
      "learning_rate": 8.3283796248847e-06,
      "loss": 0.33,
      "step": 5699
    },
    {
      "epoch": 1.17,
      "grad_norm": 1.1684257984161377,
      "learning_rate": 8.32632981449216e-06,
      "loss": 0.3494,
      "step": 5700
    },
    {
      "epoch": 1.17,
      "grad_norm": 0.9190942049026489,
      "learning_rate": 8.324280004099622e-06,
      "loss": 0.3046,
      "step": 5701
    },
    {
      "epoch": 1.17,
      "grad_norm": 1.146606206893921,
      "learning_rate": 8.322230193707082e-06,
      "loss": 0.308,
      "step": 5702
    },
    {
      "epoch": 1.17,
      "grad_norm": 0.9355761408805847,
      "learning_rate": 8.320180383314544e-06,
      "loss": 0.2764,
      "step": 5703
    },
    {
      "epoch": 1.17,
      "grad_norm": 1.1950407028198242,
      "learning_rate": 8.318130572922006e-06,
      "loss": 0.3941,
      "step": 5704
    },
    {
      "epoch": 1.17,
      "grad_norm": 0.964880645275116,
      "learning_rate": 8.316080762529468e-06,
      "loss": 0.4257,
      "step": 5705
    },
    {
      "epoch": 1.17,
      "grad_norm": 1.343349575996399,
      "learning_rate": 8.314030952136928e-06,
      "loss": 0.3248,
      "step": 5706
    },
    {
      "epoch": 1.17,
      "grad_norm": 1.0093193054199219,
      "learning_rate": 8.31198114174439e-06,
      "loss": 0.338,
      "step": 5707
    },
    {
      "epoch": 1.17,
      "grad_norm": 1.9789634943008423,
      "learning_rate": 8.30993133135185e-06,
      "loss": 0.3702,
      "step": 5708
    },
    {
      "epoch": 1.17,
      "grad_norm": 1.1523973941802979,
      "learning_rate": 8.307881520959312e-06,
      "loss": 0.3653,
      "step": 5709
    },
    {
      "epoch": 1.17,
      "grad_norm": 0.9016009569168091,
      "learning_rate": 8.305831710566774e-06,
      "loss": 0.257,
      "step": 5710
    },
    {
      "epoch": 1.17,
      "grad_norm": 1.0768810510635376,
      "learning_rate": 8.303781900174236e-06,
      "loss": 0.4373,
      "step": 5711
    },
    {
      "epoch": 1.17,
      "grad_norm": 2.1457576751708984,
      "learning_rate": 8.301732089781696e-06,
      "loss": 0.3626,
      "step": 5712
    },
    {
      "epoch": 1.17,
      "grad_norm": 1.5132098197937012,
      "learning_rate": 8.299682279389158e-06,
      "loss": 0.3305,
      "step": 5713
    },
    {
      "epoch": 1.17,
      "grad_norm": 1.3075065612792969,
      "learning_rate": 8.297632468996618e-06,
      "loss": 0.4195,
      "step": 5714
    },
    {
      "epoch": 1.17,
      "grad_norm": 2.6601548194885254,
      "learning_rate": 8.29558265860408e-06,
      "loss": 0.4171,
      "step": 5715
    },
    {
      "epoch": 1.17,
      "grad_norm": 5.118735313415527,
      "learning_rate": 8.293532848211541e-06,
      "loss": 0.3451,
      "step": 5716
    },
    {
      "epoch": 1.17,
      "grad_norm": 1.6628241539001465,
      "learning_rate": 8.291483037819003e-06,
      "loss": 0.4613,
      "step": 5717
    },
    {
      "epoch": 1.17,
      "grad_norm": 1.2577072381973267,
      "learning_rate": 8.289433227426463e-06,
      "loss": 0.3146,
      "step": 5718
    },
    {
      "epoch": 1.17,
      "grad_norm": 1.6356117725372314,
      "learning_rate": 8.287383417033925e-06,
      "loss": 0.388,
      "step": 5719
    },
    {
      "epoch": 1.17,
      "grad_norm": 2.375833749771118,
      "learning_rate": 8.285333606641385e-06,
      "loss": 0.4936,
      "step": 5720
    },
    {
      "epoch": 1.17,
      "grad_norm": 1.4024484157562256,
      "learning_rate": 8.283283796248847e-06,
      "loss": 0.3607,
      "step": 5721
    },
    {
      "epoch": 1.17,
      "grad_norm": 1.1999963521957397,
      "learning_rate": 8.28123398585631e-06,
      "loss": 0.311,
      "step": 5722
    },
    {
      "epoch": 1.17,
      "grad_norm": 0.7748870849609375,
      "learning_rate": 8.279184175463771e-06,
      "loss": 0.2554,
      "step": 5723
    },
    {
      "epoch": 1.17,
      "grad_norm": 1.981641173362732,
      "learning_rate": 8.277134365071233e-06,
      "loss": 0.359,
      "step": 5724
    },
    {
      "epoch": 1.17,
      "grad_norm": 3.499288558959961,
      "learning_rate": 8.275084554678693e-06,
      "loss": 0.4138,
      "step": 5725
    },
    {
      "epoch": 1.17,
      "grad_norm": 1.5815587043762207,
      "learning_rate": 8.273034744286155e-06,
      "loss": 0.3171,
      "step": 5726
    },
    {
      "epoch": 1.17,
      "grad_norm": 0.8647168874740601,
      "learning_rate": 8.270984933893615e-06,
      "loss": 0.3064,
      "step": 5727
    },
    {
      "epoch": 1.17,
      "grad_norm": 1.2632529735565186,
      "learning_rate": 8.268935123501077e-06,
      "loss": 0.2626,
      "step": 5728
    },
    {
      "epoch": 1.17,
      "grad_norm": 2.5493557453155518,
      "learning_rate": 8.266885313108539e-06,
      "loss": 0.2558,
      "step": 5729
    },
    {
      "epoch": 1.17,
      "grad_norm": 2.434981107711792,
      "learning_rate": 8.264835502716e-06,
      "loss": 0.2957,
      "step": 5730
    },
    {
      "epoch": 1.17,
      "grad_norm": 0.7728900909423828,
      "learning_rate": 8.26278569232346e-06,
      "loss": 0.4086,
      "step": 5731
    },
    {
      "epoch": 1.17,
      "grad_norm": 2.6379287242889404,
      "learning_rate": 8.260735881930923e-06,
      "loss": 0.3052,
      "step": 5732
    },
    {
      "epoch": 1.17,
      "grad_norm": 2.2863612174987793,
      "learning_rate": 8.258686071538383e-06,
      "loss": 0.3423,
      "step": 5733
    },
    {
      "epoch": 1.17,
      "grad_norm": 1.3395005464553833,
      "learning_rate": 8.256636261145845e-06,
      "loss": 0.304,
      "step": 5734
    },
    {
      "epoch": 1.17,
      "grad_norm": 0.964151918888092,
      "learning_rate": 8.254586450753307e-06,
      "loss": 0.182,
      "step": 5735
    },
    {
      "epoch": 1.18,
      "grad_norm": 2.392580032348633,
      "learning_rate": 8.252536640360768e-06,
      "loss": 0.1852,
      "step": 5736
    },
    {
      "epoch": 1.18,
      "grad_norm": 1.873503565788269,
      "learning_rate": 8.250486829968229e-06,
      "loss": 0.428,
      "step": 5737
    },
    {
      "epoch": 1.18,
      "grad_norm": 1.2198662757873535,
      "learning_rate": 8.24843701957569e-06,
      "loss": 0.4645,
      "step": 5738
    },
    {
      "epoch": 1.18,
      "grad_norm": 1.3364495038986206,
      "learning_rate": 8.24638720918315e-06,
      "loss": 0.4079,
      "step": 5739
    },
    {
      "epoch": 1.18,
      "grad_norm": 0.9341062903404236,
      "learning_rate": 8.244337398790612e-06,
      "loss": 0.3579,
      "step": 5740
    },
    {
      "epoch": 1.18,
      "grad_norm": 1.2218589782714844,
      "learning_rate": 8.242287588398074e-06,
      "loss": 0.3093,
      "step": 5741
    },
    {
      "epoch": 1.18,
      "grad_norm": 1.2423303127288818,
      "learning_rate": 8.240237778005536e-06,
      "loss": 0.2303,
      "step": 5742
    },
    {
      "epoch": 1.18,
      "grad_norm": 1.395777940750122,
      "learning_rate": 8.238187967612996e-06,
      "loss": 0.4171,
      "step": 5743
    },
    {
      "epoch": 1.18,
      "grad_norm": 1.4103500843048096,
      "learning_rate": 8.236138157220458e-06,
      "loss": 0.3997,
      "step": 5744
    },
    {
      "epoch": 1.18,
      "grad_norm": 1.1221468448638916,
      "learning_rate": 8.234088346827918e-06,
      "loss": 0.3905,
      "step": 5745
    },
    {
      "epoch": 1.18,
      "grad_norm": 0.6827521324157715,
      "learning_rate": 8.23203853643538e-06,
      "loss": 0.2518,
      "step": 5746
    },
    {
      "epoch": 1.18,
      "grad_norm": 1.04856276512146,
      "learning_rate": 8.229988726042842e-06,
      "loss": 0.4486,
      "step": 5747
    },
    {
      "epoch": 1.18,
      "grad_norm": 1.4803234338760376,
      "learning_rate": 8.227938915650304e-06,
      "loss": 0.3417,
      "step": 5748
    },
    {
      "epoch": 1.18,
      "grad_norm": 1.0313568115234375,
      "learning_rate": 8.225889105257764e-06,
      "loss": 0.4151,
      "step": 5749
    },
    {
      "epoch": 1.18,
      "grad_norm": 1.2926056385040283,
      "learning_rate": 8.223839294865226e-06,
      "loss": 0.3674,
      "step": 5750
    },
    {
      "epoch": 1.18,
      "grad_norm": 1.186809778213501,
      "learning_rate": 8.221789484472686e-06,
      "loss": 0.5654,
      "step": 5751
    },
    {
      "epoch": 1.18,
      "grad_norm": 1.4859611988067627,
      "learning_rate": 8.219739674080148e-06,
      "loss": 0.4054,
      "step": 5752
    },
    {
      "epoch": 1.18,
      "grad_norm": 1.6248793601989746,
      "learning_rate": 8.21768986368761e-06,
      "loss": 0.4828,
      "step": 5753
    },
    {
      "epoch": 1.18,
      "grad_norm": 1.8536423444747925,
      "learning_rate": 8.215640053295072e-06,
      "loss": 0.3189,
      "step": 5754
    },
    {
      "epoch": 1.18,
      "grad_norm": 1.7188156843185425,
      "learning_rate": 8.213590242902533e-06,
      "loss": 0.4552,
      "step": 5755
    },
    {
      "epoch": 1.18,
      "grad_norm": 1.365861177444458,
      "learning_rate": 8.211540432509994e-06,
      "loss": 0.3736,
      "step": 5756
    },
    {
      "epoch": 1.18,
      "grad_norm": 1.7575395107269287,
      "learning_rate": 8.209490622117456e-06,
      "loss": 0.2415,
      "step": 5757
    },
    {
      "epoch": 1.18,
      "grad_norm": 0.9822461605072021,
      "learning_rate": 8.207440811724916e-06,
      "loss": 0.2777,
      "step": 5758
    },
    {
      "epoch": 1.18,
      "grad_norm": 1.5877467393875122,
      "learning_rate": 8.205391001332378e-06,
      "loss": 0.352,
      "step": 5759
    },
    {
      "epoch": 1.18,
      "grad_norm": 1.2934861183166504,
      "learning_rate": 8.20334119093984e-06,
      "loss": 0.2683,
      "step": 5760
    },
    {
      "epoch": 1.18,
      "grad_norm": 1.2261748313903809,
      "learning_rate": 8.201291380547301e-06,
      "loss": 0.3986,
      "step": 5761
    },
    {
      "epoch": 1.18,
      "grad_norm": 1.1087075471878052,
      "learning_rate": 8.199241570154761e-06,
      "loss": 0.2965,
      "step": 5762
    },
    {
      "epoch": 1.18,
      "grad_norm": 1.5064185857772827,
      "learning_rate": 8.197191759762223e-06,
      "loss": 0.4243,
      "step": 5763
    },
    {
      "epoch": 1.18,
      "grad_norm": 1.5610469579696655,
      "learning_rate": 8.195141949369683e-06,
      "loss": 0.3052,
      "step": 5764
    },
    {
      "epoch": 1.18,
      "grad_norm": 1.4839057922363281,
      "learning_rate": 8.193092138977145e-06,
      "loss": 0.3429,
      "step": 5765
    },
    {
      "epoch": 1.18,
      "grad_norm": 1.5915340185165405,
      "learning_rate": 8.191042328584607e-06,
      "loss": 0.3739,
      "step": 5766
    },
    {
      "epoch": 1.18,
      "grad_norm": 1.6310065984725952,
      "learning_rate": 8.188992518192069e-06,
      "loss": 0.3202,
      "step": 5767
    },
    {
      "epoch": 1.18,
      "grad_norm": 1.6963924169540405,
      "learning_rate": 8.18694270779953e-06,
      "loss": 0.3108,
      "step": 5768
    },
    {
      "epoch": 1.18,
      "grad_norm": 1.0610625743865967,
      "learning_rate": 8.184892897406991e-06,
      "loss": 0.47,
      "step": 5769
    },
    {
      "epoch": 1.18,
      "grad_norm": 0.7748921513557434,
      "learning_rate": 8.182843087014451e-06,
      "loss": 0.3805,
      "step": 5770
    },
    {
      "epoch": 1.18,
      "grad_norm": 1.8415733575820923,
      "learning_rate": 8.180793276621913e-06,
      "loss": 0.3463,
      "step": 5771
    },
    {
      "epoch": 1.18,
      "grad_norm": 0.8899827003479004,
      "learning_rate": 8.178743466229375e-06,
      "loss": 0.3672,
      "step": 5772
    },
    {
      "epoch": 1.18,
      "grad_norm": 1.2499412298202515,
      "learning_rate": 8.176693655836837e-06,
      "loss": 0.3968,
      "step": 5773
    },
    {
      "epoch": 1.18,
      "grad_norm": 1.1962553262710571,
      "learning_rate": 8.174643845444297e-06,
      "loss": 0.4047,
      "step": 5774
    },
    {
      "epoch": 1.18,
      "grad_norm": 1.4807811975479126,
      "learning_rate": 8.172594035051759e-06,
      "loss": 0.3277,
      "step": 5775
    },
    {
      "epoch": 1.18,
      "grad_norm": 0.8848609328269958,
      "learning_rate": 8.170544224659219e-06,
      "loss": 0.2967,
      "step": 5776
    },
    {
      "epoch": 1.18,
      "grad_norm": 0.9329294562339783,
      "learning_rate": 8.16849441426668e-06,
      "loss": 0.4008,
      "step": 5777
    },
    {
      "epoch": 1.18,
      "grad_norm": 2.3948118686676025,
      "learning_rate": 8.166444603874143e-06,
      "loss": 0.3594,
      "step": 5778
    },
    {
      "epoch": 1.18,
      "grad_norm": 1.511285662651062,
      "learning_rate": 8.164394793481604e-06,
      "loss": 0.3652,
      "step": 5779
    },
    {
      "epoch": 1.18,
      "grad_norm": 2.939652442932129,
      "learning_rate": 8.162344983089065e-06,
      "loss": 0.4302,
      "step": 5780
    },
    {
      "epoch": 1.18,
      "grad_norm": 1.3421553373336792,
      "learning_rate": 8.160295172696527e-06,
      "loss": 0.4183,
      "step": 5781
    },
    {
      "epoch": 1.18,
      "grad_norm": 1.6746644973754883,
      "learning_rate": 8.158245362303987e-06,
      "loss": 0.381,
      "step": 5782
    },
    {
      "epoch": 1.18,
      "grad_norm": 1.7428466081619263,
      "learning_rate": 8.156195551911449e-06,
      "loss": 0.3395,
      "step": 5783
    },
    {
      "epoch": 1.19,
      "grad_norm": 2.4497311115264893,
      "learning_rate": 8.15414574151891e-06,
      "loss": 0.3278,
      "step": 5784
    },
    {
      "epoch": 1.19,
      "grad_norm": 0.8218421339988708,
      "learning_rate": 8.152095931126372e-06,
      "loss": 0.352,
      "step": 5785
    },
    {
      "epoch": 1.19,
      "grad_norm": 1.503185749053955,
      "learning_rate": 8.150046120733834e-06,
      "loss": 0.2774,
      "step": 5786
    },
    {
      "epoch": 1.19,
      "grad_norm": 1.45734441280365,
      "learning_rate": 8.147996310341294e-06,
      "loss": 0.4057,
      "step": 5787
    },
    {
      "epoch": 1.19,
      "grad_norm": 0.7515274286270142,
      "learning_rate": 8.145946499948756e-06,
      "loss": 0.2438,
      "step": 5788
    },
    {
      "epoch": 1.19,
      "grad_norm": 1.15520441532135,
      "learning_rate": 8.143896689556216e-06,
      "loss": 0.3276,
      "step": 5789
    },
    {
      "epoch": 1.19,
      "grad_norm": 1.8533097505569458,
      "learning_rate": 8.141846879163678e-06,
      "loss": 0.3292,
      "step": 5790
    },
    {
      "epoch": 1.19,
      "grad_norm": 2.440875291824341,
      "learning_rate": 8.13979706877114e-06,
      "loss": 0.4833,
      "step": 5791
    },
    {
      "epoch": 1.19,
      "grad_norm": 1.6529215574264526,
      "learning_rate": 8.137747258378602e-06,
      "loss": 0.3868,
      "step": 5792
    },
    {
      "epoch": 1.19,
      "grad_norm": 1.1675434112548828,
      "learning_rate": 8.135697447986062e-06,
      "loss": 0.3206,
      "step": 5793
    },
    {
      "epoch": 1.19,
      "grad_norm": 1.1401864290237427,
      "learning_rate": 8.133647637593524e-06,
      "loss": 0.3399,
      "step": 5794
    },
    {
      "epoch": 1.19,
      "grad_norm": 2.2346596717834473,
      "learning_rate": 8.131597827200984e-06,
      "loss": 0.3544,
      "step": 5795
    },
    {
      "epoch": 1.19,
      "grad_norm": 0.9627009630203247,
      "learning_rate": 8.129548016808446e-06,
      "loss": 0.4404,
      "step": 5796
    },
    {
      "epoch": 1.19,
      "grad_norm": 1.0528525114059448,
      "learning_rate": 8.127498206415908e-06,
      "loss": 0.2867,
      "step": 5797
    },
    {
      "epoch": 1.19,
      "grad_norm": 1.1482659578323364,
      "learning_rate": 8.12544839602337e-06,
      "loss": 0.4681,
      "step": 5798
    },
    {
      "epoch": 1.19,
      "grad_norm": 1.4161242246627808,
      "learning_rate": 8.12339858563083e-06,
      "loss": 0.2283,
      "step": 5799
    },
    {
      "epoch": 1.19,
      "grad_norm": 1.0835129022598267,
      "learning_rate": 8.121348775238292e-06,
      "loss": 0.3515,
      "step": 5800
    },
    {
      "epoch": 1.19,
      "grad_norm": 1.3807824850082397,
      "learning_rate": 8.119298964845752e-06,
      "loss": 0.3956,
      "step": 5801
    },
    {
      "epoch": 1.19,
      "grad_norm": 1.5756500959396362,
      "learning_rate": 8.117249154453214e-06,
      "loss": 0.2858,
      "step": 5802
    },
    {
      "epoch": 1.19,
      "grad_norm": 1.1973828077316284,
      "learning_rate": 8.115199344060675e-06,
      "loss": 0.3775,
      "step": 5803
    },
    {
      "epoch": 1.19,
      "grad_norm": 0.8191805481910706,
      "learning_rate": 8.113149533668137e-06,
      "loss": 0.3719,
      "step": 5804
    },
    {
      "epoch": 1.19,
      "grad_norm": 2.47379732131958,
      "learning_rate": 8.111099723275598e-06,
      "loss": 0.3625,
      "step": 5805
    },
    {
      "epoch": 1.19,
      "grad_norm": 1.437572956085205,
      "learning_rate": 8.10904991288306e-06,
      "loss": 0.3533,
      "step": 5806
    },
    {
      "epoch": 1.19,
      "grad_norm": 1.223362684249878,
      "learning_rate": 8.10700010249052e-06,
      "loss": 0.4675,
      "step": 5807
    },
    {
      "epoch": 1.19,
      "grad_norm": 1.8143967390060425,
      "learning_rate": 8.104950292097981e-06,
      "loss": 0.3984,
      "step": 5808
    },
    {
      "epoch": 1.19,
      "grad_norm": 2.462839126586914,
      "learning_rate": 8.102900481705443e-06,
      "loss": 0.3196,
      "step": 5809
    },
    {
      "epoch": 1.19,
      "grad_norm": 1.3932470083236694,
      "learning_rate": 8.100850671312905e-06,
      "loss": 0.4015,
      "step": 5810
    },
    {
      "epoch": 1.19,
      "grad_norm": 0.9883980751037598,
      "learning_rate": 8.098800860920365e-06,
      "loss": 0.4968,
      "step": 5811
    },
    {
      "epoch": 1.19,
      "grad_norm": 1.0784950256347656,
      "learning_rate": 8.096751050527827e-06,
      "loss": 0.3363,
      "step": 5812
    },
    {
      "epoch": 1.19,
      "grad_norm": 1.0525425672531128,
      "learning_rate": 8.094701240135289e-06,
      "loss": 0.2583,
      "step": 5813
    },
    {
      "epoch": 1.19,
      "grad_norm": 1.011974573135376,
      "learning_rate": 8.092651429742749e-06,
      "loss": 0.4871,
      "step": 5814
    },
    {
      "epoch": 1.19,
      "grad_norm": 1.7782596349716187,
      "learning_rate": 8.090601619350211e-06,
      "loss": 0.3317,
      "step": 5815
    },
    {
      "epoch": 1.19,
      "grad_norm": 0.8864597678184509,
      "learning_rate": 8.088551808957671e-06,
      "loss": 0.3734,
      "step": 5816
    },
    {
      "epoch": 1.19,
      "grad_norm": 2.0944430828094482,
      "learning_rate": 8.086501998565133e-06,
      "loss": 0.3543,
      "step": 5817
    },
    {
      "epoch": 1.19,
      "grad_norm": 1.0628063678741455,
      "learning_rate": 8.084452188172595e-06,
      "loss": 0.2564,
      "step": 5818
    },
    {
      "epoch": 1.19,
      "grad_norm": 1.4069695472717285,
      "learning_rate": 8.082402377780057e-06,
      "loss": 0.227,
      "step": 5819
    },
    {
      "epoch": 1.19,
      "grad_norm": 1.0033727884292603,
      "learning_rate": 8.080352567387517e-06,
      "loss": 0.3159,
      "step": 5820
    },
    {
      "epoch": 1.19,
      "grad_norm": 1.4964193105697632,
      "learning_rate": 8.078302756994979e-06,
      "loss": 0.429,
      "step": 5821
    },
    {
      "epoch": 1.19,
      "grad_norm": 2.7088117599487305,
      "learning_rate": 8.076252946602439e-06,
      "loss": 0.4734,
      "step": 5822
    },
    {
      "epoch": 1.19,
      "grad_norm": 1.842746376991272,
      "learning_rate": 8.0742031362099e-06,
      "loss": 0.3068,
      "step": 5823
    },
    {
      "epoch": 1.19,
      "grad_norm": 1.9387456178665161,
      "learning_rate": 8.072153325817363e-06,
      "loss": 0.2841,
      "step": 5824
    },
    {
      "epoch": 1.19,
      "grad_norm": 1.1830096244812012,
      "learning_rate": 8.070103515424824e-06,
      "loss": 0.3958,
      "step": 5825
    },
    {
      "epoch": 1.19,
      "grad_norm": 3.7823808193206787,
      "learning_rate": 8.068053705032285e-06,
      "loss": 0.5368,
      "step": 5826
    },
    {
      "epoch": 1.19,
      "grad_norm": 1.2774206399917603,
      "learning_rate": 8.066003894639746e-06,
      "loss": 0.297,
      "step": 5827
    },
    {
      "epoch": 1.19,
      "grad_norm": 1.6163557767868042,
      "learning_rate": 8.063954084247207e-06,
      "loss": 0.3571,
      "step": 5828
    },
    {
      "epoch": 1.19,
      "grad_norm": 0.7994360327720642,
      "learning_rate": 8.061904273854669e-06,
      "loss": 0.2507,
      "step": 5829
    },
    {
      "epoch": 1.19,
      "grad_norm": 1.1141043901443481,
      "learning_rate": 8.05985446346213e-06,
      "loss": 0.1565,
      "step": 5830
    },
    {
      "epoch": 1.19,
      "grad_norm": 2.0421195030212402,
      "learning_rate": 8.057804653069592e-06,
      "loss": 0.3912,
      "step": 5831
    },
    {
      "epoch": 1.19,
      "grad_norm": 2.409641981124878,
      "learning_rate": 8.055754842677052e-06,
      "loss": 0.4364,
      "step": 5832
    },
    {
      "epoch": 1.2,
      "grad_norm": 1.5469353199005127,
      "learning_rate": 8.053705032284514e-06,
      "loss": 0.3412,
      "step": 5833
    },
    {
      "epoch": 1.2,
      "grad_norm": 1.043601155281067,
      "learning_rate": 8.051655221891974e-06,
      "loss": 0.3081,
      "step": 5834
    },
    {
      "epoch": 1.2,
      "grad_norm": 1.3965222835540771,
      "learning_rate": 8.049605411499436e-06,
      "loss": 0.2445,
      "step": 5835
    },
    {
      "epoch": 1.2,
      "grad_norm": 0.7798353433609009,
      "learning_rate": 8.047555601106898e-06,
      "loss": 0.2611,
      "step": 5836
    },
    {
      "epoch": 1.2,
      "grad_norm": 0.935926079750061,
      "learning_rate": 8.04550579071436e-06,
      "loss": 0.2119,
      "step": 5837
    },
    {
      "epoch": 1.2,
      "grad_norm": 1.2135920524597168,
      "learning_rate": 8.04345598032182e-06,
      "loss": 0.4094,
      "step": 5838
    },
    {
      "epoch": 1.2,
      "grad_norm": 0.8980136513710022,
      "learning_rate": 8.041406169929282e-06,
      "loss": 0.3965,
      "step": 5839
    },
    {
      "epoch": 1.2,
      "grad_norm": 1.0442878007888794,
      "learning_rate": 8.039356359536742e-06,
      "loss": 0.4216,
      "step": 5840
    },
    {
      "epoch": 1.2,
      "grad_norm": 0.9189984202384949,
      "learning_rate": 8.037306549144204e-06,
      "loss": 0.2501,
      "step": 5841
    },
    {
      "epoch": 1.2,
      "grad_norm": 1.23041832447052,
      "learning_rate": 8.035256738751666e-06,
      "loss": 0.2178,
      "step": 5842
    },
    {
      "epoch": 1.2,
      "grad_norm": 0.8075724244117737,
      "learning_rate": 8.033206928359128e-06,
      "loss": 0.2359,
      "step": 5843
    },
    {
      "epoch": 1.2,
      "grad_norm": 1.4460645914077759,
      "learning_rate": 8.03115711796659e-06,
      "loss": 0.4654,
      "step": 5844
    },
    {
      "epoch": 1.2,
      "grad_norm": 1.462912917137146,
      "learning_rate": 8.02910730757405e-06,
      "loss": 0.5124,
      "step": 5845
    },
    {
      "epoch": 1.2,
      "grad_norm": 1.3252493143081665,
      "learning_rate": 8.027057497181512e-06,
      "loss": 0.333,
      "step": 5846
    },
    {
      "epoch": 1.2,
      "grad_norm": 1.0392860174179077,
      "learning_rate": 8.025007686788972e-06,
      "loss": 0.426,
      "step": 5847
    },
    {
      "epoch": 1.2,
      "grad_norm": 1.099265217781067,
      "learning_rate": 8.022957876396434e-06,
      "loss": 0.2783,
      "step": 5848
    },
    {
      "epoch": 1.2,
      "grad_norm": 1.4450844526290894,
      "learning_rate": 8.020908066003895e-06,
      "loss": 0.406,
      "step": 5849
    },
    {
      "epoch": 1.2,
      "grad_norm": 1.1581556797027588,
      "learning_rate": 8.018858255611357e-06,
      "loss": 0.5003,
      "step": 5850
    },
    {
      "epoch": 1.2,
      "grad_norm": 2.664416790008545,
      "learning_rate": 8.016808445218817e-06,
      "loss": 0.2695,
      "step": 5851
    },
    {
      "epoch": 1.2,
      "grad_norm": 0.9527456164360046,
      "learning_rate": 8.01475863482628e-06,
      "loss": 0.3704,
      "step": 5852
    },
    {
      "epoch": 1.2,
      "grad_norm": 1.310205340385437,
      "learning_rate": 8.01270882443374e-06,
      "loss": 0.3879,
      "step": 5853
    },
    {
      "epoch": 1.2,
      "grad_norm": 1.0398285388946533,
      "learning_rate": 8.010659014041201e-06,
      "loss": 0.3624,
      "step": 5854
    },
    {
      "epoch": 1.2,
      "grad_norm": 0.9194638133049011,
      "learning_rate": 8.008609203648663e-06,
      "loss": 0.3201,
      "step": 5855
    },
    {
      "epoch": 1.2,
      "grad_norm": 1.0572185516357422,
      "learning_rate": 8.006559393256125e-06,
      "loss": 0.3776,
      "step": 5856
    },
    {
      "epoch": 1.2,
      "grad_norm": 1.4335826635360718,
      "learning_rate": 8.004509582863585e-06,
      "loss": 0.316,
      "step": 5857
    },
    {
      "epoch": 1.2,
      "grad_norm": 2.4499671459198,
      "learning_rate": 8.002459772471047e-06,
      "loss": 0.3846,
      "step": 5858
    },
    {
      "epoch": 1.2,
      "grad_norm": 1.0312288999557495,
      "learning_rate": 8.000409962078507e-06,
      "loss": 0.2058,
      "step": 5859
    },
    {
      "epoch": 1.2,
      "grad_norm": 0.8464870452880859,
      "learning_rate": 7.998360151685969e-06,
      "loss": 0.3082,
      "step": 5860
    },
    {
      "epoch": 1.2,
      "grad_norm": 1.8543915748596191,
      "learning_rate": 7.996310341293431e-06,
      "loss": 0.4051,
      "step": 5861
    },
    {
      "epoch": 1.2,
      "grad_norm": 0.9821158647537231,
      "learning_rate": 7.994260530900893e-06,
      "loss": 0.4006,
      "step": 5862
    },
    {
      "epoch": 1.2,
      "grad_norm": 1.2647333145141602,
      "learning_rate": 7.992210720508353e-06,
      "loss": 0.301,
      "step": 5863
    },
    {
      "epoch": 1.2,
      "grad_norm": 1.2808001041412354,
      "learning_rate": 7.990160910115815e-06,
      "loss": 0.3021,
      "step": 5864
    },
    {
      "epoch": 1.2,
      "grad_norm": 1.9013824462890625,
      "learning_rate": 7.988111099723275e-06,
      "loss": 0.3109,
      "step": 5865
    },
    {
      "epoch": 1.2,
      "grad_norm": 0.9554628729820251,
      "learning_rate": 7.986061289330737e-06,
      "loss": 0.2958,
      "step": 5866
    },
    {
      "epoch": 1.2,
      "grad_norm": 2.0182719230651855,
      "learning_rate": 7.984011478938199e-06,
      "loss": 0.4167,
      "step": 5867
    },
    {
      "epoch": 1.2,
      "grad_norm": 2.6966121196746826,
      "learning_rate": 7.98196166854566e-06,
      "loss": 0.4255,
      "step": 5868
    },
    {
      "epoch": 1.2,
      "grad_norm": 1.3721890449523926,
      "learning_rate": 7.97991185815312e-06,
      "loss": 0.4342,
      "step": 5869
    },
    {
      "epoch": 1.2,
      "grad_norm": 2.4743027687072754,
      "learning_rate": 7.977862047760583e-06,
      "loss": 0.4757,
      "step": 5870
    },
    {
      "epoch": 1.2,
      "grad_norm": 1.7776857614517212,
      "learning_rate": 7.975812237368044e-06,
      "loss": 0.3331,
      "step": 5871
    },
    {
      "epoch": 1.2,
      "grad_norm": 1.4946328401565552,
      "learning_rate": 7.973762426975505e-06,
      "loss": 0.3795,
      "step": 5872
    },
    {
      "epoch": 1.2,
      "grad_norm": 1.958506464958191,
      "learning_rate": 7.971712616582966e-06,
      "loss": 0.3797,
      "step": 5873
    },
    {
      "epoch": 1.2,
      "grad_norm": 2.0348665714263916,
      "learning_rate": 7.969662806190428e-06,
      "loss": 0.2483,
      "step": 5874
    },
    {
      "epoch": 1.2,
      "grad_norm": 2.0775303840637207,
      "learning_rate": 7.96761299579789e-06,
      "loss": 0.2452,
      "step": 5875
    },
    {
      "epoch": 1.2,
      "grad_norm": 1.0307868719100952,
      "learning_rate": 7.96556318540535e-06,
      "loss": 0.4413,
      "step": 5876
    },
    {
      "epoch": 1.2,
      "grad_norm": 1.2801660299301147,
      "learning_rate": 7.963513375012812e-06,
      "loss": 0.3153,
      "step": 5877
    },
    {
      "epoch": 1.2,
      "grad_norm": 2.1804723739624023,
      "learning_rate": 7.961463564620272e-06,
      "loss": 0.3161,
      "step": 5878
    },
    {
      "epoch": 1.2,
      "grad_norm": 1.1737053394317627,
      "learning_rate": 7.959413754227734e-06,
      "loss": 0.2488,
      "step": 5879
    },
    {
      "epoch": 1.2,
      "grad_norm": 0.9467177391052246,
      "learning_rate": 7.957363943835196e-06,
      "loss": 0.2648,
      "step": 5880
    },
    {
      "epoch": 1.2,
      "grad_norm": 3.190286874771118,
      "learning_rate": 7.955314133442658e-06,
      "loss": 0.2459,
      "step": 5881
    },
    {
      "epoch": 1.21,
      "grad_norm": 1.5940816402435303,
      "learning_rate": 7.953264323050118e-06,
      "loss": 0.2737,
      "step": 5882
    },
    {
      "epoch": 1.21,
      "grad_norm": 1.3270963430404663,
      "learning_rate": 7.95121451265758e-06,
      "loss": 0.4338,
      "step": 5883
    },
    {
      "epoch": 1.21,
      "grad_norm": 1.339269757270813,
      "learning_rate": 7.94916470226504e-06,
      "loss": 0.2123,
      "step": 5884
    },
    {
      "epoch": 1.21,
      "grad_norm": 0.9714887738227844,
      "learning_rate": 7.947114891872502e-06,
      "loss": 0.4588,
      "step": 5885
    },
    {
      "epoch": 1.21,
      "grad_norm": 1.0069833993911743,
      "learning_rate": 7.945065081479964e-06,
      "loss": 0.4234,
      "step": 5886
    },
    {
      "epoch": 1.21,
      "grad_norm": 1.179855465888977,
      "learning_rate": 7.943015271087426e-06,
      "loss": 0.4979,
      "step": 5887
    },
    {
      "epoch": 1.21,
      "grad_norm": 1.0199519395828247,
      "learning_rate": 7.940965460694886e-06,
      "loss": 0.3211,
      "step": 5888
    },
    {
      "epoch": 1.21,
      "grad_norm": 1.4900572299957275,
      "learning_rate": 7.938915650302348e-06,
      "loss": 0.3605,
      "step": 5889
    },
    {
      "epoch": 1.21,
      "grad_norm": 2.0687942504882812,
      "learning_rate": 7.936865839909808e-06,
      "loss": 0.3458,
      "step": 5890
    },
    {
      "epoch": 1.21,
      "grad_norm": 1.9014126062393188,
      "learning_rate": 7.93481602951727e-06,
      "loss": 0.2924,
      "step": 5891
    },
    {
      "epoch": 1.21,
      "grad_norm": 1.159821629524231,
      "learning_rate": 7.932766219124732e-06,
      "loss": 0.3325,
      "step": 5892
    },
    {
      "epoch": 1.21,
      "grad_norm": 1.4392704963684082,
      "learning_rate": 7.930716408732193e-06,
      "loss": 0.4773,
      "step": 5893
    },
    {
      "epoch": 1.21,
      "grad_norm": 0.8200211524963379,
      "learning_rate": 7.928666598339654e-06,
      "loss": 0.4618,
      "step": 5894
    },
    {
      "epoch": 1.21,
      "grad_norm": 2.3320767879486084,
      "learning_rate": 7.926616787947115e-06,
      "loss": 0.2578,
      "step": 5895
    },
    {
      "epoch": 1.21,
      "grad_norm": 1.5230318307876587,
      "learning_rate": 7.924566977554576e-06,
      "loss": 0.3192,
      "step": 5896
    },
    {
      "epoch": 1.21,
      "grad_norm": 1.1298528909683228,
      "learning_rate": 7.922517167162037e-06,
      "loss": 0.344,
      "step": 5897
    },
    {
      "epoch": 1.21,
      "grad_norm": 1.2070648670196533,
      "learning_rate": 7.9204673567695e-06,
      "loss": 0.313,
      "step": 5898
    },
    {
      "epoch": 1.21,
      "grad_norm": 1.6602505445480347,
      "learning_rate": 7.918417546376961e-06,
      "loss": 0.4474,
      "step": 5899
    },
    {
      "epoch": 1.21,
      "grad_norm": 0.9544450640678406,
      "learning_rate": 7.916367735984421e-06,
      "loss": 0.2418,
      "step": 5900
    },
    {
      "epoch": 1.21,
      "grad_norm": 0.8598228096961975,
      "learning_rate": 7.914317925591883e-06,
      "loss": 0.4012,
      "step": 5901
    },
    {
      "epoch": 1.21,
      "grad_norm": 0.9979849457740784,
      "learning_rate": 7.912268115199345e-06,
      "loss": 0.3572,
      "step": 5902
    },
    {
      "epoch": 1.21,
      "grad_norm": 1.034651279449463,
      "learning_rate": 7.910218304806805e-06,
      "loss": 0.3802,
      "step": 5903
    },
    {
      "epoch": 1.21,
      "grad_norm": 1.473317265510559,
      "learning_rate": 7.908168494414267e-06,
      "loss": 0.3295,
      "step": 5904
    },
    {
      "epoch": 1.21,
      "grad_norm": 1.200205683708191,
      "learning_rate": 7.906118684021729e-06,
      "loss": 0.345,
      "step": 5905
    },
    {
      "epoch": 1.21,
      "grad_norm": 0.8913419842720032,
      "learning_rate": 7.90406887362919e-06,
      "loss": 0.295,
      "step": 5906
    },
    {
      "epoch": 1.21,
      "grad_norm": 1.0645943880081177,
      "learning_rate": 7.902019063236651e-06,
      "loss": 0.3395,
      "step": 5907
    },
    {
      "epoch": 1.21,
      "grad_norm": 1.0499000549316406,
      "learning_rate": 7.899969252844113e-06,
      "loss": 0.4725,
      "step": 5908
    },
    {
      "epoch": 1.21,
      "grad_norm": 1.1597051620483398,
      "learning_rate": 7.897919442451573e-06,
      "loss": 0.3248,
      "step": 5909
    },
    {
      "epoch": 1.21,
      "grad_norm": 0.7729942798614502,
      "learning_rate": 7.895869632059035e-06,
      "loss": 0.2405,
      "step": 5910
    },
    {
      "epoch": 1.21,
      "grad_norm": 1.240461826324463,
      "learning_rate": 7.893819821666497e-06,
      "loss": 0.3559,
      "step": 5911
    },
    {
      "epoch": 1.21,
      "grad_norm": 1.1923502683639526,
      "learning_rate": 7.891770011273959e-06,
      "loss": 0.3489,
      "step": 5912
    },
    {
      "epoch": 1.21,
      "grad_norm": 1.3482542037963867,
      "learning_rate": 7.889720200881419e-06,
      "loss": 0.4282,
      "step": 5913
    },
    {
      "epoch": 1.21,
      "grad_norm": 1.2616822719573975,
      "learning_rate": 7.88767039048888e-06,
      "loss": 0.3316,
      "step": 5914
    },
    {
      "epoch": 1.21,
      "grad_norm": 0.7252165079116821,
      "learning_rate": 7.88562058009634e-06,
      "loss": 0.3133,
      "step": 5915
    },
    {
      "epoch": 1.21,
      "grad_norm": 1.1931648254394531,
      "learning_rate": 7.883570769703803e-06,
      "loss": 0.2591,
      "step": 5916
    },
    {
      "epoch": 1.21,
      "grad_norm": 1.0290473699569702,
      "learning_rate": 7.881520959311264e-06,
      "loss": 0.2156,
      "step": 5917
    },
    {
      "epoch": 1.21,
      "grad_norm": 1.2380921840667725,
      "learning_rate": 7.879471148918726e-06,
      "loss": 0.3052,
      "step": 5918
    },
    {
      "epoch": 1.21,
      "grad_norm": 0.8975645899772644,
      "learning_rate": 7.877421338526186e-06,
      "loss": 0.2917,
      "step": 5919
    },
    {
      "epoch": 1.21,
      "grad_norm": 2.538051128387451,
      "learning_rate": 7.875371528133648e-06,
      "loss": 0.3404,
      "step": 5920
    },
    {
      "epoch": 1.21,
      "grad_norm": 2.44218111038208,
      "learning_rate": 7.873321717741108e-06,
      "loss": 0.323,
      "step": 5921
    },
    {
      "epoch": 1.21,
      "grad_norm": 1.0905762910842896,
      "learning_rate": 7.87127190734857e-06,
      "loss": 0.3652,
      "step": 5922
    },
    {
      "epoch": 1.21,
      "grad_norm": 1.1624412536621094,
      "learning_rate": 7.869222096956032e-06,
      "loss": 0.3095,
      "step": 5923
    },
    {
      "epoch": 1.21,
      "grad_norm": 1.0657416582107544,
      "learning_rate": 7.867172286563494e-06,
      "loss": 0.358,
      "step": 5924
    },
    {
      "epoch": 1.21,
      "grad_norm": 1.3391624689102173,
      "learning_rate": 7.865122476170954e-06,
      "loss": 0.3889,
      "step": 5925
    },
    {
      "epoch": 1.21,
      "grad_norm": 1.779326319694519,
      "learning_rate": 7.863072665778416e-06,
      "loss": 0.2449,
      "step": 5926
    },
    {
      "epoch": 1.21,
      "grad_norm": 2.000471353530884,
      "learning_rate": 7.861022855385876e-06,
      "loss": 0.2325,
      "step": 5927
    },
    {
      "epoch": 1.21,
      "grad_norm": 0.8180689811706543,
      "learning_rate": 7.858973044993338e-06,
      "loss": 0.3833,
      "step": 5928
    },
    {
      "epoch": 1.21,
      "grad_norm": 1.1971622705459595,
      "learning_rate": 7.8569232346008e-06,
      "loss": 0.4317,
      "step": 5929
    },
    {
      "epoch": 1.21,
      "grad_norm": 1.3905243873596191,
      "learning_rate": 7.854873424208262e-06,
      "loss": 0.5606,
      "step": 5930
    },
    {
      "epoch": 1.22,
      "grad_norm": 1.1753623485565186,
      "learning_rate": 7.852823613815724e-06,
      "loss": 0.2263,
      "step": 5931
    },
    {
      "epoch": 1.22,
      "grad_norm": 1.0793899297714233,
      "learning_rate": 7.850773803423184e-06,
      "loss": 0.2596,
      "step": 5932
    },
    {
      "epoch": 1.22,
      "grad_norm": 1.1774799823760986,
      "learning_rate": 7.848723993030646e-06,
      "loss": 0.3248,
      "step": 5933
    },
    {
      "epoch": 1.22,
      "grad_norm": 1.3852953910827637,
      "learning_rate": 7.846674182638106e-06,
      "loss": 0.5342,
      "step": 5934
    },
    {
      "epoch": 1.22,
      "grad_norm": 1.4424386024475098,
      "learning_rate": 7.844624372245568e-06,
      "loss": 0.2875,
      "step": 5935
    },
    {
      "epoch": 1.22,
      "grad_norm": 4.150489807128906,
      "learning_rate": 7.84257456185303e-06,
      "loss": 0.4582,
      "step": 5936
    },
    {
      "epoch": 1.22,
      "grad_norm": 2.236243486404419,
      "learning_rate": 7.840524751460491e-06,
      "loss": 0.2985,
      "step": 5937
    },
    {
      "epoch": 1.22,
      "grad_norm": 1.3167754411697388,
      "learning_rate": 7.838474941067952e-06,
      "loss": 0.3621,
      "step": 5938
    },
    {
      "epoch": 1.22,
      "grad_norm": 1.6122270822525024,
      "learning_rate": 7.836425130675413e-06,
      "loss": 0.2866,
      "step": 5939
    },
    {
      "epoch": 1.22,
      "grad_norm": 1.011765718460083,
      "learning_rate": 7.834375320282874e-06,
      "loss": 0.3787,
      "step": 5940
    },
    {
      "epoch": 1.22,
      "grad_norm": 1.3221598863601685,
      "learning_rate": 7.832325509890335e-06,
      "loss": 0.3292,
      "step": 5941
    },
    {
      "epoch": 1.22,
      "grad_norm": 1.0173619985580444,
      "learning_rate": 7.830275699497797e-06,
      "loss": 0.2148,
      "step": 5942
    },
    {
      "epoch": 1.22,
      "grad_norm": 0.7246554493904114,
      "learning_rate": 7.82822588910526e-06,
      "loss": 0.2712,
      "step": 5943
    },
    {
      "epoch": 1.22,
      "grad_norm": 2.518949508666992,
      "learning_rate": 7.82617607871272e-06,
      "loss": 0.2424,
      "step": 5944
    },
    {
      "epoch": 1.22,
      "grad_norm": 1.3128992319107056,
      "learning_rate": 7.824126268320181e-06,
      "loss": 0.3544,
      "step": 5945
    },
    {
      "epoch": 1.22,
      "grad_norm": 1.1548207998275757,
      "learning_rate": 7.822076457927641e-06,
      "loss": 0.3205,
      "step": 5946
    },
    {
      "epoch": 1.22,
      "grad_norm": 1.7731355428695679,
      "learning_rate": 7.820026647535103e-06,
      "loss": 0.3544,
      "step": 5947
    },
    {
      "epoch": 1.22,
      "grad_norm": 1.129193902015686,
      "learning_rate": 7.817976837142565e-06,
      "loss": 0.3693,
      "step": 5948
    },
    {
      "epoch": 1.22,
      "grad_norm": 1.1118626594543457,
      "learning_rate": 7.815927026750027e-06,
      "loss": 0.4095,
      "step": 5949
    },
    {
      "epoch": 1.22,
      "grad_norm": 1.0325812101364136,
      "learning_rate": 7.813877216357487e-06,
      "loss": 0.4152,
      "step": 5950
    },
    {
      "epoch": 1.22,
      "grad_norm": 1.6059317588806152,
      "learning_rate": 7.811827405964949e-06,
      "loss": 0.4299,
      "step": 5951
    },
    {
      "epoch": 1.22,
      "grad_norm": 0.9337916970252991,
      "learning_rate": 7.809777595572409e-06,
      "loss": 0.3556,
      "step": 5952
    },
    {
      "epoch": 1.22,
      "grad_norm": 1.1887980699539185,
      "learning_rate": 7.807727785179871e-06,
      "loss": 0.4387,
      "step": 5953
    },
    {
      "epoch": 1.22,
      "grad_norm": 1.0976426601409912,
      "learning_rate": 7.805677974787333e-06,
      "loss": 0.3492,
      "step": 5954
    },
    {
      "epoch": 1.22,
      "grad_norm": 2.0383520126342773,
      "learning_rate": 7.803628164394795e-06,
      "loss": 0.4104,
      "step": 5955
    },
    {
      "epoch": 1.22,
      "grad_norm": 1.0361180305480957,
      "learning_rate": 7.801578354002255e-06,
      "loss": 0.3235,
      "step": 5956
    },
    {
      "epoch": 1.22,
      "grad_norm": 1.4149030447006226,
      "learning_rate": 7.799528543609717e-06,
      "loss": 0.4373,
      "step": 5957
    },
    {
      "epoch": 1.22,
      "grad_norm": 1.2622349262237549,
      "learning_rate": 7.797478733217177e-06,
      "loss": 0.4108,
      "step": 5958
    },
    {
      "epoch": 1.22,
      "grad_norm": 0.7635571956634521,
      "learning_rate": 7.795428922824639e-06,
      "loss": 0.2301,
      "step": 5959
    },
    {
      "epoch": 1.22,
      "grad_norm": 1.0226571559906006,
      "learning_rate": 7.7933791124321e-06,
      "loss": 0.3096,
      "step": 5960
    },
    {
      "epoch": 1.22,
      "grad_norm": 1.7219542264938354,
      "learning_rate": 7.791329302039562e-06,
      "loss": 0.4749,
      "step": 5961
    },
    {
      "epoch": 1.22,
      "grad_norm": 0.7924245595932007,
      "learning_rate": 7.789279491647024e-06,
      "loss": 0.3254,
      "step": 5962
    },
    {
      "epoch": 1.22,
      "grad_norm": 1.299128770828247,
      "learning_rate": 7.787229681254484e-06,
      "loss": 0.3852,
      "step": 5963
    },
    {
      "epoch": 1.22,
      "grad_norm": 1.2418601512908936,
      "learning_rate": 7.785179870861946e-06,
      "loss": 0.535,
      "step": 5964
    },
    {
      "epoch": 1.22,
      "grad_norm": 0.8725666999816895,
      "learning_rate": 7.783130060469406e-06,
      "loss": 0.2925,
      "step": 5965
    },
    {
      "epoch": 1.22,
      "grad_norm": 1.4880496263504028,
      "learning_rate": 7.781080250076868e-06,
      "loss": 0.409,
      "step": 5966
    },
    {
      "epoch": 1.22,
      "grad_norm": 1.628973364830017,
      "learning_rate": 7.77903043968433e-06,
      "loss": 0.3915,
      "step": 5967
    },
    {
      "epoch": 1.22,
      "grad_norm": 1.799150824546814,
      "learning_rate": 7.776980629291792e-06,
      "loss": 0.3919,
      "step": 5968
    },
    {
      "epoch": 1.22,
      "grad_norm": 3.8122196197509766,
      "learning_rate": 7.774930818899252e-06,
      "loss": 0.3107,
      "step": 5969
    },
    {
      "epoch": 1.22,
      "grad_norm": 0.7452144026756287,
      "learning_rate": 7.772881008506714e-06,
      "loss": 0.2393,
      "step": 5970
    },
    {
      "epoch": 1.22,
      "grad_norm": 1.5528886318206787,
      "learning_rate": 7.770831198114174e-06,
      "loss": 0.388,
      "step": 5971
    },
    {
      "epoch": 1.22,
      "grad_norm": 0.9562444090843201,
      "learning_rate": 7.768781387721636e-06,
      "loss": 0.3763,
      "step": 5972
    },
    {
      "epoch": 1.22,
      "grad_norm": 0.8182660937309265,
      "learning_rate": 7.766731577329098e-06,
      "loss": 0.3946,
      "step": 5973
    },
    {
      "epoch": 1.22,
      "grad_norm": 1.147010326385498,
      "learning_rate": 7.76468176693656e-06,
      "loss": 0.3072,
      "step": 5974
    },
    {
      "epoch": 1.22,
      "grad_norm": 1.1700130701065063,
      "learning_rate": 7.76263195654402e-06,
      "loss": 0.3772,
      "step": 5975
    },
    {
      "epoch": 1.22,
      "grad_norm": 0.9703452587127686,
      "learning_rate": 7.760582146151482e-06,
      "loss": 0.3287,
      "step": 5976
    },
    {
      "epoch": 1.22,
      "grad_norm": 0.9172565340995789,
      "learning_rate": 7.758532335758942e-06,
      "loss": 0.4105,
      "step": 5977
    },
    {
      "epoch": 1.22,
      "grad_norm": 1.1560633182525635,
      "learning_rate": 7.756482525366404e-06,
      "loss": 0.512,
      "step": 5978
    },
    {
      "epoch": 1.22,
      "grad_norm": 1.1842528581619263,
      "learning_rate": 7.754432714973866e-06,
      "loss": 0.446,
      "step": 5979
    },
    {
      "epoch": 1.23,
      "grad_norm": 1.398564338684082,
      "learning_rate": 7.752382904581328e-06,
      "loss": 0.3703,
      "step": 5980
    },
    {
      "epoch": 1.23,
      "grad_norm": 1.6336877346038818,
      "learning_rate": 7.750333094188788e-06,
      "loss": 0.1963,
      "step": 5981
    },
    {
      "epoch": 1.23,
      "grad_norm": 1.2720069885253906,
      "learning_rate": 7.74828328379625e-06,
      "loss": 0.294,
      "step": 5982
    },
    {
      "epoch": 1.23,
      "grad_norm": 1.1146653890609741,
      "learning_rate": 7.74623347340371e-06,
      "loss": 0.2594,
      "step": 5983
    },
    {
      "epoch": 1.23,
      "grad_norm": 0.7958775162696838,
      "learning_rate": 7.744183663011172e-06,
      "loss": 0.2405,
      "step": 5984
    },
    {
      "epoch": 1.23,
      "grad_norm": 1.1284390687942505,
      "learning_rate": 7.742133852618633e-06,
      "loss": 0.4259,
      "step": 5985
    },
    {
      "epoch": 1.23,
      "grad_norm": 1.4944525957107544,
      "learning_rate": 7.740084042226095e-06,
      "loss": 0.2331,
      "step": 5986
    },
    {
      "epoch": 1.23,
      "grad_norm": 1.054187536239624,
      "learning_rate": 7.738034231833555e-06,
      "loss": 0.287,
      "step": 5987
    },
    {
      "epoch": 1.23,
      "grad_norm": 0.9054927825927734,
      "learning_rate": 7.735984421441017e-06,
      "loss": 0.268,
      "step": 5988
    },
    {
      "epoch": 1.23,
      "grad_norm": 1.0956199169158936,
      "learning_rate": 7.733934611048479e-06,
      "loss": 0.3981,
      "step": 5989
    },
    {
      "epoch": 1.23,
      "grad_norm": 1.412317156791687,
      "learning_rate": 7.73188480065594e-06,
      "loss": 0.4776,
      "step": 5990
    },
    {
      "epoch": 1.23,
      "grad_norm": 1.7917091846466064,
      "learning_rate": 7.729834990263401e-06,
      "loss": 0.4147,
      "step": 5991
    },
    {
      "epoch": 1.23,
      "grad_norm": 1.1938419342041016,
      "learning_rate": 7.727785179870863e-06,
      "loss": 0.3536,
      "step": 5992
    },
    {
      "epoch": 1.23,
      "grad_norm": 1.2467074394226074,
      "learning_rate": 7.725735369478325e-06,
      "loss": 0.3022,
      "step": 5993
    },
    {
      "epoch": 1.23,
      "grad_norm": 1.9667781591415405,
      "learning_rate": 7.723685559085785e-06,
      "loss": 0.4573,
      "step": 5994
    },
    {
      "epoch": 1.23,
      "grad_norm": 1.062414288520813,
      "learning_rate": 7.721635748693247e-06,
      "loss": 0.4273,
      "step": 5995
    },
    {
      "epoch": 1.23,
      "grad_norm": 2.318415641784668,
      "learning_rate": 7.719585938300707e-06,
      "loss": 0.3793,
      "step": 5996
    },
    {
      "epoch": 1.23,
      "grad_norm": 1.2433946132659912,
      "learning_rate": 7.717536127908169e-06,
      "loss": 0.3985,
      "step": 5997
    },
    {
      "epoch": 1.23,
      "grad_norm": 1.4953771829605103,
      "learning_rate": 7.71548631751563e-06,
      "loss": 0.3951,
      "step": 5998
    },
    {
      "epoch": 1.23,
      "grad_norm": 1.0500524044036865,
      "learning_rate": 7.713436507123093e-06,
      "loss": 0.3675,
      "step": 5999
    },
    {
      "epoch": 1.23,
      "grad_norm": 1.2023862600326538,
      "learning_rate": 7.711386696730553e-06,
      "loss": 0.4247,
      "step": 6000
    },
    {
      "epoch": 1.23,
      "eval_loss": 0.3582344055175781,
      "eval_runtime": 668.4735,
      "eval_samples_per_second": 14.959,
      "eval_steps_per_second": 1.87,
      "step": 6000
    },
    {
      "epoch": 1.23,
      "grad_norm": 1.4629780054092407,
      "learning_rate": 7.709336886338015e-06,
      "loss": 0.4179,
      "step": 6001
    },
    {
      "epoch": 1.23,
      "grad_norm": 1.0961158275604248,
      "learning_rate": 7.707287075945475e-06,
      "loss": 0.3781,
      "step": 6002
    },
    {
      "epoch": 1.23,
      "grad_norm": 1.3030203580856323,
      "learning_rate": 7.705237265552937e-06,
      "loss": 0.4663,
      "step": 6003
    },
    {
      "epoch": 1.23,
      "grad_norm": 0.9237304329872131,
      "learning_rate": 7.703187455160399e-06,
      "loss": 0.355,
      "step": 6004
    },
    {
      "epoch": 1.23,
      "grad_norm": 0.9249173402786255,
      "learning_rate": 7.70113764476786e-06,
      "loss": 0.2182,
      "step": 6005
    },
    {
      "epoch": 1.23,
      "grad_norm": 1.5469671487808228,
      "learning_rate": 7.69908783437532e-06,
      "loss": 0.4719,
      "step": 6006
    },
    {
      "epoch": 1.23,
      "grad_norm": 1.481627345085144,
      "learning_rate": 7.697038023982782e-06,
      "loss": 0.321,
      "step": 6007
    },
    {
      "epoch": 1.23,
      "grad_norm": 0.9554252624511719,
      "learning_rate": 7.694988213590243e-06,
      "loss": 0.2299,
      "step": 6008
    },
    {
      "epoch": 1.23,
      "grad_norm": 0.7746432423591614,
      "learning_rate": 7.692938403197704e-06,
      "loss": 0.3178,
      "step": 6009
    },
    {
      "epoch": 1.23,
      "grad_norm": 0.8853917717933655,
      "learning_rate": 7.690888592805166e-06,
      "loss": 0.2433,
      "step": 6010
    },
    {
      "epoch": 1.23,
      "grad_norm": 1.0977675914764404,
      "learning_rate": 7.688838782412628e-06,
      "loss": 0.3901,
      "step": 6011
    },
    {
      "epoch": 1.23,
      "grad_norm": 0.9359238147735596,
      "learning_rate": 7.686788972020088e-06,
      "loss": 0.302,
      "step": 6012
    },
    {
      "epoch": 1.23,
      "grad_norm": 1.1946805715560913,
      "learning_rate": 7.68473916162755e-06,
      "loss": 0.3476,
      "step": 6013
    },
    {
      "epoch": 1.23,
      "grad_norm": 1.511844515800476,
      "learning_rate": 7.68268935123501e-06,
      "loss": 0.3753,
      "step": 6014
    },
    {
      "epoch": 1.23,
      "grad_norm": 0.7833101749420166,
      "learning_rate": 7.680639540842472e-06,
      "loss": 0.3902,
      "step": 6015
    },
    {
      "epoch": 1.23,
      "grad_norm": 1.297032356262207,
      "learning_rate": 7.678589730449934e-06,
      "loss": 0.34,
      "step": 6016
    },
    {
      "epoch": 1.23,
      "grad_norm": 3.1625733375549316,
      "learning_rate": 7.676539920057396e-06,
      "loss": 0.4386,
      "step": 6017
    },
    {
      "epoch": 1.23,
      "grad_norm": 1.074458122253418,
      "learning_rate": 7.674490109664856e-06,
      "loss": 0.4669,
      "step": 6018
    },
    {
      "epoch": 1.23,
      "grad_norm": 1.0559699535369873,
      "learning_rate": 7.672440299272318e-06,
      "loss": 0.4153,
      "step": 6019
    },
    {
      "epoch": 1.23,
      "grad_norm": 4.215511322021484,
      "learning_rate": 7.67039048887978e-06,
      "loss": 0.4809,
      "step": 6020
    },
    {
      "epoch": 1.23,
      "grad_norm": 2.770275831222534,
      "learning_rate": 7.66834067848724e-06,
      "loss": 0.3714,
      "step": 6021
    },
    {
      "epoch": 1.23,
      "grad_norm": 1.1980587244033813,
      "learning_rate": 7.666290868094702e-06,
      "loss": 0.428,
      "step": 6022
    },
    {
      "epoch": 1.23,
      "grad_norm": 0.8973923325538635,
      "learning_rate": 7.664241057702164e-06,
      "loss": 0.3271,
      "step": 6023
    },
    {
      "epoch": 1.23,
      "grad_norm": 0.7819594740867615,
      "learning_rate": 7.662191247309625e-06,
      "loss": 0.1302,
      "step": 6024
    },
    {
      "epoch": 1.23,
      "grad_norm": 0.6533764004707336,
      "learning_rate": 7.660141436917086e-06,
      "loss": 0.2625,
      "step": 6025
    },
    {
      "epoch": 1.23,
      "grad_norm": 2.7884585857391357,
      "learning_rate": 7.658091626524548e-06,
      "loss": 0.4175,
      "step": 6026
    },
    {
      "epoch": 1.23,
      "grad_norm": 1.2336727380752563,
      "learning_rate": 7.656041816132008e-06,
      "loss": 0.4681,
      "step": 6027
    },
    {
      "epoch": 1.23,
      "grad_norm": 2.517866373062134,
      "learning_rate": 7.65399200573947e-06,
      "loss": 0.3394,
      "step": 6028
    },
    {
      "epoch": 1.24,
      "grad_norm": 1.2293211221694946,
      "learning_rate": 7.651942195346931e-06,
      "loss": 0.4044,
      "step": 6029
    },
    {
      "epoch": 1.24,
      "grad_norm": 1.2757363319396973,
      "learning_rate": 7.649892384954393e-06,
      "loss": 0.2476,
      "step": 6030
    },
    {
      "epoch": 1.24,
      "grad_norm": 1.4126027822494507,
      "learning_rate": 7.647842574561853e-06,
      "loss": 0.489,
      "step": 6031
    },
    {
      "epoch": 1.24,
      "grad_norm": 1.3065917491912842,
      "learning_rate": 7.645792764169315e-06,
      "loss": 0.4428,
      "step": 6032
    },
    {
      "epoch": 1.24,
      "grad_norm": 1.6445355415344238,
      "learning_rate": 7.643742953776775e-06,
      "loss": 0.3626,
      "step": 6033
    },
    {
      "epoch": 1.24,
      "grad_norm": 0.9694370627403259,
      "learning_rate": 7.641693143384237e-06,
      "loss": 0.3686,
      "step": 6034
    },
    {
      "epoch": 1.24,
      "grad_norm": 1.49483060836792,
      "learning_rate": 7.639643332991699e-06,
      "loss": 0.3324,
      "step": 6035
    },
    {
      "epoch": 1.24,
      "grad_norm": 2.277387857437134,
      "learning_rate": 7.637593522599161e-06,
      "loss": 0.4385,
      "step": 6036
    },
    {
      "epoch": 1.24,
      "grad_norm": 2.329679012298584,
      "learning_rate": 7.635543712206621e-06,
      "loss": 0.5122,
      "step": 6037
    },
    {
      "epoch": 1.24,
      "grad_norm": 0.9261133074760437,
      "learning_rate": 7.633493901814083e-06,
      "loss": 0.2151,
      "step": 6038
    },
    {
      "epoch": 1.24,
      "grad_norm": 1.1290209293365479,
      "learning_rate": 7.631444091421543e-06,
      "loss": 0.4346,
      "step": 6039
    },
    {
      "epoch": 1.24,
      "grad_norm": 1.272766351699829,
      "learning_rate": 7.629394281029006e-06,
      "loss": 0.3138,
      "step": 6040
    },
    {
      "epoch": 1.24,
      "grad_norm": 1.4689148664474487,
      "learning_rate": 7.627344470636466e-06,
      "loss": 0.5019,
      "step": 6041
    },
    {
      "epoch": 1.24,
      "grad_norm": 1.5548063516616821,
      "learning_rate": 7.625294660243928e-06,
      "loss": 0.2931,
      "step": 6042
    },
    {
      "epoch": 1.24,
      "grad_norm": 1.0322450399398804,
      "learning_rate": 7.623244849851389e-06,
      "loss": 0.362,
      "step": 6043
    },
    {
      "epoch": 1.24,
      "grad_norm": 1.8903580904006958,
      "learning_rate": 7.621195039458851e-06,
      "loss": 0.2827,
      "step": 6044
    },
    {
      "epoch": 1.24,
      "grad_norm": 1.330560564994812,
      "learning_rate": 7.619145229066312e-06,
      "loss": 0.4164,
      "step": 6045
    },
    {
      "epoch": 1.24,
      "grad_norm": 1.0155746936798096,
      "learning_rate": 7.617095418673774e-06,
      "loss": 0.3252,
      "step": 6046
    },
    {
      "epoch": 1.24,
      "grad_norm": 0.9378849267959595,
      "learning_rate": 7.615045608281234e-06,
      "loss": 0.3823,
      "step": 6047
    },
    {
      "epoch": 1.24,
      "grad_norm": 1.2785571813583374,
      "learning_rate": 7.612995797888696e-06,
      "loss": 0.2588,
      "step": 6048
    },
    {
      "epoch": 1.24,
      "grad_norm": 1.417764663696289,
      "learning_rate": 7.6109459874961575e-06,
      "loss": 0.2789,
      "step": 6049
    },
    {
      "epoch": 1.24,
      "grad_norm": 1.1254456043243408,
      "learning_rate": 7.6088961771036185e-06,
      "loss": 0.3736,
      "step": 6050
    },
    {
      "epoch": 1.24,
      "grad_norm": 1.123751163482666,
      "learning_rate": 7.60684636671108e-06,
      "loss": 0.3211,
      "step": 6051
    },
    {
      "epoch": 1.24,
      "grad_norm": 1.3533908128738403,
      "learning_rate": 7.604796556318541e-06,
      "loss": 0.4158,
      "step": 6052
    },
    {
      "epoch": 1.24,
      "grad_norm": 1.5180854797363281,
      "learning_rate": 7.602746745926003e-06,
      "loss": 0.2838,
      "step": 6053
    },
    {
      "epoch": 1.24,
      "grad_norm": 1.2368956804275513,
      "learning_rate": 7.600696935533463e-06,
      "loss": 0.365,
      "step": 6054
    },
    {
      "epoch": 1.24,
      "grad_norm": 1.6587457656860352,
      "learning_rate": 7.598647125140925e-06,
      "loss": 0.3941,
      "step": 6055
    },
    {
      "epoch": 1.24,
      "grad_norm": 1.34086275100708,
      "learning_rate": 7.596597314748386e-06,
      "loss": 0.4715,
      "step": 6056
    },
    {
      "epoch": 1.24,
      "grad_norm": 0.9965716004371643,
      "learning_rate": 7.594547504355848e-06,
      "loss": 0.2019,
      "step": 6057
    },
    {
      "epoch": 1.24,
      "grad_norm": 1.2675625085830688,
      "learning_rate": 7.592497693963309e-06,
      "loss": 0.387,
      "step": 6058
    },
    {
      "epoch": 1.24,
      "grad_norm": 0.7160002589225769,
      "learning_rate": 7.590447883570771e-06,
      "loss": 0.3175,
      "step": 6059
    },
    {
      "epoch": 1.24,
      "grad_norm": 0.8506023287773132,
      "learning_rate": 7.588398073178231e-06,
      "loss": 0.3097,
      "step": 6060
    },
    {
      "epoch": 1.24,
      "grad_norm": 1.7833609580993652,
      "learning_rate": 7.586348262785693e-06,
      "loss": 0.4106,
      "step": 6061
    },
    {
      "epoch": 1.24,
      "grad_norm": 2.174942970275879,
      "learning_rate": 7.584298452393154e-06,
      "loss": 0.4398,
      "step": 6062
    },
    {
      "epoch": 1.24,
      "grad_norm": 1.2300268411636353,
      "learning_rate": 7.582248642000616e-06,
      "loss": 0.392,
      "step": 6063
    },
    {
      "epoch": 1.24,
      "grad_norm": 0.8002959489822388,
      "learning_rate": 7.580198831608077e-06,
      "loss": 0.3404,
      "step": 6064
    },
    {
      "epoch": 1.24,
      "grad_norm": 1.3169435262680054,
      "learning_rate": 7.578149021215539e-06,
      "loss": 0.4631,
      "step": 6065
    },
    {
      "epoch": 1.24,
      "grad_norm": 0.9265027046203613,
      "learning_rate": 7.576099210822999e-06,
      "loss": 0.2857,
      "step": 6066
    },
    {
      "epoch": 1.24,
      "grad_norm": 0.9396361708641052,
      "learning_rate": 7.574049400430461e-06,
      "loss": 0.4632,
      "step": 6067
    },
    {
      "epoch": 1.24,
      "grad_norm": 1.238382339477539,
      "learning_rate": 7.571999590037922e-06,
      "loss": 0.4373,
      "step": 6068
    },
    {
      "epoch": 1.24,
      "grad_norm": 1.0094505548477173,
      "learning_rate": 7.569949779645384e-06,
      "loss": 0.4258,
      "step": 6069
    },
    {
      "epoch": 1.24,
      "grad_norm": 1.4057904481887817,
      "learning_rate": 7.567899969252845e-06,
      "loss": 0.3998,
      "step": 6070
    },
    {
      "epoch": 1.24,
      "grad_norm": 1.8168681859970093,
      "learning_rate": 7.5658501588603065e-06,
      "loss": 0.5047,
      "step": 6071
    },
    {
      "epoch": 1.24,
      "grad_norm": 1.7121881246566772,
      "learning_rate": 7.563800348467767e-06,
      "loss": 0.3038,
      "step": 6072
    },
    {
      "epoch": 1.24,
      "grad_norm": 1.4378784894943237,
      "learning_rate": 7.5617505380752285e-06,
      "loss": 0.3895,
      "step": 6073
    },
    {
      "epoch": 1.24,
      "grad_norm": 2.0708653926849365,
      "learning_rate": 7.5597007276826895e-06,
      "loss": 0.5605,
      "step": 6074
    },
    {
      "epoch": 1.24,
      "grad_norm": 2.459028959274292,
      "learning_rate": 7.557650917290151e-06,
      "loss": 0.2924,
      "step": 6075
    },
    {
      "epoch": 1.24,
      "grad_norm": 1.2925467491149902,
      "learning_rate": 7.555601106897612e-06,
      "loss": 0.4789,
      "step": 6076
    },
    {
      "epoch": 1.25,
      "grad_norm": 1.0948270559310913,
      "learning_rate": 7.553551296505074e-06,
      "loss": 0.3506,
      "step": 6077
    },
    {
      "epoch": 1.25,
      "grad_norm": 3.642202377319336,
      "learning_rate": 7.551501486112536e-06,
      "loss": 0.265,
      "step": 6078
    },
    {
      "epoch": 1.25,
      "grad_norm": 2.3409383296966553,
      "learning_rate": 7.549451675719996e-06,
      "loss": 0.2399,
      "step": 6079
    },
    {
      "epoch": 1.25,
      "grad_norm": 1.0201764106750488,
      "learning_rate": 7.547401865327458e-06,
      "loss": 0.2489,
      "step": 6080
    },
    {
      "epoch": 1.25,
      "grad_norm": 1.049809455871582,
      "learning_rate": 7.545352054934919e-06,
      "loss": 0.2414,
      "step": 6081
    },
    {
      "epoch": 1.25,
      "grad_norm": 1.2050583362579346,
      "learning_rate": 7.543302244542381e-06,
      "loss": 0.3279,
      "step": 6082
    },
    {
      "epoch": 1.25,
      "grad_norm": 2.2871406078338623,
      "learning_rate": 7.541252434149842e-06,
      "loss": 0.4145,
      "step": 6083
    },
    {
      "epoch": 1.25,
      "grad_norm": 0.9266756772994995,
      "learning_rate": 7.539202623757304e-06,
      "loss": 0.2205,
      "step": 6084
    },
    {
      "epoch": 1.25,
      "grad_norm": 1.096475601196289,
      "learning_rate": 7.537152813364764e-06,
      "loss": 0.3892,
      "step": 6085
    },
    {
      "epoch": 1.25,
      "grad_norm": 1.1663447618484497,
      "learning_rate": 7.535103002972226e-06,
      "loss": 0.3899,
      "step": 6086
    },
    {
      "epoch": 1.25,
      "grad_norm": 1.469786524772644,
      "learning_rate": 7.533053192579687e-06,
      "loss": 0.3074,
      "step": 6087
    },
    {
      "epoch": 1.25,
      "grad_norm": 0.9048497676849365,
      "learning_rate": 7.531003382187149e-06,
      "loss": 0.3329,
      "step": 6088
    },
    {
      "epoch": 1.25,
      "grad_norm": 1.0783976316452026,
      "learning_rate": 7.52895357179461e-06,
      "loss": 0.3248,
      "step": 6089
    },
    {
      "epoch": 1.25,
      "grad_norm": 2.207782745361328,
      "learning_rate": 7.526903761402072e-06,
      "loss": 0.2942,
      "step": 6090
    },
    {
      "epoch": 1.25,
      "grad_norm": 1.4822860956192017,
      "learning_rate": 7.524853951009532e-06,
      "loss": 0.3793,
      "step": 6091
    },
    {
      "epoch": 1.25,
      "grad_norm": 0.8851790428161621,
      "learning_rate": 7.522804140616994e-06,
      "loss": 0.1855,
      "step": 6092
    },
    {
      "epoch": 1.25,
      "grad_norm": 1.1679348945617676,
      "learning_rate": 7.520754330224455e-06,
      "loss": 0.3761,
      "step": 6093
    },
    {
      "epoch": 1.25,
      "grad_norm": 1.8913462162017822,
      "learning_rate": 7.5187045198319165e-06,
      "loss": 0.4035,
      "step": 6094
    },
    {
      "epoch": 1.25,
      "grad_norm": 1.7817864418029785,
      "learning_rate": 7.5166547094393775e-06,
      "loss": 0.3615,
      "step": 6095
    },
    {
      "epoch": 1.25,
      "grad_norm": 1.4453991651535034,
      "learning_rate": 7.514604899046839e-06,
      "loss": 0.488,
      "step": 6096
    },
    {
      "epoch": 1.25,
      "grad_norm": 2.986436605453491,
      "learning_rate": 7.5125550886542995e-06,
      "loss": 0.3223,
      "step": 6097
    },
    {
      "epoch": 1.25,
      "grad_norm": 2.744083881378174,
      "learning_rate": 7.510505278261761e-06,
      "loss": 0.2937,
      "step": 6098
    },
    {
      "epoch": 1.25,
      "grad_norm": 2.794621229171753,
      "learning_rate": 7.508455467869222e-06,
      "loss": 0.3517,
      "step": 6099
    },
    {
      "epoch": 1.25,
      "grad_norm": 1.282046914100647,
      "learning_rate": 7.506405657476684e-06,
      "loss": 0.3818,
      "step": 6100
    },
    {
      "epoch": 1.25,
      "grad_norm": 1.6661255359649658,
      "learning_rate": 7.504355847084145e-06,
      "loss": 0.3257,
      "step": 6101
    },
    {
      "epoch": 1.25,
      "grad_norm": 3.0538904666900635,
      "learning_rate": 7.502306036691607e-06,
      "loss": 0.3347,
      "step": 6102
    },
    {
      "epoch": 1.25,
      "grad_norm": 1.1768099069595337,
      "learning_rate": 7.500256226299067e-06,
      "loss": 0.5294,
      "step": 6103
    },
    {
      "epoch": 1.25,
      "grad_norm": 1.6101161241531372,
      "learning_rate": 7.498206415906529e-06,
      "loss": 0.3752,
      "step": 6104
    },
    {
      "epoch": 1.25,
      "grad_norm": 0.9943408966064453,
      "learning_rate": 7.49615660551399e-06,
      "loss": 0.3276,
      "step": 6105
    },
    {
      "epoch": 1.25,
      "grad_norm": 1.4638210535049438,
      "learning_rate": 7.494106795121452e-06,
      "loss": 0.257,
      "step": 6106
    },
    {
      "epoch": 1.25,
      "grad_norm": 1.8665646314620972,
      "learning_rate": 7.492056984728914e-06,
      "loss": 0.1921,
      "step": 6107
    },
    {
      "epoch": 1.25,
      "grad_norm": 1.3225558996200562,
      "learning_rate": 7.490007174336375e-06,
      "loss": 0.3018,
      "step": 6108
    },
    {
      "epoch": 1.25,
      "grad_norm": 1.1648145914077759,
      "learning_rate": 7.487957363943837e-06,
      "loss": 0.2828,
      "step": 6109
    },
    {
      "epoch": 1.25,
      "grad_norm": 0.8569376468658447,
      "learning_rate": 7.485907553551297e-06,
      "loss": 0.3477,
      "step": 6110
    },
    {
      "epoch": 1.25,
      "grad_norm": 1.3648567199707031,
      "learning_rate": 7.483857743158759e-06,
      "loss": 0.3586,
      "step": 6111
    },
    {
      "epoch": 1.25,
      "grad_norm": 0.7982712388038635,
      "learning_rate": 7.48180793276622e-06,
      "loss": 0.2904,
      "step": 6112
    },
    {
      "epoch": 1.25,
      "grad_norm": 1.2151621580123901,
      "learning_rate": 7.4797581223736816e-06,
      "loss": 0.3902,
      "step": 6113
    },
    {
      "epoch": 1.25,
      "grad_norm": 1.8127716779708862,
      "learning_rate": 7.477708311981143e-06,
      "loss": 0.4122,
      "step": 6114
    },
    {
      "epoch": 1.25,
      "grad_norm": 2.018122673034668,
      "learning_rate": 7.4756585015886044e-06,
      "loss": 0.3288,
      "step": 6115
    },
    {
      "epoch": 1.25,
      "grad_norm": 1.146249771118164,
      "learning_rate": 7.473608691196065e-06,
      "loss": 0.3039,
      "step": 6116
    },
    {
      "epoch": 1.25,
      "grad_norm": 0.9973404407501221,
      "learning_rate": 7.4715588808035265e-06,
      "loss": 0.4124,
      "step": 6117
    },
    {
      "epoch": 1.25,
      "grad_norm": 2.064298629760742,
      "learning_rate": 7.4695090704109875e-06,
      "loss": 0.3922,
      "step": 6118
    },
    {
      "epoch": 1.25,
      "grad_norm": 1.1841468811035156,
      "learning_rate": 7.467459260018449e-06,
      "loss": 0.48,
      "step": 6119
    },
    {
      "epoch": 1.25,
      "grad_norm": 1.8161373138427734,
      "learning_rate": 7.46540944962591e-06,
      "loss": 0.4918,
      "step": 6120
    },
    {
      "epoch": 1.25,
      "grad_norm": 1.3946356773376465,
      "learning_rate": 7.463359639233372e-06,
      "loss": 0.2963,
      "step": 6121
    },
    {
      "epoch": 1.25,
      "grad_norm": 1.1909434795379639,
      "learning_rate": 7.461309828840832e-06,
      "loss": 0.3515,
      "step": 6122
    },
    {
      "epoch": 1.25,
      "grad_norm": 0.9462702870368958,
      "learning_rate": 7.459260018448294e-06,
      "loss": 0.3154,
      "step": 6123
    },
    {
      "epoch": 1.25,
      "grad_norm": 1.191348671913147,
      "learning_rate": 7.457210208055755e-06,
      "loss": 0.4041,
      "step": 6124
    },
    {
      "epoch": 1.25,
      "grad_norm": 1.639058232307434,
      "learning_rate": 7.455160397663217e-06,
      "loss": 0.355,
      "step": 6125
    },
    {
      "epoch": 1.26,
      "grad_norm": 1.6172350645065308,
      "learning_rate": 7.453110587270678e-06,
      "loss": 0.2515,
      "step": 6126
    },
    {
      "epoch": 1.26,
      "grad_norm": 1.0041242837905884,
      "learning_rate": 7.45106077687814e-06,
      "loss": 0.4177,
      "step": 6127
    },
    {
      "epoch": 1.26,
      "grad_norm": 1.5795435905456543,
      "learning_rate": 7.4490109664856e-06,
      "loss": 0.3905,
      "step": 6128
    },
    {
      "epoch": 1.26,
      "grad_norm": 2.2620701789855957,
      "learning_rate": 7.446961156093062e-06,
      "loss": 0.4272,
      "step": 6129
    },
    {
      "epoch": 1.26,
      "grad_norm": 1.2541735172271729,
      "learning_rate": 7.444911345700523e-06,
      "loss": 0.4756,
      "step": 6130
    },
    {
      "epoch": 1.26,
      "grad_norm": 1.0703116655349731,
      "learning_rate": 7.442861535307985e-06,
      "loss": 0.3586,
      "step": 6131
    },
    {
      "epoch": 1.26,
      "grad_norm": 1.5099068880081177,
      "learning_rate": 7.440811724915446e-06,
      "loss": 0.2677,
      "step": 6132
    },
    {
      "epoch": 1.26,
      "grad_norm": 1.0381141901016235,
      "learning_rate": 7.438761914522908e-06,
      "loss": 0.3981,
      "step": 6133
    },
    {
      "epoch": 1.26,
      "grad_norm": 2.0360069274902344,
      "learning_rate": 7.436712104130368e-06,
      "loss": 0.3832,
      "step": 6134
    },
    {
      "epoch": 1.26,
      "grad_norm": 0.8028723001480103,
      "learning_rate": 7.43466229373783e-06,
      "loss": 0.3056,
      "step": 6135
    },
    {
      "epoch": 1.26,
      "grad_norm": 1.2188109159469604,
      "learning_rate": 7.432612483345291e-06,
      "loss": 0.3517,
      "step": 6136
    },
    {
      "epoch": 1.26,
      "grad_norm": 1.2883684635162354,
      "learning_rate": 7.4305626729527526e-06,
      "loss": 0.3721,
      "step": 6137
    },
    {
      "epoch": 1.26,
      "grad_norm": 1.308083176612854,
      "learning_rate": 7.4285128625602144e-06,
      "loss": 0.1945,
      "step": 6138
    },
    {
      "epoch": 1.26,
      "grad_norm": 1.076026439666748,
      "learning_rate": 7.4264630521676754e-06,
      "loss": 0.4388,
      "step": 6139
    },
    {
      "epoch": 1.26,
      "grad_norm": 1.2963975667953491,
      "learning_rate": 7.424413241775137e-06,
      "loss": 0.4496,
      "step": 6140
    },
    {
      "epoch": 1.26,
      "grad_norm": 0.7584338784217834,
      "learning_rate": 7.4223634313825975e-06,
      "loss": 0.2919,
      "step": 6141
    },
    {
      "epoch": 1.26,
      "grad_norm": 1.4699571132659912,
      "learning_rate": 7.420313620990059e-06,
      "loss": 0.3404,
      "step": 6142
    },
    {
      "epoch": 1.26,
      "grad_norm": 1.0861061811447144,
      "learning_rate": 7.41826381059752e-06,
      "loss": 0.3793,
      "step": 6143
    },
    {
      "epoch": 1.26,
      "grad_norm": 1.088779330253601,
      "learning_rate": 7.416214000204982e-06,
      "loss": 0.336,
      "step": 6144
    },
    {
      "epoch": 1.26,
      "grad_norm": 1.0794601440429688,
      "learning_rate": 7.414164189812443e-06,
      "loss": 0.4048,
      "step": 6145
    },
    {
      "epoch": 1.26,
      "grad_norm": 1.9108812808990479,
      "learning_rate": 7.412114379419905e-06,
      "loss": 0.2995,
      "step": 6146
    },
    {
      "epoch": 1.26,
      "grad_norm": 1.5580017566680908,
      "learning_rate": 7.410064569027365e-06,
      "loss": 0.3992,
      "step": 6147
    },
    {
      "epoch": 1.26,
      "grad_norm": 1.6101807355880737,
      "learning_rate": 7.408014758634827e-06,
      "loss": 0.3372,
      "step": 6148
    },
    {
      "epoch": 1.26,
      "grad_norm": 1.591726303100586,
      "learning_rate": 7.405964948242288e-06,
      "loss": 0.4483,
      "step": 6149
    },
    {
      "epoch": 1.26,
      "grad_norm": 1.0742204189300537,
      "learning_rate": 7.40391513784975e-06,
      "loss": 0.447,
      "step": 6150
    },
    {
      "epoch": 1.26,
      "grad_norm": 1.1515237092971802,
      "learning_rate": 7.401865327457211e-06,
      "loss": 0.4352,
      "step": 6151
    },
    {
      "epoch": 1.26,
      "grad_norm": 1.1042295694351196,
      "learning_rate": 7.399815517064673e-06,
      "loss": 0.3601,
      "step": 6152
    },
    {
      "epoch": 1.26,
      "grad_norm": 1.1326786279678345,
      "learning_rate": 7.397765706672133e-06,
      "loss": 0.3833,
      "step": 6153
    },
    {
      "epoch": 1.26,
      "grad_norm": 1.1037464141845703,
      "learning_rate": 7.395715896279595e-06,
      "loss": 0.3695,
      "step": 6154
    },
    {
      "epoch": 1.26,
      "grad_norm": 2.0749826431274414,
      "learning_rate": 7.393666085887056e-06,
      "loss": 0.5843,
      "step": 6155
    },
    {
      "epoch": 1.26,
      "grad_norm": 1.025891661643982,
      "learning_rate": 7.391616275494518e-06,
      "loss": 0.3559,
      "step": 6156
    },
    {
      "epoch": 1.26,
      "grad_norm": 2.1738359928131104,
      "learning_rate": 7.389566465101979e-06,
      "loss": 0.3661,
      "step": 6157
    },
    {
      "epoch": 1.26,
      "grad_norm": 3.1903023719787598,
      "learning_rate": 7.3875166547094405e-06,
      "loss": 0.3058,
      "step": 6158
    },
    {
      "epoch": 1.26,
      "grad_norm": 1.0360264778137207,
      "learning_rate": 7.385466844316901e-06,
      "loss": 0.2931,
      "step": 6159
    },
    {
      "epoch": 1.26,
      "grad_norm": 2.327838182449341,
      "learning_rate": 7.3834170339243626e-06,
      "loss": 0.2409,
      "step": 6160
    },
    {
      "epoch": 1.26,
      "grad_norm": 1.1367931365966797,
      "learning_rate": 7.381367223531824e-06,
      "loss": 0.4202,
      "step": 6161
    },
    {
      "epoch": 1.26,
      "grad_norm": 1.013431429862976,
      "learning_rate": 7.3793174131392854e-06,
      "loss": 0.3248,
      "step": 6162
    },
    {
      "epoch": 1.26,
      "grad_norm": 0.9329175353050232,
      "learning_rate": 7.3772676027467464e-06,
      "loss": 0.5186,
      "step": 6163
    },
    {
      "epoch": 1.26,
      "grad_norm": 1.2939307689666748,
      "learning_rate": 7.3752177923542075e-06,
      "loss": 0.2558,
      "step": 6164
    },
    {
      "epoch": 1.26,
      "grad_norm": 1.891660213470459,
      "learning_rate": 7.3731679819616685e-06,
      "loss": 0.4184,
      "step": 6165
    },
    {
      "epoch": 1.26,
      "grad_norm": 1.2987996339797974,
      "learning_rate": 7.37111817156913e-06,
      "loss": 0.2847,
      "step": 6166
    },
    {
      "epoch": 1.26,
      "grad_norm": 0.9419040679931641,
      "learning_rate": 7.369068361176592e-06,
      "loss": 0.3753,
      "step": 6167
    },
    {
      "epoch": 1.26,
      "grad_norm": 1.3506860733032227,
      "learning_rate": 7.367018550784053e-06,
      "loss": 0.3871,
      "step": 6168
    },
    {
      "epoch": 1.26,
      "grad_norm": 1.2497899532318115,
      "learning_rate": 7.364968740391515e-06,
      "loss": 0.2866,
      "step": 6169
    },
    {
      "epoch": 1.26,
      "grad_norm": 1.0171953439712524,
      "learning_rate": 7.362918929998975e-06,
      "loss": 0.3806,
      "step": 6170
    },
    {
      "epoch": 1.26,
      "grad_norm": 2.3693463802337646,
      "learning_rate": 7.360869119606437e-06,
      "loss": 0.2785,
      "step": 6171
    },
    {
      "epoch": 1.26,
      "grad_norm": 1.267945647239685,
      "learning_rate": 7.358819309213898e-06,
      "loss": 0.357,
      "step": 6172
    },
    {
      "epoch": 1.26,
      "grad_norm": 1.2024260759353638,
      "learning_rate": 7.35676949882136e-06,
      "loss": 0.4075,
      "step": 6173
    },
    {
      "epoch": 1.26,
      "grad_norm": 1.4573307037353516,
      "learning_rate": 7.354719688428821e-06,
      "loss": 0.3092,
      "step": 6174
    },
    {
      "epoch": 1.27,
      "grad_norm": 1.4585942029953003,
      "learning_rate": 7.352669878036283e-06,
      "loss": 0.4296,
      "step": 6175
    },
    {
      "epoch": 1.27,
      "grad_norm": 2.097222328186035,
      "learning_rate": 7.350620067643743e-06,
      "loss": 0.4861,
      "step": 6176
    },
    {
      "epoch": 1.27,
      "grad_norm": 0.9936177134513855,
      "learning_rate": 7.348570257251205e-06,
      "loss": 0.2895,
      "step": 6177
    },
    {
      "epoch": 1.27,
      "grad_norm": 0.9372768402099609,
      "learning_rate": 7.346520446858666e-06,
      "loss": 0.221,
      "step": 6178
    },
    {
      "epoch": 1.27,
      "grad_norm": 1.9985195398330688,
      "learning_rate": 7.344470636466128e-06,
      "loss": 0.2772,
      "step": 6179
    },
    {
      "epoch": 1.27,
      "grad_norm": 1.0640298128128052,
      "learning_rate": 7.342420826073589e-06,
      "loss": 0.2945,
      "step": 6180
    },
    {
      "epoch": 1.27,
      "grad_norm": 1.1107536554336548,
      "learning_rate": 7.3403710156810505e-06,
      "loss": 0.3319,
      "step": 6181
    },
    {
      "epoch": 1.27,
      "grad_norm": 1.1899280548095703,
      "learning_rate": 7.338321205288511e-06,
      "loss": 0.4244,
      "step": 6182
    },
    {
      "epoch": 1.27,
      "grad_norm": 1.127726674079895,
      "learning_rate": 7.3362713948959726e-06,
      "loss": 0.3629,
      "step": 6183
    },
    {
      "epoch": 1.27,
      "grad_norm": 1.7509135007858276,
      "learning_rate": 7.3342215845034336e-06,
      "loss": 0.3601,
      "step": 6184
    },
    {
      "epoch": 1.27,
      "grad_norm": 0.8983062505722046,
      "learning_rate": 7.3321717741108954e-06,
      "loss": 0.2939,
      "step": 6185
    },
    {
      "epoch": 1.27,
      "grad_norm": 1.2587153911590576,
      "learning_rate": 7.3301219637183564e-06,
      "loss": 0.302,
      "step": 6186
    },
    {
      "epoch": 1.27,
      "grad_norm": 0.9963915944099426,
      "learning_rate": 7.328072153325818e-06,
      "loss": 0.4863,
      "step": 6187
    },
    {
      "epoch": 1.27,
      "grad_norm": 1.2212542295455933,
      "learning_rate": 7.3260223429332785e-06,
      "loss": 0.3845,
      "step": 6188
    },
    {
      "epoch": 1.27,
      "grad_norm": 0.8992146253585815,
      "learning_rate": 7.32397253254074e-06,
      "loss": 0.2761,
      "step": 6189
    },
    {
      "epoch": 1.27,
      "grad_norm": 1.4061288833618164,
      "learning_rate": 7.321922722148201e-06,
      "loss": 0.3924,
      "step": 6190
    },
    {
      "epoch": 1.27,
      "grad_norm": 1.1471102237701416,
      "learning_rate": 7.319872911755663e-06,
      "loss": 0.3502,
      "step": 6191
    },
    {
      "epoch": 1.27,
      "grad_norm": 0.9513641595840454,
      "learning_rate": 7.317823101363124e-06,
      "loss": 0.3012,
      "step": 6192
    },
    {
      "epoch": 1.27,
      "grad_norm": 1.279563546180725,
      "learning_rate": 7.315773290970586e-06,
      "loss": 0.2914,
      "step": 6193
    },
    {
      "epoch": 1.27,
      "grad_norm": 1.3275508880615234,
      "learning_rate": 7.313723480578046e-06,
      "loss": 0.4737,
      "step": 6194
    },
    {
      "epoch": 1.27,
      "grad_norm": 1.2684246301651,
      "learning_rate": 7.311673670185508e-06,
      "loss": 0.3439,
      "step": 6195
    },
    {
      "epoch": 1.27,
      "grad_norm": 1.9632920026779175,
      "learning_rate": 7.30962385979297e-06,
      "loss": 0.4131,
      "step": 6196
    },
    {
      "epoch": 1.27,
      "grad_norm": 0.8321435451507568,
      "learning_rate": 7.307574049400431e-06,
      "loss": 0.2457,
      "step": 6197
    },
    {
      "epoch": 1.27,
      "grad_norm": 0.8414265513420105,
      "learning_rate": 7.305524239007893e-06,
      "loss": 0.32,
      "step": 6198
    },
    {
      "epoch": 1.27,
      "grad_norm": 1.6304852962493896,
      "learning_rate": 7.303474428615354e-06,
      "loss": 0.2386,
      "step": 6199
    },
    {
      "epoch": 1.27,
      "grad_norm": 1.962475061416626,
      "learning_rate": 7.301424618222816e-06,
      "loss": 0.4553,
      "step": 6200
    },
    {
      "epoch": 1.27,
      "grad_norm": 1.4700862169265747,
      "learning_rate": 7.299374807830276e-06,
      "loss": 0.3622,
      "step": 6201
    },
    {
      "epoch": 1.27,
      "grad_norm": 1.2274972200393677,
      "learning_rate": 7.297324997437738e-06,
      "loss": 0.3565,
      "step": 6202
    },
    {
      "epoch": 1.27,
      "grad_norm": 1.7155572175979614,
      "learning_rate": 7.295275187045199e-06,
      "loss": 0.3957,
      "step": 6203
    },
    {
      "epoch": 1.27,
      "grad_norm": 4.339588642120361,
      "learning_rate": 7.2932253766526605e-06,
      "loss": 0.3675,
      "step": 6204
    },
    {
      "epoch": 1.27,
      "grad_norm": 1.8015934228897095,
      "learning_rate": 7.2911755662601215e-06,
      "loss": 0.2768,
      "step": 6205
    },
    {
      "epoch": 1.27,
      "grad_norm": 0.959674060344696,
      "learning_rate": 7.289125755867583e-06,
      "loss": 0.354,
      "step": 6206
    },
    {
      "epoch": 1.27,
      "grad_norm": 1.646069884300232,
      "learning_rate": 7.2870759454750436e-06,
      "loss": 0.2921,
      "step": 6207
    },
    {
      "epoch": 1.27,
      "grad_norm": 0.9393767714500427,
      "learning_rate": 7.285026135082505e-06,
      "loss": 0.2866,
      "step": 6208
    },
    {
      "epoch": 1.27,
      "grad_norm": 0.6622121334075928,
      "learning_rate": 7.2829763246899664e-06,
      "loss": 0.2355,
      "step": 6209
    },
    {
      "epoch": 1.27,
      "grad_norm": 1.5369431972503662,
      "learning_rate": 7.280926514297428e-06,
      "loss": 0.4482,
      "step": 6210
    },
    {
      "epoch": 1.27,
      "grad_norm": 1.8086929321289062,
      "learning_rate": 7.278876703904889e-06,
      "loss": 0.3211,
      "step": 6211
    },
    {
      "epoch": 1.27,
      "grad_norm": 1.6928911209106445,
      "learning_rate": 7.276826893512351e-06,
      "loss": 0.2887,
      "step": 6212
    },
    {
      "epoch": 1.27,
      "grad_norm": 0.9536213874816895,
      "learning_rate": 7.274777083119811e-06,
      "loss": 0.4563,
      "step": 6213
    },
    {
      "epoch": 1.27,
      "grad_norm": 1.0848997831344604,
      "learning_rate": 7.272727272727273e-06,
      "loss": 0.2698,
      "step": 6214
    },
    {
      "epoch": 1.27,
      "grad_norm": 1.144506573677063,
      "learning_rate": 7.270677462334734e-06,
      "loss": 0.3015,
      "step": 6215
    },
    {
      "epoch": 1.27,
      "grad_norm": 1.108088493347168,
      "learning_rate": 7.268627651942196e-06,
      "loss": 0.5859,
      "step": 6216
    },
    {
      "epoch": 1.27,
      "grad_norm": 1.9825518131256104,
      "learning_rate": 7.266577841549657e-06,
      "loss": 0.4638,
      "step": 6217
    },
    {
      "epoch": 1.27,
      "grad_norm": 1.2407182455062866,
      "learning_rate": 7.264528031157119e-06,
      "loss": 0.4161,
      "step": 6218
    },
    {
      "epoch": 1.27,
      "grad_norm": 1.9138317108154297,
      "learning_rate": 7.262478220764579e-06,
      "loss": 0.3756,
      "step": 6219
    },
    {
      "epoch": 1.27,
      "grad_norm": 2.7575578689575195,
      "learning_rate": 7.260428410372041e-06,
      "loss": 0.2915,
      "step": 6220
    },
    {
      "epoch": 1.27,
      "grad_norm": 0.9907107949256897,
      "learning_rate": 7.258378599979502e-06,
      "loss": 0.2886,
      "step": 6221
    },
    {
      "epoch": 1.27,
      "grad_norm": 0.9538012146949768,
      "learning_rate": 7.256328789586964e-06,
      "loss": 0.3353,
      "step": 6222
    },
    {
      "epoch": 1.27,
      "grad_norm": 0.91106778383255,
      "learning_rate": 7.254278979194425e-06,
      "loss": 0.2654,
      "step": 6223
    },
    {
      "epoch": 1.28,
      "grad_norm": 1.9613397121429443,
      "learning_rate": 7.252229168801887e-06,
      "loss": 0.4063,
      "step": 6224
    },
    {
      "epoch": 1.28,
      "grad_norm": 1.1373531818389893,
      "learning_rate": 7.2501793584093485e-06,
      "loss": 0.3273,
      "step": 6225
    },
    {
      "epoch": 1.28,
      "grad_norm": 2.8165652751922607,
      "learning_rate": 7.248129548016809e-06,
      "loss": 0.4286,
      "step": 6226
    },
    {
      "epoch": 1.28,
      "grad_norm": 2.1216843128204346,
      "learning_rate": 7.2460797376242705e-06,
      "loss": 0.3221,
      "step": 6227
    },
    {
      "epoch": 1.28,
      "grad_norm": 1.7903590202331543,
      "learning_rate": 7.2440299272317315e-06,
      "loss": 0.4309,
      "step": 6228
    },
    {
      "epoch": 1.28,
      "grad_norm": 1.2949120998382568,
      "learning_rate": 7.241980116839193e-06,
      "loss": 0.2866,
      "step": 6229
    },
    {
      "epoch": 1.28,
      "grad_norm": 1.0571240186691284,
      "learning_rate": 7.239930306446654e-06,
      "loss": 0.3127,
      "step": 6230
    },
    {
      "epoch": 1.28,
      "grad_norm": 1.5174256563186646,
      "learning_rate": 7.237880496054116e-06,
      "loss": 0.2431,
      "step": 6231
    },
    {
      "epoch": 1.28,
      "grad_norm": 2.455277919769287,
      "learning_rate": 7.235830685661576e-06,
      "loss": 0.3409,
      "step": 6232
    },
    {
      "epoch": 1.28,
      "grad_norm": 1.1334331035614014,
      "learning_rate": 7.233780875269038e-06,
      "loss": 0.2682,
      "step": 6233
    },
    {
      "epoch": 1.28,
      "grad_norm": 0.7140867710113525,
      "learning_rate": 7.231731064876499e-06,
      "loss": 0.3325,
      "step": 6234
    },
    {
      "epoch": 1.28,
      "grad_norm": 1.56544029712677,
      "learning_rate": 7.229681254483961e-06,
      "loss": 0.4811,
      "step": 6235
    },
    {
      "epoch": 1.28,
      "grad_norm": 2.5351998805999756,
      "learning_rate": 7.227631444091422e-06,
      "loss": 0.3398,
      "step": 6236
    },
    {
      "epoch": 1.28,
      "grad_norm": 1.862139344215393,
      "learning_rate": 7.225581633698884e-06,
      "loss": 0.2619,
      "step": 6237
    },
    {
      "epoch": 1.28,
      "grad_norm": 1.1495753526687622,
      "learning_rate": 7.223531823306344e-06,
      "loss": 0.4112,
      "step": 6238
    },
    {
      "epoch": 1.28,
      "grad_norm": 3.028493881225586,
      "learning_rate": 7.221482012913806e-06,
      "loss": 0.1981,
      "step": 6239
    },
    {
      "epoch": 1.28,
      "grad_norm": 2.079771041870117,
      "learning_rate": 7.219432202521267e-06,
      "loss": 0.3049,
      "step": 6240
    },
    {
      "epoch": 1.28,
      "grad_norm": 2.3401942253112793,
      "learning_rate": 7.217382392128729e-06,
      "loss": 0.4329,
      "step": 6241
    },
    {
      "epoch": 1.28,
      "grad_norm": 1.231224775314331,
      "learning_rate": 7.21533258173619e-06,
      "loss": 0.3928,
      "step": 6242
    },
    {
      "epoch": 1.28,
      "grad_norm": 1.3561900854110718,
      "learning_rate": 7.213282771343652e-06,
      "loss": 0.3746,
      "step": 6243
    },
    {
      "epoch": 1.28,
      "grad_norm": 2.0197718143463135,
      "learning_rate": 7.211232960951112e-06,
      "loss": 0.4588,
      "step": 6244
    },
    {
      "epoch": 1.28,
      "grad_norm": 2.6870038509368896,
      "learning_rate": 7.209183150558574e-06,
      "loss": 0.2392,
      "step": 6245
    },
    {
      "epoch": 1.28,
      "grad_norm": 1.8509883880615234,
      "learning_rate": 7.207133340166035e-06,
      "loss": 0.2885,
      "step": 6246
    },
    {
      "epoch": 1.28,
      "grad_norm": 1.8524914979934692,
      "learning_rate": 7.205083529773497e-06,
      "loss": 0.2531,
      "step": 6247
    },
    {
      "epoch": 1.28,
      "grad_norm": 2.0370171070098877,
      "learning_rate": 7.203033719380958e-06,
      "loss": 0.3606,
      "step": 6248
    },
    {
      "epoch": 1.28,
      "grad_norm": 2.9983227252960205,
      "learning_rate": 7.2009839089884195e-06,
      "loss": 0.2922,
      "step": 6249
    },
    {
      "epoch": 1.28,
      "grad_norm": 1.284285545349121,
      "learning_rate": 7.19893409859588e-06,
      "loss": 0.3791,
      "step": 6250
    },
    {
      "epoch": 1.28,
      "grad_norm": 1.5973870754241943,
      "learning_rate": 7.1968842882033415e-06,
      "loss": 0.4111,
      "step": 6251
    },
    {
      "epoch": 1.28,
      "grad_norm": 2.1086654663085938,
      "learning_rate": 7.1948344778108025e-06,
      "loss": 0.4239,
      "step": 6252
    },
    {
      "epoch": 1.28,
      "grad_norm": 1.9747077226638794,
      "learning_rate": 7.192784667418264e-06,
      "loss": 0.2916,
      "step": 6253
    },
    {
      "epoch": 1.28,
      "grad_norm": 0.9449241757392883,
      "learning_rate": 7.190734857025725e-06,
      "loss": 0.366,
      "step": 6254
    },
    {
      "epoch": 1.28,
      "grad_norm": 1.4185583591461182,
      "learning_rate": 7.188685046633187e-06,
      "loss": 0.2615,
      "step": 6255
    },
    {
      "epoch": 1.28,
      "grad_norm": 1.259325623512268,
      "learning_rate": 7.186635236240649e-06,
      "loss": 0.2166,
      "step": 6256
    },
    {
      "epoch": 1.28,
      "grad_norm": 1.9539296627044678,
      "learning_rate": 7.184585425848109e-06,
      "loss": 0.4629,
      "step": 6257
    },
    {
      "epoch": 1.28,
      "grad_norm": 1.1678892374038696,
      "learning_rate": 7.182535615455571e-06,
      "loss": 0.339,
      "step": 6258
    },
    {
      "epoch": 1.28,
      "grad_norm": 1.769307017326355,
      "learning_rate": 7.180485805063032e-06,
      "loss": 0.3443,
      "step": 6259
    },
    {
      "epoch": 1.28,
      "grad_norm": 1.153971552848816,
      "learning_rate": 7.178435994670494e-06,
      "loss": 0.2091,
      "step": 6260
    },
    {
      "epoch": 1.28,
      "grad_norm": 1.064065933227539,
      "learning_rate": 7.176386184277955e-06,
      "loss": 0.4259,
      "step": 6261
    },
    {
      "epoch": 1.28,
      "grad_norm": 1.2009118795394897,
      "learning_rate": 7.174336373885417e-06,
      "loss": 0.3476,
      "step": 6262
    },
    {
      "epoch": 1.28,
      "grad_norm": 1.2960795164108276,
      "learning_rate": 7.172286563492877e-06,
      "loss": 0.2838,
      "step": 6263
    },
    {
      "epoch": 1.28,
      "grad_norm": 0.9935511350631714,
      "learning_rate": 7.170236753100339e-06,
      "loss": 0.3417,
      "step": 6264
    },
    {
      "epoch": 1.28,
      "grad_norm": 1.276825189590454,
      "learning_rate": 7.1681869427078e-06,
      "loss": 0.3258,
      "step": 6265
    },
    {
      "epoch": 1.28,
      "grad_norm": 1.869566798210144,
      "learning_rate": 7.166137132315262e-06,
      "loss": 0.3966,
      "step": 6266
    },
    {
      "epoch": 1.28,
      "grad_norm": 1.5289134979248047,
      "learning_rate": 7.164087321922723e-06,
      "loss": 0.4109,
      "step": 6267
    },
    {
      "epoch": 1.28,
      "grad_norm": 1.1866189241409302,
      "learning_rate": 7.162037511530185e-06,
      "loss": 0.3007,
      "step": 6268
    },
    {
      "epoch": 1.28,
      "grad_norm": 0.987019956111908,
      "learning_rate": 7.159987701137645e-06,
      "loss": 0.3457,
      "step": 6269
    },
    {
      "epoch": 1.28,
      "grad_norm": 1.8618913888931274,
      "learning_rate": 7.157937890745107e-06,
      "loss": 0.305,
      "step": 6270
    },
    {
      "epoch": 1.28,
      "grad_norm": 1.4430588483810425,
      "learning_rate": 7.155888080352568e-06,
      "loss": 0.3966,
      "step": 6271
    },
    {
      "epoch": 1.28,
      "grad_norm": 1.3012170791625977,
      "learning_rate": 7.1538382699600295e-06,
      "loss": 0.4931,
      "step": 6272
    },
    {
      "epoch": 1.29,
      "grad_norm": 1.142056941986084,
      "learning_rate": 7.1517884595674905e-06,
      "loss": 0.33,
      "step": 6273
    },
    {
      "epoch": 1.29,
      "grad_norm": 1.3513883352279663,
      "learning_rate": 7.149738649174952e-06,
      "loss": 0.306,
      "step": 6274
    },
    {
      "epoch": 1.29,
      "grad_norm": 1.4768269062042236,
      "learning_rate": 7.1476888387824125e-06,
      "loss": 0.4048,
      "step": 6275
    },
    {
      "epoch": 1.29,
      "grad_norm": 1.854325532913208,
      "learning_rate": 7.145639028389874e-06,
      "loss": 0.4042,
      "step": 6276
    },
    {
      "epoch": 1.29,
      "grad_norm": 1.5106561183929443,
      "learning_rate": 7.143589217997335e-06,
      "loss": 0.3968,
      "step": 6277
    },
    {
      "epoch": 1.29,
      "grad_norm": 0.9346552491188049,
      "learning_rate": 7.141539407604797e-06,
      "loss": 0.2505,
      "step": 6278
    },
    {
      "epoch": 1.29,
      "grad_norm": 2.188427686691284,
      "learning_rate": 7.139489597212258e-06,
      "loss": 0.4546,
      "step": 6279
    },
    {
      "epoch": 1.29,
      "grad_norm": 2.2728099822998047,
      "learning_rate": 7.13743978681972e-06,
      "loss": 0.2893,
      "step": 6280
    },
    {
      "epoch": 1.29,
      "grad_norm": 1.0851207971572876,
      "learning_rate": 7.13538997642718e-06,
      "loss": 0.4246,
      "step": 6281
    },
    {
      "epoch": 1.29,
      "grad_norm": 0.7750487923622131,
      "learning_rate": 7.133340166034642e-06,
      "loss": 0.4227,
      "step": 6282
    },
    {
      "epoch": 1.29,
      "grad_norm": 1.5702059268951416,
      "learning_rate": 7.131290355642103e-06,
      "loss": 0.3595,
      "step": 6283
    },
    {
      "epoch": 1.29,
      "grad_norm": 1.2259435653686523,
      "learning_rate": 7.129240545249565e-06,
      "loss": 0.3876,
      "step": 6284
    },
    {
      "epoch": 1.29,
      "grad_norm": 0.9525370001792908,
      "learning_rate": 7.127190734857027e-06,
      "loss": 0.2646,
      "step": 6285
    },
    {
      "epoch": 1.29,
      "grad_norm": 1.3482292890548706,
      "learning_rate": 7.125140924464488e-06,
      "loss": 0.3394,
      "step": 6286
    },
    {
      "epoch": 1.29,
      "grad_norm": 1.7941999435424805,
      "learning_rate": 7.12309111407195e-06,
      "loss": 0.446,
      "step": 6287
    },
    {
      "epoch": 1.29,
      "grad_norm": 1.0585753917694092,
      "learning_rate": 7.12104130367941e-06,
      "loss": 0.381,
      "step": 6288
    },
    {
      "epoch": 1.29,
      "grad_norm": 1.0165361166000366,
      "learning_rate": 7.118991493286872e-06,
      "loss": 0.2771,
      "step": 6289
    },
    {
      "epoch": 1.29,
      "grad_norm": 1.012414813041687,
      "learning_rate": 7.116941682894333e-06,
      "loss": 0.4516,
      "step": 6290
    },
    {
      "epoch": 1.29,
      "grad_norm": 1.846961259841919,
      "learning_rate": 7.114891872501795e-06,
      "loss": 0.2084,
      "step": 6291
    },
    {
      "epoch": 1.29,
      "grad_norm": 1.3718106746673584,
      "learning_rate": 7.112842062109256e-06,
      "loss": 0.3783,
      "step": 6292
    },
    {
      "epoch": 1.29,
      "grad_norm": 1.1403310298919678,
      "learning_rate": 7.1107922517167175e-06,
      "loss": 0.3482,
      "step": 6293
    },
    {
      "epoch": 1.29,
      "grad_norm": 1.8888702392578125,
      "learning_rate": 7.108742441324178e-06,
      "loss": 0.3286,
      "step": 6294
    },
    {
      "epoch": 1.29,
      "grad_norm": 1.6064215898513794,
      "learning_rate": 7.1066926309316395e-06,
      "loss": 0.4154,
      "step": 6295
    },
    {
      "epoch": 1.29,
      "grad_norm": 1.205284595489502,
      "learning_rate": 7.1046428205391005e-06,
      "loss": 0.3868,
      "step": 6296
    },
    {
      "epoch": 1.29,
      "grad_norm": 2.617339611053467,
      "learning_rate": 7.102593010146562e-06,
      "loss": 0.3749,
      "step": 6297
    },
    {
      "epoch": 1.29,
      "grad_norm": 1.5299676656723022,
      "learning_rate": 7.100543199754023e-06,
      "loss": 0.4068,
      "step": 6298
    },
    {
      "epoch": 1.29,
      "grad_norm": 1.2250908613204956,
      "learning_rate": 7.098493389361485e-06,
      "loss": 0.3874,
      "step": 6299
    },
    {
      "epoch": 1.29,
      "grad_norm": 1.2996786832809448,
      "learning_rate": 7.096443578968945e-06,
      "loss": 0.2112,
      "step": 6300
    },
    {
      "epoch": 1.29,
      "grad_norm": 1.350862741470337,
      "learning_rate": 7.094393768576407e-06,
      "loss": 0.4371,
      "step": 6301
    },
    {
      "epoch": 1.29,
      "grad_norm": 2.7243058681488037,
      "learning_rate": 7.092343958183868e-06,
      "loss": 0.5006,
      "step": 6302
    },
    {
      "epoch": 1.29,
      "grad_norm": 2.5689733028411865,
      "learning_rate": 7.09029414779133e-06,
      "loss": 0.3104,
      "step": 6303
    },
    {
      "epoch": 1.29,
      "grad_norm": 1.0074728727340698,
      "learning_rate": 7.088244337398791e-06,
      "loss": 0.3255,
      "step": 6304
    },
    {
      "epoch": 1.29,
      "grad_norm": 1.0619864463806152,
      "learning_rate": 7.086194527006253e-06,
      "loss": 0.5493,
      "step": 6305
    },
    {
      "epoch": 1.29,
      "grad_norm": 1.630774974822998,
      "learning_rate": 7.084144716613713e-06,
      "loss": 0.3271,
      "step": 6306
    },
    {
      "epoch": 1.29,
      "grad_norm": 1.8087599277496338,
      "learning_rate": 7.082094906221175e-06,
      "loss": 0.3495,
      "step": 6307
    },
    {
      "epoch": 1.29,
      "grad_norm": 1.3796184062957764,
      "learning_rate": 7.080045095828636e-06,
      "loss": 0.2948,
      "step": 6308
    },
    {
      "epoch": 1.29,
      "grad_norm": 1.628678798675537,
      "learning_rate": 7.077995285436098e-06,
      "loss": 0.3727,
      "step": 6309
    },
    {
      "epoch": 1.29,
      "grad_norm": 1.2117880582809448,
      "learning_rate": 7.075945475043559e-06,
      "loss": 0.471,
      "step": 6310
    },
    {
      "epoch": 1.29,
      "grad_norm": 1.6202601194381714,
      "learning_rate": 7.073895664651021e-06,
      "loss": 0.4963,
      "step": 6311
    },
    {
      "epoch": 1.29,
      "grad_norm": 1.3492597341537476,
      "learning_rate": 7.071845854258481e-06,
      "loss": 0.3475,
      "step": 6312
    },
    {
      "epoch": 1.29,
      "grad_norm": 1.4172909259796143,
      "learning_rate": 7.069796043865943e-06,
      "loss": 0.3731,
      "step": 6313
    },
    {
      "epoch": 1.29,
      "grad_norm": 2.1572535037994385,
      "learning_rate": 7.067746233473405e-06,
      "loss": 0.3172,
      "step": 6314
    },
    {
      "epoch": 1.29,
      "grad_norm": 2.5898008346557617,
      "learning_rate": 7.065696423080866e-06,
      "loss": 0.2868,
      "step": 6315
    },
    {
      "epoch": 1.29,
      "grad_norm": 1.3183720111846924,
      "learning_rate": 7.0636466126883275e-06,
      "loss": 0.4666,
      "step": 6316
    },
    {
      "epoch": 1.29,
      "grad_norm": 1.6582002639770508,
      "learning_rate": 7.0615968022957885e-06,
      "loss": 0.3159,
      "step": 6317
    },
    {
      "epoch": 1.29,
      "grad_norm": 1.4454634189605713,
      "learning_rate": 7.05954699190325e-06,
      "loss": 0.4473,
      "step": 6318
    },
    {
      "epoch": 1.29,
      "grad_norm": 1.7680593729019165,
      "learning_rate": 7.0574971815107105e-06,
      "loss": 0.4704,
      "step": 6319
    },
    {
      "epoch": 1.29,
      "grad_norm": 1.0100407600402832,
      "learning_rate": 7.055447371118172e-06,
      "loss": 0.2918,
      "step": 6320
    },
    {
      "epoch": 1.3,
      "grad_norm": 1.685996413230896,
      "learning_rate": 7.053397560725633e-06,
      "loss": 0.3169,
      "step": 6321
    },
    {
      "epoch": 1.3,
      "grad_norm": 2.5358877182006836,
      "learning_rate": 7.051347750333095e-06,
      "loss": 0.4267,
      "step": 6322
    },
    {
      "epoch": 1.3,
      "grad_norm": 2.2527620792388916,
      "learning_rate": 7.049297939940556e-06,
      "loss": 0.3348,
      "step": 6323
    },
    {
      "epoch": 1.3,
      "grad_norm": 1.3106300830841064,
      "learning_rate": 7.047248129548018e-06,
      "loss": 0.4017,
      "step": 6324
    },
    {
      "epoch": 1.3,
      "grad_norm": 1.7114859819412231,
      "learning_rate": 7.045198319155478e-06,
      "loss": 0.3133,
      "step": 6325
    },
    {
      "epoch": 1.3,
      "grad_norm": 1.0078898668289185,
      "learning_rate": 7.04314850876294e-06,
      "loss": 0.2888,
      "step": 6326
    },
    {
      "epoch": 1.3,
      "grad_norm": 2.239924430847168,
      "learning_rate": 7.041098698370401e-06,
      "loss": 0.3777,
      "step": 6327
    },
    {
      "epoch": 1.3,
      "grad_norm": 1.154366374015808,
      "learning_rate": 7.039048887977863e-06,
      "loss": 0.2724,
      "step": 6328
    },
    {
      "epoch": 1.3,
      "grad_norm": 1.3156756162643433,
      "learning_rate": 7.036999077585324e-06,
      "loss": 0.4475,
      "step": 6329
    },
    {
      "epoch": 1.3,
      "grad_norm": 1.5746026039123535,
      "learning_rate": 7.034949267192786e-06,
      "loss": 0.3222,
      "step": 6330
    },
    {
      "epoch": 1.3,
      "grad_norm": 2.4455149173736572,
      "learning_rate": 7.032899456800246e-06,
      "loss": 0.3944,
      "step": 6331
    },
    {
      "epoch": 1.3,
      "grad_norm": 0.8179168701171875,
      "learning_rate": 7.030849646407708e-06,
      "loss": 0.3105,
      "step": 6332
    },
    {
      "epoch": 1.3,
      "grad_norm": 2.226931571960449,
      "learning_rate": 7.028799836015169e-06,
      "loss": 0.4889,
      "step": 6333
    },
    {
      "epoch": 1.3,
      "grad_norm": 1.739876389503479,
      "learning_rate": 7.026750025622631e-06,
      "loss": 0.3135,
      "step": 6334
    },
    {
      "epoch": 1.3,
      "grad_norm": 0.9043244123458862,
      "learning_rate": 7.024700215230092e-06,
      "loss": 0.3236,
      "step": 6335
    },
    {
      "epoch": 1.3,
      "grad_norm": 1.464690923690796,
      "learning_rate": 7.022650404837554e-06,
      "loss": 0.2346,
      "step": 6336
    },
    {
      "epoch": 1.3,
      "grad_norm": 0.9986226558685303,
      "learning_rate": 7.020600594445014e-06,
      "loss": 0.3413,
      "step": 6337
    },
    {
      "epoch": 1.3,
      "grad_norm": 1.0722508430480957,
      "learning_rate": 7.018550784052476e-06,
      "loss": 0.3866,
      "step": 6338
    },
    {
      "epoch": 1.3,
      "grad_norm": 1.268789291381836,
      "learning_rate": 7.016500973659937e-06,
      "loss": 0.3809,
      "step": 6339
    },
    {
      "epoch": 1.3,
      "grad_norm": 1.0082319974899292,
      "learning_rate": 7.0144511632673985e-06,
      "loss": 0.3548,
      "step": 6340
    },
    {
      "epoch": 1.3,
      "grad_norm": 1.190722107887268,
      "learning_rate": 7.0124013528748595e-06,
      "loss": 0.4343,
      "step": 6341
    },
    {
      "epoch": 1.3,
      "grad_norm": 1.2637819051742554,
      "learning_rate": 7.010351542482321e-06,
      "loss": 0.2661,
      "step": 6342
    },
    {
      "epoch": 1.3,
      "grad_norm": 3.0627427101135254,
      "learning_rate": 7.008301732089783e-06,
      "loss": 0.3483,
      "step": 6343
    },
    {
      "epoch": 1.3,
      "grad_norm": 0.9161593317985535,
      "learning_rate": 7.006251921697243e-06,
      "loss": 0.3284,
      "step": 6344
    },
    {
      "epoch": 1.3,
      "grad_norm": 1.345770001411438,
      "learning_rate": 7.004202111304705e-06,
      "loss": 0.3423,
      "step": 6345
    },
    {
      "epoch": 1.3,
      "grad_norm": 0.9947507381439209,
      "learning_rate": 7.002152300912166e-06,
      "loss": 0.3627,
      "step": 6346
    },
    {
      "epoch": 1.3,
      "grad_norm": 1.1275900602340698,
      "learning_rate": 7.000102490519628e-06,
      "loss": 0.2149,
      "step": 6347
    },
    {
      "epoch": 1.3,
      "grad_norm": 1.2216604948043823,
      "learning_rate": 6.998052680127089e-06,
      "loss": 0.4222,
      "step": 6348
    },
    {
      "epoch": 1.3,
      "grad_norm": 1.6577107906341553,
      "learning_rate": 6.996002869734551e-06,
      "loss": 0.2173,
      "step": 6349
    },
    {
      "epoch": 1.3,
      "grad_norm": 0.9576247930526733,
      "learning_rate": 6.993953059342011e-06,
      "loss": 0.3588,
      "step": 6350
    },
    {
      "epoch": 1.3,
      "grad_norm": 1.2600536346435547,
      "learning_rate": 6.991903248949473e-06,
      "loss": 0.3826,
      "step": 6351
    },
    {
      "epoch": 1.3,
      "grad_norm": 1.819130301475525,
      "learning_rate": 6.989853438556934e-06,
      "loss": 0.346,
      "step": 6352
    },
    {
      "epoch": 1.3,
      "grad_norm": 0.9787728190422058,
      "learning_rate": 6.987803628164396e-06,
      "loss": 0.4347,
      "step": 6353
    },
    {
      "epoch": 1.3,
      "grad_norm": 1.7626041173934937,
      "learning_rate": 6.985753817771857e-06,
      "loss": 0.3801,
      "step": 6354
    },
    {
      "epoch": 1.3,
      "grad_norm": 1.0593698024749756,
      "learning_rate": 6.983704007379319e-06,
      "loss": 0.458,
      "step": 6355
    },
    {
      "epoch": 1.3,
      "grad_norm": 1.2983434200286865,
      "learning_rate": 6.981654196986779e-06,
      "loss": 0.3812,
      "step": 6356
    },
    {
      "epoch": 1.3,
      "grad_norm": 1.289427399635315,
      "learning_rate": 6.979604386594241e-06,
      "loss": 0.3702,
      "step": 6357
    },
    {
      "epoch": 1.3,
      "grad_norm": 1.4371384382247925,
      "learning_rate": 6.977554576201702e-06,
      "loss": 0.4358,
      "step": 6358
    },
    {
      "epoch": 1.3,
      "grad_norm": 1.2959846258163452,
      "learning_rate": 6.9755047658091636e-06,
      "loss": 0.3288,
      "step": 6359
    },
    {
      "epoch": 1.3,
      "grad_norm": 1.3404244184494019,
      "learning_rate": 6.973454955416625e-06,
      "loss": 0.3726,
      "step": 6360
    },
    {
      "epoch": 1.3,
      "grad_norm": 1.9445356130599976,
      "learning_rate": 6.9714051450240864e-06,
      "loss": 0.2606,
      "step": 6361
    },
    {
      "epoch": 1.3,
      "grad_norm": 1.7642325162887573,
      "learning_rate": 6.969355334631547e-06,
      "loss": 0.3172,
      "step": 6362
    },
    {
      "epoch": 1.3,
      "grad_norm": 1.4223856925964355,
      "learning_rate": 6.9673055242390085e-06,
      "loss": 0.4439,
      "step": 6363
    },
    {
      "epoch": 1.3,
      "grad_norm": 1.9931917190551758,
      "learning_rate": 6.9652557138464695e-06,
      "loss": 0.3253,
      "step": 6364
    },
    {
      "epoch": 1.3,
      "grad_norm": 1.6087454557418823,
      "learning_rate": 6.963205903453931e-06,
      "loss": 0.3813,
      "step": 6365
    },
    {
      "epoch": 1.3,
      "grad_norm": 0.9119297862052917,
      "learning_rate": 6.961156093061392e-06,
      "loss": 0.3164,
      "step": 6366
    },
    {
      "epoch": 1.3,
      "grad_norm": 1.4809170961380005,
      "learning_rate": 6.959106282668854e-06,
      "loss": 0.2469,
      "step": 6367
    },
    {
      "epoch": 1.3,
      "grad_norm": 1.7088621854782104,
      "learning_rate": 6.957056472276314e-06,
      "loss": 0.3382,
      "step": 6368
    },
    {
      "epoch": 1.3,
      "grad_norm": 0.9599224925041199,
      "learning_rate": 6.955006661883776e-06,
      "loss": 0.2843,
      "step": 6369
    },
    {
      "epoch": 1.31,
      "grad_norm": 1.2431895732879639,
      "learning_rate": 6.952956851491237e-06,
      "loss": 0.4792,
      "step": 6370
    },
    {
      "epoch": 1.31,
      "grad_norm": 1.570434331893921,
      "learning_rate": 6.950907041098699e-06,
      "loss": 0.4359,
      "step": 6371
    },
    {
      "epoch": 1.31,
      "grad_norm": 1.1775685548782349,
      "learning_rate": 6.94885723070616e-06,
      "loss": 0.4027,
      "step": 6372
    },
    {
      "epoch": 1.31,
      "grad_norm": 1.4716728925704956,
      "learning_rate": 6.946807420313622e-06,
      "loss": 0.3893,
      "step": 6373
    },
    {
      "epoch": 1.31,
      "grad_norm": 0.989672839641571,
      "learning_rate": 6.944757609921084e-06,
      "loss": 0.2364,
      "step": 6374
    },
    {
      "epoch": 1.31,
      "grad_norm": 1.4571561813354492,
      "learning_rate": 6.942707799528544e-06,
      "loss": 0.423,
      "step": 6375
    },
    {
      "epoch": 1.31,
      "grad_norm": 1.312047004699707,
      "learning_rate": 6.940657989136006e-06,
      "loss": 0.2842,
      "step": 6376
    },
    {
      "epoch": 1.31,
      "grad_norm": 0.9468308091163635,
      "learning_rate": 6.938608178743467e-06,
      "loss": 0.371,
      "step": 6377
    },
    {
      "epoch": 1.31,
      "grad_norm": 1.4371095895767212,
      "learning_rate": 6.936558368350929e-06,
      "loss": 0.3864,
      "step": 6378
    },
    {
      "epoch": 1.31,
      "grad_norm": 1.668172001838684,
      "learning_rate": 6.93450855795839e-06,
      "loss": 0.2472,
      "step": 6379
    },
    {
      "epoch": 1.31,
      "grad_norm": 1.1675750017166138,
      "learning_rate": 6.9324587475658515e-06,
      "loss": 0.4623,
      "step": 6380
    },
    {
      "epoch": 1.31,
      "grad_norm": 0.9367103576660156,
      "learning_rate": 6.930408937173312e-06,
      "loss": 0.4492,
      "step": 6381
    },
    {
      "epoch": 1.31,
      "grad_norm": 2.9740006923675537,
      "learning_rate": 6.9283591267807736e-06,
      "loss": 0.3852,
      "step": 6382
    },
    {
      "epoch": 1.31,
      "grad_norm": 1.1910473108291626,
      "learning_rate": 6.9263093163882346e-06,
      "loss": 0.2911,
      "step": 6383
    },
    {
      "epoch": 1.31,
      "grad_norm": 1.0721040964126587,
      "learning_rate": 6.9242595059956964e-06,
      "loss": 0.2239,
      "step": 6384
    },
    {
      "epoch": 1.31,
      "grad_norm": 1.0013664960861206,
      "learning_rate": 6.9222096956031574e-06,
      "loss": 0.2903,
      "step": 6385
    },
    {
      "epoch": 1.31,
      "grad_norm": 1.3738244771957397,
      "learning_rate": 6.920159885210619e-06,
      "loss": 0.2911,
      "step": 6386
    },
    {
      "epoch": 1.31,
      "grad_norm": 1.1143603324890137,
      "learning_rate": 6.9181100748180795e-06,
      "loss": 0.3195,
      "step": 6387
    },
    {
      "epoch": 1.31,
      "grad_norm": 1.5992568731307983,
      "learning_rate": 6.916060264425541e-06,
      "loss": 0.3626,
      "step": 6388
    },
    {
      "epoch": 1.31,
      "grad_norm": 1.5629379749298096,
      "learning_rate": 6.914010454033002e-06,
      "loss": 0.5036,
      "step": 6389
    },
    {
      "epoch": 1.31,
      "grad_norm": 0.880232572555542,
      "learning_rate": 6.911960643640464e-06,
      "loss": 0.4428,
      "step": 6390
    },
    {
      "epoch": 1.31,
      "grad_norm": 1.328967809677124,
      "learning_rate": 6.909910833247925e-06,
      "loss": 0.308,
      "step": 6391
    },
    {
      "epoch": 1.31,
      "grad_norm": 1.2489166259765625,
      "learning_rate": 6.907861022855386e-06,
      "loss": 0.2695,
      "step": 6392
    },
    {
      "epoch": 1.31,
      "grad_norm": 1.5987154245376587,
      "learning_rate": 6.905811212462847e-06,
      "loss": 0.3203,
      "step": 6393
    },
    {
      "epoch": 1.31,
      "grad_norm": 1.274498701095581,
      "learning_rate": 6.903761402070309e-06,
      "loss": 0.4934,
      "step": 6394
    },
    {
      "epoch": 1.31,
      "grad_norm": 1.2917476892471313,
      "learning_rate": 6.90171159167777e-06,
      "loss": 0.4165,
      "step": 6395
    },
    {
      "epoch": 1.31,
      "grad_norm": 1.1386916637420654,
      "learning_rate": 6.899661781285232e-06,
      "loss": 0.2463,
      "step": 6396
    },
    {
      "epoch": 1.31,
      "grad_norm": 1.1103099584579468,
      "learning_rate": 6.897611970892693e-06,
      "loss": 0.2838,
      "step": 6397
    },
    {
      "epoch": 1.31,
      "grad_norm": 1.3585476875305176,
      "learning_rate": 6.895562160500154e-06,
      "loss": 0.3532,
      "step": 6398
    },
    {
      "epoch": 1.31,
      "grad_norm": 1.2688212394714355,
      "learning_rate": 6.893512350107615e-06,
      "loss": 0.4177,
      "step": 6399
    },
    {
      "epoch": 1.31,
      "grad_norm": 1.3435921669006348,
      "learning_rate": 6.891462539715077e-06,
      "loss": 0.4348,
      "step": 6400
    },
    {
      "epoch": 1.31,
      "grad_norm": 1.020271897315979,
      "learning_rate": 6.889412729322538e-06,
      "loss": 0.3025,
      "step": 6401
    },
    {
      "epoch": 1.31,
      "grad_norm": 1.4363930225372314,
      "learning_rate": 6.88736291893e-06,
      "loss": 0.4469,
      "step": 6402
    },
    {
      "epoch": 1.31,
      "grad_norm": 1.092806339263916,
      "learning_rate": 6.8853131085374615e-06,
      "loss": 0.4341,
      "step": 6403
    },
    {
      "epoch": 1.31,
      "grad_norm": 1.9371899366378784,
      "learning_rate": 6.883263298144922e-06,
      "loss": 0.4556,
      "step": 6404
    },
    {
      "epoch": 1.31,
      "grad_norm": 1.4856033325195312,
      "learning_rate": 6.8812134877523836e-06,
      "loss": 0.4055,
      "step": 6405
    },
    {
      "epoch": 1.31,
      "grad_norm": 1.6106122732162476,
      "learning_rate": 6.8791636773598446e-06,
      "loss": 0.4221,
      "step": 6406
    },
    {
      "epoch": 1.31,
      "grad_norm": 1.7175401449203491,
      "learning_rate": 6.877113866967306e-06,
      "loss": 0.4145,
      "step": 6407
    },
    {
      "epoch": 1.31,
      "grad_norm": 0.8059620261192322,
      "learning_rate": 6.8750640565747674e-06,
      "loss": 0.3843,
      "step": 6408
    },
    {
      "epoch": 1.31,
      "grad_norm": 1.7557096481323242,
      "learning_rate": 6.873014246182229e-06,
      "loss": 0.4251,
      "step": 6409
    },
    {
      "epoch": 1.31,
      "grad_norm": 1.9476509094238281,
      "learning_rate": 6.8709644357896895e-06,
      "loss": 0.3153,
      "step": 6410
    },
    {
      "epoch": 1.31,
      "grad_norm": 1.367209553718567,
      "learning_rate": 6.868914625397151e-06,
      "loss": 0.3014,
      "step": 6411
    },
    {
      "epoch": 1.31,
      "grad_norm": 2.727842330932617,
      "learning_rate": 6.866864815004612e-06,
      "loss": 0.4138,
      "step": 6412
    },
    {
      "epoch": 1.31,
      "grad_norm": 2.903958559036255,
      "learning_rate": 6.864815004612074e-06,
      "loss": 0.3498,
      "step": 6413
    },
    {
      "epoch": 1.31,
      "grad_norm": 1.1249970197677612,
      "learning_rate": 6.862765194219535e-06,
      "loss": 0.2304,
      "step": 6414
    },
    {
      "epoch": 1.31,
      "grad_norm": 1.987892985343933,
      "learning_rate": 6.860715383826997e-06,
      "loss": 0.2781,
      "step": 6415
    },
    {
      "epoch": 1.31,
      "grad_norm": 2.938582181930542,
      "learning_rate": 6.858665573434457e-06,
      "loss": 0.3647,
      "step": 6416
    },
    {
      "epoch": 1.31,
      "grad_norm": 2.3471806049346924,
      "learning_rate": 6.856615763041919e-06,
      "loss": 0.3877,
      "step": 6417
    },
    {
      "epoch": 1.31,
      "grad_norm": 1.5227768421173096,
      "learning_rate": 6.85456595264938e-06,
      "loss": 0.3863,
      "step": 6418
    },
    {
      "epoch": 1.32,
      "grad_norm": 1.5518032312393188,
      "learning_rate": 6.852516142256842e-06,
      "loss": 0.4248,
      "step": 6419
    },
    {
      "epoch": 1.32,
      "grad_norm": 2.3232367038726807,
      "learning_rate": 6.850466331864303e-06,
      "loss": 0.286,
      "step": 6420
    },
    {
      "epoch": 1.32,
      "grad_norm": 1.429412841796875,
      "learning_rate": 6.848416521471765e-06,
      "loss": 0.4811,
      "step": 6421
    },
    {
      "epoch": 1.32,
      "grad_norm": 1.128734827041626,
      "learning_rate": 6.846366711079225e-06,
      "loss": 0.3,
      "step": 6422
    },
    {
      "epoch": 1.32,
      "grad_norm": 1.2313848733901978,
      "learning_rate": 6.844316900686687e-06,
      "loss": 0.3552,
      "step": 6423
    },
    {
      "epoch": 1.32,
      "grad_norm": 1.306869626045227,
      "learning_rate": 6.842267090294148e-06,
      "loss": 0.306,
      "step": 6424
    },
    {
      "epoch": 1.32,
      "grad_norm": 1.1691949367523193,
      "learning_rate": 6.84021727990161e-06,
      "loss": 0.3831,
      "step": 6425
    },
    {
      "epoch": 1.32,
      "grad_norm": 1.5338436365127563,
      "learning_rate": 6.838167469509071e-06,
      "loss": 0.2791,
      "step": 6426
    },
    {
      "epoch": 1.32,
      "grad_norm": 1.8422198295593262,
      "learning_rate": 6.8361176591165325e-06,
      "loss": 0.393,
      "step": 6427
    },
    {
      "epoch": 1.32,
      "grad_norm": 0.9312724471092224,
      "learning_rate": 6.834067848723993e-06,
      "loss": 0.5066,
      "step": 6428
    },
    {
      "epoch": 1.32,
      "grad_norm": 1.093927264213562,
      "learning_rate": 6.8320180383314546e-06,
      "loss": 0.2587,
      "step": 6429
    },
    {
      "epoch": 1.32,
      "grad_norm": 0.9065700173377991,
      "learning_rate": 6.8299682279389156e-06,
      "loss": 0.1483,
      "step": 6430
    },
    {
      "epoch": 1.32,
      "grad_norm": 1.4589580297470093,
      "learning_rate": 6.8279184175463774e-06,
      "loss": 0.3707,
      "step": 6431
    },
    {
      "epoch": 1.32,
      "grad_norm": 1.1084628105163574,
      "learning_rate": 6.825868607153839e-06,
      "loss": 0.5148,
      "step": 6432
    },
    {
      "epoch": 1.32,
      "grad_norm": 1.050277590751648,
      "learning_rate": 6.8238187967613e-06,
      "loss": 0.3144,
      "step": 6433
    },
    {
      "epoch": 1.32,
      "grad_norm": 1.2020478248596191,
      "learning_rate": 6.821768986368762e-06,
      "loss": 0.3043,
      "step": 6434
    },
    {
      "epoch": 1.32,
      "grad_norm": 1.0913487672805786,
      "learning_rate": 6.819719175976222e-06,
      "loss": 0.3167,
      "step": 6435
    },
    {
      "epoch": 1.32,
      "grad_norm": 1.2741996049880981,
      "learning_rate": 6.817669365583684e-06,
      "loss": 0.3065,
      "step": 6436
    },
    {
      "epoch": 1.32,
      "grad_norm": 1.4815138578414917,
      "learning_rate": 6.815619555191145e-06,
      "loss": 0.4698,
      "step": 6437
    },
    {
      "epoch": 1.32,
      "grad_norm": 1.087852120399475,
      "learning_rate": 6.813569744798607e-06,
      "loss": 0.2954,
      "step": 6438
    },
    {
      "epoch": 1.32,
      "grad_norm": 1.4407261610031128,
      "learning_rate": 6.811519934406068e-06,
      "loss": 0.3242,
      "step": 6439
    },
    {
      "epoch": 1.32,
      "grad_norm": 1.0779706239700317,
      "learning_rate": 6.80947012401353e-06,
      "loss": 0.4795,
      "step": 6440
    },
    {
      "epoch": 1.32,
      "grad_norm": 0.9293094277381897,
      "learning_rate": 6.80742031362099e-06,
      "loss": 0.2926,
      "step": 6441
    },
    {
      "epoch": 1.32,
      "grad_norm": 1.5002427101135254,
      "learning_rate": 6.805370503228452e-06,
      "loss": 0.3052,
      "step": 6442
    },
    {
      "epoch": 1.32,
      "grad_norm": 1.147055983543396,
      "learning_rate": 6.803320692835913e-06,
      "loss": 0.3112,
      "step": 6443
    },
    {
      "epoch": 1.32,
      "grad_norm": 1.6700743436813354,
      "learning_rate": 6.801270882443375e-06,
      "loss": 0.5197,
      "step": 6444
    },
    {
      "epoch": 1.32,
      "grad_norm": 1.5082149505615234,
      "learning_rate": 6.799221072050836e-06,
      "loss": 0.5004,
      "step": 6445
    },
    {
      "epoch": 1.32,
      "grad_norm": 1.1765109300613403,
      "learning_rate": 6.797171261658298e-06,
      "loss": 0.3,
      "step": 6446
    },
    {
      "epoch": 1.32,
      "grad_norm": 0.9489306807518005,
      "learning_rate": 6.795121451265758e-06,
      "loss": 0.4316,
      "step": 6447
    },
    {
      "epoch": 1.32,
      "grad_norm": 1.1541646718978882,
      "learning_rate": 6.79307164087322e-06,
      "loss": 0.4573,
      "step": 6448
    },
    {
      "epoch": 1.32,
      "grad_norm": 1.1772505044937134,
      "learning_rate": 6.791021830480681e-06,
      "loss": 0.4543,
      "step": 6449
    },
    {
      "epoch": 1.32,
      "grad_norm": 1.785922884941101,
      "learning_rate": 6.7889720200881425e-06,
      "loss": 0.3881,
      "step": 6450
    },
    {
      "epoch": 1.32,
      "grad_norm": 1.5890158414840698,
      "learning_rate": 6.7869222096956035e-06,
      "loss": 0.3063,
      "step": 6451
    },
    {
      "epoch": 1.32,
      "grad_norm": 1.059047818183899,
      "learning_rate": 6.784872399303065e-06,
      "loss": 0.3019,
      "step": 6452
    },
    {
      "epoch": 1.32,
      "grad_norm": 1.087359070777893,
      "learning_rate": 6.7828225889105256e-06,
      "loss": 0.2603,
      "step": 6453
    },
    {
      "epoch": 1.32,
      "grad_norm": 1.3822147846221924,
      "learning_rate": 6.780772778517987e-06,
      "loss": 0.2619,
      "step": 6454
    },
    {
      "epoch": 1.32,
      "grad_norm": 1.6865746974945068,
      "learning_rate": 6.7787229681254484e-06,
      "loss": 0.355,
      "step": 6455
    },
    {
      "epoch": 1.32,
      "grad_norm": 1.1053767204284668,
      "learning_rate": 6.77667315773291e-06,
      "loss": 0.5115,
      "step": 6456
    },
    {
      "epoch": 1.32,
      "grad_norm": 1.9337825775146484,
      "learning_rate": 6.774623347340371e-06,
      "loss": 0.2118,
      "step": 6457
    },
    {
      "epoch": 1.32,
      "grad_norm": 1.5237560272216797,
      "learning_rate": 6.772573536947833e-06,
      "loss": 0.3353,
      "step": 6458
    },
    {
      "epoch": 1.32,
      "grad_norm": 1.5529685020446777,
      "learning_rate": 6.770523726555293e-06,
      "loss": 0.3448,
      "step": 6459
    },
    {
      "epoch": 1.32,
      "grad_norm": 1.3024725914001465,
      "learning_rate": 6.768473916162755e-06,
      "loss": 0.3052,
      "step": 6460
    },
    {
      "epoch": 1.32,
      "grad_norm": 1.8031812906265259,
      "learning_rate": 6.766424105770217e-06,
      "loss": 0.3592,
      "step": 6461
    },
    {
      "epoch": 1.32,
      "grad_norm": 1.697354793548584,
      "learning_rate": 6.764374295377678e-06,
      "loss": 0.278,
      "step": 6462
    },
    {
      "epoch": 1.32,
      "grad_norm": 1.112244725227356,
      "learning_rate": 6.76232448498514e-06,
      "loss": 0.4318,
      "step": 6463
    },
    {
      "epoch": 1.32,
      "grad_norm": 3.112943172454834,
      "learning_rate": 6.760274674592601e-06,
      "loss": 0.3687,
      "step": 6464
    },
    {
      "epoch": 1.32,
      "grad_norm": 2.2548859119415283,
      "learning_rate": 6.758224864200063e-06,
      "loss": 0.4596,
      "step": 6465
    },
    {
      "epoch": 1.32,
      "grad_norm": 1.0522485971450806,
      "learning_rate": 6.756175053807523e-06,
      "loss": 0.3498,
      "step": 6466
    },
    {
      "epoch": 1.32,
      "grad_norm": 2.452951669692993,
      "learning_rate": 6.754125243414985e-06,
      "loss": 0.3179,
      "step": 6467
    },
    {
      "epoch": 1.33,
      "grad_norm": 1.9587677717208862,
      "learning_rate": 6.752075433022446e-06,
      "loss": 0.5048,
      "step": 6468
    },
    {
      "epoch": 1.33,
      "grad_norm": 2.0270144939422607,
      "learning_rate": 6.750025622629908e-06,
      "loss": 0.5324,
      "step": 6469
    },
    {
      "epoch": 1.33,
      "grad_norm": 1.146851658821106,
      "learning_rate": 6.747975812237369e-06,
      "loss": 0.3719,
      "step": 6470
    },
    {
      "epoch": 1.33,
      "grad_norm": 1.9722765684127808,
      "learning_rate": 6.7459260018448305e-06,
      "loss": 0.3561,
      "step": 6471
    },
    {
      "epoch": 1.33,
      "grad_norm": 1.2751660346984863,
      "learning_rate": 6.743876191452291e-06,
      "loss": 0.3281,
      "step": 6472
    },
    {
      "epoch": 1.33,
      "grad_norm": 1.987927794456482,
      "learning_rate": 6.7418263810597525e-06,
      "loss": 0.4414,
      "step": 6473
    },
    {
      "epoch": 1.33,
      "grad_norm": 1.3395105600357056,
      "learning_rate": 6.7397765706672135e-06,
      "loss": 0.2694,
      "step": 6474
    },
    {
      "epoch": 1.33,
      "grad_norm": 2.070103645324707,
      "learning_rate": 6.737726760274675e-06,
      "loss": 0.3854,
      "step": 6475
    },
    {
      "epoch": 1.33,
      "grad_norm": 1.7751851081848145,
      "learning_rate": 6.735676949882136e-06,
      "loss": 0.3568,
      "step": 6476
    },
    {
      "epoch": 1.33,
      "grad_norm": 1.19287109375,
      "learning_rate": 6.733627139489598e-06,
      "loss": 0.3321,
      "step": 6477
    },
    {
      "epoch": 1.33,
      "grad_norm": 1.257676362991333,
      "learning_rate": 6.731577329097058e-06,
      "loss": 0.2875,
      "step": 6478
    },
    {
      "epoch": 1.33,
      "grad_norm": 1.0015789270401,
      "learning_rate": 6.72952751870452e-06,
      "loss": 0.2795,
      "step": 6479
    },
    {
      "epoch": 1.33,
      "grad_norm": 1.5198630094528198,
      "learning_rate": 6.727477708311981e-06,
      "loss": 0.4451,
      "step": 6480
    },
    {
      "epoch": 1.33,
      "grad_norm": 1.5297725200653076,
      "learning_rate": 6.725427897919443e-06,
      "loss": 0.4096,
      "step": 6481
    },
    {
      "epoch": 1.33,
      "grad_norm": 1.9654004573822021,
      "learning_rate": 6.723378087526904e-06,
      "loss": 0.303,
      "step": 6482
    },
    {
      "epoch": 1.33,
      "grad_norm": 1.648471474647522,
      "learning_rate": 6.721328277134366e-06,
      "loss": 0.2497,
      "step": 6483
    },
    {
      "epoch": 1.33,
      "grad_norm": 1.0906482934951782,
      "learning_rate": 6.719278466741826e-06,
      "loss": 0.4326,
      "step": 6484
    },
    {
      "epoch": 1.33,
      "grad_norm": 1.2755491733551025,
      "learning_rate": 6.717228656349288e-06,
      "loss": 0.4458,
      "step": 6485
    },
    {
      "epoch": 1.33,
      "grad_norm": 0.967072069644928,
      "learning_rate": 6.715178845956749e-06,
      "loss": 0.4709,
      "step": 6486
    },
    {
      "epoch": 1.33,
      "grad_norm": 1.6993217468261719,
      "learning_rate": 6.713129035564211e-06,
      "loss": 0.4333,
      "step": 6487
    },
    {
      "epoch": 1.33,
      "grad_norm": 1.5880039930343628,
      "learning_rate": 6.711079225171672e-06,
      "loss": 0.448,
      "step": 6488
    },
    {
      "epoch": 1.33,
      "grad_norm": 1.2286465167999268,
      "learning_rate": 6.709029414779134e-06,
      "loss": 0.3689,
      "step": 6489
    },
    {
      "epoch": 1.33,
      "grad_norm": 1.76580011844635,
      "learning_rate": 6.706979604386594e-06,
      "loss": 0.4323,
      "step": 6490
    },
    {
      "epoch": 1.33,
      "grad_norm": 1.4120261669158936,
      "learning_rate": 6.704929793994056e-06,
      "loss": 0.3113,
      "step": 6491
    },
    {
      "epoch": 1.33,
      "grad_norm": 1.0042608976364136,
      "learning_rate": 6.702879983601518e-06,
      "loss": 0.3355,
      "step": 6492
    },
    {
      "epoch": 1.33,
      "grad_norm": 1.3199788331985474,
      "learning_rate": 6.700830173208979e-06,
      "loss": 0.3379,
      "step": 6493
    },
    {
      "epoch": 1.33,
      "grad_norm": 1.1766034364700317,
      "learning_rate": 6.6987803628164405e-06,
      "loss": 0.3462,
      "step": 6494
    },
    {
      "epoch": 1.33,
      "grad_norm": 1.1903431415557861,
      "learning_rate": 6.6967305524239015e-06,
      "loss": 0.3094,
      "step": 6495
    },
    {
      "epoch": 1.33,
      "grad_norm": 1.1957284212112427,
      "learning_rate": 6.694680742031363e-06,
      "loss": 0.2304,
      "step": 6496
    },
    {
      "epoch": 1.33,
      "grad_norm": 1.1622222661972046,
      "learning_rate": 6.6926309316388235e-06,
      "loss": 0.4366,
      "step": 6497
    },
    {
      "epoch": 1.33,
      "grad_norm": 2.0173609256744385,
      "learning_rate": 6.690581121246285e-06,
      "loss": 0.4508,
      "step": 6498
    },
    {
      "epoch": 1.33,
      "grad_norm": 1.135708212852478,
      "learning_rate": 6.688531310853746e-06,
      "loss": 0.2156,
      "step": 6499
    },
    {
      "epoch": 1.33,
      "grad_norm": 1.6752946376800537,
      "learning_rate": 6.686481500461208e-06,
      "loss": 0.3408,
      "step": 6500
    },
    {
      "epoch": 1.33,
      "grad_norm": 1.1854320764541626,
      "learning_rate": 6.684431690068669e-06,
      "loss": 0.2078,
      "step": 6501
    },
    {
      "epoch": 1.33,
      "grad_norm": 1.3058444261550903,
      "learning_rate": 6.682381879676131e-06,
      "loss": 0.376,
      "step": 6502
    },
    {
      "epoch": 1.33,
      "grad_norm": 0.8190343976020813,
      "learning_rate": 6.680332069283591e-06,
      "loss": 0.2865,
      "step": 6503
    },
    {
      "epoch": 1.33,
      "grad_norm": 1.064839482307434,
      "learning_rate": 6.678282258891053e-06,
      "loss": 0.3141,
      "step": 6504
    },
    {
      "epoch": 1.33,
      "grad_norm": 1.2578155994415283,
      "learning_rate": 6.676232448498514e-06,
      "loss": 0.3334,
      "step": 6505
    },
    {
      "epoch": 1.33,
      "grad_norm": 1.5203185081481934,
      "learning_rate": 6.674182638105976e-06,
      "loss": 0.3207,
      "step": 6506
    },
    {
      "epoch": 1.33,
      "grad_norm": 1.5509194135665894,
      "learning_rate": 6.672132827713437e-06,
      "loss": 0.2958,
      "step": 6507
    },
    {
      "epoch": 1.33,
      "grad_norm": 1.0177510976791382,
      "learning_rate": 6.670083017320899e-06,
      "loss": 0.2358,
      "step": 6508
    },
    {
      "epoch": 1.33,
      "grad_norm": 1.051201343536377,
      "learning_rate": 6.668033206928359e-06,
      "loss": 0.3968,
      "step": 6509
    },
    {
      "epoch": 1.33,
      "grad_norm": 1.295936942100525,
      "learning_rate": 6.665983396535821e-06,
      "loss": 0.3196,
      "step": 6510
    },
    {
      "epoch": 1.33,
      "grad_norm": 1.1539684534072876,
      "learning_rate": 6.663933586143282e-06,
      "loss": 0.3228,
      "step": 6511
    },
    {
      "epoch": 1.33,
      "grad_norm": 1.0233488082885742,
      "learning_rate": 6.661883775750744e-06,
      "loss": 0.2925,
      "step": 6512
    },
    {
      "epoch": 1.33,
      "grad_norm": 1.2782984972000122,
      "learning_rate": 6.659833965358205e-06,
      "loss": 0.3478,
      "step": 6513
    },
    {
      "epoch": 1.33,
      "grad_norm": 0.9928916692733765,
      "learning_rate": 6.657784154965667e-06,
      "loss": 0.3335,
      "step": 6514
    },
    {
      "epoch": 1.33,
      "grad_norm": 0.8013836145401001,
      "learning_rate": 6.655734344573127e-06,
      "loss": 0.2834,
      "step": 6515
    },
    {
      "epoch": 1.33,
      "grad_norm": 1.2610983848571777,
      "learning_rate": 6.653684534180589e-06,
      "loss": 0.3509,
      "step": 6516
    },
    {
      "epoch": 1.34,
      "grad_norm": 0.9840736389160156,
      "learning_rate": 6.65163472378805e-06,
      "loss": 0.5855,
      "step": 6517
    },
    {
      "epoch": 1.34,
      "grad_norm": 1.029191255569458,
      "learning_rate": 6.6495849133955115e-06,
      "loss": 0.4306,
      "step": 6518
    },
    {
      "epoch": 1.34,
      "grad_norm": 1.0420308113098145,
      "learning_rate": 6.6475351030029725e-06,
      "loss": 0.3686,
      "step": 6519
    },
    {
      "epoch": 1.34,
      "grad_norm": 1.7399840354919434,
      "learning_rate": 6.645485292610434e-06,
      "loss": 0.2107,
      "step": 6520
    },
    {
      "epoch": 1.34,
      "grad_norm": 0.9716286659240723,
      "learning_rate": 6.643435482217896e-06,
      "loss": 0.373,
      "step": 6521
    },
    {
      "epoch": 1.34,
      "grad_norm": 0.9439476132392883,
      "learning_rate": 6.641385671825356e-06,
      "loss": 0.3895,
      "step": 6522
    },
    {
      "epoch": 1.34,
      "grad_norm": 1.2369319200515747,
      "learning_rate": 6.639335861432818e-06,
      "loss": 0.4346,
      "step": 6523
    },
    {
      "epoch": 1.34,
      "grad_norm": 1.013173222541809,
      "learning_rate": 6.637286051040279e-06,
      "loss": 0.2124,
      "step": 6524
    },
    {
      "epoch": 1.34,
      "grad_norm": 1.6010546684265137,
      "learning_rate": 6.635236240647741e-06,
      "loss": 0.3582,
      "step": 6525
    },
    {
      "epoch": 1.34,
      "grad_norm": 1.1618361473083496,
      "learning_rate": 6.633186430255202e-06,
      "loss": 0.3608,
      "step": 6526
    },
    {
      "epoch": 1.34,
      "grad_norm": 0.9257054924964905,
      "learning_rate": 6.631136619862664e-06,
      "loss": 0.4433,
      "step": 6527
    },
    {
      "epoch": 1.34,
      "grad_norm": 4.039903163909912,
      "learning_rate": 6.629086809470124e-06,
      "loss": 0.5522,
      "step": 6528
    },
    {
      "epoch": 1.34,
      "grad_norm": 1.3964574337005615,
      "learning_rate": 6.627036999077586e-06,
      "loss": 0.3096,
      "step": 6529
    },
    {
      "epoch": 1.34,
      "grad_norm": 1.1889759302139282,
      "learning_rate": 6.624987188685047e-06,
      "loss": 0.4112,
      "step": 6530
    },
    {
      "epoch": 1.34,
      "grad_norm": 1.125204086303711,
      "learning_rate": 6.622937378292509e-06,
      "loss": 0.4831,
      "step": 6531
    },
    {
      "epoch": 1.34,
      "grad_norm": 1.5987539291381836,
      "learning_rate": 6.62088756789997e-06,
      "loss": 0.6017,
      "step": 6532
    },
    {
      "epoch": 1.34,
      "grad_norm": 1.3949644565582275,
      "learning_rate": 6.618837757507432e-06,
      "loss": 0.4611,
      "step": 6533
    },
    {
      "epoch": 1.34,
      "grad_norm": 1.163796305656433,
      "learning_rate": 6.616787947114892e-06,
      "loss": 0.3617,
      "step": 6534
    },
    {
      "epoch": 1.34,
      "grad_norm": 1.0185085535049438,
      "learning_rate": 6.614738136722354e-06,
      "loss": 0.4123,
      "step": 6535
    },
    {
      "epoch": 1.34,
      "grad_norm": 1.1533328294754028,
      "learning_rate": 6.612688326329815e-06,
      "loss": 0.467,
      "step": 6536
    },
    {
      "epoch": 1.34,
      "grad_norm": 3.575063705444336,
      "learning_rate": 6.610638515937277e-06,
      "loss": 0.3574,
      "step": 6537
    },
    {
      "epoch": 1.34,
      "grad_norm": 1.5273466110229492,
      "learning_rate": 6.608588705544738e-06,
      "loss": 0.2965,
      "step": 6538
    },
    {
      "epoch": 1.34,
      "grad_norm": 1.4828367233276367,
      "learning_rate": 6.6065388951521995e-06,
      "loss": 0.2152,
      "step": 6539
    },
    {
      "epoch": 1.34,
      "grad_norm": 2.037076473236084,
      "learning_rate": 6.60448908475966e-06,
      "loss": 0.4618,
      "step": 6540
    },
    {
      "epoch": 1.34,
      "grad_norm": 1.555677056312561,
      "learning_rate": 6.6024392743671215e-06,
      "loss": 0.2877,
      "step": 6541
    },
    {
      "epoch": 1.34,
      "grad_norm": 1.5218608379364014,
      "learning_rate": 6.6003894639745825e-06,
      "loss": 0.3477,
      "step": 6542
    },
    {
      "epoch": 1.34,
      "grad_norm": 1.317577600479126,
      "learning_rate": 6.598339653582044e-06,
      "loss": 0.2464,
      "step": 6543
    },
    {
      "epoch": 1.34,
      "grad_norm": 1.9602547883987427,
      "learning_rate": 6.596289843189505e-06,
      "loss": 0.4586,
      "step": 6544
    },
    {
      "epoch": 1.34,
      "grad_norm": 1.0019607543945312,
      "learning_rate": 6.594240032796967e-06,
      "loss": 0.3919,
      "step": 6545
    },
    {
      "epoch": 1.34,
      "grad_norm": 1.455227255821228,
      "learning_rate": 6.592190222404427e-06,
      "loss": 0.3675,
      "step": 6546
    },
    {
      "epoch": 1.34,
      "grad_norm": 1.098939061164856,
      "learning_rate": 6.590140412011889e-06,
      "loss": 0.3219,
      "step": 6547
    },
    {
      "epoch": 1.34,
      "grad_norm": 1.8946431875228882,
      "learning_rate": 6.58809060161935e-06,
      "loss": 0.328,
      "step": 6548
    },
    {
      "epoch": 1.34,
      "grad_norm": 1.6484675407409668,
      "learning_rate": 6.586040791226812e-06,
      "loss": 0.3706,
      "step": 6549
    },
    {
      "epoch": 1.34,
      "grad_norm": 1.4487522840499878,
      "learning_rate": 6.583990980834274e-06,
      "loss": 0.4709,
      "step": 6550
    },
    {
      "epoch": 1.34,
      "grad_norm": 1.6012734174728394,
      "learning_rate": 6.581941170441735e-06,
      "loss": 0.3787,
      "step": 6551
    },
    {
      "epoch": 1.34,
      "grad_norm": 1.2123037576675415,
      "learning_rate": 6.579891360049197e-06,
      "loss": 0.2729,
      "step": 6552
    },
    {
      "epoch": 1.34,
      "grad_norm": 1.286213755607605,
      "learning_rate": 6.577841549656657e-06,
      "loss": 0.2595,
      "step": 6553
    },
    {
      "epoch": 1.34,
      "grad_norm": 1.3180779218673706,
      "learning_rate": 6.575791739264119e-06,
      "loss": 0.2584,
      "step": 6554
    },
    {
      "epoch": 1.34,
      "grad_norm": 0.8082932829856873,
      "learning_rate": 6.57374192887158e-06,
      "loss": 0.2327,
      "step": 6555
    },
    {
      "epoch": 1.34,
      "grad_norm": 1.384423017501831,
      "learning_rate": 6.571692118479042e-06,
      "loss": 0.2702,
      "step": 6556
    },
    {
      "epoch": 1.34,
      "grad_norm": 3.288954257965088,
      "learning_rate": 6.569642308086503e-06,
      "loss": 0.3398,
      "step": 6557
    },
    {
      "epoch": 1.34,
      "grad_norm": 1.4695024490356445,
      "learning_rate": 6.567592497693965e-06,
      "loss": 0.3743,
      "step": 6558
    },
    {
      "epoch": 1.34,
      "grad_norm": 1.1148972511291504,
      "learning_rate": 6.565542687301425e-06,
      "loss": 0.3619,
      "step": 6559
    },
    {
      "epoch": 1.34,
      "grad_norm": 1.437138319015503,
      "learning_rate": 6.563492876908887e-06,
      "loss": 0.5293,
      "step": 6560
    },
    {
      "epoch": 1.34,
      "grad_norm": 1.6010229587554932,
      "learning_rate": 6.561443066516348e-06,
      "loss": 0.2969,
      "step": 6561
    },
    {
      "epoch": 1.34,
      "grad_norm": 1.1943258047103882,
      "learning_rate": 6.5593932561238095e-06,
      "loss": 0.4126,
      "step": 6562
    },
    {
      "epoch": 1.34,
      "grad_norm": 2.1554408073425293,
      "learning_rate": 6.5573434457312705e-06,
      "loss": 0.3026,
      "step": 6563
    },
    {
      "epoch": 1.34,
      "grad_norm": 1.1539422273635864,
      "learning_rate": 6.555293635338732e-06,
      "loss": 0.4778,
      "step": 6564
    },
    {
      "epoch": 1.35,
      "grad_norm": 1.1589480638504028,
      "learning_rate": 6.5532438249461925e-06,
      "loss": 0.3922,
      "step": 6565
    },
    {
      "epoch": 1.35,
      "grad_norm": 1.1245803833007812,
      "learning_rate": 6.551194014553654e-06,
      "loss": 0.4247,
      "step": 6566
    },
    {
      "epoch": 1.35,
      "grad_norm": 0.8416194319725037,
      "learning_rate": 6.549144204161115e-06,
      "loss": 0.2432,
      "step": 6567
    },
    {
      "epoch": 1.35,
      "grad_norm": 1.554689884185791,
      "learning_rate": 6.547094393768577e-06,
      "loss": 0.2836,
      "step": 6568
    },
    {
      "epoch": 1.35,
      "grad_norm": 1.3286887407302856,
      "learning_rate": 6.545044583376038e-06,
      "loss": 0.3088,
      "step": 6569
    },
    {
      "epoch": 1.35,
      "grad_norm": 1.3011256456375122,
      "learning_rate": 6.5429947729835e-06,
      "loss": 0.1947,
      "step": 6570
    },
    {
      "epoch": 1.35,
      "grad_norm": 1.0198107957839966,
      "learning_rate": 6.54094496259096e-06,
      "loss": 0.3281,
      "step": 6571
    },
    {
      "epoch": 1.35,
      "grad_norm": 1.3859505653381348,
      "learning_rate": 6.538895152198422e-06,
      "loss": 0.3506,
      "step": 6572
    },
    {
      "epoch": 1.35,
      "grad_norm": 1.1252360343933105,
      "learning_rate": 6.536845341805883e-06,
      "loss": 0.3026,
      "step": 6573
    },
    {
      "epoch": 1.35,
      "grad_norm": 1.490417242050171,
      "learning_rate": 6.534795531413345e-06,
      "loss": 0.4142,
      "step": 6574
    },
    {
      "epoch": 1.35,
      "grad_norm": 1.3429367542266846,
      "learning_rate": 6.532745721020806e-06,
      "loss": 0.3343,
      "step": 6575
    },
    {
      "epoch": 1.35,
      "grad_norm": 0.7880961894989014,
      "learning_rate": 6.530695910628268e-06,
      "loss": 0.1775,
      "step": 6576
    },
    {
      "epoch": 1.35,
      "grad_norm": 1.13899827003479,
      "learning_rate": 6.528646100235728e-06,
      "loss": 0.3478,
      "step": 6577
    },
    {
      "epoch": 1.35,
      "grad_norm": 0.7636800408363342,
      "learning_rate": 6.52659628984319e-06,
      "loss": 0.2101,
      "step": 6578
    },
    {
      "epoch": 1.35,
      "grad_norm": 1.7687716484069824,
      "learning_rate": 6.524546479450652e-06,
      "loss": 0.4714,
      "step": 6579
    },
    {
      "epoch": 1.35,
      "grad_norm": 0.9349541068077087,
      "learning_rate": 6.522496669058113e-06,
      "loss": 0.2415,
      "step": 6580
    },
    {
      "epoch": 1.35,
      "grad_norm": 1.3747509717941284,
      "learning_rate": 6.5204468586655746e-06,
      "loss": 0.3372,
      "step": 6581
    },
    {
      "epoch": 1.35,
      "grad_norm": 1.962873935699463,
      "learning_rate": 6.518397048273036e-06,
      "loss": 0.3765,
      "step": 6582
    },
    {
      "epoch": 1.35,
      "grad_norm": 0.9974057674407959,
      "learning_rate": 6.5163472378804974e-06,
      "loss": 0.328,
      "step": 6583
    },
    {
      "epoch": 1.35,
      "grad_norm": 1.0520552396774292,
      "learning_rate": 6.514297427487958e-06,
      "loss": 0.2701,
      "step": 6584
    },
    {
      "epoch": 1.35,
      "grad_norm": 1.2503823041915894,
      "learning_rate": 6.5122476170954195e-06,
      "loss": 0.337,
      "step": 6585
    },
    {
      "epoch": 1.35,
      "grad_norm": 1.2698392868041992,
      "learning_rate": 6.5101978067028805e-06,
      "loss": 0.2627,
      "step": 6586
    },
    {
      "epoch": 1.35,
      "grad_norm": 2.0943541526794434,
      "learning_rate": 6.508147996310342e-06,
      "loss": 0.3039,
      "step": 6587
    },
    {
      "epoch": 1.35,
      "grad_norm": 1.3014898300170898,
      "learning_rate": 6.506098185917803e-06,
      "loss": 0.3849,
      "step": 6588
    },
    {
      "epoch": 1.35,
      "grad_norm": 1.2494267225265503,
      "learning_rate": 6.504048375525265e-06,
      "loss": 0.343,
      "step": 6589
    },
    {
      "epoch": 1.35,
      "grad_norm": 1.3569902181625366,
      "learning_rate": 6.501998565132725e-06,
      "loss": 0.3864,
      "step": 6590
    },
    {
      "epoch": 1.35,
      "grad_norm": 1.4287519454956055,
      "learning_rate": 6.499948754740187e-06,
      "loss": 0.4817,
      "step": 6591
    },
    {
      "epoch": 1.35,
      "grad_norm": 1.2998424768447876,
      "learning_rate": 6.497898944347648e-06,
      "loss": 0.2416,
      "step": 6592
    },
    {
      "epoch": 1.35,
      "grad_norm": 1.8781298398971558,
      "learning_rate": 6.49584913395511e-06,
      "loss": 0.2658,
      "step": 6593
    },
    {
      "epoch": 1.35,
      "grad_norm": 1.0648479461669922,
      "learning_rate": 6.493799323562571e-06,
      "loss": 0.3246,
      "step": 6594
    },
    {
      "epoch": 1.35,
      "grad_norm": 1.4318572282791138,
      "learning_rate": 6.491749513170033e-06,
      "loss": 0.3396,
      "step": 6595
    },
    {
      "epoch": 1.35,
      "grad_norm": 0.907915472984314,
      "learning_rate": 6.489699702777493e-06,
      "loss": 0.2931,
      "step": 6596
    },
    {
      "epoch": 1.35,
      "grad_norm": 1.2544773817062378,
      "learning_rate": 6.487649892384955e-06,
      "loss": 0.3755,
      "step": 6597
    },
    {
      "epoch": 1.35,
      "grad_norm": 1.1738168001174927,
      "learning_rate": 6.485600081992416e-06,
      "loss": 0.3432,
      "step": 6598
    },
    {
      "epoch": 1.35,
      "grad_norm": 1.4893585443496704,
      "learning_rate": 6.483550271599878e-06,
      "loss": 0.1916,
      "step": 6599
    },
    {
      "epoch": 1.35,
      "grad_norm": 1.4219361543655396,
      "learning_rate": 6.481500461207339e-06,
      "loss": 0.2868,
      "step": 6600
    },
    {
      "epoch": 1.35,
      "grad_norm": 1.1724342107772827,
      "learning_rate": 6.479450650814801e-06,
      "loss": 0.2889,
      "step": 6601
    },
    {
      "epoch": 1.35,
      "grad_norm": 1.2097643613815308,
      "learning_rate": 6.477400840422261e-06,
      "loss": 0.3652,
      "step": 6602
    },
    {
      "epoch": 1.35,
      "grad_norm": 2.542191505432129,
      "learning_rate": 6.475351030029723e-06,
      "loss": 0.2832,
      "step": 6603
    },
    {
      "epoch": 1.35,
      "grad_norm": 1.6428526639938354,
      "learning_rate": 6.473301219637184e-06,
      "loss": 0.4406,
      "step": 6604
    },
    {
      "epoch": 1.35,
      "grad_norm": 1.6629146337509155,
      "learning_rate": 6.4712514092446456e-06,
      "loss": 0.4159,
      "step": 6605
    },
    {
      "epoch": 1.35,
      "grad_norm": 2.015810012817383,
      "learning_rate": 6.469201598852107e-06,
      "loss": 0.1815,
      "step": 6606
    },
    {
      "epoch": 1.35,
      "grad_norm": 0.7868866324424744,
      "learning_rate": 6.4671517884595684e-06,
      "loss": 0.459,
      "step": 6607
    },
    {
      "epoch": 1.35,
      "grad_norm": 1.011502981185913,
      "learning_rate": 6.46510197806703e-06,
      "loss": 0.3187,
      "step": 6608
    },
    {
      "epoch": 1.35,
      "grad_norm": 1.4643296003341675,
      "learning_rate": 6.4630521676744905e-06,
      "loss": 0.3927,
      "step": 6609
    },
    {
      "epoch": 1.35,
      "grad_norm": 1.3090441226959229,
      "learning_rate": 6.461002357281952e-06,
      "loss": 0.4397,
      "step": 6610
    },
    {
      "epoch": 1.35,
      "grad_norm": 1.359826683998108,
      "learning_rate": 6.458952546889413e-06,
      "loss": 0.2322,
      "step": 6611
    },
    {
      "epoch": 1.35,
      "grad_norm": 1.6979162693023682,
      "learning_rate": 6.456902736496875e-06,
      "loss": 0.3654,
      "step": 6612
    },
    {
      "epoch": 1.35,
      "grad_norm": 1.9041205644607544,
      "learning_rate": 6.454852926104336e-06,
      "loss": 0.3028,
      "step": 6613
    },
    {
      "epoch": 1.36,
      "grad_norm": 2.2368526458740234,
      "learning_rate": 6.452803115711798e-06,
      "loss": 0.2535,
      "step": 6614
    },
    {
      "epoch": 1.36,
      "grad_norm": 1.4872170686721802,
      "learning_rate": 6.450753305319258e-06,
      "loss": 0.2635,
      "step": 6615
    },
    {
      "epoch": 1.36,
      "grad_norm": 1.7313939332962036,
      "learning_rate": 6.44870349492672e-06,
      "loss": 0.2508,
      "step": 6616
    },
    {
      "epoch": 1.36,
      "grad_norm": 1.5117721557617188,
      "learning_rate": 6.446653684534181e-06,
      "loss": 0.339,
      "step": 6617
    },
    {
      "epoch": 1.36,
      "grad_norm": 1.5799205303192139,
      "learning_rate": 6.444603874141643e-06,
      "loss": 0.52,
      "step": 6618
    },
    {
      "epoch": 1.36,
      "grad_norm": 1.2031738758087158,
      "learning_rate": 6.442554063749104e-06,
      "loss": 0.2995,
      "step": 6619
    },
    {
      "epoch": 1.36,
      "grad_norm": 1.856600284576416,
      "learning_rate": 6.440504253356566e-06,
      "loss": 0.3721,
      "step": 6620
    },
    {
      "epoch": 1.36,
      "grad_norm": 1.4369845390319824,
      "learning_rate": 6.438454442964026e-06,
      "loss": 0.3892,
      "step": 6621
    },
    {
      "epoch": 1.36,
      "grad_norm": 1.1550071239471436,
      "learning_rate": 6.436404632571488e-06,
      "loss": 0.3679,
      "step": 6622
    },
    {
      "epoch": 1.36,
      "grad_norm": 1.0967682600021362,
      "learning_rate": 6.434354822178949e-06,
      "loss": 0.3738,
      "step": 6623
    },
    {
      "epoch": 1.36,
      "grad_norm": 1.2451858520507812,
      "learning_rate": 6.432305011786411e-06,
      "loss": 0.2499,
      "step": 6624
    },
    {
      "epoch": 1.36,
      "grad_norm": 1.3100241422653198,
      "learning_rate": 6.430255201393872e-06,
      "loss": 0.2855,
      "step": 6625
    },
    {
      "epoch": 1.36,
      "grad_norm": 1.2255568504333496,
      "learning_rate": 6.428205391001333e-06,
      "loss": 0.4461,
      "step": 6626
    },
    {
      "epoch": 1.36,
      "grad_norm": 1.3236490488052368,
      "learning_rate": 6.426155580608794e-06,
      "loss": 0.3692,
      "step": 6627
    },
    {
      "epoch": 1.36,
      "grad_norm": 1.7034600973129272,
      "learning_rate": 6.4241057702162556e-06,
      "loss": 0.4019,
      "step": 6628
    },
    {
      "epoch": 1.36,
      "grad_norm": 1.0430705547332764,
      "learning_rate": 6.4220559598237166e-06,
      "loss": 0.3093,
      "step": 6629
    },
    {
      "epoch": 1.36,
      "grad_norm": 0.7838383913040161,
      "learning_rate": 6.4200061494311784e-06,
      "loss": 0.3068,
      "step": 6630
    },
    {
      "epoch": 1.36,
      "grad_norm": 1.419630765914917,
      "learning_rate": 6.4179563390386394e-06,
      "loss": 0.1859,
      "step": 6631
    },
    {
      "epoch": 1.36,
      "grad_norm": 1.119844913482666,
      "learning_rate": 6.4159065286461004e-06,
      "loss": 0.358,
      "step": 6632
    },
    {
      "epoch": 1.36,
      "grad_norm": 1.3076832294464111,
      "learning_rate": 6.4138567182535615e-06,
      "loss": 0.3298,
      "step": 6633
    },
    {
      "epoch": 1.36,
      "grad_norm": 1.1300617456436157,
      "learning_rate": 6.411806907861023e-06,
      "loss": 0.2723,
      "step": 6634
    },
    {
      "epoch": 1.36,
      "grad_norm": 1.0998097658157349,
      "learning_rate": 6.409757097468484e-06,
      "loss": 0.2493,
      "step": 6635
    },
    {
      "epoch": 1.36,
      "grad_norm": 1.161736249923706,
      "learning_rate": 6.407707287075946e-06,
      "loss": 0.2581,
      "step": 6636
    },
    {
      "epoch": 1.36,
      "grad_norm": 0.8799901008605957,
      "learning_rate": 6.405657476683406e-06,
      "loss": 0.1645,
      "step": 6637
    },
    {
      "epoch": 1.36,
      "grad_norm": 1.3429867029190063,
      "learning_rate": 6.403607666290868e-06,
      "loss": 0.3649,
      "step": 6638
    },
    {
      "epoch": 1.36,
      "grad_norm": 1.132592797279358,
      "learning_rate": 6.40155785589833e-06,
      "loss": 0.3104,
      "step": 6639
    },
    {
      "epoch": 1.36,
      "grad_norm": 1.283596396446228,
      "learning_rate": 6.399508045505791e-06,
      "loss": 0.3683,
      "step": 6640
    },
    {
      "epoch": 1.36,
      "grad_norm": 1.4037182331085205,
      "learning_rate": 6.397458235113253e-06,
      "loss": 0.2077,
      "step": 6641
    },
    {
      "epoch": 1.36,
      "grad_norm": 0.9442242980003357,
      "learning_rate": 6.395408424720714e-06,
      "loss": 0.3027,
      "step": 6642
    },
    {
      "epoch": 1.36,
      "grad_norm": 1.2527347803115845,
      "learning_rate": 6.393358614328176e-06,
      "loss": 0.3585,
      "step": 6643
    },
    {
      "epoch": 1.36,
      "grad_norm": 1.393371820449829,
      "learning_rate": 6.391308803935636e-06,
      "loss": 0.3193,
      "step": 6644
    },
    {
      "epoch": 1.36,
      "grad_norm": 1.0635346174240112,
      "learning_rate": 6.389258993543098e-06,
      "loss": 0.3295,
      "step": 6645
    },
    {
      "epoch": 1.36,
      "grad_norm": 0.9191756248474121,
      "learning_rate": 6.387209183150559e-06,
      "loss": 0.3968,
      "step": 6646
    },
    {
      "epoch": 1.36,
      "grad_norm": 1.1033589839935303,
      "learning_rate": 6.385159372758021e-06,
      "loss": 0.2585,
      "step": 6647
    },
    {
      "epoch": 1.36,
      "grad_norm": 1.558403491973877,
      "learning_rate": 6.383109562365482e-06,
      "loss": 0.3844,
      "step": 6648
    },
    {
      "epoch": 1.36,
      "grad_norm": 1.1244393587112427,
      "learning_rate": 6.3810597519729435e-06,
      "loss": 0.2201,
      "step": 6649
    },
    {
      "epoch": 1.36,
      "grad_norm": 1.2662862539291382,
      "learning_rate": 6.379009941580404e-06,
      "loss": 0.3181,
      "step": 6650
    },
    {
      "epoch": 1.36,
      "grad_norm": 1.318733811378479,
      "learning_rate": 6.3769601311878656e-06,
      "loss": 0.3709,
      "step": 6651
    },
    {
      "epoch": 1.36,
      "grad_norm": 1.273393988609314,
      "learning_rate": 6.3749103207953266e-06,
      "loss": 0.3885,
      "step": 6652
    },
    {
      "epoch": 1.36,
      "grad_norm": 0.8362136483192444,
      "learning_rate": 6.372860510402788e-06,
      "loss": 0.3082,
      "step": 6653
    },
    {
      "epoch": 1.36,
      "grad_norm": 1.959524393081665,
      "learning_rate": 6.3708107000102494e-06,
      "loss": 0.3063,
      "step": 6654
    },
    {
      "epoch": 1.36,
      "grad_norm": 0.9504722952842712,
      "learning_rate": 6.368760889617711e-06,
      "loss": 0.2623,
      "step": 6655
    },
    {
      "epoch": 1.36,
      "grad_norm": 1.5126354694366455,
      "learning_rate": 6.3667110792251714e-06,
      "loss": 0.4102,
      "step": 6656
    },
    {
      "epoch": 1.36,
      "grad_norm": 0.983462929725647,
      "learning_rate": 6.364661268832633e-06,
      "loss": 0.3226,
      "step": 6657
    },
    {
      "epoch": 1.36,
      "grad_norm": 1.133126974105835,
      "learning_rate": 6.362611458440094e-06,
      "loss": 0.3864,
      "step": 6658
    },
    {
      "epoch": 1.36,
      "grad_norm": 1.8193262815475464,
      "learning_rate": 6.360561648047556e-06,
      "loss": 0.2813,
      "step": 6659
    },
    {
      "epoch": 1.36,
      "grad_norm": 1.1806468963623047,
      "learning_rate": 6.358511837655017e-06,
      "loss": 0.441,
      "step": 6660
    },
    {
      "epoch": 1.36,
      "grad_norm": 1.0726872682571411,
      "learning_rate": 6.356462027262479e-06,
      "loss": 0.2531,
      "step": 6661
    },
    {
      "epoch": 1.36,
      "grad_norm": 0.7231402397155762,
      "learning_rate": 6.354412216869939e-06,
      "loss": 0.2665,
      "step": 6662
    },
    {
      "epoch": 1.37,
      "grad_norm": 1.3892258405685425,
      "learning_rate": 6.352362406477401e-06,
      "loss": 0.3782,
      "step": 6663
    },
    {
      "epoch": 1.37,
      "grad_norm": 1.2813067436218262,
      "learning_rate": 6.350312596084862e-06,
      "loss": 0.2506,
      "step": 6664
    },
    {
      "epoch": 1.37,
      "grad_norm": 1.2989212274551392,
      "learning_rate": 6.348262785692324e-06,
      "loss": 0.4953,
      "step": 6665
    },
    {
      "epoch": 1.37,
      "grad_norm": 1.8242522478103638,
      "learning_rate": 6.346212975299785e-06,
      "loss": 0.2216,
      "step": 6666
    },
    {
      "epoch": 1.37,
      "grad_norm": 1.7271978855133057,
      "learning_rate": 6.344163164907247e-06,
      "loss": 0.2298,
      "step": 6667
    },
    {
      "epoch": 1.37,
      "grad_norm": 0.9988422393798828,
      "learning_rate": 6.342113354514709e-06,
      "loss": 0.3513,
      "step": 6668
    },
    {
      "epoch": 1.37,
      "grad_norm": 1.0064979791641235,
      "learning_rate": 6.340063544122169e-06,
      "loss": 0.364,
      "step": 6669
    },
    {
      "epoch": 1.37,
      "grad_norm": 1.7131065130233765,
      "learning_rate": 6.338013733729631e-06,
      "loss": 0.2931,
      "step": 6670
    },
    {
      "epoch": 1.37,
      "grad_norm": 2.0373542308807373,
      "learning_rate": 6.335963923337092e-06,
      "loss": 0.2338,
      "step": 6671
    },
    {
      "epoch": 1.37,
      "grad_norm": 2.52180814743042,
      "learning_rate": 6.3339141129445535e-06,
      "loss": 0.3098,
      "step": 6672
    },
    {
      "epoch": 1.37,
      "grad_norm": 1.4745829105377197,
      "learning_rate": 6.3318643025520145e-06,
      "loss": 0.4294,
      "step": 6673
    },
    {
      "epoch": 1.37,
      "grad_norm": 1.1755346059799194,
      "learning_rate": 6.329814492159476e-06,
      "loss": 0.4831,
      "step": 6674
    },
    {
      "epoch": 1.37,
      "grad_norm": 1.8976612091064453,
      "learning_rate": 6.3277646817669366e-06,
      "loss": 0.3332,
      "step": 6675
    },
    {
      "epoch": 1.37,
      "grad_norm": 1.621425747871399,
      "learning_rate": 6.325714871374398e-06,
      "loss": 0.2457,
      "step": 6676
    },
    {
      "epoch": 1.37,
      "grad_norm": 1.2488551139831543,
      "learning_rate": 6.323665060981859e-06,
      "loss": 0.3473,
      "step": 6677
    },
    {
      "epoch": 1.37,
      "grad_norm": 1.412975549697876,
      "learning_rate": 6.321615250589321e-06,
      "loss": 0.3046,
      "step": 6678
    },
    {
      "epoch": 1.37,
      "grad_norm": 2.708867073059082,
      "learning_rate": 6.319565440196782e-06,
      "loss": 0.2882,
      "step": 6679
    },
    {
      "epoch": 1.37,
      "grad_norm": 1.0914885997772217,
      "learning_rate": 6.317515629804244e-06,
      "loss": 0.3677,
      "step": 6680
    },
    {
      "epoch": 1.37,
      "grad_norm": 0.7114818096160889,
      "learning_rate": 6.315465819411704e-06,
      "loss": 0.1775,
      "step": 6681
    },
    {
      "epoch": 1.37,
      "grad_norm": 1.9078545570373535,
      "learning_rate": 6.313416009019166e-06,
      "loss": 0.3699,
      "step": 6682
    },
    {
      "epoch": 1.37,
      "grad_norm": 2.630709648132324,
      "learning_rate": 6.311366198626627e-06,
      "loss": 0.5173,
      "step": 6683
    },
    {
      "epoch": 1.37,
      "grad_norm": 1.2280247211456299,
      "learning_rate": 6.309316388234089e-06,
      "loss": 0.3282,
      "step": 6684
    },
    {
      "epoch": 1.37,
      "grad_norm": 1.0910037755966187,
      "learning_rate": 6.30726657784155e-06,
      "loss": 0.2162,
      "step": 6685
    },
    {
      "epoch": 1.37,
      "grad_norm": 1.8770653009414673,
      "learning_rate": 6.305216767449012e-06,
      "loss": 0.367,
      "step": 6686
    },
    {
      "epoch": 1.37,
      "grad_norm": 1.3916220664978027,
      "learning_rate": 6.303166957056472e-06,
      "loss": 0.4102,
      "step": 6687
    },
    {
      "epoch": 1.37,
      "grad_norm": 1.218972086906433,
      "learning_rate": 6.301117146663934e-06,
      "loss": 0.4678,
      "step": 6688
    },
    {
      "epoch": 1.37,
      "grad_norm": 1.142130732536316,
      "learning_rate": 6.299067336271395e-06,
      "loss": 0.331,
      "step": 6689
    },
    {
      "epoch": 1.37,
      "grad_norm": 1.7345589399337769,
      "learning_rate": 6.297017525878857e-06,
      "loss": 0.466,
      "step": 6690
    },
    {
      "epoch": 1.37,
      "grad_norm": 1.0512444972991943,
      "learning_rate": 6.294967715486318e-06,
      "loss": 0.2602,
      "step": 6691
    },
    {
      "epoch": 1.37,
      "grad_norm": 0.8254780769348145,
      "learning_rate": 6.29291790509378e-06,
      "loss": 0.3403,
      "step": 6692
    },
    {
      "epoch": 1.37,
      "grad_norm": 1.2206835746765137,
      "learning_rate": 6.29086809470124e-06,
      "loss": 0.2523,
      "step": 6693
    },
    {
      "epoch": 1.37,
      "grad_norm": 0.885005533695221,
      "learning_rate": 6.288818284308702e-06,
      "loss": 0.2963,
      "step": 6694
    },
    {
      "epoch": 1.37,
      "grad_norm": 1.0105925798416138,
      "learning_rate": 6.286768473916163e-06,
      "loss": 0.2564,
      "step": 6695
    },
    {
      "epoch": 1.37,
      "grad_norm": 1.121159553527832,
      "learning_rate": 6.2847186635236245e-06,
      "loss": 0.2837,
      "step": 6696
    },
    {
      "epoch": 1.37,
      "grad_norm": 0.9805818796157837,
      "learning_rate": 6.282668853131086e-06,
      "loss": 0.3642,
      "step": 6697
    },
    {
      "epoch": 1.37,
      "grad_norm": 0.9942842721939087,
      "learning_rate": 6.280619042738547e-06,
      "loss": 0.24,
      "step": 6698
    },
    {
      "epoch": 1.37,
      "grad_norm": 1.084172010421753,
      "learning_rate": 6.278569232346009e-06,
      "loss": 0.4371,
      "step": 6699
    },
    {
      "epoch": 1.37,
      "grad_norm": 0.950222373008728,
      "learning_rate": 6.276519421953469e-06,
      "loss": 0.304,
      "step": 6700
    },
    {
      "epoch": 1.37,
      "grad_norm": 1.5459837913513184,
      "learning_rate": 6.274469611560931e-06,
      "loss": 0.3674,
      "step": 6701
    },
    {
      "epoch": 1.37,
      "grad_norm": 0.9930962920188904,
      "learning_rate": 6.272419801168392e-06,
      "loss": 0.3242,
      "step": 6702
    },
    {
      "epoch": 1.37,
      "grad_norm": 0.9860029220581055,
      "learning_rate": 6.270369990775854e-06,
      "loss": 0.3151,
      "step": 6703
    },
    {
      "epoch": 1.37,
      "grad_norm": 1.0246269702911377,
      "learning_rate": 6.268320180383315e-06,
      "loss": 0.446,
      "step": 6704
    },
    {
      "epoch": 1.37,
      "grad_norm": 1.1973005533218384,
      "learning_rate": 6.266270369990777e-06,
      "loss": 0.3802,
      "step": 6705
    },
    {
      "epoch": 1.37,
      "grad_norm": 0.9643215537071228,
      "learning_rate": 6.264220559598237e-06,
      "loss": 0.2004,
      "step": 6706
    },
    {
      "epoch": 1.37,
      "grad_norm": 1.1827099323272705,
      "learning_rate": 6.262170749205699e-06,
      "loss": 0.3012,
      "step": 6707
    },
    {
      "epoch": 1.37,
      "grad_norm": 1.1550244092941284,
      "learning_rate": 6.26012093881316e-06,
      "loss": 0.3343,
      "step": 6708
    },
    {
      "epoch": 1.37,
      "grad_norm": 1.1803717613220215,
      "learning_rate": 6.258071128420622e-06,
      "loss": 0.3277,
      "step": 6709
    },
    {
      "epoch": 1.37,
      "grad_norm": 1.2662373781204224,
      "learning_rate": 6.256021318028083e-06,
      "loss": 0.2791,
      "step": 6710
    },
    {
      "epoch": 1.37,
      "grad_norm": 1.3419842720031738,
      "learning_rate": 6.253971507635545e-06,
      "loss": 0.4938,
      "step": 6711
    },
    {
      "epoch": 1.38,
      "grad_norm": 1.202620506286621,
      "learning_rate": 6.251921697243005e-06,
      "loss": 0.4625,
      "step": 6712
    },
    {
      "epoch": 1.38,
      "grad_norm": 1.100584864616394,
      "learning_rate": 6.249871886850467e-06,
      "loss": 0.4032,
      "step": 6713
    },
    {
      "epoch": 1.38,
      "grad_norm": 0.8360300660133362,
      "learning_rate": 6.247822076457928e-06,
      "loss": 0.2293,
      "step": 6714
    },
    {
      "epoch": 1.38,
      "grad_norm": 0.8410554528236389,
      "learning_rate": 6.24577226606539e-06,
      "loss": 0.2543,
      "step": 6715
    },
    {
      "epoch": 1.38,
      "grad_norm": 1.448096513748169,
      "learning_rate": 6.243722455672851e-06,
      "loss": 0.2946,
      "step": 6716
    },
    {
      "epoch": 1.38,
      "grad_norm": 1.1110235452651978,
      "learning_rate": 6.2416726452803125e-06,
      "loss": 0.3873,
      "step": 6717
    },
    {
      "epoch": 1.38,
      "grad_norm": 0.8866925835609436,
      "learning_rate": 6.239622834887773e-06,
      "loss": 0.2637,
      "step": 6718
    },
    {
      "epoch": 1.38,
      "grad_norm": 1.0284425020217896,
      "learning_rate": 6.2375730244952345e-06,
      "loss": 0.2854,
      "step": 6719
    },
    {
      "epoch": 1.38,
      "grad_norm": 0.8425444960594177,
      "learning_rate": 6.2355232141026955e-06,
      "loss": 0.2403,
      "step": 6720
    },
    {
      "epoch": 1.38,
      "grad_norm": 0.9873977899551392,
      "learning_rate": 6.233473403710157e-06,
      "loss": 0.2865,
      "step": 6721
    },
    {
      "epoch": 1.38,
      "grad_norm": 1.2782660722732544,
      "learning_rate": 6.231423593317618e-06,
      "loss": 0.2666,
      "step": 6722
    },
    {
      "epoch": 1.38,
      "grad_norm": 1.2080522775650024,
      "learning_rate": 6.22937378292508e-06,
      "loss": 0.3265,
      "step": 6723
    },
    {
      "epoch": 1.38,
      "grad_norm": 1.0917006731033325,
      "learning_rate": 6.22732397253254e-06,
      "loss": 0.4267,
      "step": 6724
    },
    {
      "epoch": 1.38,
      "grad_norm": 1.2599046230316162,
      "learning_rate": 6.225274162140002e-06,
      "loss": 0.3322,
      "step": 6725
    },
    {
      "epoch": 1.38,
      "grad_norm": 0.9579405188560486,
      "learning_rate": 6.223224351747464e-06,
      "loss": 0.2986,
      "step": 6726
    },
    {
      "epoch": 1.38,
      "grad_norm": 2.6642744541168213,
      "learning_rate": 6.221174541354925e-06,
      "loss": 0.3325,
      "step": 6727
    },
    {
      "epoch": 1.38,
      "grad_norm": 1.2555643320083618,
      "learning_rate": 6.219124730962387e-06,
      "loss": 0.3384,
      "step": 6728
    },
    {
      "epoch": 1.38,
      "grad_norm": 1.1031447649002075,
      "learning_rate": 6.217074920569848e-06,
      "loss": 0.3596,
      "step": 6729
    },
    {
      "epoch": 1.38,
      "grad_norm": 2.1968584060668945,
      "learning_rate": 6.21502511017731e-06,
      "loss": 0.3948,
      "step": 6730
    },
    {
      "epoch": 1.38,
      "grad_norm": 1.1447523832321167,
      "learning_rate": 6.21297529978477e-06,
      "loss": 0.4508,
      "step": 6731
    },
    {
      "epoch": 1.38,
      "grad_norm": 1.4535331726074219,
      "learning_rate": 6.210925489392232e-06,
      "loss": 0.4965,
      "step": 6732
    },
    {
      "epoch": 1.38,
      "grad_norm": 1.0155465602874756,
      "learning_rate": 6.208875678999693e-06,
      "loss": 0.2487,
      "step": 6733
    },
    {
      "epoch": 1.38,
      "grad_norm": 0.9208515286445618,
      "learning_rate": 6.206825868607155e-06,
      "loss": 0.302,
      "step": 6734
    },
    {
      "epoch": 1.38,
      "grad_norm": 2.388657808303833,
      "learning_rate": 6.204776058214616e-06,
      "loss": 0.3113,
      "step": 6735
    },
    {
      "epoch": 1.38,
      "grad_norm": 1.0244722366333008,
      "learning_rate": 6.202726247822078e-06,
      "loss": 0.3682,
      "step": 6736
    },
    {
      "epoch": 1.38,
      "grad_norm": 1.7370799779891968,
      "learning_rate": 6.200676437429538e-06,
      "loss": 0.3173,
      "step": 6737
    },
    {
      "epoch": 1.38,
      "grad_norm": 1.3879228830337524,
      "learning_rate": 6.198626627037e-06,
      "loss": 0.424,
      "step": 6738
    },
    {
      "epoch": 1.38,
      "grad_norm": 1.5310665369033813,
      "learning_rate": 6.196576816644461e-06,
      "loss": 0.3968,
      "step": 6739
    },
    {
      "epoch": 1.38,
      "grad_norm": 1.467094898223877,
      "learning_rate": 6.1945270062519225e-06,
      "loss": 0.4168,
      "step": 6740
    },
    {
      "epoch": 1.38,
      "grad_norm": 1.1565444469451904,
      "learning_rate": 6.1924771958593835e-06,
      "loss": 0.3152,
      "step": 6741
    },
    {
      "epoch": 1.38,
      "grad_norm": 1.1393685340881348,
      "learning_rate": 6.190427385466845e-06,
      "loss": 0.4698,
      "step": 6742
    },
    {
      "epoch": 1.38,
      "grad_norm": 0.8971595764160156,
      "learning_rate": 6.1883775750743055e-06,
      "loss": 0.4188,
      "step": 6743
    },
    {
      "epoch": 1.38,
      "grad_norm": 0.8982541561126709,
      "learning_rate": 6.186327764681767e-06,
      "loss": 0.2805,
      "step": 6744
    },
    {
      "epoch": 1.38,
      "grad_norm": 1.0235103368759155,
      "learning_rate": 6.184277954289228e-06,
      "loss": 0.3064,
      "step": 6745
    },
    {
      "epoch": 1.38,
      "grad_norm": 0.9025331139564514,
      "learning_rate": 6.18222814389669e-06,
      "loss": 0.2888,
      "step": 6746
    },
    {
      "epoch": 1.38,
      "grad_norm": 1.3138742446899414,
      "learning_rate": 6.180178333504151e-06,
      "loss": 0.392,
      "step": 6747
    },
    {
      "epoch": 1.38,
      "grad_norm": 1.4200633764266968,
      "learning_rate": 6.178128523111613e-06,
      "loss": 0.2966,
      "step": 6748
    },
    {
      "epoch": 1.38,
      "grad_norm": 1.9687172174453735,
      "learning_rate": 6.176078712719073e-06,
      "loss": 0.3066,
      "step": 6749
    },
    {
      "epoch": 1.38,
      "grad_norm": 1.402349591255188,
      "learning_rate": 6.174028902326535e-06,
      "loss": 0.4085,
      "step": 6750
    },
    {
      "epoch": 1.38,
      "grad_norm": 0.8829079866409302,
      "learning_rate": 6.171979091933996e-06,
      "loss": 0.1763,
      "step": 6751
    },
    {
      "epoch": 1.38,
      "grad_norm": 1.419364094734192,
      "learning_rate": 6.169929281541458e-06,
      "loss": 0.4503,
      "step": 6752
    },
    {
      "epoch": 1.38,
      "grad_norm": 1.4286142587661743,
      "learning_rate": 6.167879471148919e-06,
      "loss": 0.5125,
      "step": 6753
    },
    {
      "epoch": 1.38,
      "grad_norm": 1.0477951765060425,
      "learning_rate": 6.165829660756381e-06,
      "loss": 0.4498,
      "step": 6754
    },
    {
      "epoch": 1.38,
      "grad_norm": 1.2642912864685059,
      "learning_rate": 6.163779850363841e-06,
      "loss": 0.4535,
      "step": 6755
    },
    {
      "epoch": 1.38,
      "grad_norm": 1.2164188623428345,
      "learning_rate": 6.161730039971303e-06,
      "loss": 0.2646,
      "step": 6756
    },
    {
      "epoch": 1.38,
      "grad_norm": 1.6407662630081177,
      "learning_rate": 6.159680229578765e-06,
      "loss": 0.3414,
      "step": 6757
    },
    {
      "epoch": 1.38,
      "grad_norm": 1.1670105457305908,
      "learning_rate": 6.157630419186226e-06,
      "loss": 0.3238,
      "step": 6758
    },
    {
      "epoch": 1.38,
      "grad_norm": 1.323441505432129,
      "learning_rate": 6.155580608793688e-06,
      "loss": 0.2359,
      "step": 6759
    },
    {
      "epoch": 1.38,
      "grad_norm": 1.2261314392089844,
      "learning_rate": 6.153530798401149e-06,
      "loss": 0.3158,
      "step": 6760
    },
    {
      "epoch": 1.39,
      "grad_norm": 1.1449352502822876,
      "learning_rate": 6.1514809880086105e-06,
      "loss": 0.3088,
      "step": 6761
    },
    {
      "epoch": 1.39,
      "grad_norm": 1.1046351194381714,
      "learning_rate": 6.149431177616071e-06,
      "loss": 0.2619,
      "step": 6762
    },
    {
      "epoch": 1.39,
      "grad_norm": 2.2049052715301514,
      "learning_rate": 6.1473813672235325e-06,
      "loss": 0.3783,
      "step": 6763
    },
    {
      "epoch": 1.39,
      "grad_norm": 1.1185579299926758,
      "learning_rate": 6.1453315568309935e-06,
      "loss": 0.3684,
      "step": 6764
    },
    {
      "epoch": 1.39,
      "grad_norm": 1.5376791954040527,
      "learning_rate": 6.143281746438455e-06,
      "loss": 0.2712,
      "step": 6765
    },
    {
      "epoch": 1.39,
      "grad_norm": 1.1374317407608032,
      "learning_rate": 6.141231936045916e-06,
      "loss": 0.3895,
      "step": 6766
    },
    {
      "epoch": 1.39,
      "grad_norm": 1.0111503601074219,
      "learning_rate": 6.139182125653378e-06,
      "loss": 0.2165,
      "step": 6767
    },
    {
      "epoch": 1.39,
      "grad_norm": 1.8190337419509888,
      "learning_rate": 6.137132315260838e-06,
      "loss": 0.431,
      "step": 6768
    },
    {
      "epoch": 1.39,
      "grad_norm": 1.0892924070358276,
      "learning_rate": 6.1350825048683e-06,
      "loss": 0.4064,
      "step": 6769
    },
    {
      "epoch": 1.39,
      "grad_norm": 0.9969141483306885,
      "learning_rate": 6.133032694475761e-06,
      "loss": 0.4043,
      "step": 6770
    },
    {
      "epoch": 1.39,
      "grad_norm": 0.8027605414390564,
      "learning_rate": 6.130982884083223e-06,
      "loss": 0.3151,
      "step": 6771
    },
    {
      "epoch": 1.39,
      "grad_norm": 1.6911767721176147,
      "learning_rate": 6.128933073690684e-06,
      "loss": 0.3082,
      "step": 6772
    },
    {
      "epoch": 1.39,
      "grad_norm": 0.9662306904792786,
      "learning_rate": 6.126883263298146e-06,
      "loss": 0.1946,
      "step": 6773
    },
    {
      "epoch": 1.39,
      "grad_norm": 1.793138861656189,
      "learning_rate": 6.124833452905606e-06,
      "loss": 0.4794,
      "step": 6774
    },
    {
      "epoch": 1.39,
      "grad_norm": 0.8667860627174377,
      "learning_rate": 6.122783642513068e-06,
      "loss": 0.2837,
      "step": 6775
    },
    {
      "epoch": 1.39,
      "grad_norm": 1.2123247385025024,
      "learning_rate": 6.120733832120529e-06,
      "loss": 0.3906,
      "step": 6776
    },
    {
      "epoch": 1.39,
      "grad_norm": 1.2630109786987305,
      "learning_rate": 6.118684021727991e-06,
      "loss": 0.4625,
      "step": 6777
    },
    {
      "epoch": 1.39,
      "grad_norm": 1.9868768453598022,
      "learning_rate": 6.116634211335452e-06,
      "loss": 0.358,
      "step": 6778
    },
    {
      "epoch": 1.39,
      "grad_norm": 1.2701551914215088,
      "learning_rate": 6.114584400942914e-06,
      "loss": 0.1885,
      "step": 6779
    },
    {
      "epoch": 1.39,
      "grad_norm": 2.135047674179077,
      "learning_rate": 6.112534590550374e-06,
      "loss": 0.3183,
      "step": 6780
    },
    {
      "epoch": 1.39,
      "grad_norm": 1.048049807548523,
      "learning_rate": 6.110484780157836e-06,
      "loss": 0.3194,
      "step": 6781
    },
    {
      "epoch": 1.39,
      "grad_norm": 2.8483145236968994,
      "learning_rate": 6.108434969765297e-06,
      "loss": 0.3469,
      "step": 6782
    },
    {
      "epoch": 1.39,
      "grad_norm": 2.83441162109375,
      "learning_rate": 6.106385159372759e-06,
      "loss": 0.2606,
      "step": 6783
    },
    {
      "epoch": 1.39,
      "grad_norm": 1.168643832206726,
      "learning_rate": 6.10433534898022e-06,
      "loss": 0.2558,
      "step": 6784
    },
    {
      "epoch": 1.39,
      "grad_norm": 1.2073637247085571,
      "learning_rate": 6.1022855385876815e-06,
      "loss": 0.2727,
      "step": 6785
    },
    {
      "epoch": 1.39,
      "grad_norm": 1.3130640983581543,
      "learning_rate": 6.100235728195143e-06,
      "loss": 0.4859,
      "step": 6786
    },
    {
      "epoch": 1.39,
      "grad_norm": 1.3673150539398193,
      "learning_rate": 6.0981859178026035e-06,
      "loss": 0.2979,
      "step": 6787
    },
    {
      "epoch": 1.39,
      "grad_norm": 1.354840874671936,
      "learning_rate": 6.096136107410065e-06,
      "loss": 0.2452,
      "step": 6788
    },
    {
      "epoch": 1.39,
      "grad_norm": 0.934624433517456,
      "learning_rate": 6.094086297017526e-06,
      "loss": 0.3692,
      "step": 6789
    },
    {
      "epoch": 1.39,
      "grad_norm": 1.122037649154663,
      "learning_rate": 6.092036486624988e-06,
      "loss": 0.3552,
      "step": 6790
    },
    {
      "epoch": 1.39,
      "grad_norm": 1.364210605621338,
      "learning_rate": 6.089986676232449e-06,
      "loss": 0.28,
      "step": 6791
    },
    {
      "epoch": 1.39,
      "grad_norm": 1.3303180932998657,
      "learning_rate": 6.087936865839911e-06,
      "loss": 0.3532,
      "step": 6792
    },
    {
      "epoch": 1.39,
      "grad_norm": 1.1532001495361328,
      "learning_rate": 6.085887055447371e-06,
      "loss": 0.35,
      "step": 6793
    },
    {
      "epoch": 1.39,
      "grad_norm": 1.825424313545227,
      "learning_rate": 6.083837245054833e-06,
      "loss": 0.2389,
      "step": 6794
    },
    {
      "epoch": 1.39,
      "grad_norm": 1.143276333808899,
      "learning_rate": 6.081787434662294e-06,
      "loss": 0.3191,
      "step": 6795
    },
    {
      "epoch": 1.39,
      "grad_norm": 0.885395884513855,
      "learning_rate": 6.079737624269756e-06,
      "loss": 0.3037,
      "step": 6796
    },
    {
      "epoch": 1.39,
      "grad_norm": 1.7171639204025269,
      "learning_rate": 6.077687813877217e-06,
      "loss": 0.3937,
      "step": 6797
    },
    {
      "epoch": 1.39,
      "grad_norm": 1.5942809581756592,
      "learning_rate": 6.075638003484679e-06,
      "loss": 0.3675,
      "step": 6798
    },
    {
      "epoch": 1.39,
      "grad_norm": 2.0965092182159424,
      "learning_rate": 6.073588193092139e-06,
      "loss": 0.4825,
      "step": 6799
    },
    {
      "epoch": 1.39,
      "grad_norm": 1.7246111631393433,
      "learning_rate": 6.071538382699601e-06,
      "loss": 0.4323,
      "step": 6800
    },
    {
      "epoch": 1.39,
      "grad_norm": 1.0629600286483765,
      "learning_rate": 6.069488572307062e-06,
      "loss": 0.3343,
      "step": 6801
    },
    {
      "epoch": 1.39,
      "grad_norm": 1.0589650869369507,
      "learning_rate": 6.067438761914524e-06,
      "loss": 0.2862,
      "step": 6802
    },
    {
      "epoch": 1.39,
      "grad_norm": 0.9118472337722778,
      "learning_rate": 6.065388951521985e-06,
      "loss": 0.2177,
      "step": 6803
    },
    {
      "epoch": 1.39,
      "grad_norm": 1.137288212776184,
      "learning_rate": 6.063339141129447e-06,
      "loss": 0.4165,
      "step": 6804
    },
    {
      "epoch": 1.39,
      "grad_norm": 1.0798215866088867,
      "learning_rate": 6.061289330736907e-06,
      "loss": 0.443,
      "step": 6805
    },
    {
      "epoch": 1.39,
      "grad_norm": 0.7391349077224731,
      "learning_rate": 6.059239520344369e-06,
      "loss": 0.278,
      "step": 6806
    },
    {
      "epoch": 1.39,
      "grad_norm": 0.9971751570701599,
      "learning_rate": 6.05718970995183e-06,
      "loss": 0.3301,
      "step": 6807
    },
    {
      "epoch": 1.39,
      "grad_norm": 1.0170663595199585,
      "learning_rate": 6.0551398995592915e-06,
      "loss": 0.2498,
      "step": 6808
    },
    {
      "epoch": 1.4,
      "grad_norm": 1.2204817533493042,
      "learning_rate": 6.0530900891667525e-06,
      "loss": 0.3167,
      "step": 6809
    },
    {
      "epoch": 1.4,
      "grad_norm": 1.2427054643630981,
      "learning_rate": 6.051040278774214e-06,
      "loss": 0.3203,
      "step": 6810
    },
    {
      "epoch": 1.4,
      "grad_norm": 1.648187279701233,
      "learning_rate": 6.0489904683816745e-06,
      "loss": 0.3054,
      "step": 6811
    },
    {
      "epoch": 1.4,
      "grad_norm": 0.7650678753852844,
      "learning_rate": 6.046940657989136e-06,
      "loss": 0.4337,
      "step": 6812
    },
    {
      "epoch": 1.4,
      "grad_norm": 1.1490933895111084,
      "learning_rate": 6.044890847596597e-06,
      "loss": 0.462,
      "step": 6813
    },
    {
      "epoch": 1.4,
      "grad_norm": 1.114717721939087,
      "learning_rate": 6.042841037204059e-06,
      "loss": 0.3766,
      "step": 6814
    },
    {
      "epoch": 1.4,
      "grad_norm": 2.3019115924835205,
      "learning_rate": 6.040791226811521e-06,
      "loss": 0.3294,
      "step": 6815
    },
    {
      "epoch": 1.4,
      "grad_norm": 0.901992917060852,
      "learning_rate": 6.038741416418982e-06,
      "loss": 0.3472,
      "step": 6816
    },
    {
      "epoch": 1.4,
      "grad_norm": 1.299543857574463,
      "learning_rate": 6.036691606026444e-06,
      "loss": 0.3793,
      "step": 6817
    },
    {
      "epoch": 1.4,
      "grad_norm": 2.6272079944610596,
      "learning_rate": 6.034641795633904e-06,
      "loss": 0.4572,
      "step": 6818
    },
    {
      "epoch": 1.4,
      "grad_norm": 1.053547739982605,
      "learning_rate": 6.032591985241366e-06,
      "loss": 0.398,
      "step": 6819
    },
    {
      "epoch": 1.4,
      "grad_norm": 0.7022075057029724,
      "learning_rate": 6.030542174848827e-06,
      "loss": 0.2952,
      "step": 6820
    },
    {
      "epoch": 1.4,
      "grad_norm": 1.727679967880249,
      "learning_rate": 6.028492364456289e-06,
      "loss": 0.3624,
      "step": 6821
    },
    {
      "epoch": 1.4,
      "grad_norm": 0.8435267210006714,
      "learning_rate": 6.02644255406375e-06,
      "loss": 0.392,
      "step": 6822
    },
    {
      "epoch": 1.4,
      "grad_norm": 1.7072737216949463,
      "learning_rate": 6.024392743671212e-06,
      "loss": 0.5305,
      "step": 6823
    },
    {
      "epoch": 1.4,
      "grad_norm": 1.390501618385315,
      "learning_rate": 6.022342933278672e-06,
      "loss": 0.373,
      "step": 6824
    },
    {
      "epoch": 1.4,
      "grad_norm": 1.2263984680175781,
      "learning_rate": 6.020293122886134e-06,
      "loss": 0.3513,
      "step": 6825
    },
    {
      "epoch": 1.4,
      "grad_norm": 1.4394729137420654,
      "learning_rate": 6.018243312493595e-06,
      "loss": 0.3007,
      "step": 6826
    },
    {
      "epoch": 1.4,
      "grad_norm": 1.2284481525421143,
      "learning_rate": 6.0161935021010566e-06,
      "loss": 0.5133,
      "step": 6827
    },
    {
      "epoch": 1.4,
      "grad_norm": 1.404768705368042,
      "learning_rate": 6.014143691708518e-06,
      "loss": 0.5289,
      "step": 6828
    },
    {
      "epoch": 1.4,
      "grad_norm": 1.6411970853805542,
      "learning_rate": 6.0120938813159794e-06,
      "loss": 0.4218,
      "step": 6829
    },
    {
      "epoch": 1.4,
      "grad_norm": 1.3295567035675049,
      "learning_rate": 6.01004407092344e-06,
      "loss": 0.4292,
      "step": 6830
    },
    {
      "epoch": 1.4,
      "grad_norm": 1.2959073781967163,
      "learning_rate": 6.0079942605309015e-06,
      "loss": 0.3178,
      "step": 6831
    },
    {
      "epoch": 1.4,
      "grad_norm": 1.9530022144317627,
      "learning_rate": 6.0059444501383625e-06,
      "loss": 0.3464,
      "step": 6832
    },
    {
      "epoch": 1.4,
      "grad_norm": 1.2834892272949219,
      "learning_rate": 6.003894639745824e-06,
      "loss": 0.4847,
      "step": 6833
    },
    {
      "epoch": 1.4,
      "grad_norm": 1.5232995748519897,
      "learning_rate": 6.001844829353285e-06,
      "loss": 0.4492,
      "step": 6834
    },
    {
      "epoch": 1.4,
      "grad_norm": 0.945849597454071,
      "learning_rate": 5.999795018960747e-06,
      "loss": 0.4177,
      "step": 6835
    },
    {
      "epoch": 1.4,
      "grad_norm": 1.458987832069397,
      "learning_rate": 5.997745208568207e-06,
      "loss": 0.3183,
      "step": 6836
    },
    {
      "epoch": 1.4,
      "grad_norm": 1.1236062049865723,
      "learning_rate": 5.995695398175669e-06,
      "loss": 0.3857,
      "step": 6837
    },
    {
      "epoch": 1.4,
      "grad_norm": 1.6412354707717896,
      "learning_rate": 5.99364558778313e-06,
      "loss": 0.3082,
      "step": 6838
    },
    {
      "epoch": 1.4,
      "grad_norm": 1.0524522066116333,
      "learning_rate": 5.991595777390592e-06,
      "loss": 0.28,
      "step": 6839
    },
    {
      "epoch": 1.4,
      "grad_norm": 1.1952050924301147,
      "learning_rate": 5.989545966998053e-06,
      "loss": 0.4867,
      "step": 6840
    },
    {
      "epoch": 1.4,
      "grad_norm": 1.3301512002944946,
      "learning_rate": 5.987496156605515e-06,
      "loss": 0.284,
      "step": 6841
    },
    {
      "epoch": 1.4,
      "grad_norm": 2.30224871635437,
      "learning_rate": 5.985446346212975e-06,
      "loss": 0.4159,
      "step": 6842
    },
    {
      "epoch": 1.4,
      "grad_norm": 2.0559682846069336,
      "learning_rate": 5.983396535820437e-06,
      "loss": 0.4333,
      "step": 6843
    },
    {
      "epoch": 1.4,
      "grad_norm": 1.0962657928466797,
      "learning_rate": 5.981346725427899e-06,
      "loss": 0.4988,
      "step": 6844
    },
    {
      "epoch": 1.4,
      "grad_norm": 1.525383472442627,
      "learning_rate": 5.97929691503536e-06,
      "loss": 0.3935,
      "step": 6845
    },
    {
      "epoch": 1.4,
      "grad_norm": 1.0088931322097778,
      "learning_rate": 5.977247104642822e-06,
      "loss": 0.3377,
      "step": 6846
    },
    {
      "epoch": 1.4,
      "grad_norm": 0.9937872886657715,
      "learning_rate": 5.975197294250283e-06,
      "loss": 0.4553,
      "step": 6847
    },
    {
      "epoch": 1.4,
      "grad_norm": 1.272788643836975,
      "learning_rate": 5.9731474838577445e-06,
      "loss": 0.3269,
      "step": 6848
    },
    {
      "epoch": 1.4,
      "grad_norm": 1.63889741897583,
      "learning_rate": 5.971097673465205e-06,
      "loss": 0.4017,
      "step": 6849
    },
    {
      "epoch": 1.4,
      "grad_norm": 1.3480621576309204,
      "learning_rate": 5.9690478630726666e-06,
      "loss": 0.3214,
      "step": 6850
    },
    {
      "epoch": 1.4,
      "grad_norm": 1.0075918436050415,
      "learning_rate": 5.9669980526801276e-06,
      "loss": 0.3389,
      "step": 6851
    },
    {
      "epoch": 1.4,
      "grad_norm": 1.052691102027893,
      "learning_rate": 5.9649482422875894e-06,
      "loss": 0.5126,
      "step": 6852
    },
    {
      "epoch": 1.4,
      "grad_norm": 1.8212791681289673,
      "learning_rate": 5.9628984318950504e-06,
      "loss": 0.3637,
      "step": 6853
    },
    {
      "epoch": 1.4,
      "grad_norm": 2.0934011936187744,
      "learning_rate": 5.9608486215025114e-06,
      "loss": 0.5523,
      "step": 6854
    },
    {
      "epoch": 1.4,
      "grad_norm": 1.3367105722427368,
      "learning_rate": 5.9587988111099725e-06,
      "loss": 0.2997,
      "step": 6855
    },
    {
      "epoch": 1.4,
      "grad_norm": 1.097103476524353,
      "learning_rate": 5.956749000717434e-06,
      "loss": 0.3377,
      "step": 6856
    },
    {
      "epoch": 1.4,
      "grad_norm": 2.219092607498169,
      "learning_rate": 5.954699190324895e-06,
      "loss": 0.4278,
      "step": 6857
    },
    {
      "epoch": 1.41,
      "grad_norm": 1.0815694332122803,
      "learning_rate": 5.952649379932357e-06,
      "loss": 0.2418,
      "step": 6858
    },
    {
      "epoch": 1.41,
      "grad_norm": 1.691407322883606,
      "learning_rate": 5.950599569539818e-06,
      "loss": 0.4446,
      "step": 6859
    },
    {
      "epoch": 1.41,
      "grad_norm": 1.5022720098495483,
      "learning_rate": 5.948549759147279e-06,
      "loss": 0.5473,
      "step": 6860
    },
    {
      "epoch": 1.41,
      "grad_norm": 1.6137174367904663,
      "learning_rate": 5.94649994875474e-06,
      "loss": 0.3787,
      "step": 6861
    },
    {
      "epoch": 1.41,
      "grad_norm": 1.8429150581359863,
      "learning_rate": 5.944450138362202e-06,
      "loss": 0.3626,
      "step": 6862
    },
    {
      "epoch": 1.41,
      "grad_norm": 0.9959284067153931,
      "learning_rate": 5.942400327969663e-06,
      "loss": 0.2548,
      "step": 6863
    },
    {
      "epoch": 1.41,
      "grad_norm": 1.4197452068328857,
      "learning_rate": 5.940350517577125e-06,
      "loss": 0.4132,
      "step": 6864
    },
    {
      "epoch": 1.41,
      "grad_norm": 1.5472815036773682,
      "learning_rate": 5.938300707184585e-06,
      "loss": 0.2712,
      "step": 6865
    },
    {
      "epoch": 1.41,
      "grad_norm": 0.9995587468147278,
      "learning_rate": 5.936250896792047e-06,
      "loss": 0.319,
      "step": 6866
    },
    {
      "epoch": 1.41,
      "grad_norm": 0.7802963852882385,
      "learning_rate": 5.934201086399508e-06,
      "loss": 0.2603,
      "step": 6867
    },
    {
      "epoch": 1.41,
      "grad_norm": 1.1704262495040894,
      "learning_rate": 5.93215127600697e-06,
      "loss": 0.2801,
      "step": 6868
    },
    {
      "epoch": 1.41,
      "grad_norm": 1.2283477783203125,
      "learning_rate": 5.930101465614431e-06,
      "loss": 0.3129,
      "step": 6869
    },
    {
      "epoch": 1.41,
      "grad_norm": 1.2739073038101196,
      "learning_rate": 5.928051655221893e-06,
      "loss": 0.286,
      "step": 6870
    },
    {
      "epoch": 1.41,
      "grad_norm": 1.0290746688842773,
      "learning_rate": 5.926001844829353e-06,
      "loss": 0.2738,
      "step": 6871
    },
    {
      "epoch": 1.41,
      "grad_norm": 1.3530778884887695,
      "learning_rate": 5.923952034436815e-06,
      "loss": 0.2425,
      "step": 6872
    },
    {
      "epoch": 1.41,
      "grad_norm": 1.145117998123169,
      "learning_rate": 5.921902224044276e-06,
      "loss": 0.3121,
      "step": 6873
    },
    {
      "epoch": 1.41,
      "grad_norm": 1.136509656906128,
      "learning_rate": 5.9198524136517376e-06,
      "loss": 0.4318,
      "step": 6874
    },
    {
      "epoch": 1.41,
      "grad_norm": 1.3962773084640503,
      "learning_rate": 5.917802603259199e-06,
      "loss": 0.5012,
      "step": 6875
    },
    {
      "epoch": 1.41,
      "grad_norm": 1.136965274810791,
      "learning_rate": 5.9157527928666604e-06,
      "loss": 0.2023,
      "step": 6876
    },
    {
      "epoch": 1.41,
      "grad_norm": 1.3079653978347778,
      "learning_rate": 5.913702982474122e-06,
      "loss": 0.4752,
      "step": 6877
    },
    {
      "epoch": 1.41,
      "grad_norm": 1.4111829996109009,
      "learning_rate": 5.9116531720815824e-06,
      "loss": 0.4709,
      "step": 6878
    },
    {
      "epoch": 1.41,
      "grad_norm": 0.778511106967926,
      "learning_rate": 5.909603361689044e-06,
      "loss": 0.2085,
      "step": 6879
    },
    {
      "epoch": 1.41,
      "grad_norm": 1.0199131965637207,
      "learning_rate": 5.907553551296505e-06,
      "loss": 0.3135,
      "step": 6880
    },
    {
      "epoch": 1.41,
      "grad_norm": 1.9316976070404053,
      "learning_rate": 5.905503740903967e-06,
      "loss": 0.3678,
      "step": 6881
    },
    {
      "epoch": 1.41,
      "grad_norm": 0.832008421421051,
      "learning_rate": 5.903453930511428e-06,
      "loss": 0.2979,
      "step": 6882
    },
    {
      "epoch": 1.41,
      "grad_norm": 1.5332798957824707,
      "learning_rate": 5.90140412011889e-06,
      "loss": 0.4332,
      "step": 6883
    },
    {
      "epoch": 1.41,
      "grad_norm": 0.9472816586494446,
      "learning_rate": 5.89935430972635e-06,
      "loss": 0.4003,
      "step": 6884
    },
    {
      "epoch": 1.41,
      "grad_norm": 1.8811033964157104,
      "learning_rate": 5.897304499333812e-06,
      "loss": 0.4177,
      "step": 6885
    },
    {
      "epoch": 1.41,
      "grad_norm": 1.4123133420944214,
      "learning_rate": 5.895254688941273e-06,
      "loss": 0.416,
      "step": 6886
    },
    {
      "epoch": 1.41,
      "grad_norm": 1.319142460823059,
      "learning_rate": 5.893204878548735e-06,
      "loss": 0.4315,
      "step": 6887
    },
    {
      "epoch": 1.41,
      "grad_norm": 1.5326334238052368,
      "learning_rate": 5.891155068156196e-06,
      "loss": 0.3021,
      "step": 6888
    },
    {
      "epoch": 1.41,
      "grad_norm": 1.0586585998535156,
      "learning_rate": 5.889105257763658e-06,
      "loss": 0.304,
      "step": 6889
    },
    {
      "epoch": 1.41,
      "grad_norm": 1.294559359550476,
      "learning_rate": 5.887055447371118e-06,
      "loss": 0.4099,
      "step": 6890
    },
    {
      "epoch": 1.41,
      "grad_norm": 2.6302263736724854,
      "learning_rate": 5.88500563697858e-06,
      "loss": 0.4787,
      "step": 6891
    },
    {
      "epoch": 1.41,
      "grad_norm": 1.2217638492584229,
      "learning_rate": 5.882955826586041e-06,
      "loss": 0.2476,
      "step": 6892
    },
    {
      "epoch": 1.41,
      "grad_norm": 2.162334442138672,
      "learning_rate": 5.880906016193503e-06,
      "loss": 0.3944,
      "step": 6893
    },
    {
      "epoch": 1.41,
      "grad_norm": 0.9129086136817932,
      "learning_rate": 5.878856205800964e-06,
      "loss": 0.3707,
      "step": 6894
    },
    {
      "epoch": 1.41,
      "grad_norm": 1.211525321006775,
      "learning_rate": 5.8768063954084255e-06,
      "loss": 0.4848,
      "step": 6895
    },
    {
      "epoch": 1.41,
      "grad_norm": 1.306195616722107,
      "learning_rate": 5.874756585015886e-06,
      "loss": 0.295,
      "step": 6896
    },
    {
      "epoch": 1.41,
      "grad_norm": 1.2392462491989136,
      "learning_rate": 5.8727067746233476e-06,
      "loss": 0.3083,
      "step": 6897
    },
    {
      "epoch": 1.41,
      "grad_norm": 1.1005773544311523,
      "learning_rate": 5.8706569642308086e-06,
      "loss": 0.3575,
      "step": 6898
    },
    {
      "epoch": 1.41,
      "grad_norm": 1.9230161905288696,
      "learning_rate": 5.86860715383827e-06,
      "loss": 0.2996,
      "step": 6899
    },
    {
      "epoch": 1.41,
      "grad_norm": 1.2376558780670166,
      "learning_rate": 5.8665573434457314e-06,
      "loss": 0.2763,
      "step": 6900
    },
    {
      "epoch": 1.41,
      "grad_norm": 3.102229118347168,
      "learning_rate": 5.864507533053193e-06,
      "loss": 0.3077,
      "step": 6901
    },
    {
      "epoch": 1.41,
      "grad_norm": 1.239270567893982,
      "learning_rate": 5.8624577226606534e-06,
      "loss": 0.3539,
      "step": 6902
    },
    {
      "epoch": 1.41,
      "grad_norm": 1.8175817728042603,
      "learning_rate": 5.860407912268115e-06,
      "loss": 0.3793,
      "step": 6903
    },
    {
      "epoch": 1.41,
      "grad_norm": 1.8689175844192505,
      "learning_rate": 5.858358101875577e-06,
      "loss": 0.4353,
      "step": 6904
    },
    {
      "epoch": 1.41,
      "grad_norm": 1.8145631551742554,
      "learning_rate": 5.856308291483038e-06,
      "loss": 0.3104,
      "step": 6905
    },
    {
      "epoch": 1.41,
      "grad_norm": 1.2326830625534058,
      "learning_rate": 5.8542584810905e-06,
      "loss": 0.2695,
      "step": 6906
    },
    {
      "epoch": 1.42,
      "grad_norm": 1.1931408643722534,
      "learning_rate": 5.852208670697961e-06,
      "loss": 0.4038,
      "step": 6907
    },
    {
      "epoch": 1.42,
      "grad_norm": 1.282305359840393,
      "learning_rate": 5.850158860305423e-06,
      "loss": 0.3889,
      "step": 6908
    },
    {
      "epoch": 1.42,
      "grad_norm": 2.11578106880188,
      "learning_rate": 5.848109049912883e-06,
      "loss": 0.3254,
      "step": 6909
    },
    {
      "epoch": 1.42,
      "grad_norm": 0.9163093566894531,
      "learning_rate": 5.846059239520345e-06,
      "loss": 0.2775,
      "step": 6910
    },
    {
      "epoch": 1.42,
      "grad_norm": 0.9340388774871826,
      "learning_rate": 5.844009429127806e-06,
      "loss": 0.4495,
      "step": 6911
    },
    {
      "epoch": 1.42,
      "grad_norm": 1.247737169265747,
      "learning_rate": 5.841959618735268e-06,
      "loss": 0.3188,
      "step": 6912
    },
    {
      "epoch": 1.42,
      "grad_norm": 2.4235289096832275,
      "learning_rate": 5.839909808342729e-06,
      "loss": 0.3508,
      "step": 6913
    },
    {
      "epoch": 1.42,
      "grad_norm": 1.6944189071655273,
      "learning_rate": 5.837859997950191e-06,
      "loss": 0.3962,
      "step": 6914
    },
    {
      "epoch": 1.42,
      "grad_norm": 0.7092982530593872,
      "learning_rate": 5.835810187557651e-06,
      "loss": 0.2718,
      "step": 6915
    },
    {
      "epoch": 1.42,
      "grad_norm": 1.0659904479980469,
      "learning_rate": 5.833760377165113e-06,
      "loss": 0.5436,
      "step": 6916
    },
    {
      "epoch": 1.42,
      "grad_norm": 1.748344898223877,
      "learning_rate": 5.831710566772574e-06,
      "loss": 0.3681,
      "step": 6917
    },
    {
      "epoch": 1.42,
      "grad_norm": 2.6540772914886475,
      "learning_rate": 5.8296607563800355e-06,
      "loss": 0.3094,
      "step": 6918
    },
    {
      "epoch": 1.42,
      "grad_norm": 1.0705509185791016,
      "learning_rate": 5.8276109459874965e-06,
      "loss": 0.3376,
      "step": 6919
    },
    {
      "epoch": 1.42,
      "grad_norm": 1.5458052158355713,
      "learning_rate": 5.825561135594958e-06,
      "loss": 0.255,
      "step": 6920
    },
    {
      "epoch": 1.42,
      "grad_norm": 0.956146240234375,
      "learning_rate": 5.8235113252024186e-06,
      "loss": 0.2954,
      "step": 6921
    },
    {
      "epoch": 1.42,
      "grad_norm": 1.4923298358917236,
      "learning_rate": 5.82146151480988e-06,
      "loss": 0.4999,
      "step": 6922
    },
    {
      "epoch": 1.42,
      "grad_norm": 1.1544772386550903,
      "learning_rate": 5.819411704417341e-06,
      "loss": 0.4237,
      "step": 6923
    },
    {
      "epoch": 1.42,
      "grad_norm": 1.1944737434387207,
      "learning_rate": 5.817361894024803e-06,
      "loss": 0.3863,
      "step": 6924
    },
    {
      "epoch": 1.42,
      "grad_norm": 1.0514953136444092,
      "learning_rate": 5.815312083632264e-06,
      "loss": 0.4546,
      "step": 6925
    },
    {
      "epoch": 1.42,
      "grad_norm": 1.3618930578231812,
      "learning_rate": 5.813262273239726e-06,
      "loss": 0.4625,
      "step": 6926
    },
    {
      "epoch": 1.42,
      "grad_norm": 1.3141026496887207,
      "learning_rate": 5.811212462847186e-06,
      "loss": 0.332,
      "step": 6927
    },
    {
      "epoch": 1.42,
      "grad_norm": 1.023511290550232,
      "learning_rate": 5.809162652454648e-06,
      "loss": 0.27,
      "step": 6928
    },
    {
      "epoch": 1.42,
      "grad_norm": 1.3403509855270386,
      "learning_rate": 5.807112842062109e-06,
      "loss": 0.4014,
      "step": 6929
    },
    {
      "epoch": 1.42,
      "grad_norm": 1.0135681629180908,
      "learning_rate": 5.805063031669571e-06,
      "loss": 0.2447,
      "step": 6930
    },
    {
      "epoch": 1.42,
      "grad_norm": 1.1613314151763916,
      "learning_rate": 5.803013221277032e-06,
      "loss": 0.4439,
      "step": 6931
    },
    {
      "epoch": 1.42,
      "grad_norm": 1.8562495708465576,
      "learning_rate": 5.800963410884494e-06,
      "loss": 0.2741,
      "step": 6932
    },
    {
      "epoch": 1.42,
      "grad_norm": 1.7387807369232178,
      "learning_rate": 5.798913600491956e-06,
      "loss": 0.3239,
      "step": 6933
    },
    {
      "epoch": 1.42,
      "grad_norm": 1.1004904508590698,
      "learning_rate": 5.796863790099416e-06,
      "loss": 0.3892,
      "step": 6934
    },
    {
      "epoch": 1.42,
      "grad_norm": 1.3157342672348022,
      "learning_rate": 5.794813979706878e-06,
      "loss": 0.3863,
      "step": 6935
    },
    {
      "epoch": 1.42,
      "grad_norm": 1.598359227180481,
      "learning_rate": 5.792764169314339e-06,
      "loss": 0.3495,
      "step": 6936
    },
    {
      "epoch": 1.42,
      "grad_norm": 1.1045185327529907,
      "learning_rate": 5.790714358921801e-06,
      "loss": 0.3171,
      "step": 6937
    },
    {
      "epoch": 1.42,
      "grad_norm": 1.0515230894088745,
      "learning_rate": 5.788664548529262e-06,
      "loss": 0.3185,
      "step": 6938
    },
    {
      "epoch": 1.42,
      "grad_norm": 1.091062068939209,
      "learning_rate": 5.7866147381367235e-06,
      "loss": 0.3462,
      "step": 6939
    },
    {
      "epoch": 1.42,
      "grad_norm": 0.8860368728637695,
      "learning_rate": 5.784564927744184e-06,
      "loss": 0.4004,
      "step": 6940
    },
    {
      "epoch": 1.42,
      "grad_norm": 1.7164714336395264,
      "learning_rate": 5.7825151173516455e-06,
      "loss": 0.1889,
      "step": 6941
    },
    {
      "epoch": 1.42,
      "grad_norm": 1.370813012123108,
      "learning_rate": 5.7804653069591065e-06,
      "loss": 0.3286,
      "step": 6942
    },
    {
      "epoch": 1.42,
      "grad_norm": 1.116929531097412,
      "learning_rate": 5.778415496566568e-06,
      "loss": 0.4262,
      "step": 6943
    },
    {
      "epoch": 1.42,
      "grad_norm": 1.1223855018615723,
      "learning_rate": 5.776365686174029e-06,
      "loss": 0.3641,
      "step": 6944
    },
    {
      "epoch": 1.42,
      "grad_norm": 1.1487873792648315,
      "learning_rate": 5.774315875781491e-06,
      "loss": 0.5664,
      "step": 6945
    },
    {
      "epoch": 1.42,
      "grad_norm": 2.3340988159179688,
      "learning_rate": 5.772266065388951e-06,
      "loss": 0.2425,
      "step": 6946
    },
    {
      "epoch": 1.42,
      "grad_norm": 1.6095973253250122,
      "learning_rate": 5.770216254996413e-06,
      "loss": 0.4247,
      "step": 6947
    },
    {
      "epoch": 1.42,
      "grad_norm": 1.8267940282821655,
      "learning_rate": 5.768166444603874e-06,
      "loss": 0.5639,
      "step": 6948
    },
    {
      "epoch": 1.42,
      "grad_norm": 0.8038054704666138,
      "learning_rate": 5.766116634211336e-06,
      "loss": 0.3385,
      "step": 6949
    },
    {
      "epoch": 1.42,
      "grad_norm": 1.3537076711654663,
      "learning_rate": 5.764066823818797e-06,
      "loss": 0.3315,
      "step": 6950
    },
    {
      "epoch": 1.42,
      "grad_norm": 1.4633289575576782,
      "learning_rate": 5.762017013426259e-06,
      "loss": 0.3467,
      "step": 6951
    },
    {
      "epoch": 1.42,
      "grad_norm": 0.9928721785545349,
      "learning_rate": 5.759967203033719e-06,
      "loss": 0.2667,
      "step": 6952
    },
    {
      "epoch": 1.42,
      "grad_norm": 1.5392885208129883,
      "learning_rate": 5.757917392641181e-06,
      "loss": 0.467,
      "step": 6953
    },
    {
      "epoch": 1.42,
      "grad_norm": 1.851663589477539,
      "learning_rate": 5.755867582248642e-06,
      "loss": 0.3388,
      "step": 6954
    },
    {
      "epoch": 1.42,
      "grad_norm": 1.6910829544067383,
      "learning_rate": 5.753817771856104e-06,
      "loss": 0.3197,
      "step": 6955
    },
    {
      "epoch": 1.43,
      "grad_norm": 1.609962821006775,
      "learning_rate": 5.751767961463565e-06,
      "loss": 0.2476,
      "step": 6956
    },
    {
      "epoch": 1.43,
      "grad_norm": 1.4780932664871216,
      "learning_rate": 5.749718151071027e-06,
      "loss": 0.3364,
      "step": 6957
    },
    {
      "epoch": 1.43,
      "grad_norm": 3.6413862705230713,
      "learning_rate": 5.747668340678487e-06,
      "loss": 0.3261,
      "step": 6958
    },
    {
      "epoch": 1.43,
      "grad_norm": 1.3196052312850952,
      "learning_rate": 5.745618530285949e-06,
      "loss": 0.2932,
      "step": 6959
    },
    {
      "epoch": 1.43,
      "grad_norm": 1.1083180904388428,
      "learning_rate": 5.74356871989341e-06,
      "loss": 0.3377,
      "step": 6960
    },
    {
      "epoch": 1.43,
      "grad_norm": 1.871101975440979,
      "learning_rate": 5.741518909500872e-06,
      "loss": 0.2424,
      "step": 6961
    },
    {
      "epoch": 1.43,
      "grad_norm": 1.6278648376464844,
      "learning_rate": 5.7394690991083335e-06,
      "loss": 0.2848,
      "step": 6962
    },
    {
      "epoch": 1.43,
      "grad_norm": 0.8920065760612488,
      "learning_rate": 5.7374192887157945e-06,
      "loss": 0.2342,
      "step": 6963
    },
    {
      "epoch": 1.43,
      "grad_norm": 0.911788284778595,
      "learning_rate": 5.735369478323256e-06,
      "loss": 0.4956,
      "step": 6964
    },
    {
      "epoch": 1.43,
      "grad_norm": 1.7993969917297363,
      "learning_rate": 5.7333196679307165e-06,
      "loss": 0.3086,
      "step": 6965
    },
    {
      "epoch": 1.43,
      "grad_norm": 2.285763740539551,
      "learning_rate": 5.731269857538178e-06,
      "loss": 0.3328,
      "step": 6966
    },
    {
      "epoch": 1.43,
      "grad_norm": 0.9914700388908386,
      "learning_rate": 5.729220047145639e-06,
      "loss": 0.2659,
      "step": 6967
    },
    {
      "epoch": 1.43,
      "grad_norm": 1.0953590869903564,
      "learning_rate": 5.727170236753101e-06,
      "loss": 0.2382,
      "step": 6968
    },
    {
      "epoch": 1.43,
      "grad_norm": 0.9129815697669983,
      "learning_rate": 5.725120426360562e-06,
      "loss": 0.3383,
      "step": 6969
    },
    {
      "epoch": 1.43,
      "grad_norm": 1.4299691915512085,
      "learning_rate": 5.723070615968024e-06,
      "loss": 0.2028,
      "step": 6970
    },
    {
      "epoch": 1.43,
      "grad_norm": 1.1756829023361206,
      "learning_rate": 5.721020805575484e-06,
      "loss": 0.3686,
      "step": 6971
    },
    {
      "epoch": 1.43,
      "grad_norm": 1.671618103981018,
      "learning_rate": 5.718970995182946e-06,
      "loss": 0.5517,
      "step": 6972
    },
    {
      "epoch": 1.43,
      "grad_norm": 1.0742394924163818,
      "learning_rate": 5.716921184790407e-06,
      "loss": 0.3049,
      "step": 6973
    },
    {
      "epoch": 1.43,
      "grad_norm": 1.6764241456985474,
      "learning_rate": 5.714871374397869e-06,
      "loss": 0.2629,
      "step": 6974
    },
    {
      "epoch": 1.43,
      "grad_norm": 1.3687459230422974,
      "learning_rate": 5.71282156400533e-06,
      "loss": 0.3391,
      "step": 6975
    },
    {
      "epoch": 1.43,
      "grad_norm": 2.0286972522735596,
      "learning_rate": 5.710771753612792e-06,
      "loss": 0.3448,
      "step": 6976
    },
    {
      "epoch": 1.43,
      "grad_norm": 1.3907397985458374,
      "learning_rate": 5.708721943220252e-06,
      "loss": 0.4908,
      "step": 6977
    },
    {
      "epoch": 1.43,
      "grad_norm": 1.4905627965927124,
      "learning_rate": 5.706672132827714e-06,
      "loss": 0.3733,
      "step": 6978
    },
    {
      "epoch": 1.43,
      "grad_norm": 2.9635276794433594,
      "learning_rate": 5.704622322435175e-06,
      "loss": 0.4474,
      "step": 6979
    },
    {
      "epoch": 1.43,
      "grad_norm": 4.640314102172852,
      "learning_rate": 5.702572512042637e-06,
      "loss": 0.3258,
      "step": 6980
    },
    {
      "epoch": 1.43,
      "grad_norm": 2.362407922744751,
      "learning_rate": 5.700522701650098e-06,
      "loss": 0.2712,
      "step": 6981
    },
    {
      "epoch": 1.43,
      "grad_norm": 0.8675270676612854,
      "learning_rate": 5.69847289125756e-06,
      "loss": 0.3094,
      "step": 6982
    },
    {
      "epoch": 1.43,
      "grad_norm": 3.5582711696624756,
      "learning_rate": 5.69642308086502e-06,
      "loss": 0.3358,
      "step": 6983
    },
    {
      "epoch": 1.43,
      "grad_norm": 2.7500321865081787,
      "learning_rate": 5.694373270472482e-06,
      "loss": 0.3015,
      "step": 6984
    },
    {
      "epoch": 1.43,
      "grad_norm": 3.106947183609009,
      "learning_rate": 5.692323460079943e-06,
      "loss": 0.2527,
      "step": 6985
    },
    {
      "epoch": 1.43,
      "grad_norm": 2.204411029815674,
      "learning_rate": 5.6902736496874045e-06,
      "loss": 0.5177,
      "step": 6986
    },
    {
      "epoch": 1.43,
      "grad_norm": 1.5469669103622437,
      "learning_rate": 5.6882238392948655e-06,
      "loss": 0.3966,
      "step": 6987
    },
    {
      "epoch": 1.43,
      "grad_norm": 1.723245620727539,
      "learning_rate": 5.686174028902327e-06,
      "loss": 0.3094,
      "step": 6988
    },
    {
      "epoch": 1.43,
      "grad_norm": 1.549728274345398,
      "learning_rate": 5.6841242185097875e-06,
      "loss": 0.5178,
      "step": 6989
    },
    {
      "epoch": 1.43,
      "grad_norm": 2.259073495864868,
      "learning_rate": 5.682074408117249e-06,
      "loss": 0.3711,
      "step": 6990
    },
    {
      "epoch": 1.43,
      "grad_norm": 1.7539186477661133,
      "learning_rate": 5.68002459772471e-06,
      "loss": 0.343,
      "step": 6991
    },
    {
      "epoch": 1.43,
      "grad_norm": 1.987372636795044,
      "learning_rate": 5.677974787332172e-06,
      "loss": 0.5249,
      "step": 6992
    },
    {
      "epoch": 1.43,
      "grad_norm": 1.8832017183303833,
      "learning_rate": 5.675924976939634e-06,
      "loss": 0.4446,
      "step": 6993
    },
    {
      "epoch": 1.43,
      "grad_norm": 2.5641376972198486,
      "learning_rate": 5.673875166547095e-06,
      "loss": 0.2811,
      "step": 6994
    },
    {
      "epoch": 1.43,
      "grad_norm": 0.7902529835700989,
      "learning_rate": 5.671825356154557e-06,
      "loss": 0.197,
      "step": 6995
    },
    {
      "epoch": 1.43,
      "grad_norm": 1.096124529838562,
      "learning_rate": 5.669775545762017e-06,
      "loss": 0.237,
      "step": 6996
    },
    {
      "epoch": 1.43,
      "grad_norm": 0.7318084836006165,
      "learning_rate": 5.667725735369479e-06,
      "loss": 0.2149,
      "step": 6997
    },
    {
      "epoch": 1.43,
      "grad_norm": 1.068713903427124,
      "learning_rate": 5.66567592497694e-06,
      "loss": 0.187,
      "step": 6998
    },
    {
      "epoch": 1.43,
      "grad_norm": 1.2269961833953857,
      "learning_rate": 5.663626114584402e-06,
      "loss": 0.2315,
      "step": 6999
    },
    {
      "epoch": 1.43,
      "grad_norm": 1.0886791944503784,
      "learning_rate": 5.661576304191863e-06,
      "loss": 0.2132,
      "step": 7000
    },
    {
      "epoch": 1.43,
      "eval_loss": 0.34459200501441956,
      "eval_runtime": 669.8891,
      "eval_samples_per_second": 14.928,
      "eval_steps_per_second": 1.866,
      "step": 7000
    },
    {
      "epoch": 1.43,
      "grad_norm": 1.694260597229004,
      "learning_rate": 5.659526493799325e-06,
      "loss": 0.2996,
      "step": 7001
    },
    {
      "epoch": 1.43,
      "grad_norm": 1.823548674583435,
      "learning_rate": 5.657476683406785e-06,
      "loss": 0.3886,
      "step": 7002
    },
    {
      "epoch": 1.43,
      "grad_norm": 1.8954061269760132,
      "learning_rate": 5.655426873014247e-06,
      "loss": 0.308,
      "step": 7003
    },
    {
      "epoch": 1.43,
      "grad_norm": 1.1673386096954346,
      "learning_rate": 5.653377062621708e-06,
      "loss": 0.4539,
      "step": 7004
    },
    {
      "epoch": 1.44,
      "grad_norm": 1.0769684314727783,
      "learning_rate": 5.65132725222917e-06,
      "loss": 0.4493,
      "step": 7005
    },
    {
      "epoch": 1.44,
      "grad_norm": 0.8419370055198669,
      "learning_rate": 5.649277441836631e-06,
      "loss": 0.3696,
      "step": 7006
    },
    {
      "epoch": 1.44,
      "grad_norm": 2.569591760635376,
      "learning_rate": 5.6472276314440925e-06,
      "loss": 0.346,
      "step": 7007
    },
    {
      "epoch": 1.44,
      "grad_norm": 1.8503413200378418,
      "learning_rate": 5.645177821051553e-06,
      "loss": 0.3835,
      "step": 7008
    },
    {
      "epoch": 1.44,
      "grad_norm": 1.9863948822021484,
      "learning_rate": 5.6431280106590145e-06,
      "loss": 0.4591,
      "step": 7009
    },
    {
      "epoch": 1.44,
      "grad_norm": 1.0334138870239258,
      "learning_rate": 5.6410782002664755e-06,
      "loss": 0.4164,
      "step": 7010
    },
    {
      "epoch": 1.44,
      "grad_norm": 1.5394312143325806,
      "learning_rate": 5.639028389873937e-06,
      "loss": 0.2063,
      "step": 7011
    },
    {
      "epoch": 1.44,
      "grad_norm": 2.0181331634521484,
      "learning_rate": 5.636978579481398e-06,
      "loss": 0.5008,
      "step": 7012
    },
    {
      "epoch": 1.44,
      "grad_norm": 1.8871301412582397,
      "learning_rate": 5.63492876908886e-06,
      "loss": 0.2668,
      "step": 7013
    },
    {
      "epoch": 1.44,
      "grad_norm": 0.9421877264976501,
      "learning_rate": 5.63287895869632e-06,
      "loss": 0.3068,
      "step": 7014
    },
    {
      "epoch": 1.44,
      "grad_norm": 1.333997368812561,
      "learning_rate": 5.630829148303782e-06,
      "loss": 0.4752,
      "step": 7015
    },
    {
      "epoch": 1.44,
      "grad_norm": 1.843401551246643,
      "learning_rate": 5.628779337911243e-06,
      "loss": 0.5109,
      "step": 7016
    },
    {
      "epoch": 1.44,
      "grad_norm": 1.437261939048767,
      "learning_rate": 5.626729527518705e-06,
      "loss": 0.3453,
      "step": 7017
    },
    {
      "epoch": 1.44,
      "grad_norm": 1.345885157585144,
      "learning_rate": 5.624679717126166e-06,
      "loss": 0.4239,
      "step": 7018
    },
    {
      "epoch": 1.44,
      "grad_norm": 0.9201855063438416,
      "learning_rate": 5.622629906733628e-06,
      "loss": 0.3539,
      "step": 7019
    },
    {
      "epoch": 1.44,
      "grad_norm": 2.0292108058929443,
      "learning_rate": 5.620580096341088e-06,
      "loss": 0.3313,
      "step": 7020
    },
    {
      "epoch": 1.44,
      "grad_norm": 1.4558781385421753,
      "learning_rate": 5.61853028594855e-06,
      "loss": 0.2015,
      "step": 7021
    },
    {
      "epoch": 1.44,
      "grad_norm": 1.3370505571365356,
      "learning_rate": 5.616480475556012e-06,
      "loss": 0.3785,
      "step": 7022
    },
    {
      "epoch": 1.44,
      "grad_norm": 1.1587600708007812,
      "learning_rate": 5.614430665163473e-06,
      "loss": 0.2813,
      "step": 7023
    },
    {
      "epoch": 1.44,
      "grad_norm": 1.1570382118225098,
      "learning_rate": 5.612380854770935e-06,
      "loss": 0.4454,
      "step": 7024
    },
    {
      "epoch": 1.44,
      "grad_norm": 1.2029445171356201,
      "learning_rate": 5.610331044378396e-06,
      "loss": 0.2906,
      "step": 7025
    },
    {
      "epoch": 1.44,
      "grad_norm": 2.204484701156616,
      "learning_rate": 5.6082812339858576e-06,
      "loss": 0.361,
      "step": 7026
    },
    {
      "epoch": 1.44,
      "grad_norm": 1.2687970399856567,
      "learning_rate": 5.606231423593318e-06,
      "loss": 0.2376,
      "step": 7027
    },
    {
      "epoch": 1.44,
      "grad_norm": 1.1778218746185303,
      "learning_rate": 5.60418161320078e-06,
      "loss": 0.3431,
      "step": 7028
    },
    {
      "epoch": 1.44,
      "grad_norm": 0.980194628238678,
      "learning_rate": 5.602131802808241e-06,
      "loss": 0.3211,
      "step": 7029
    },
    {
      "epoch": 1.44,
      "grad_norm": 2.1721839904785156,
      "learning_rate": 5.6000819924157025e-06,
      "loss": 0.2916,
      "step": 7030
    },
    {
      "epoch": 1.44,
      "grad_norm": 1.2461445331573486,
      "learning_rate": 5.5980321820231635e-06,
      "loss": 0.3522,
      "step": 7031
    },
    {
      "epoch": 1.44,
      "grad_norm": 1.276063084602356,
      "learning_rate": 5.595982371630625e-06,
      "loss": 0.3947,
      "step": 7032
    },
    {
      "epoch": 1.44,
      "grad_norm": 2.053535223007202,
      "learning_rate": 5.5939325612380855e-06,
      "loss": 0.2479,
      "step": 7033
    },
    {
      "epoch": 1.44,
      "grad_norm": 2.3215432167053223,
      "learning_rate": 5.591882750845547e-06,
      "loss": 0.4889,
      "step": 7034
    },
    {
      "epoch": 1.44,
      "grad_norm": 1.4354350566864014,
      "learning_rate": 5.589832940453008e-06,
      "loss": 0.4251,
      "step": 7035
    },
    {
      "epoch": 1.44,
      "grad_norm": 1.3623414039611816,
      "learning_rate": 5.58778313006047e-06,
      "loss": 0.228,
      "step": 7036
    },
    {
      "epoch": 1.44,
      "grad_norm": 1.218262791633606,
      "learning_rate": 5.585733319667931e-06,
      "loss": 0.2824,
      "step": 7037
    },
    {
      "epoch": 1.44,
      "grad_norm": 1.2442272901535034,
      "learning_rate": 5.583683509275393e-06,
      "loss": 0.3485,
      "step": 7038
    },
    {
      "epoch": 1.44,
      "grad_norm": 2.3847439289093018,
      "learning_rate": 5.581633698882853e-06,
      "loss": 0.4535,
      "step": 7039
    },
    {
      "epoch": 1.44,
      "grad_norm": 0.9677506685256958,
      "learning_rate": 5.579583888490315e-06,
      "loss": 0.2351,
      "step": 7040
    },
    {
      "epoch": 1.44,
      "grad_norm": 0.9055221676826477,
      "learning_rate": 5.577534078097776e-06,
      "loss": 0.3288,
      "step": 7041
    },
    {
      "epoch": 1.44,
      "grad_norm": 1.7936183214187622,
      "learning_rate": 5.575484267705238e-06,
      "loss": 0.2153,
      "step": 7042
    },
    {
      "epoch": 1.44,
      "grad_norm": 1.2389085292816162,
      "learning_rate": 5.573434457312699e-06,
      "loss": 0.3337,
      "step": 7043
    },
    {
      "epoch": 1.44,
      "grad_norm": 1.1264480352401733,
      "learning_rate": 5.571384646920161e-06,
      "loss": 0.2785,
      "step": 7044
    },
    {
      "epoch": 1.44,
      "grad_norm": 1.0469869375228882,
      "learning_rate": 5.569334836527621e-06,
      "loss": 0.2724,
      "step": 7045
    },
    {
      "epoch": 1.44,
      "grad_norm": 0.937991201877594,
      "learning_rate": 5.567285026135083e-06,
      "loss": 0.2745,
      "step": 7046
    },
    {
      "epoch": 1.44,
      "grad_norm": 1.2509815692901611,
      "learning_rate": 5.565235215742544e-06,
      "loss": 0.3513,
      "step": 7047
    },
    {
      "epoch": 1.44,
      "grad_norm": 1.116609811782837,
      "learning_rate": 5.563185405350006e-06,
      "loss": 0.4916,
      "step": 7048
    },
    {
      "epoch": 1.44,
      "grad_norm": 1.3092703819274902,
      "learning_rate": 5.561135594957467e-06,
      "loss": 0.4026,
      "step": 7049
    },
    {
      "epoch": 1.44,
      "grad_norm": 0.704094409942627,
      "learning_rate": 5.5590857845649286e-06,
      "loss": 0.199,
      "step": 7050
    },
    {
      "epoch": 1.44,
      "grad_norm": 1.1141480207443237,
      "learning_rate": 5.5570359741723904e-06,
      "loss": 0.4182,
      "step": 7051
    },
    {
      "epoch": 1.44,
      "grad_norm": 1.3090159893035889,
      "learning_rate": 5.554986163779851e-06,
      "loss": 0.3853,
      "step": 7052
    },
    {
      "epoch": 1.44,
      "grad_norm": 1.1159542798995972,
      "learning_rate": 5.5529363533873125e-06,
      "loss": 0.2829,
      "step": 7053
    },
    {
      "epoch": 1.45,
      "grad_norm": 0.8182183504104614,
      "learning_rate": 5.5508865429947735e-06,
      "loss": 0.3232,
      "step": 7054
    },
    {
      "epoch": 1.45,
      "grad_norm": 1.4161186218261719,
      "learning_rate": 5.548836732602235e-06,
      "loss": 0.3196,
      "step": 7055
    },
    {
      "epoch": 1.45,
      "grad_norm": 1.332793116569519,
      "learning_rate": 5.546786922209696e-06,
      "loss": 0.2854,
      "step": 7056
    },
    {
      "epoch": 1.45,
      "grad_norm": 0.9153635501861572,
      "learning_rate": 5.544737111817158e-06,
      "loss": 0.2813,
      "step": 7057
    },
    {
      "epoch": 1.45,
      "grad_norm": 0.9691668152809143,
      "learning_rate": 5.542687301424618e-06,
      "loss": 0.3996,
      "step": 7058
    },
    {
      "epoch": 1.45,
      "grad_norm": 2.2993502616882324,
      "learning_rate": 5.54063749103208e-06,
      "loss": 0.4148,
      "step": 7059
    },
    {
      "epoch": 1.45,
      "grad_norm": 0.9496995210647583,
      "learning_rate": 5.538587680639541e-06,
      "loss": 0.3093,
      "step": 7060
    },
    {
      "epoch": 1.45,
      "grad_norm": 1.466757893562317,
      "learning_rate": 5.536537870247003e-06,
      "loss": 0.4708,
      "step": 7061
    },
    {
      "epoch": 1.45,
      "grad_norm": 1.3645669221878052,
      "learning_rate": 5.534488059854464e-06,
      "loss": 0.2139,
      "step": 7062
    },
    {
      "epoch": 1.45,
      "grad_norm": 1.9707083702087402,
      "learning_rate": 5.532438249461926e-06,
      "loss": 0.3839,
      "step": 7063
    },
    {
      "epoch": 1.45,
      "grad_norm": 1.289423942565918,
      "learning_rate": 5.530388439069386e-06,
      "loss": 0.4719,
      "step": 7064
    },
    {
      "epoch": 1.45,
      "grad_norm": 1.0816961526870728,
      "learning_rate": 5.528338628676848e-06,
      "loss": 0.3703,
      "step": 7065
    },
    {
      "epoch": 1.45,
      "grad_norm": 1.8021835088729858,
      "learning_rate": 5.526288818284309e-06,
      "loss": 0.2459,
      "step": 7066
    },
    {
      "epoch": 1.45,
      "grad_norm": 1.8767155408859253,
      "learning_rate": 5.524239007891771e-06,
      "loss": 0.2353,
      "step": 7067
    },
    {
      "epoch": 1.45,
      "grad_norm": 1.3159745931625366,
      "learning_rate": 5.522189197499232e-06,
      "loss": 0.3534,
      "step": 7068
    },
    {
      "epoch": 1.45,
      "grad_norm": 1.0469353199005127,
      "learning_rate": 5.520139387106694e-06,
      "loss": 0.2828,
      "step": 7069
    },
    {
      "epoch": 1.45,
      "grad_norm": 2.206211805343628,
      "learning_rate": 5.518089576714154e-06,
      "loss": 0.3994,
      "step": 7070
    },
    {
      "epoch": 1.45,
      "grad_norm": 1.5929021835327148,
      "learning_rate": 5.516039766321616e-06,
      "loss": 0.3709,
      "step": 7071
    },
    {
      "epoch": 1.45,
      "grad_norm": 1.9045228958129883,
      "learning_rate": 5.513989955929077e-06,
      "loss": 0.275,
      "step": 7072
    },
    {
      "epoch": 1.45,
      "grad_norm": 1.463969111442566,
      "learning_rate": 5.5119401455365386e-06,
      "loss": 0.2223,
      "step": 7073
    },
    {
      "epoch": 1.45,
      "grad_norm": 0.861771821975708,
      "learning_rate": 5.5098903351439996e-06,
      "loss": 0.2148,
      "step": 7074
    },
    {
      "epoch": 1.45,
      "grad_norm": 1.1252683401107788,
      "learning_rate": 5.5078405247514614e-06,
      "loss": 0.4181,
      "step": 7075
    },
    {
      "epoch": 1.45,
      "grad_norm": 1.4846272468566895,
      "learning_rate": 5.505790714358922e-06,
      "loss": 0.318,
      "step": 7076
    },
    {
      "epoch": 1.45,
      "grad_norm": 1.7107963562011719,
      "learning_rate": 5.5037409039663835e-06,
      "loss": 0.366,
      "step": 7077
    },
    {
      "epoch": 1.45,
      "grad_norm": 1.2014139890670776,
      "learning_rate": 5.5016910935738445e-06,
      "loss": 0.2612,
      "step": 7078
    },
    {
      "epoch": 1.45,
      "grad_norm": 1.4096165895462036,
      "learning_rate": 5.499641283181306e-06,
      "loss": 0.2902,
      "step": 7079
    },
    {
      "epoch": 1.45,
      "grad_norm": 1.210023045539856,
      "learning_rate": 5.497591472788768e-06,
      "loss": 0.396,
      "step": 7080
    },
    {
      "epoch": 1.45,
      "grad_norm": 1.1831806898117065,
      "learning_rate": 5.495541662396229e-06,
      "loss": 0.4678,
      "step": 7081
    },
    {
      "epoch": 1.45,
      "grad_norm": 1.2860217094421387,
      "learning_rate": 5.493491852003691e-06,
      "loss": 0.2335,
      "step": 7082
    },
    {
      "epoch": 1.45,
      "grad_norm": 0.864596426486969,
      "learning_rate": 5.491442041611151e-06,
      "loss": 0.3571,
      "step": 7083
    },
    {
      "epoch": 1.45,
      "grad_norm": 1.4854130744934082,
      "learning_rate": 5.489392231218613e-06,
      "loss": 0.3435,
      "step": 7084
    },
    {
      "epoch": 1.45,
      "grad_norm": 1.0558555126190186,
      "learning_rate": 5.487342420826074e-06,
      "loss": 0.381,
      "step": 7085
    },
    {
      "epoch": 1.45,
      "grad_norm": 2.2062599658966064,
      "learning_rate": 5.485292610433536e-06,
      "loss": 0.3462,
      "step": 7086
    },
    {
      "epoch": 1.45,
      "grad_norm": 1.5056637525558472,
      "learning_rate": 5.483242800040997e-06,
      "loss": 0.3718,
      "step": 7087
    },
    {
      "epoch": 1.45,
      "grad_norm": 1.4054591655731201,
      "learning_rate": 5.481192989648458e-06,
      "loss": 0.3508,
      "step": 7088
    },
    {
      "epoch": 1.45,
      "grad_norm": 0.8774521946907043,
      "learning_rate": 5.479143179255919e-06,
      "loss": 0.2943,
      "step": 7089
    },
    {
      "epoch": 1.45,
      "grad_norm": 1.094404935836792,
      "learning_rate": 5.477093368863381e-06,
      "loss": 0.3487,
      "step": 7090
    },
    {
      "epoch": 1.45,
      "grad_norm": 1.5386900901794434,
      "learning_rate": 5.475043558470842e-06,
      "loss": 0.3379,
      "step": 7091
    },
    {
      "epoch": 1.45,
      "grad_norm": 1.2476613521575928,
      "learning_rate": 5.472993748078304e-06,
      "loss": 0.3081,
      "step": 7092
    },
    {
      "epoch": 1.45,
      "grad_norm": 1.1825357675552368,
      "learning_rate": 5.470943937685765e-06,
      "loss": 0.3353,
      "step": 7093
    },
    {
      "epoch": 1.45,
      "grad_norm": 1.412381887435913,
      "learning_rate": 5.468894127293226e-06,
      "loss": 0.2407,
      "step": 7094
    },
    {
      "epoch": 1.45,
      "grad_norm": 1.420233964920044,
      "learning_rate": 5.466844316900687e-06,
      "loss": 0.5551,
      "step": 7095
    },
    {
      "epoch": 1.45,
      "grad_norm": 1.147404432296753,
      "learning_rate": 5.4647945065081486e-06,
      "loss": 0.3306,
      "step": 7096
    },
    {
      "epoch": 1.45,
      "grad_norm": 1.487735390663147,
      "learning_rate": 5.4627446961156096e-06,
      "loss": 0.4044,
      "step": 7097
    },
    {
      "epoch": 1.45,
      "grad_norm": 1.176669716835022,
      "learning_rate": 5.4606948857230714e-06,
      "loss": 0.28,
      "step": 7098
    },
    {
      "epoch": 1.45,
      "grad_norm": 1.4306166172027588,
      "learning_rate": 5.458645075330532e-06,
      "loss": 0.3926,
      "step": 7099
    },
    {
      "epoch": 1.45,
      "grad_norm": 1.2020952701568604,
      "learning_rate": 5.4565952649379934e-06,
      "loss": 0.2548,
      "step": 7100
    },
    {
      "epoch": 1.45,
      "grad_norm": 1.355038046836853,
      "learning_rate": 5.4545454545454545e-06,
      "loss": 0.37,
      "step": 7101
    },
    {
      "epoch": 1.46,
      "grad_norm": 1.7541041374206543,
      "learning_rate": 5.452495644152916e-06,
      "loss": 0.3364,
      "step": 7102
    },
    {
      "epoch": 1.46,
      "grad_norm": 1.319381594657898,
      "learning_rate": 5.450445833760377e-06,
      "loss": 0.4014,
      "step": 7103
    },
    {
      "epoch": 1.46,
      "grad_norm": 1.0809378623962402,
      "learning_rate": 5.448396023367839e-06,
      "loss": 0.3601,
      "step": 7104
    },
    {
      "epoch": 1.46,
      "grad_norm": 1.3303881883621216,
      "learning_rate": 5.446346212975299e-06,
      "loss": 0.421,
      "step": 7105
    },
    {
      "epoch": 1.46,
      "grad_norm": 1.3201178312301636,
      "learning_rate": 5.444296402582761e-06,
      "loss": 0.3163,
      "step": 7106
    },
    {
      "epoch": 1.46,
      "grad_norm": 1.0399155616760254,
      "learning_rate": 5.442246592190222e-06,
      "loss": 0.3867,
      "step": 7107
    },
    {
      "epoch": 1.46,
      "grad_norm": 0.970373272895813,
      "learning_rate": 5.440196781797684e-06,
      "loss": 0.2206,
      "step": 7108
    },
    {
      "epoch": 1.46,
      "grad_norm": 1.355048656463623,
      "learning_rate": 5.438146971405145e-06,
      "loss": 0.3698,
      "step": 7109
    },
    {
      "epoch": 1.46,
      "grad_norm": 0.995762825012207,
      "learning_rate": 5.436097161012607e-06,
      "loss": 0.2694,
      "step": 7110
    },
    {
      "epoch": 1.46,
      "grad_norm": 1.324345350265503,
      "learning_rate": 5.434047350620069e-06,
      "loss": 0.406,
      "step": 7111
    },
    {
      "epoch": 1.46,
      "grad_norm": 1.3271104097366333,
      "learning_rate": 5.431997540227529e-06,
      "loss": 0.2404,
      "step": 7112
    },
    {
      "epoch": 1.46,
      "grad_norm": 1.195406198501587,
      "learning_rate": 5.429947729834991e-06,
      "loss": 0.3131,
      "step": 7113
    },
    {
      "epoch": 1.46,
      "grad_norm": 1.1935914754867554,
      "learning_rate": 5.427897919442452e-06,
      "loss": 0.3055,
      "step": 7114
    },
    {
      "epoch": 1.46,
      "grad_norm": 0.8201839327812195,
      "learning_rate": 5.425848109049914e-06,
      "loss": 0.2835,
      "step": 7115
    },
    {
      "epoch": 1.46,
      "grad_norm": 1.288185477256775,
      "learning_rate": 5.423798298657375e-06,
      "loss": 0.2868,
      "step": 7116
    },
    {
      "epoch": 1.46,
      "grad_norm": 1.6498854160308838,
      "learning_rate": 5.4217484882648365e-06,
      "loss": 0.3847,
      "step": 7117
    },
    {
      "epoch": 1.46,
      "grad_norm": 0.7878654599189758,
      "learning_rate": 5.419698677872297e-06,
      "loss": 0.1874,
      "step": 7118
    },
    {
      "epoch": 1.46,
      "grad_norm": 1.1088329553604126,
      "learning_rate": 5.4176488674797586e-06,
      "loss": 0.3578,
      "step": 7119
    },
    {
      "epoch": 1.46,
      "grad_norm": 1.6654607057571411,
      "learning_rate": 5.4155990570872196e-06,
      "loss": 0.277,
      "step": 7120
    },
    {
      "epoch": 1.46,
      "grad_norm": 1.420757532119751,
      "learning_rate": 5.413549246694681e-06,
      "loss": 0.4014,
      "step": 7121
    },
    {
      "epoch": 1.46,
      "grad_norm": 1.302509069442749,
      "learning_rate": 5.4114994363021424e-06,
      "loss": 0.271,
      "step": 7122
    },
    {
      "epoch": 1.46,
      "grad_norm": 1.137955665588379,
      "learning_rate": 5.409449625909604e-06,
      "loss": 0.3208,
      "step": 7123
    },
    {
      "epoch": 1.46,
      "grad_norm": 0.8975672721862793,
      "learning_rate": 5.4073998155170644e-06,
      "loss": 0.3252,
      "step": 7124
    },
    {
      "epoch": 1.46,
      "grad_norm": 1.7253425121307373,
      "learning_rate": 5.405350005124526e-06,
      "loss": 0.4043,
      "step": 7125
    },
    {
      "epoch": 1.46,
      "grad_norm": 1.0033142566680908,
      "learning_rate": 5.403300194731987e-06,
      "loss": 0.3245,
      "step": 7126
    },
    {
      "epoch": 1.46,
      "grad_norm": 1.1216896772384644,
      "learning_rate": 5.401250384339449e-06,
      "loss": 0.3866,
      "step": 7127
    },
    {
      "epoch": 1.46,
      "grad_norm": 1.2768393754959106,
      "learning_rate": 5.39920057394691e-06,
      "loss": 0.4295,
      "step": 7128
    },
    {
      "epoch": 1.46,
      "grad_norm": 1.1751171350479126,
      "learning_rate": 5.397150763554372e-06,
      "loss": 0.3503,
      "step": 7129
    },
    {
      "epoch": 1.46,
      "grad_norm": 1.968285083770752,
      "learning_rate": 5.395100953161832e-06,
      "loss": 0.4784,
      "step": 7130
    },
    {
      "epoch": 1.46,
      "grad_norm": 1.2504751682281494,
      "learning_rate": 5.393051142769294e-06,
      "loss": 0.2673,
      "step": 7131
    },
    {
      "epoch": 1.46,
      "grad_norm": 0.7632312178611755,
      "learning_rate": 5.391001332376755e-06,
      "loss": 0.2938,
      "step": 7132
    },
    {
      "epoch": 1.46,
      "grad_norm": 1.159747838973999,
      "learning_rate": 5.388951521984217e-06,
      "loss": 0.293,
      "step": 7133
    },
    {
      "epoch": 1.46,
      "grad_norm": 0.8603544235229492,
      "learning_rate": 5.386901711591678e-06,
      "loss": 0.3852,
      "step": 7134
    },
    {
      "epoch": 1.46,
      "grad_norm": 1.4833639860153198,
      "learning_rate": 5.38485190119914e-06,
      "loss": 0.3441,
      "step": 7135
    },
    {
      "epoch": 1.46,
      "grad_norm": 1.7150776386260986,
      "learning_rate": 5.3828020908066e-06,
      "loss": 0.4063,
      "step": 7136
    },
    {
      "epoch": 1.46,
      "grad_norm": 1.3918941020965576,
      "learning_rate": 5.380752280414062e-06,
      "loss": 0.3552,
      "step": 7137
    },
    {
      "epoch": 1.46,
      "grad_norm": 1.5290716886520386,
      "learning_rate": 5.378702470021523e-06,
      "loss": 0.2456,
      "step": 7138
    },
    {
      "epoch": 1.46,
      "grad_norm": 0.9542681574821472,
      "learning_rate": 5.376652659628985e-06,
      "loss": 0.3327,
      "step": 7139
    },
    {
      "epoch": 1.46,
      "grad_norm": 1.486717700958252,
      "learning_rate": 5.3746028492364465e-06,
      "loss": 0.3986,
      "step": 7140
    },
    {
      "epoch": 1.46,
      "grad_norm": 1.7578219175338745,
      "learning_rate": 5.3725530388439075e-06,
      "loss": 0.4487,
      "step": 7141
    },
    {
      "epoch": 1.46,
      "grad_norm": 1.1725361347198486,
      "learning_rate": 5.370503228451369e-06,
      "loss": 0.3122,
      "step": 7142
    },
    {
      "epoch": 1.46,
      "grad_norm": 1.210585117340088,
      "learning_rate": 5.3684534180588296e-06,
      "loss": 0.3946,
      "step": 7143
    },
    {
      "epoch": 1.46,
      "grad_norm": 1.5226738452911377,
      "learning_rate": 5.366403607666291e-06,
      "loss": 0.3461,
      "step": 7144
    },
    {
      "epoch": 1.46,
      "grad_norm": 1.8584221601486206,
      "learning_rate": 5.364353797273752e-06,
      "loss": 0.293,
      "step": 7145
    },
    {
      "epoch": 1.46,
      "grad_norm": 0.8983821868896484,
      "learning_rate": 5.362303986881214e-06,
      "loss": 0.3309,
      "step": 7146
    },
    {
      "epoch": 1.46,
      "grad_norm": 2.026231288909912,
      "learning_rate": 5.360254176488675e-06,
      "loss": 0.426,
      "step": 7147
    },
    {
      "epoch": 1.46,
      "grad_norm": 1.0929306745529175,
      "learning_rate": 5.358204366096137e-06,
      "loss": 0.3707,
      "step": 7148
    },
    {
      "epoch": 1.46,
      "grad_norm": 1.2413077354431152,
      "learning_rate": 5.356154555703597e-06,
      "loss": 0.3761,
      "step": 7149
    },
    {
      "epoch": 1.46,
      "grad_norm": 1.3135600090026855,
      "learning_rate": 5.354104745311059e-06,
      "loss": 0.3352,
      "step": 7150
    },
    {
      "epoch": 1.47,
      "grad_norm": 1.0687448978424072,
      "learning_rate": 5.35205493491852e-06,
      "loss": 0.2389,
      "step": 7151
    },
    {
      "epoch": 1.47,
      "grad_norm": 1.1480547189712524,
      "learning_rate": 5.350005124525982e-06,
      "loss": 0.3395,
      "step": 7152
    },
    {
      "epoch": 1.47,
      "grad_norm": 1.2425516843795776,
      "learning_rate": 5.347955314133443e-06,
      "loss": 0.2581,
      "step": 7153
    },
    {
      "epoch": 1.47,
      "grad_norm": 1.2635109424591064,
      "learning_rate": 5.345905503740905e-06,
      "loss": 0.3948,
      "step": 7154
    },
    {
      "epoch": 1.47,
      "grad_norm": 1.062103033065796,
      "learning_rate": 5.343855693348365e-06,
      "loss": 0.3475,
      "step": 7155
    },
    {
      "epoch": 1.47,
      "grad_norm": 1.0428870916366577,
      "learning_rate": 5.341805882955827e-06,
      "loss": 0.3621,
      "step": 7156
    },
    {
      "epoch": 1.47,
      "grad_norm": 1.1314424276351929,
      "learning_rate": 5.339756072563288e-06,
      "loss": 0.3788,
      "step": 7157
    },
    {
      "epoch": 1.47,
      "grad_norm": 1.9526517391204834,
      "learning_rate": 5.33770626217075e-06,
      "loss": 0.4994,
      "step": 7158
    },
    {
      "epoch": 1.47,
      "grad_norm": 0.9577609300613403,
      "learning_rate": 5.335656451778211e-06,
      "loss": 0.2999,
      "step": 7159
    },
    {
      "epoch": 1.47,
      "grad_norm": 1.2537641525268555,
      "learning_rate": 5.333606641385673e-06,
      "loss": 0.4956,
      "step": 7160
    },
    {
      "epoch": 1.47,
      "grad_norm": 1.0757964849472046,
      "learning_rate": 5.331556830993133e-06,
      "loss": 0.4477,
      "step": 7161
    },
    {
      "epoch": 1.47,
      "grad_norm": 1.477066159248352,
      "learning_rate": 5.329507020600595e-06,
      "loss": 0.3636,
      "step": 7162
    },
    {
      "epoch": 1.47,
      "grad_norm": 0.9303966164588928,
      "learning_rate": 5.327457210208056e-06,
      "loss": 0.3132,
      "step": 7163
    },
    {
      "epoch": 1.47,
      "grad_norm": 1.2830326557159424,
      "learning_rate": 5.3254073998155175e-06,
      "loss": 0.5494,
      "step": 7164
    },
    {
      "epoch": 1.47,
      "grad_norm": 1.104998230934143,
      "learning_rate": 5.3233575894229785e-06,
      "loss": 0.3561,
      "step": 7165
    },
    {
      "epoch": 1.47,
      "grad_norm": 1.3919916152954102,
      "learning_rate": 5.32130777903044e-06,
      "loss": 0.3733,
      "step": 7166
    },
    {
      "epoch": 1.47,
      "grad_norm": 1.061869740486145,
      "learning_rate": 5.3192579686379006e-06,
      "loss": 0.2842,
      "step": 7167
    },
    {
      "epoch": 1.47,
      "grad_norm": 1.147523283958435,
      "learning_rate": 5.317208158245362e-06,
      "loss": 0.3389,
      "step": 7168
    },
    {
      "epoch": 1.47,
      "grad_norm": 1.3066540956497192,
      "learning_rate": 5.315158347852824e-06,
      "loss": 0.4892,
      "step": 7169
    },
    {
      "epoch": 1.47,
      "grad_norm": 1.0320950746536255,
      "learning_rate": 5.313108537460285e-06,
      "loss": 0.4488,
      "step": 7170
    },
    {
      "epoch": 1.47,
      "grad_norm": 1.1020808219909668,
      "learning_rate": 5.311058727067747e-06,
      "loss": 0.3673,
      "step": 7171
    },
    {
      "epoch": 1.47,
      "grad_norm": 0.9658301472663879,
      "learning_rate": 5.309008916675208e-06,
      "loss": 0.2528,
      "step": 7172
    },
    {
      "epoch": 1.47,
      "grad_norm": 1.1647149324417114,
      "learning_rate": 5.30695910628267e-06,
      "loss": 0.3045,
      "step": 7173
    },
    {
      "epoch": 1.47,
      "grad_norm": 0.9960193634033203,
      "learning_rate": 5.30490929589013e-06,
      "loss": 0.3052,
      "step": 7174
    },
    {
      "epoch": 1.47,
      "grad_norm": 1.4126070737838745,
      "learning_rate": 5.302859485497592e-06,
      "loss": 0.4016,
      "step": 7175
    },
    {
      "epoch": 1.47,
      "grad_norm": 0.7480453252792358,
      "learning_rate": 5.300809675105053e-06,
      "loss": 0.2902,
      "step": 7176
    },
    {
      "epoch": 1.47,
      "grad_norm": 1.052135705947876,
      "learning_rate": 5.298759864712515e-06,
      "loss": 0.3374,
      "step": 7177
    },
    {
      "epoch": 1.47,
      "grad_norm": 1.1387659311294556,
      "learning_rate": 5.296710054319976e-06,
      "loss": 0.3054,
      "step": 7178
    },
    {
      "epoch": 1.47,
      "grad_norm": 1.4535183906555176,
      "learning_rate": 5.294660243927438e-06,
      "loss": 0.3357,
      "step": 7179
    },
    {
      "epoch": 1.47,
      "grad_norm": 0.9461081027984619,
      "learning_rate": 5.292610433534898e-06,
      "loss": 0.3578,
      "step": 7180
    },
    {
      "epoch": 1.47,
      "grad_norm": 0.9242797493934631,
      "learning_rate": 5.29056062314236e-06,
      "loss": 0.439,
      "step": 7181
    },
    {
      "epoch": 1.47,
      "grad_norm": 1.542832374572754,
      "learning_rate": 5.288510812749821e-06,
      "loss": 0.2779,
      "step": 7182
    },
    {
      "epoch": 1.47,
      "grad_norm": 1.3538482189178467,
      "learning_rate": 5.286461002357283e-06,
      "loss": 0.3413,
      "step": 7183
    },
    {
      "epoch": 1.47,
      "grad_norm": 1.1940652132034302,
      "learning_rate": 5.284411191964744e-06,
      "loss": 0.3827,
      "step": 7184
    },
    {
      "epoch": 1.47,
      "grad_norm": 1.6803183555603027,
      "learning_rate": 5.2823613815722055e-06,
      "loss": 0.4888,
      "step": 7185
    },
    {
      "epoch": 1.47,
      "grad_norm": 1.6530665159225464,
      "learning_rate": 5.280311571179666e-06,
      "loss": 0.2165,
      "step": 7186
    },
    {
      "epoch": 1.47,
      "grad_norm": 1.2782554626464844,
      "learning_rate": 5.2782617607871275e-06,
      "loss": 0.2393,
      "step": 7187
    },
    {
      "epoch": 1.47,
      "grad_norm": 1.405927062034607,
      "learning_rate": 5.2762119503945885e-06,
      "loss": 0.3234,
      "step": 7188
    },
    {
      "epoch": 1.47,
      "grad_norm": 1.1977813243865967,
      "learning_rate": 5.27416214000205e-06,
      "loss": 0.4295,
      "step": 7189
    },
    {
      "epoch": 1.47,
      "grad_norm": 0.9676555395126343,
      "learning_rate": 5.272112329609511e-06,
      "loss": 0.2663,
      "step": 7190
    },
    {
      "epoch": 1.47,
      "grad_norm": 1.1187183856964111,
      "learning_rate": 5.270062519216973e-06,
      "loss": 0.3103,
      "step": 7191
    },
    {
      "epoch": 1.47,
      "grad_norm": 0.827276885509491,
      "learning_rate": 5.268012708824433e-06,
      "loss": 0.2728,
      "step": 7192
    },
    {
      "epoch": 1.47,
      "grad_norm": 1.3289692401885986,
      "learning_rate": 5.265962898431895e-06,
      "loss": 0.3127,
      "step": 7193
    },
    {
      "epoch": 1.47,
      "grad_norm": 1.2450740337371826,
      "learning_rate": 5.263913088039356e-06,
      "loss": 0.2866,
      "step": 7194
    },
    {
      "epoch": 1.47,
      "grad_norm": 1.082950472831726,
      "learning_rate": 5.261863277646818e-06,
      "loss": 0.3923,
      "step": 7195
    },
    {
      "epoch": 1.47,
      "grad_norm": 2.201977252960205,
      "learning_rate": 5.259813467254279e-06,
      "loss": 0.2566,
      "step": 7196
    },
    {
      "epoch": 1.47,
      "grad_norm": 1.4586282968521118,
      "learning_rate": 5.257763656861741e-06,
      "loss": 0.3064,
      "step": 7197
    },
    {
      "epoch": 1.47,
      "grad_norm": 1.525316834449768,
      "learning_rate": 5.255713846469203e-06,
      "loss": 0.3701,
      "step": 7198
    },
    {
      "epoch": 1.47,
      "grad_norm": 0.9445861577987671,
      "learning_rate": 5.253664036076663e-06,
      "loss": 0.3176,
      "step": 7199
    },
    {
      "epoch": 1.48,
      "grad_norm": 2.293907642364502,
      "learning_rate": 5.251614225684125e-06,
      "loss": 0.2682,
      "step": 7200
    },
    {
      "epoch": 1.48,
      "grad_norm": 1.124443531036377,
      "learning_rate": 5.249564415291586e-06,
      "loss": 0.2319,
      "step": 7201
    },
    {
      "epoch": 1.48,
      "grad_norm": 1.3080329895019531,
      "learning_rate": 5.247514604899048e-06,
      "loss": 0.3205,
      "step": 7202
    },
    {
      "epoch": 1.48,
      "grad_norm": 1.109073281288147,
      "learning_rate": 5.245464794506509e-06,
      "loss": 0.4772,
      "step": 7203
    },
    {
      "epoch": 1.48,
      "grad_norm": 1.5088508129119873,
      "learning_rate": 5.243414984113971e-06,
      "loss": 0.3116,
      "step": 7204
    },
    {
      "epoch": 1.48,
      "grad_norm": 2.0135903358459473,
      "learning_rate": 5.241365173721431e-06,
      "loss": 0.2703,
      "step": 7205
    },
    {
      "epoch": 1.48,
      "grad_norm": 2.2129180431365967,
      "learning_rate": 5.239315363328893e-06,
      "loss": 0.2869,
      "step": 7206
    },
    {
      "epoch": 1.48,
      "grad_norm": 1.6487486362457275,
      "learning_rate": 5.237265552936354e-06,
      "loss": 0.4032,
      "step": 7207
    },
    {
      "epoch": 1.48,
      "grad_norm": 1.8369594812393188,
      "learning_rate": 5.2352157425438155e-06,
      "loss": 0.4191,
      "step": 7208
    },
    {
      "epoch": 1.48,
      "grad_norm": 3.4399120807647705,
      "learning_rate": 5.2331659321512765e-06,
      "loss": 0.3735,
      "step": 7209
    },
    {
      "epoch": 1.48,
      "grad_norm": 1.611078143119812,
      "learning_rate": 5.231116121758738e-06,
      "loss": 0.3645,
      "step": 7210
    },
    {
      "epoch": 1.48,
      "grad_norm": 0.8638195395469666,
      "learning_rate": 5.2290663113661985e-06,
      "loss": 0.2569,
      "step": 7211
    },
    {
      "epoch": 1.48,
      "grad_norm": 1.9986330270767212,
      "learning_rate": 5.22701650097366e-06,
      "loss": 0.3019,
      "step": 7212
    },
    {
      "epoch": 1.48,
      "grad_norm": 1.531725287437439,
      "learning_rate": 5.224966690581121e-06,
      "loss": 0.1819,
      "step": 7213
    },
    {
      "epoch": 1.48,
      "grad_norm": 1.4982308149337769,
      "learning_rate": 5.222916880188583e-06,
      "loss": 0.3267,
      "step": 7214
    },
    {
      "epoch": 1.48,
      "grad_norm": 1.466393232345581,
      "learning_rate": 5.220867069796044e-06,
      "loss": 0.4174,
      "step": 7215
    },
    {
      "epoch": 1.48,
      "grad_norm": 2.4253687858581543,
      "learning_rate": 5.218817259403506e-06,
      "loss": 0.3469,
      "step": 7216
    },
    {
      "epoch": 1.48,
      "grad_norm": 1.4603371620178223,
      "learning_rate": 5.216767449010966e-06,
      "loss": 0.5017,
      "step": 7217
    },
    {
      "epoch": 1.48,
      "grad_norm": 1.3152304887771606,
      "learning_rate": 5.214717638618428e-06,
      "loss": 0.268,
      "step": 7218
    },
    {
      "epoch": 1.48,
      "grad_norm": 1.3021016120910645,
      "learning_rate": 5.212667828225889e-06,
      "loss": 0.4143,
      "step": 7219
    },
    {
      "epoch": 1.48,
      "grad_norm": 0.571527361869812,
      "learning_rate": 5.210618017833351e-06,
      "loss": 0.2038,
      "step": 7220
    },
    {
      "epoch": 1.48,
      "grad_norm": 2.2483091354370117,
      "learning_rate": 5.208568207440812e-06,
      "loss": 0.2212,
      "step": 7221
    },
    {
      "epoch": 1.48,
      "grad_norm": 1.421701431274414,
      "learning_rate": 5.206518397048274e-06,
      "loss": 0.343,
      "step": 7222
    },
    {
      "epoch": 1.48,
      "grad_norm": 1.187502384185791,
      "learning_rate": 5.204468586655734e-06,
      "loss": 0.3132,
      "step": 7223
    },
    {
      "epoch": 1.48,
      "grad_norm": 1.2434766292572021,
      "learning_rate": 5.202418776263196e-06,
      "loss": 0.3902,
      "step": 7224
    },
    {
      "epoch": 1.48,
      "grad_norm": 0.8076186180114746,
      "learning_rate": 5.200368965870657e-06,
      "loss": 0.324,
      "step": 7225
    },
    {
      "epoch": 1.48,
      "grad_norm": 1.977255940437317,
      "learning_rate": 5.198319155478119e-06,
      "loss": 0.4253,
      "step": 7226
    },
    {
      "epoch": 1.48,
      "grad_norm": 1.9213955402374268,
      "learning_rate": 5.196269345085581e-06,
      "loss": 0.3335,
      "step": 7227
    },
    {
      "epoch": 1.48,
      "grad_norm": 1.5426714420318604,
      "learning_rate": 5.194219534693042e-06,
      "loss": 0.3364,
      "step": 7228
    },
    {
      "epoch": 1.48,
      "grad_norm": 1.609302282333374,
      "learning_rate": 5.1921697243005035e-06,
      "loss": 0.3676,
      "step": 7229
    },
    {
      "epoch": 1.48,
      "grad_norm": 1.6206021308898926,
      "learning_rate": 5.190119913907964e-06,
      "loss": 0.2413,
      "step": 7230
    },
    {
      "epoch": 1.48,
      "grad_norm": 1.1619242429733276,
      "learning_rate": 5.1880701035154255e-06,
      "loss": 0.4584,
      "step": 7231
    },
    {
      "epoch": 1.48,
      "grad_norm": 1.4382588863372803,
      "learning_rate": 5.1860202931228865e-06,
      "loss": 0.3679,
      "step": 7232
    },
    {
      "epoch": 1.48,
      "grad_norm": 1.4897123575210571,
      "learning_rate": 5.183970482730348e-06,
      "loss": 0.4235,
      "step": 7233
    },
    {
      "epoch": 1.48,
      "grad_norm": 1.037316918373108,
      "learning_rate": 5.181920672337809e-06,
      "loss": 0.2929,
      "step": 7234
    },
    {
      "epoch": 1.48,
      "grad_norm": 1.2021530866622925,
      "learning_rate": 5.179870861945271e-06,
      "loss": 0.3847,
      "step": 7235
    },
    {
      "epoch": 1.48,
      "grad_norm": 0.9904906749725342,
      "learning_rate": 5.177821051552731e-06,
      "loss": 0.321,
      "step": 7236
    },
    {
      "epoch": 1.48,
      "grad_norm": 1.2351853847503662,
      "learning_rate": 5.175771241160193e-06,
      "loss": 0.2473,
      "step": 7237
    },
    {
      "epoch": 1.48,
      "grad_norm": 1.0292383432388306,
      "learning_rate": 5.173721430767654e-06,
      "loss": 0.2973,
      "step": 7238
    },
    {
      "epoch": 1.48,
      "grad_norm": 1.525647759437561,
      "learning_rate": 5.171671620375116e-06,
      "loss": 0.3964,
      "step": 7239
    },
    {
      "epoch": 1.48,
      "grad_norm": 1.0470820665359497,
      "learning_rate": 5.169621809982577e-06,
      "loss": 0.2487,
      "step": 7240
    },
    {
      "epoch": 1.48,
      "grad_norm": 0.8462145328521729,
      "learning_rate": 5.167571999590039e-06,
      "loss": 0.3842,
      "step": 7241
    },
    {
      "epoch": 1.48,
      "grad_norm": 1.8023349046707153,
      "learning_rate": 5.165522189197499e-06,
      "loss": 0.1929,
      "step": 7242
    },
    {
      "epoch": 1.48,
      "grad_norm": 0.9875282049179077,
      "learning_rate": 5.163472378804961e-06,
      "loss": 0.1762,
      "step": 7243
    },
    {
      "epoch": 1.48,
      "grad_norm": 0.8921344876289368,
      "learning_rate": 5.161422568412422e-06,
      "loss": 0.2709,
      "step": 7244
    },
    {
      "epoch": 1.48,
      "grad_norm": 1.5450522899627686,
      "learning_rate": 5.159372758019884e-06,
      "loss": 0.3741,
      "step": 7245
    },
    {
      "epoch": 1.48,
      "grad_norm": 1.0254250764846802,
      "learning_rate": 5.157322947627345e-06,
      "loss": 0.2877,
      "step": 7246
    },
    {
      "epoch": 1.48,
      "grad_norm": 1.2007228136062622,
      "learning_rate": 5.155273137234807e-06,
      "loss": 0.3176,
      "step": 7247
    },
    {
      "epoch": 1.48,
      "grad_norm": 1.005283236503601,
      "learning_rate": 5.153223326842267e-06,
      "loss": 0.4206,
      "step": 7248
    },
    {
      "epoch": 1.49,
      "grad_norm": 1.0431662797927856,
      "learning_rate": 5.151173516449729e-06,
      "loss": 0.396,
      "step": 7249
    },
    {
      "epoch": 1.49,
      "grad_norm": 1.1642388105392456,
      "learning_rate": 5.14912370605719e-06,
      "loss": 0.4121,
      "step": 7250
    },
    {
      "epoch": 1.49,
      "grad_norm": 0.9927949905395508,
      "learning_rate": 5.147073895664652e-06,
      "loss": 0.4461,
      "step": 7251
    },
    {
      "epoch": 1.49,
      "grad_norm": 1.5768452882766724,
      "learning_rate": 5.145024085272113e-06,
      "loss": 0.3244,
      "step": 7252
    },
    {
      "epoch": 1.49,
      "grad_norm": 1.4474796056747437,
      "learning_rate": 5.1429742748795745e-06,
      "loss": 0.4691,
      "step": 7253
    },
    {
      "epoch": 1.49,
      "grad_norm": 1.0474852323532104,
      "learning_rate": 5.140924464487035e-06,
      "loss": 0.337,
      "step": 7254
    },
    {
      "epoch": 1.49,
      "grad_norm": 1.4906905889511108,
      "learning_rate": 5.1388746540944965e-06,
      "loss": 0.3403,
      "step": 7255
    },
    {
      "epoch": 1.49,
      "grad_norm": 1.2232450246810913,
      "learning_rate": 5.1368248437019575e-06,
      "loss": 0.3021,
      "step": 7256
    },
    {
      "epoch": 1.49,
      "grad_norm": 0.9696823954582214,
      "learning_rate": 5.134775033309419e-06,
      "loss": 0.4236,
      "step": 7257
    },
    {
      "epoch": 1.49,
      "grad_norm": 1.234285593032837,
      "learning_rate": 5.132725222916881e-06,
      "loss": 0.3184,
      "step": 7258
    },
    {
      "epoch": 1.49,
      "grad_norm": 1.2412644624710083,
      "learning_rate": 5.130675412524342e-06,
      "loss": 0.4705,
      "step": 7259
    },
    {
      "epoch": 1.49,
      "grad_norm": 1.501510500907898,
      "learning_rate": 5.128625602131804e-06,
      "loss": 0.2762,
      "step": 7260
    },
    {
      "epoch": 1.49,
      "grad_norm": 1.2697229385375977,
      "learning_rate": 5.126575791739264e-06,
      "loss": 0.4483,
      "step": 7261
    },
    {
      "epoch": 1.49,
      "grad_norm": 0.9641067385673523,
      "learning_rate": 5.124525981346726e-06,
      "loss": 0.2893,
      "step": 7262
    },
    {
      "epoch": 1.49,
      "grad_norm": 1.7210843563079834,
      "learning_rate": 5.122476170954187e-06,
      "loss": 0.3145,
      "step": 7263
    },
    {
      "epoch": 1.49,
      "grad_norm": 1.2844830751419067,
      "learning_rate": 5.120426360561649e-06,
      "loss": 0.2765,
      "step": 7264
    },
    {
      "epoch": 1.49,
      "grad_norm": 1.4195646047592163,
      "learning_rate": 5.11837655016911e-06,
      "loss": 0.3124,
      "step": 7265
    },
    {
      "epoch": 1.49,
      "grad_norm": 1.2753262519836426,
      "learning_rate": 5.116326739776572e-06,
      "loss": 0.5885,
      "step": 7266
    },
    {
      "epoch": 1.49,
      "grad_norm": 1.222458839416504,
      "learning_rate": 5.114276929384032e-06,
      "loss": 0.432,
      "step": 7267
    },
    {
      "epoch": 1.49,
      "grad_norm": 1.0471190214157104,
      "learning_rate": 5.112227118991494e-06,
      "loss": 0.5043,
      "step": 7268
    },
    {
      "epoch": 1.49,
      "grad_norm": 1.6016230583190918,
      "learning_rate": 5.110177308598955e-06,
      "loss": 0.4786,
      "step": 7269
    },
    {
      "epoch": 1.49,
      "grad_norm": 1.0137693881988525,
      "learning_rate": 5.108127498206417e-06,
      "loss": 0.2459,
      "step": 7270
    },
    {
      "epoch": 1.49,
      "grad_norm": 1.207597017288208,
      "learning_rate": 5.106077687813878e-06,
      "loss": 0.3525,
      "step": 7271
    },
    {
      "epoch": 1.49,
      "grad_norm": 1.495704174041748,
      "learning_rate": 5.1040278774213396e-06,
      "loss": 0.4681,
      "step": 7272
    },
    {
      "epoch": 1.49,
      "grad_norm": 0.8857563138008118,
      "learning_rate": 5.1019780670288e-06,
      "loss": 0.3981,
      "step": 7273
    },
    {
      "epoch": 1.49,
      "grad_norm": 0.8796441555023193,
      "learning_rate": 5.099928256636262e-06,
      "loss": 0.3292,
      "step": 7274
    },
    {
      "epoch": 1.49,
      "grad_norm": 1.2235721349716187,
      "learning_rate": 5.097878446243723e-06,
      "loss": 0.4863,
      "step": 7275
    },
    {
      "epoch": 1.49,
      "grad_norm": 1.400851845741272,
      "learning_rate": 5.0958286358511845e-06,
      "loss": 0.4275,
      "step": 7276
    },
    {
      "epoch": 1.49,
      "grad_norm": 1.1620330810546875,
      "learning_rate": 5.0937788254586455e-06,
      "loss": 0.4091,
      "step": 7277
    },
    {
      "epoch": 1.49,
      "grad_norm": 1.330994725227356,
      "learning_rate": 5.091729015066107e-06,
      "loss": 0.4838,
      "step": 7278
    },
    {
      "epoch": 1.49,
      "grad_norm": 1.0451005697250366,
      "learning_rate": 5.0896792046735675e-06,
      "loss": 0.2761,
      "step": 7279
    },
    {
      "epoch": 1.49,
      "grad_norm": 1.2119163274765015,
      "learning_rate": 5.087629394281029e-06,
      "loss": 0.5122,
      "step": 7280
    },
    {
      "epoch": 1.49,
      "grad_norm": 1.8860065937042236,
      "learning_rate": 5.08557958388849e-06,
      "loss": 0.3437,
      "step": 7281
    },
    {
      "epoch": 1.49,
      "grad_norm": 1.3007774353027344,
      "learning_rate": 5.083529773495952e-06,
      "loss": 0.3663,
      "step": 7282
    },
    {
      "epoch": 1.49,
      "grad_norm": 0.8565847277641296,
      "learning_rate": 5.081479963103413e-06,
      "loss": 0.2895,
      "step": 7283
    },
    {
      "epoch": 1.49,
      "grad_norm": 1.3230499029159546,
      "learning_rate": 5.079430152710875e-06,
      "loss": 0.2483,
      "step": 7284
    },
    {
      "epoch": 1.49,
      "grad_norm": 1.8092056512832642,
      "learning_rate": 5.077380342318335e-06,
      "loss": 0.2998,
      "step": 7285
    },
    {
      "epoch": 1.49,
      "grad_norm": 1.0540778636932373,
      "learning_rate": 5.075330531925797e-06,
      "loss": 0.3602,
      "step": 7286
    },
    {
      "epoch": 1.49,
      "grad_norm": 1.3642594814300537,
      "learning_rate": 5.073280721533259e-06,
      "loss": 0.494,
      "step": 7287
    },
    {
      "epoch": 1.49,
      "grad_norm": 1.6312217712402344,
      "learning_rate": 5.07123091114072e-06,
      "loss": 0.4323,
      "step": 7288
    },
    {
      "epoch": 1.49,
      "grad_norm": 1.0146212577819824,
      "learning_rate": 5.069181100748182e-06,
      "loss": 0.3441,
      "step": 7289
    },
    {
      "epoch": 1.49,
      "grad_norm": 1.51778244972229,
      "learning_rate": 5.067131290355643e-06,
      "loss": 0.309,
      "step": 7290
    },
    {
      "epoch": 1.49,
      "grad_norm": 1.2164967060089111,
      "learning_rate": 5.065081479963105e-06,
      "loss": 0.5246,
      "step": 7291
    },
    {
      "epoch": 1.49,
      "grad_norm": 0.8215259909629822,
      "learning_rate": 5.063031669570565e-06,
      "loss": 0.3483,
      "step": 7292
    },
    {
      "epoch": 1.49,
      "grad_norm": 2.1225061416625977,
      "learning_rate": 5.060981859178027e-06,
      "loss": 0.3754,
      "step": 7293
    },
    {
      "epoch": 1.49,
      "grad_norm": 0.8361937403678894,
      "learning_rate": 5.058932048785488e-06,
      "loss": 0.3947,
      "step": 7294
    },
    {
      "epoch": 1.49,
      "grad_norm": 1.142573356628418,
      "learning_rate": 5.0568822383929496e-06,
      "loss": 0.2668,
      "step": 7295
    },
    {
      "epoch": 1.49,
      "grad_norm": 1.3329038619995117,
      "learning_rate": 5.0548324280004106e-06,
      "loss": 0.4768,
      "step": 7296
    },
    {
      "epoch": 1.49,
      "grad_norm": 1.5782164335250854,
      "learning_rate": 5.0527826176078724e-06,
      "loss": 0.3132,
      "step": 7297
    },
    {
      "epoch": 1.5,
      "grad_norm": 1.7129756212234497,
      "learning_rate": 5.050732807215333e-06,
      "loss": 0.3745,
      "step": 7298
    },
    {
      "epoch": 1.5,
      "grad_norm": 1.2743897438049316,
      "learning_rate": 5.0486829968227944e-06,
      "loss": 0.4313,
      "step": 7299
    },
    {
      "epoch": 1.5,
      "grad_norm": 0.7977510094642639,
      "learning_rate": 5.0466331864302555e-06,
      "loss": 0.3069,
      "step": 7300
    },
    {
      "epoch": 1.5,
      "grad_norm": 1.8334455490112305,
      "learning_rate": 5.044583376037717e-06,
      "loss": 0.3672,
      "step": 7301
    },
    {
      "epoch": 1.5,
      "grad_norm": 1.0456334352493286,
      "learning_rate": 5.042533565645178e-06,
      "loss": 0.1934,
      "step": 7302
    },
    {
      "epoch": 1.5,
      "grad_norm": 1.135208249092102,
      "learning_rate": 5.04048375525264e-06,
      "loss": 0.2904,
      "step": 7303
    },
    {
      "epoch": 1.5,
      "grad_norm": 1.3946986198425293,
      "learning_rate": 5.0384339448601e-06,
      "loss": 0.3782,
      "step": 7304
    },
    {
      "epoch": 1.5,
      "grad_norm": 0.9448155760765076,
      "learning_rate": 5.036384134467562e-06,
      "loss": 0.1966,
      "step": 7305
    },
    {
      "epoch": 1.5,
      "grad_norm": 1.5107313394546509,
      "learning_rate": 5.034334324075023e-06,
      "loss": 0.4058,
      "step": 7306
    },
    {
      "epoch": 1.5,
      "grad_norm": 1.218504786491394,
      "learning_rate": 5.032284513682485e-06,
      "loss": 0.3064,
      "step": 7307
    },
    {
      "epoch": 1.5,
      "grad_norm": 1.0403146743774414,
      "learning_rate": 5.030234703289946e-06,
      "loss": 0.2662,
      "step": 7308
    },
    {
      "epoch": 1.5,
      "grad_norm": 1.7021327018737793,
      "learning_rate": 5.028184892897408e-06,
      "loss": 0.1822,
      "step": 7309
    },
    {
      "epoch": 1.5,
      "grad_norm": 1.2632721662521362,
      "learning_rate": 5.026135082504868e-06,
      "loss": 0.37,
      "step": 7310
    },
    {
      "epoch": 1.5,
      "grad_norm": 1.5308024883270264,
      "learning_rate": 5.02408527211233e-06,
      "loss": 0.4334,
      "step": 7311
    },
    {
      "epoch": 1.5,
      "grad_norm": 2.52295184135437,
      "learning_rate": 5.022035461719791e-06,
      "loss": 0.3539,
      "step": 7312
    },
    {
      "epoch": 1.5,
      "grad_norm": 1.173279047012329,
      "learning_rate": 5.019985651327253e-06,
      "loss": 0.2806,
      "step": 7313
    },
    {
      "epoch": 1.5,
      "grad_norm": 1.2558584213256836,
      "learning_rate": 5.017935840934714e-06,
      "loss": 0.2605,
      "step": 7314
    },
    {
      "epoch": 1.5,
      "grad_norm": 1.4170401096343994,
      "learning_rate": 5.015886030542176e-06,
      "loss": 0.3748,
      "step": 7315
    },
    {
      "epoch": 1.5,
      "grad_norm": 2.11922025680542,
      "learning_rate": 5.013836220149637e-06,
      "loss": 0.4237,
      "step": 7316
    },
    {
      "epoch": 1.5,
      "grad_norm": 1.192183256149292,
      "learning_rate": 5.011786409757098e-06,
      "loss": 0.4328,
      "step": 7317
    },
    {
      "epoch": 1.5,
      "grad_norm": 1.861230731010437,
      "learning_rate": 5.0097365993645596e-06,
      "loss": 0.459,
      "step": 7318
    },
    {
      "epoch": 1.5,
      "grad_norm": 1.7975587844848633,
      "learning_rate": 5.0076867889720206e-06,
      "loss": 0.345,
      "step": 7319
    },
    {
      "epoch": 1.5,
      "grad_norm": 2.6363980770111084,
      "learning_rate": 5.005636978579482e-06,
      "loss": 0.3796,
      "step": 7320
    },
    {
      "epoch": 1.5,
      "grad_norm": 1.192628026008606,
      "learning_rate": 5.0035871681869434e-06,
      "loss": 0.3024,
      "step": 7321
    },
    {
      "epoch": 1.5,
      "grad_norm": 0.8014398217201233,
      "learning_rate": 5.0015373577944044e-06,
      "loss": 0.4242,
      "step": 7322
    },
    {
      "epoch": 1.5,
      "grad_norm": 3.16338849067688,
      "learning_rate": 4.9994875474018654e-06,
      "loss": 0.3915,
      "step": 7323
    },
    {
      "epoch": 1.5,
      "grad_norm": 1.602475643157959,
      "learning_rate": 4.997437737009327e-06,
      "loss": 0.202,
      "step": 7324
    },
    {
      "epoch": 1.5,
      "grad_norm": 2.7232229709625244,
      "learning_rate": 4.995387926616788e-06,
      "loss": 0.3107,
      "step": 7325
    },
    {
      "epoch": 1.5,
      "grad_norm": 1.448046088218689,
      "learning_rate": 4.993338116224249e-06,
      "loss": 0.3704,
      "step": 7326
    },
    {
      "epoch": 1.5,
      "grad_norm": 1.485772967338562,
      "learning_rate": 4.99128830583171e-06,
      "loss": 0.3176,
      "step": 7327
    },
    {
      "epoch": 1.5,
      "grad_norm": 1.6311259269714355,
      "learning_rate": 4.989238495439172e-06,
      "loss": 0.3365,
      "step": 7328
    },
    {
      "epoch": 1.5,
      "grad_norm": 3.692195177078247,
      "learning_rate": 4.987188685046633e-06,
      "loss": 0.375,
      "step": 7329
    },
    {
      "epoch": 1.5,
      "grad_norm": 1.559144377708435,
      "learning_rate": 4.985138874654094e-06,
      "loss": 0.3409,
      "step": 7330
    },
    {
      "epoch": 1.5,
      "grad_norm": 0.9084171652793884,
      "learning_rate": 4.983089064261556e-06,
      "loss": 0.3732,
      "step": 7331
    },
    {
      "epoch": 1.5,
      "grad_norm": 2.2138538360595703,
      "learning_rate": 4.981039253869018e-06,
      "loss": 0.3425,
      "step": 7332
    },
    {
      "epoch": 1.5,
      "grad_norm": 0.7711020708084106,
      "learning_rate": 4.978989443476479e-06,
      "loss": 0.2914,
      "step": 7333
    },
    {
      "epoch": 1.5,
      "grad_norm": 1.1799958944320679,
      "learning_rate": 4.97693963308394e-06,
      "loss": 0.3171,
      "step": 7334
    },
    {
      "epoch": 1.5,
      "grad_norm": 2.080385208129883,
      "learning_rate": 4.974889822691402e-06,
      "loss": 0.3211,
      "step": 7335
    },
    {
      "epoch": 1.5,
      "grad_norm": 0.8754144310951233,
      "learning_rate": 4.972840012298863e-06,
      "loss": 0.3553,
      "step": 7336
    },
    {
      "epoch": 1.5,
      "grad_norm": 1.5261211395263672,
      "learning_rate": 4.970790201906324e-06,
      "loss": 0.4164,
      "step": 7337
    },
    {
      "epoch": 1.5,
      "grad_norm": 1.1356546878814697,
      "learning_rate": 4.968740391513786e-06,
      "loss": 0.2862,
      "step": 7338
    },
    {
      "epoch": 1.5,
      "grad_norm": 1.3834199905395508,
      "learning_rate": 4.966690581121247e-06,
      "loss": 0.2796,
      "step": 7339
    },
    {
      "epoch": 1.5,
      "grad_norm": 0.8883135318756104,
      "learning_rate": 4.964640770728708e-06,
      "loss": 0.2069,
      "step": 7340
    },
    {
      "epoch": 1.5,
      "grad_norm": 1.2090277671813965,
      "learning_rate": 4.9625909603361695e-06,
      "loss": 0.3669,
      "step": 7341
    },
    {
      "epoch": 1.5,
      "grad_norm": 1.1685203313827515,
      "learning_rate": 4.9605411499436306e-06,
      "loss": 0.2802,
      "step": 7342
    },
    {
      "epoch": 1.5,
      "grad_norm": 1.1624109745025635,
      "learning_rate": 4.9584913395510916e-06,
      "loss": 0.1821,
      "step": 7343
    },
    {
      "epoch": 1.5,
      "grad_norm": 0.6275664567947388,
      "learning_rate": 4.956441529158553e-06,
      "loss": 0.2698,
      "step": 7344
    },
    {
      "epoch": 1.5,
      "grad_norm": 0.9965196251869202,
      "learning_rate": 4.9543917187660144e-06,
      "loss": 0.3111,
      "step": 7345
    },
    {
      "epoch": 1.51,
      "grad_norm": 0.9855764508247375,
      "learning_rate": 4.9523419083734754e-06,
      "loss": 0.2716,
      "step": 7346
    },
    {
      "epoch": 1.51,
      "grad_norm": 1.3927881717681885,
      "learning_rate": 4.950292097980937e-06,
      "loss": 0.3363,
      "step": 7347
    },
    {
      "epoch": 1.51,
      "grad_norm": 1.268241286277771,
      "learning_rate": 4.948242287588398e-06,
      "loss": 0.3199,
      "step": 7348
    },
    {
      "epoch": 1.51,
      "grad_norm": 1.4210201501846313,
      "learning_rate": 4.946192477195859e-06,
      "loss": 0.2962,
      "step": 7349
    },
    {
      "epoch": 1.51,
      "grad_norm": 1.4597492218017578,
      "learning_rate": 4.944142666803321e-06,
      "loss": 0.4041,
      "step": 7350
    },
    {
      "epoch": 1.51,
      "grad_norm": 0.955897331237793,
      "learning_rate": 4.942092856410782e-06,
      "loss": 0.1924,
      "step": 7351
    },
    {
      "epoch": 1.51,
      "grad_norm": 1.1089972257614136,
      "learning_rate": 4.940043046018243e-06,
      "loss": 0.3457,
      "step": 7352
    },
    {
      "epoch": 1.51,
      "grad_norm": 1.4737458229064941,
      "learning_rate": 4.937993235625705e-06,
      "loss": 0.2605,
      "step": 7353
    },
    {
      "epoch": 1.51,
      "grad_norm": 1.1518131494522095,
      "learning_rate": 4.935943425233166e-06,
      "loss": 0.3926,
      "step": 7354
    },
    {
      "epoch": 1.51,
      "grad_norm": 2.520055055618286,
      "learning_rate": 4.933893614840627e-06,
      "loss": 0.3148,
      "step": 7355
    },
    {
      "epoch": 1.51,
      "grad_norm": 1.8067905902862549,
      "learning_rate": 4.931843804448089e-06,
      "loss": 0.4762,
      "step": 7356
    },
    {
      "epoch": 1.51,
      "grad_norm": 1.3184311389923096,
      "learning_rate": 4.92979399405555e-06,
      "loss": 0.2001,
      "step": 7357
    },
    {
      "epoch": 1.51,
      "grad_norm": 0.8841206431388855,
      "learning_rate": 4.927744183663011e-06,
      "loss": 0.3004,
      "step": 7358
    },
    {
      "epoch": 1.51,
      "grad_norm": 1.0050382614135742,
      "learning_rate": 4.925694373270473e-06,
      "loss": 0.3434,
      "step": 7359
    },
    {
      "epoch": 1.51,
      "grad_norm": 0.8588247299194336,
      "learning_rate": 4.923644562877935e-06,
      "loss": 0.2155,
      "step": 7360
    },
    {
      "epoch": 1.51,
      "grad_norm": 1.3721736669540405,
      "learning_rate": 4.921594752485396e-06,
      "loss": 0.2803,
      "step": 7361
    },
    {
      "epoch": 1.51,
      "grad_norm": 1.0564160346984863,
      "learning_rate": 4.919544942092857e-06,
      "loss": 0.343,
      "step": 7362
    },
    {
      "epoch": 1.51,
      "grad_norm": 1.2037298679351807,
      "learning_rate": 4.9174951317003185e-06,
      "loss": 0.5405,
      "step": 7363
    },
    {
      "epoch": 1.51,
      "grad_norm": 0.714016854763031,
      "learning_rate": 4.9154453213077795e-06,
      "loss": 0.1658,
      "step": 7364
    },
    {
      "epoch": 1.51,
      "grad_norm": 1.7207962274551392,
      "learning_rate": 4.9133955109152405e-06,
      "loss": 0.3963,
      "step": 7365
    },
    {
      "epoch": 1.51,
      "grad_norm": 1.2121031284332275,
      "learning_rate": 4.911345700522702e-06,
      "loss": 0.2339,
      "step": 7366
    },
    {
      "epoch": 1.51,
      "grad_norm": 2.9381508827209473,
      "learning_rate": 4.909295890130163e-06,
      "loss": 0.3128,
      "step": 7367
    },
    {
      "epoch": 1.51,
      "grad_norm": 0.7673419713973999,
      "learning_rate": 4.9072460797376244e-06,
      "loss": 0.2982,
      "step": 7368
    },
    {
      "epoch": 1.51,
      "grad_norm": 1.4588675498962402,
      "learning_rate": 4.905196269345086e-06,
      "loss": 0.4118,
      "step": 7369
    },
    {
      "epoch": 1.51,
      "grad_norm": 1.045161247253418,
      "learning_rate": 4.903146458952547e-06,
      "loss": 0.382,
      "step": 7370
    },
    {
      "epoch": 1.51,
      "grad_norm": 0.9117961525917053,
      "learning_rate": 4.901096648560008e-06,
      "loss": 0.3473,
      "step": 7371
    },
    {
      "epoch": 1.51,
      "grad_norm": 1.834240436553955,
      "learning_rate": 4.89904683816747e-06,
      "loss": 0.3873,
      "step": 7372
    },
    {
      "epoch": 1.51,
      "grad_norm": 1.5132877826690674,
      "learning_rate": 4.896997027774931e-06,
      "loss": 0.398,
      "step": 7373
    },
    {
      "epoch": 1.51,
      "grad_norm": 1.1911004781723022,
      "learning_rate": 4.894947217382392e-06,
      "loss": 0.2297,
      "step": 7374
    },
    {
      "epoch": 1.51,
      "grad_norm": 3.838472604751587,
      "learning_rate": 4.892897406989854e-06,
      "loss": 0.3333,
      "step": 7375
    },
    {
      "epoch": 1.51,
      "grad_norm": 2.5185446739196777,
      "learning_rate": 4.890847596597315e-06,
      "loss": 0.294,
      "step": 7376
    },
    {
      "epoch": 1.51,
      "grad_norm": 1.4041404724121094,
      "learning_rate": 4.888797786204776e-06,
      "loss": 0.4239,
      "step": 7377
    },
    {
      "epoch": 1.51,
      "grad_norm": 1.1419378519058228,
      "learning_rate": 4.886747975812238e-06,
      "loss": 0.3521,
      "step": 7378
    },
    {
      "epoch": 1.51,
      "grad_norm": 3.304853677749634,
      "learning_rate": 4.884698165419699e-06,
      "loss": 0.3163,
      "step": 7379
    },
    {
      "epoch": 1.51,
      "grad_norm": 1.5417940616607666,
      "learning_rate": 4.88264835502716e-06,
      "loss": 0.3891,
      "step": 7380
    },
    {
      "epoch": 1.51,
      "grad_norm": 2.2033517360687256,
      "learning_rate": 4.880598544634622e-06,
      "loss": 0.4592,
      "step": 7381
    },
    {
      "epoch": 1.51,
      "grad_norm": 1.085232138633728,
      "learning_rate": 4.878548734242083e-06,
      "loss": 0.3944,
      "step": 7382
    },
    {
      "epoch": 1.51,
      "grad_norm": 1.8268442153930664,
      "learning_rate": 4.876498923849544e-06,
      "loss": 0.3008,
      "step": 7383
    },
    {
      "epoch": 1.51,
      "grad_norm": 2.558548927307129,
      "learning_rate": 4.874449113457006e-06,
      "loss": 0.4383,
      "step": 7384
    },
    {
      "epoch": 1.51,
      "grad_norm": 2.6724517345428467,
      "learning_rate": 4.872399303064467e-06,
      "loss": 0.3358,
      "step": 7385
    },
    {
      "epoch": 1.51,
      "grad_norm": 1.0624747276306152,
      "learning_rate": 4.870349492671928e-06,
      "loss": 0.3389,
      "step": 7386
    },
    {
      "epoch": 1.51,
      "grad_norm": 1.4349745512008667,
      "learning_rate": 4.8682996822793895e-06,
      "loss": 0.3613,
      "step": 7387
    },
    {
      "epoch": 1.51,
      "grad_norm": 3.392887830734253,
      "learning_rate": 4.8662498718868505e-06,
      "loss": 0.1776,
      "step": 7388
    },
    {
      "epoch": 1.51,
      "grad_norm": 1.6580952405929565,
      "learning_rate": 4.8642000614943116e-06,
      "loss": 0.398,
      "step": 7389
    },
    {
      "epoch": 1.51,
      "grad_norm": 1.4133896827697754,
      "learning_rate": 4.862150251101773e-06,
      "loss": 0.394,
      "step": 7390
    },
    {
      "epoch": 1.51,
      "grad_norm": 1.293019413948059,
      "learning_rate": 4.860100440709235e-06,
      "loss": 0.4112,
      "step": 7391
    },
    {
      "epoch": 1.51,
      "grad_norm": 3.110401153564453,
      "learning_rate": 4.858050630316696e-06,
      "loss": 0.4987,
      "step": 7392
    },
    {
      "epoch": 1.51,
      "grad_norm": 1.4358506202697754,
      "learning_rate": 4.856000819924157e-06,
      "loss": 0.3293,
      "step": 7393
    },
    {
      "epoch": 1.51,
      "grad_norm": 2.1415438652038574,
      "learning_rate": 4.853951009531619e-06,
      "loss": 0.4019,
      "step": 7394
    },
    {
      "epoch": 1.52,
      "grad_norm": 1.0312713384628296,
      "learning_rate": 4.85190119913908e-06,
      "loss": 0.3472,
      "step": 7395
    },
    {
      "epoch": 1.52,
      "grad_norm": 1.4315882921218872,
      "learning_rate": 4.849851388746541e-06,
      "loss": 0.4208,
      "step": 7396
    },
    {
      "epoch": 1.52,
      "grad_norm": 1.7407091856002808,
      "learning_rate": 4.847801578354003e-06,
      "loss": 0.3474,
      "step": 7397
    },
    {
      "epoch": 1.52,
      "grad_norm": 1.280838131904602,
      "learning_rate": 4.845751767961464e-06,
      "loss": 0.2652,
      "step": 7398
    },
    {
      "epoch": 1.52,
      "grad_norm": 1.0409858226776123,
      "learning_rate": 4.843701957568925e-06,
      "loss": 0.3398,
      "step": 7399
    },
    {
      "epoch": 1.52,
      "grad_norm": 1.4260525703430176,
      "learning_rate": 4.841652147176387e-06,
      "loss": 0.4695,
      "step": 7400
    },
    {
      "epoch": 1.52,
      "grad_norm": 1.9501144886016846,
      "learning_rate": 4.839602336783848e-06,
      "loss": 0.3984,
      "step": 7401
    },
    {
      "epoch": 1.52,
      "grad_norm": 2.5254244804382324,
      "learning_rate": 4.837552526391309e-06,
      "loss": 0.3372,
      "step": 7402
    },
    {
      "epoch": 1.52,
      "grad_norm": 1.6304912567138672,
      "learning_rate": 4.835502715998771e-06,
      "loss": 0.3384,
      "step": 7403
    },
    {
      "epoch": 1.52,
      "grad_norm": 1.3727375268936157,
      "learning_rate": 4.833452905606232e-06,
      "loss": 0.3292,
      "step": 7404
    },
    {
      "epoch": 1.52,
      "grad_norm": 1.0351065397262573,
      "learning_rate": 4.831403095213693e-06,
      "loss": 0.3044,
      "step": 7405
    },
    {
      "epoch": 1.52,
      "grad_norm": 1.0753384828567505,
      "learning_rate": 4.829353284821155e-06,
      "loss": 0.2799,
      "step": 7406
    },
    {
      "epoch": 1.52,
      "grad_norm": 1.2039939165115356,
      "learning_rate": 4.827303474428616e-06,
      "loss": 0.1761,
      "step": 7407
    },
    {
      "epoch": 1.52,
      "grad_norm": 1.8079050779342651,
      "learning_rate": 4.825253664036077e-06,
      "loss": 0.3072,
      "step": 7408
    },
    {
      "epoch": 1.52,
      "grad_norm": 1.5605610609054565,
      "learning_rate": 4.8232038536435385e-06,
      "loss": 0.4462,
      "step": 7409
    },
    {
      "epoch": 1.52,
      "grad_norm": 0.9632338285446167,
      "learning_rate": 4.8211540432509995e-06,
      "loss": 0.3091,
      "step": 7410
    },
    {
      "epoch": 1.52,
      "grad_norm": 1.7595434188842773,
      "learning_rate": 4.8191042328584605e-06,
      "loss": 0.4188,
      "step": 7411
    },
    {
      "epoch": 1.52,
      "grad_norm": 1.17262864112854,
      "learning_rate": 4.817054422465922e-06,
      "loss": 0.3009,
      "step": 7412
    },
    {
      "epoch": 1.52,
      "grad_norm": 1.8320797681808472,
      "learning_rate": 4.815004612073383e-06,
      "loss": 0.4037,
      "step": 7413
    },
    {
      "epoch": 1.52,
      "grad_norm": 1.0832329988479614,
      "learning_rate": 4.812954801680844e-06,
      "loss": 0.2628,
      "step": 7414
    },
    {
      "epoch": 1.52,
      "grad_norm": 1.3421143293380737,
      "learning_rate": 4.810904991288306e-06,
      "loss": 0.332,
      "step": 7415
    },
    {
      "epoch": 1.52,
      "grad_norm": 1.3942153453826904,
      "learning_rate": 4.808855180895767e-06,
      "loss": 0.4896,
      "step": 7416
    },
    {
      "epoch": 1.52,
      "grad_norm": 0.9591146111488342,
      "learning_rate": 4.806805370503228e-06,
      "loss": 0.5097,
      "step": 7417
    },
    {
      "epoch": 1.52,
      "grad_norm": 1.3443129062652588,
      "learning_rate": 4.80475556011069e-06,
      "loss": 0.34,
      "step": 7418
    },
    {
      "epoch": 1.52,
      "grad_norm": 0.8793331384658813,
      "learning_rate": 4.802705749718152e-06,
      "loss": 0.4506,
      "step": 7419
    },
    {
      "epoch": 1.52,
      "grad_norm": 1.0629652738571167,
      "learning_rate": 4.800655939325613e-06,
      "loss": 0.2672,
      "step": 7420
    },
    {
      "epoch": 1.52,
      "grad_norm": 1.4083433151245117,
      "learning_rate": 4.798606128933074e-06,
      "loss": 0.3338,
      "step": 7421
    },
    {
      "epoch": 1.52,
      "grad_norm": 1.1275238990783691,
      "learning_rate": 4.796556318540536e-06,
      "loss": 0.3273,
      "step": 7422
    },
    {
      "epoch": 1.52,
      "grad_norm": 2.2740790843963623,
      "learning_rate": 4.794506508147997e-06,
      "loss": 0.3564,
      "step": 7423
    },
    {
      "epoch": 1.52,
      "grad_norm": 1.5324794054031372,
      "learning_rate": 4.792456697755458e-06,
      "loss": 0.2606,
      "step": 7424
    },
    {
      "epoch": 1.52,
      "grad_norm": 1.9015460014343262,
      "learning_rate": 4.79040688736292e-06,
      "loss": 0.2992,
      "step": 7425
    },
    {
      "epoch": 1.52,
      "grad_norm": 1.0076110363006592,
      "learning_rate": 4.788357076970381e-06,
      "loss": 0.3264,
      "step": 7426
    },
    {
      "epoch": 1.52,
      "grad_norm": 1.4387140274047852,
      "learning_rate": 4.786307266577842e-06,
      "loss": 0.365,
      "step": 7427
    },
    {
      "epoch": 1.52,
      "grad_norm": 1.9551939964294434,
      "learning_rate": 4.784257456185304e-06,
      "loss": 0.2559,
      "step": 7428
    },
    {
      "epoch": 1.52,
      "grad_norm": 1.5747934579849243,
      "learning_rate": 4.782207645792765e-06,
      "loss": 0.4,
      "step": 7429
    },
    {
      "epoch": 1.52,
      "grad_norm": 0.9827354550361633,
      "learning_rate": 4.780157835400226e-06,
      "loss": 0.2637,
      "step": 7430
    },
    {
      "epoch": 1.52,
      "grad_norm": 1.3122198581695557,
      "learning_rate": 4.7781080250076875e-06,
      "loss": 0.2483,
      "step": 7431
    },
    {
      "epoch": 1.52,
      "grad_norm": 1.9625136852264404,
      "learning_rate": 4.7760582146151485e-06,
      "loss": 0.3139,
      "step": 7432
    },
    {
      "epoch": 1.52,
      "grad_norm": 1.081998348236084,
      "learning_rate": 4.7740084042226095e-06,
      "loss": 0.3321,
      "step": 7433
    },
    {
      "epoch": 1.52,
      "grad_norm": 1.3215199708938599,
      "learning_rate": 4.771958593830071e-06,
      "loss": 0.2741,
      "step": 7434
    },
    {
      "epoch": 1.52,
      "grad_norm": 0.9328983426094055,
      "learning_rate": 4.769908783437532e-06,
      "loss": 0.2376,
      "step": 7435
    },
    {
      "epoch": 1.52,
      "grad_norm": 1.1583794355392456,
      "learning_rate": 4.767858973044993e-06,
      "loss": 0.2941,
      "step": 7436
    },
    {
      "epoch": 1.52,
      "grad_norm": 1.2623213529586792,
      "learning_rate": 4.765809162652455e-06,
      "loss": 0.355,
      "step": 7437
    },
    {
      "epoch": 1.52,
      "grad_norm": 1.5232300758361816,
      "learning_rate": 4.763759352259916e-06,
      "loss": 0.3793,
      "step": 7438
    },
    {
      "epoch": 1.52,
      "grad_norm": 1.1765038967132568,
      "learning_rate": 4.761709541867377e-06,
      "loss": 0.4336,
      "step": 7439
    },
    {
      "epoch": 1.52,
      "grad_norm": 1.6609944105148315,
      "learning_rate": 4.759659731474839e-06,
      "loss": 0.4664,
      "step": 7440
    },
    {
      "epoch": 1.52,
      "grad_norm": 0.8725451827049255,
      "learning_rate": 4.7576099210823e-06,
      "loss": 0.2616,
      "step": 7441
    },
    {
      "epoch": 1.52,
      "grad_norm": 1.3130583763122559,
      "learning_rate": 4.755560110689761e-06,
      "loss": 0.2621,
      "step": 7442
    },
    {
      "epoch": 1.52,
      "grad_norm": 1.2254717350006104,
      "learning_rate": 4.753510300297223e-06,
      "loss": 0.3773,
      "step": 7443
    },
    {
      "epoch": 1.53,
      "grad_norm": 1.2600574493408203,
      "learning_rate": 4.751460489904684e-06,
      "loss": 0.3913,
      "step": 7444
    },
    {
      "epoch": 1.53,
      "grad_norm": 0.8468311429023743,
      "learning_rate": 4.749410679512145e-06,
      "loss": 0.2145,
      "step": 7445
    },
    {
      "epoch": 1.53,
      "grad_norm": 0.9531253576278687,
      "learning_rate": 4.747360869119607e-06,
      "loss": 0.2565,
      "step": 7446
    },
    {
      "epoch": 1.53,
      "grad_norm": 1.4598335027694702,
      "learning_rate": 4.745311058727068e-06,
      "loss": 0.3695,
      "step": 7447
    },
    {
      "epoch": 1.53,
      "grad_norm": 1.3693541288375854,
      "learning_rate": 4.743261248334529e-06,
      "loss": 0.3761,
      "step": 7448
    },
    {
      "epoch": 1.53,
      "grad_norm": 1.3201408386230469,
      "learning_rate": 4.741211437941991e-06,
      "loss": 0.3361,
      "step": 7449
    },
    {
      "epoch": 1.53,
      "grad_norm": 2.3842365741729736,
      "learning_rate": 4.739161627549453e-06,
      "loss": 0.4137,
      "step": 7450
    },
    {
      "epoch": 1.53,
      "grad_norm": 1.8277097940444946,
      "learning_rate": 4.737111817156914e-06,
      "loss": 0.4117,
      "step": 7451
    },
    {
      "epoch": 1.53,
      "grad_norm": 1.0942585468292236,
      "learning_rate": 4.735062006764375e-06,
      "loss": 0.4381,
      "step": 7452
    },
    {
      "epoch": 1.53,
      "grad_norm": 0.8073745965957642,
      "learning_rate": 4.7330121963718365e-06,
      "loss": 0.3895,
      "step": 7453
    },
    {
      "epoch": 1.53,
      "grad_norm": 1.6062477827072144,
      "learning_rate": 4.7309623859792975e-06,
      "loss": 0.3472,
      "step": 7454
    },
    {
      "epoch": 1.53,
      "grad_norm": 0.9597843885421753,
      "learning_rate": 4.7289125755867585e-06,
      "loss": 0.2695,
      "step": 7455
    },
    {
      "epoch": 1.53,
      "grad_norm": 0.9922845959663391,
      "learning_rate": 4.72686276519422e-06,
      "loss": 0.3952,
      "step": 7456
    },
    {
      "epoch": 1.53,
      "grad_norm": 0.9910966157913208,
      "learning_rate": 4.724812954801681e-06,
      "loss": 0.3698,
      "step": 7457
    },
    {
      "epoch": 1.53,
      "grad_norm": 1.097157597541809,
      "learning_rate": 4.722763144409142e-06,
      "loss": 0.2616,
      "step": 7458
    },
    {
      "epoch": 1.53,
      "grad_norm": 1.1747252941131592,
      "learning_rate": 4.720713334016604e-06,
      "loss": 0.333,
      "step": 7459
    },
    {
      "epoch": 1.53,
      "grad_norm": 1.528475046157837,
      "learning_rate": 4.718663523624065e-06,
      "loss": 0.3298,
      "step": 7460
    },
    {
      "epoch": 1.53,
      "grad_norm": 1.463379144668579,
      "learning_rate": 4.716613713231526e-06,
      "loss": 0.2952,
      "step": 7461
    },
    {
      "epoch": 1.53,
      "grad_norm": 1.4036166667938232,
      "learning_rate": 4.714563902838988e-06,
      "loss": 0.395,
      "step": 7462
    },
    {
      "epoch": 1.53,
      "grad_norm": 1.1291465759277344,
      "learning_rate": 4.712514092446449e-06,
      "loss": 0.2497,
      "step": 7463
    },
    {
      "epoch": 1.53,
      "grad_norm": 1.3030869960784912,
      "learning_rate": 4.71046428205391e-06,
      "loss": 0.4586,
      "step": 7464
    },
    {
      "epoch": 1.53,
      "grad_norm": 1.4462456703186035,
      "learning_rate": 4.708414471661372e-06,
      "loss": 0.2667,
      "step": 7465
    },
    {
      "epoch": 1.53,
      "grad_norm": 1.250645399093628,
      "learning_rate": 4.706364661268833e-06,
      "loss": 0.4043,
      "step": 7466
    },
    {
      "epoch": 1.53,
      "grad_norm": 1.190704345703125,
      "learning_rate": 4.704314850876294e-06,
      "loss": 0.3552,
      "step": 7467
    },
    {
      "epoch": 1.53,
      "grad_norm": 1.250732421875,
      "learning_rate": 4.702265040483756e-06,
      "loss": 0.2726,
      "step": 7468
    },
    {
      "epoch": 1.53,
      "grad_norm": 1.113921046257019,
      "learning_rate": 4.700215230091217e-06,
      "loss": 0.3531,
      "step": 7469
    },
    {
      "epoch": 1.53,
      "grad_norm": 1.17256498336792,
      "learning_rate": 4.698165419698678e-06,
      "loss": 0.3487,
      "step": 7470
    },
    {
      "epoch": 1.53,
      "grad_norm": 1.582257866859436,
      "learning_rate": 4.69611560930614e-06,
      "loss": 0.2574,
      "step": 7471
    },
    {
      "epoch": 1.53,
      "grad_norm": 1.3677462339401245,
      "learning_rate": 4.694065798913601e-06,
      "loss": 0.3018,
      "step": 7472
    },
    {
      "epoch": 1.53,
      "grad_norm": 1.145552158355713,
      "learning_rate": 4.692015988521062e-06,
      "loss": 0.268,
      "step": 7473
    },
    {
      "epoch": 1.53,
      "grad_norm": 1.0018573999404907,
      "learning_rate": 4.689966178128524e-06,
      "loss": 0.3043,
      "step": 7474
    },
    {
      "epoch": 1.53,
      "grad_norm": 2.504378318786621,
      "learning_rate": 4.687916367735985e-06,
      "loss": 0.426,
      "step": 7475
    },
    {
      "epoch": 1.53,
      "grad_norm": 1.7062188386917114,
      "learning_rate": 4.685866557343446e-06,
      "loss": 0.4364,
      "step": 7476
    },
    {
      "epoch": 1.53,
      "grad_norm": 1.0716335773468018,
      "learning_rate": 4.6838167469509075e-06,
      "loss": 0.3565,
      "step": 7477
    },
    {
      "epoch": 1.53,
      "grad_norm": 1.779760479927063,
      "learning_rate": 4.681766936558369e-06,
      "loss": 0.4509,
      "step": 7478
    },
    {
      "epoch": 1.53,
      "grad_norm": 1.8978331089019775,
      "learning_rate": 4.67971712616583e-06,
      "loss": 0.3883,
      "step": 7479
    },
    {
      "epoch": 1.53,
      "grad_norm": 0.8861845135688782,
      "learning_rate": 4.677667315773291e-06,
      "loss": 0.4203,
      "step": 7480
    },
    {
      "epoch": 1.53,
      "grad_norm": 1.1494213342666626,
      "learning_rate": 4.675617505380753e-06,
      "loss": 0.3254,
      "step": 7481
    },
    {
      "epoch": 1.53,
      "grad_norm": 1.3530269861221313,
      "learning_rate": 4.673567694988214e-06,
      "loss": 0.2784,
      "step": 7482
    },
    {
      "epoch": 1.53,
      "grad_norm": 1.8842060565948486,
      "learning_rate": 4.671517884595675e-06,
      "loss": 0.4218,
      "step": 7483
    },
    {
      "epoch": 1.53,
      "grad_norm": 0.7502882480621338,
      "learning_rate": 4.669468074203137e-06,
      "loss": 0.2678,
      "step": 7484
    },
    {
      "epoch": 1.53,
      "grad_norm": 1.2920517921447754,
      "learning_rate": 4.667418263810598e-06,
      "loss": 0.4929,
      "step": 7485
    },
    {
      "epoch": 1.53,
      "grad_norm": 0.9164187908172607,
      "learning_rate": 4.665368453418059e-06,
      "loss": 0.3807,
      "step": 7486
    },
    {
      "epoch": 1.53,
      "grad_norm": 0.9599522948265076,
      "learning_rate": 4.663318643025521e-06,
      "loss": 0.488,
      "step": 7487
    },
    {
      "epoch": 1.53,
      "grad_norm": 1.2325350046157837,
      "learning_rate": 4.661268832632982e-06,
      "loss": 0.4024,
      "step": 7488
    },
    {
      "epoch": 1.53,
      "grad_norm": 1.634482979774475,
      "learning_rate": 4.659219022240443e-06,
      "loss": 0.3919,
      "step": 7489
    },
    {
      "epoch": 1.53,
      "grad_norm": 1.646963357925415,
      "learning_rate": 4.657169211847905e-06,
      "loss": 0.4013,
      "step": 7490
    },
    {
      "epoch": 1.53,
      "grad_norm": 1.5185469388961792,
      "learning_rate": 4.655119401455366e-06,
      "loss": 0.2858,
      "step": 7491
    },
    {
      "epoch": 1.53,
      "grad_norm": 1.2279071807861328,
      "learning_rate": 4.653069591062827e-06,
      "loss": 0.3365,
      "step": 7492
    },
    {
      "epoch": 1.54,
      "grad_norm": 1.107545018196106,
      "learning_rate": 4.651019780670289e-06,
      "loss": 0.3904,
      "step": 7493
    },
    {
      "epoch": 1.54,
      "grad_norm": 1.3178184032440186,
      "learning_rate": 4.64896997027775e-06,
      "loss": 0.3631,
      "step": 7494
    },
    {
      "epoch": 1.54,
      "grad_norm": 1.4572774171829224,
      "learning_rate": 4.646920159885211e-06,
      "loss": 0.23,
      "step": 7495
    },
    {
      "epoch": 1.54,
      "grad_norm": 0.9941035509109497,
      "learning_rate": 4.644870349492673e-06,
      "loss": 0.2793,
      "step": 7496
    },
    {
      "epoch": 1.54,
      "grad_norm": 0.7937902212142944,
      "learning_rate": 4.642820539100134e-06,
      "loss": 0.2729,
      "step": 7497
    },
    {
      "epoch": 1.54,
      "grad_norm": 1.238213300704956,
      "learning_rate": 4.640770728707595e-06,
      "loss": 0.3983,
      "step": 7498
    },
    {
      "epoch": 1.54,
      "grad_norm": 1.249488115310669,
      "learning_rate": 4.6387209183150565e-06,
      "loss": 0.4585,
      "step": 7499
    },
    {
      "epoch": 1.54,
      "grad_norm": 1.296255350112915,
      "learning_rate": 4.6366711079225175e-06,
      "loss": 0.3159,
      "step": 7500
    },
    {
      "epoch": 1.54,
      "grad_norm": 0.7258192896842957,
      "learning_rate": 4.6346212975299785e-06,
      "loss": 0.1584,
      "step": 7501
    },
    {
      "epoch": 1.54,
      "grad_norm": 1.57308828830719,
      "learning_rate": 4.63257148713744e-06,
      "loss": 0.4223,
      "step": 7502
    },
    {
      "epoch": 1.54,
      "grad_norm": 2.4910292625427246,
      "learning_rate": 4.630521676744901e-06,
      "loss": 0.4858,
      "step": 7503
    },
    {
      "epoch": 1.54,
      "grad_norm": 1.3749021291732788,
      "learning_rate": 4.628471866352362e-06,
      "loss": 0.411,
      "step": 7504
    },
    {
      "epoch": 1.54,
      "grad_norm": 0.885565459728241,
      "learning_rate": 4.626422055959824e-06,
      "loss": 0.2659,
      "step": 7505
    },
    {
      "epoch": 1.54,
      "grad_norm": 1.0572714805603027,
      "learning_rate": 4.624372245567285e-06,
      "loss": 0.338,
      "step": 7506
    },
    {
      "epoch": 1.54,
      "grad_norm": 1.3327950239181519,
      "learning_rate": 4.622322435174747e-06,
      "loss": 0.312,
      "step": 7507
    },
    {
      "epoch": 1.54,
      "grad_norm": 1.0506740808486938,
      "learning_rate": 4.620272624782208e-06,
      "loss": 0.3708,
      "step": 7508
    },
    {
      "epoch": 1.54,
      "grad_norm": 1.1508241891860962,
      "learning_rate": 4.61822281438967e-06,
      "loss": 0.2453,
      "step": 7509
    },
    {
      "epoch": 1.54,
      "grad_norm": 1.7897095680236816,
      "learning_rate": 4.616173003997131e-06,
      "loss": 0.32,
      "step": 7510
    },
    {
      "epoch": 1.54,
      "grad_norm": 1.231378197669983,
      "learning_rate": 4.614123193604592e-06,
      "loss": 0.2898,
      "step": 7511
    },
    {
      "epoch": 1.54,
      "grad_norm": 1.6504158973693848,
      "learning_rate": 4.612073383212054e-06,
      "loss": 0.3643,
      "step": 7512
    },
    {
      "epoch": 1.54,
      "grad_norm": 0.768670916557312,
      "learning_rate": 4.610023572819515e-06,
      "loss": 0.3338,
      "step": 7513
    },
    {
      "epoch": 1.54,
      "grad_norm": 1.473191738128662,
      "learning_rate": 4.607973762426976e-06,
      "loss": 0.3705,
      "step": 7514
    },
    {
      "epoch": 1.54,
      "grad_norm": 1.3362879753112793,
      "learning_rate": 4.605923952034438e-06,
      "loss": 0.337,
      "step": 7515
    },
    {
      "epoch": 1.54,
      "grad_norm": 1.3338840007781982,
      "learning_rate": 4.603874141641899e-06,
      "loss": 0.4017,
      "step": 7516
    },
    {
      "epoch": 1.54,
      "grad_norm": 0.9927762746810913,
      "learning_rate": 4.60182433124936e-06,
      "loss": 0.4886,
      "step": 7517
    },
    {
      "epoch": 1.54,
      "grad_norm": 1.0958561897277832,
      "learning_rate": 4.5997745208568216e-06,
      "loss": 0.3623,
      "step": 7518
    },
    {
      "epoch": 1.54,
      "grad_norm": 0.911178469657898,
      "learning_rate": 4.597724710464283e-06,
      "loss": 0.363,
      "step": 7519
    },
    {
      "epoch": 1.54,
      "grad_norm": 1.1747045516967773,
      "learning_rate": 4.595674900071744e-06,
      "loss": 0.3238,
      "step": 7520
    },
    {
      "epoch": 1.54,
      "grad_norm": 1.1143324375152588,
      "learning_rate": 4.5936250896792054e-06,
      "loss": 0.2721,
      "step": 7521
    },
    {
      "epoch": 1.54,
      "grad_norm": 1.533785343170166,
      "learning_rate": 4.5915752792866665e-06,
      "loss": 0.2653,
      "step": 7522
    },
    {
      "epoch": 1.54,
      "grad_norm": 1.247321605682373,
      "learning_rate": 4.5895254688941275e-06,
      "loss": 0.3163,
      "step": 7523
    },
    {
      "epoch": 1.54,
      "grad_norm": 1.4325443506240845,
      "learning_rate": 4.587475658501589e-06,
      "loss": 0.5434,
      "step": 7524
    },
    {
      "epoch": 1.54,
      "grad_norm": 1.0107203722000122,
      "learning_rate": 4.58542584810905e-06,
      "loss": 0.2677,
      "step": 7525
    },
    {
      "epoch": 1.54,
      "grad_norm": 0.9672539234161377,
      "learning_rate": 4.583376037716511e-06,
      "loss": 0.291,
      "step": 7526
    },
    {
      "epoch": 1.54,
      "grad_norm": 1.3925591707229614,
      "learning_rate": 4.581326227323973e-06,
      "loss": 0.3761,
      "step": 7527
    },
    {
      "epoch": 1.54,
      "grad_norm": 1.4154819250106812,
      "learning_rate": 4.579276416931434e-06,
      "loss": 0.2388,
      "step": 7528
    },
    {
      "epoch": 1.54,
      "grad_norm": 1.6470109224319458,
      "learning_rate": 4.577226606538895e-06,
      "loss": 0.263,
      "step": 7529
    },
    {
      "epoch": 1.54,
      "grad_norm": 0.9868788123130798,
      "learning_rate": 4.575176796146357e-06,
      "loss": 0.3192,
      "step": 7530
    },
    {
      "epoch": 1.54,
      "grad_norm": 1.4026391506195068,
      "learning_rate": 4.573126985753818e-06,
      "loss": 0.3984,
      "step": 7531
    },
    {
      "epoch": 1.54,
      "grad_norm": 1.064814805984497,
      "learning_rate": 4.571077175361279e-06,
      "loss": 0.3228,
      "step": 7532
    },
    {
      "epoch": 1.54,
      "grad_norm": 1.2853330373764038,
      "learning_rate": 4.569027364968741e-06,
      "loss": 0.2921,
      "step": 7533
    },
    {
      "epoch": 1.54,
      "grad_norm": 1.3809560537338257,
      "learning_rate": 4.566977554576202e-06,
      "loss": 0.4676,
      "step": 7534
    },
    {
      "epoch": 1.54,
      "grad_norm": 1.149757742881775,
      "learning_rate": 4.564927744183663e-06,
      "loss": 0.2736,
      "step": 7535
    },
    {
      "epoch": 1.54,
      "grad_norm": 0.9853143692016602,
      "learning_rate": 4.562877933791125e-06,
      "loss": 0.351,
      "step": 7536
    },
    {
      "epoch": 1.54,
      "grad_norm": 1.2679141759872437,
      "learning_rate": 4.560828123398587e-06,
      "loss": 0.3467,
      "step": 7537
    },
    {
      "epoch": 1.54,
      "grad_norm": 1.114142656326294,
      "learning_rate": 4.558778313006048e-06,
      "loss": 0.4409,
      "step": 7538
    },
    {
      "epoch": 1.54,
      "grad_norm": 0.7287874817848206,
      "learning_rate": 4.556728502613509e-06,
      "loss": 0.266,
      "step": 7539
    },
    {
      "epoch": 1.54,
      "grad_norm": 1.0396080017089844,
      "learning_rate": 4.5546786922209706e-06,
      "loss": 0.4825,
      "step": 7540
    },
    {
      "epoch": 1.54,
      "grad_norm": 1.241275429725647,
      "learning_rate": 4.5526288818284316e-06,
      "loss": 0.4486,
      "step": 7541
    },
    {
      "epoch": 1.55,
      "grad_norm": 1.0197809934616089,
      "learning_rate": 4.5505790714358926e-06,
      "loss": 0.3816,
      "step": 7542
    },
    {
      "epoch": 1.55,
      "grad_norm": 0.8666449785232544,
      "learning_rate": 4.5485292610433544e-06,
      "loss": 0.3017,
      "step": 7543
    },
    {
      "epoch": 1.55,
      "grad_norm": 1.2888177633285522,
      "learning_rate": 4.5464794506508154e-06,
      "loss": 0.4628,
      "step": 7544
    },
    {
      "epoch": 1.55,
      "grad_norm": 1.5241626501083374,
      "learning_rate": 4.5444296402582764e-06,
      "loss": 0.3782,
      "step": 7545
    },
    {
      "epoch": 1.55,
      "grad_norm": 1.5655887126922607,
      "learning_rate": 4.542379829865738e-06,
      "loss": 0.3878,
      "step": 7546
    },
    {
      "epoch": 1.55,
      "grad_norm": 2.029665946960449,
      "learning_rate": 4.540330019473199e-06,
      "loss": 0.4417,
      "step": 7547
    },
    {
      "epoch": 1.55,
      "grad_norm": 1.601902961730957,
      "learning_rate": 4.53828020908066e-06,
      "loss": 0.4005,
      "step": 7548
    },
    {
      "epoch": 1.55,
      "grad_norm": 2.0866055488586426,
      "learning_rate": 4.536230398688122e-06,
      "loss": 0.4111,
      "step": 7549
    },
    {
      "epoch": 1.55,
      "grad_norm": 1.062408208847046,
      "learning_rate": 4.534180588295583e-06,
      "loss": 0.2613,
      "step": 7550
    },
    {
      "epoch": 1.55,
      "grad_norm": 1.0000985860824585,
      "learning_rate": 4.532130777903044e-06,
      "loss": 0.3744,
      "step": 7551
    },
    {
      "epoch": 1.55,
      "grad_norm": 1.243470549583435,
      "learning_rate": 4.530080967510506e-06,
      "loss": 0.3783,
      "step": 7552
    },
    {
      "epoch": 1.55,
      "grad_norm": 1.0174332857131958,
      "learning_rate": 4.528031157117967e-06,
      "loss": 0.273,
      "step": 7553
    },
    {
      "epoch": 1.55,
      "grad_norm": 1.7140673398971558,
      "learning_rate": 4.525981346725428e-06,
      "loss": 0.4871,
      "step": 7554
    },
    {
      "epoch": 1.55,
      "grad_norm": 1.5253279209136963,
      "learning_rate": 4.52393153633289e-06,
      "loss": 0.466,
      "step": 7555
    },
    {
      "epoch": 1.55,
      "grad_norm": 1.146864414215088,
      "learning_rate": 4.521881725940351e-06,
      "loss": 0.5582,
      "step": 7556
    },
    {
      "epoch": 1.55,
      "grad_norm": 1.3255057334899902,
      "learning_rate": 4.519831915547812e-06,
      "loss": 0.2458,
      "step": 7557
    },
    {
      "epoch": 1.55,
      "grad_norm": 1.1897164583206177,
      "learning_rate": 4.517782105155273e-06,
      "loss": 0.2438,
      "step": 7558
    },
    {
      "epoch": 1.55,
      "grad_norm": 1.5325210094451904,
      "learning_rate": 4.515732294762735e-06,
      "loss": 0.4573,
      "step": 7559
    },
    {
      "epoch": 1.55,
      "grad_norm": 1.1286754608154297,
      "learning_rate": 4.513682484370196e-06,
      "loss": 0.3234,
      "step": 7560
    },
    {
      "epoch": 1.55,
      "grad_norm": 0.8833119869232178,
      "learning_rate": 4.511632673977657e-06,
      "loss": 0.3128,
      "step": 7561
    },
    {
      "epoch": 1.55,
      "grad_norm": 0.5986039638519287,
      "learning_rate": 4.509582863585119e-06,
      "loss": 0.1913,
      "step": 7562
    },
    {
      "epoch": 1.55,
      "grad_norm": 1.0327138900756836,
      "learning_rate": 4.50753305319258e-06,
      "loss": 0.2977,
      "step": 7563
    },
    {
      "epoch": 1.55,
      "grad_norm": 1.1428178548812866,
      "learning_rate": 4.505483242800041e-06,
      "loss": 0.3375,
      "step": 7564
    },
    {
      "epoch": 1.55,
      "grad_norm": 1.3668795824050903,
      "learning_rate": 4.5034334324075026e-06,
      "loss": 0.4182,
      "step": 7565
    },
    {
      "epoch": 1.55,
      "grad_norm": 1.2637492418289185,
      "learning_rate": 4.501383622014964e-06,
      "loss": 0.3936,
      "step": 7566
    },
    {
      "epoch": 1.55,
      "grad_norm": 1.0512917041778564,
      "learning_rate": 4.4993338116224254e-06,
      "loss": 0.4709,
      "step": 7567
    },
    {
      "epoch": 1.55,
      "grad_norm": 1.777510404586792,
      "learning_rate": 4.4972840012298864e-06,
      "loss": 0.2682,
      "step": 7568
    },
    {
      "epoch": 1.55,
      "grad_norm": 1.1210013628005981,
      "learning_rate": 4.495234190837348e-06,
      "loss": 0.2841,
      "step": 7569
    },
    {
      "epoch": 1.55,
      "grad_norm": 1.7656643390655518,
      "learning_rate": 4.493184380444809e-06,
      "loss": 0.2787,
      "step": 7570
    },
    {
      "epoch": 1.55,
      "grad_norm": 1.9412848949432373,
      "learning_rate": 4.49113457005227e-06,
      "loss": 0.3626,
      "step": 7571
    },
    {
      "epoch": 1.55,
      "grad_norm": 2.146182060241699,
      "learning_rate": 4.489084759659732e-06,
      "loss": 0.4243,
      "step": 7572
    },
    {
      "epoch": 1.55,
      "grad_norm": 1.4343111515045166,
      "learning_rate": 4.487034949267193e-06,
      "loss": 0.4371,
      "step": 7573
    },
    {
      "epoch": 1.55,
      "grad_norm": 1.0429638624191284,
      "learning_rate": 4.484985138874654e-06,
      "loss": 0.2934,
      "step": 7574
    },
    {
      "epoch": 1.55,
      "grad_norm": 1.0819599628448486,
      "learning_rate": 4.482935328482116e-06,
      "loss": 0.3303,
      "step": 7575
    },
    {
      "epoch": 1.55,
      "grad_norm": 1.3696250915527344,
      "learning_rate": 4.480885518089577e-06,
      "loss": 0.2425,
      "step": 7576
    },
    {
      "epoch": 1.55,
      "grad_norm": 0.8286024332046509,
      "learning_rate": 4.478835707697038e-06,
      "loss": 0.2865,
      "step": 7577
    },
    {
      "epoch": 1.55,
      "grad_norm": 0.895605742931366,
      "learning_rate": 4.4767858973045e-06,
      "loss": 0.2077,
      "step": 7578
    },
    {
      "epoch": 1.55,
      "grad_norm": 1.3406753540039062,
      "learning_rate": 4.474736086911961e-06,
      "loss": 0.345,
      "step": 7579
    },
    {
      "epoch": 1.55,
      "grad_norm": 1.5691219568252563,
      "learning_rate": 4.472686276519422e-06,
      "loss": 0.263,
      "step": 7580
    },
    {
      "epoch": 1.55,
      "grad_norm": 1.1327491998672485,
      "learning_rate": 4.470636466126884e-06,
      "loss": 0.4124,
      "step": 7581
    },
    {
      "epoch": 1.55,
      "grad_norm": 1.4370522499084473,
      "learning_rate": 4.468586655734345e-06,
      "loss": 0.3081,
      "step": 7582
    },
    {
      "epoch": 1.55,
      "grad_norm": 2.5756945610046387,
      "learning_rate": 4.466536845341806e-06,
      "loss": 0.3127,
      "step": 7583
    },
    {
      "epoch": 1.55,
      "grad_norm": 1.817376732826233,
      "learning_rate": 4.464487034949268e-06,
      "loss": 0.3565,
      "step": 7584
    },
    {
      "epoch": 1.55,
      "grad_norm": 1.138758659362793,
      "learning_rate": 4.462437224556729e-06,
      "loss": 0.2861,
      "step": 7585
    },
    {
      "epoch": 1.55,
      "grad_norm": 1.7241250276565552,
      "learning_rate": 4.46038741416419e-06,
      "loss": 0.3265,
      "step": 7586
    },
    {
      "epoch": 1.55,
      "grad_norm": 2.2113728523254395,
      "learning_rate": 4.4583376037716515e-06,
      "loss": 0.3473,
      "step": 7587
    },
    {
      "epoch": 1.55,
      "grad_norm": 2.0131936073303223,
      "learning_rate": 4.4562877933791126e-06,
      "loss": 0.3741,
      "step": 7588
    },
    {
      "epoch": 1.55,
      "grad_norm": 0.8534929752349854,
      "learning_rate": 4.4542379829865736e-06,
      "loss": 0.25,
      "step": 7589
    },
    {
      "epoch": 1.56,
      "grad_norm": 0.9463364481925964,
      "learning_rate": 4.452188172594035e-06,
      "loss": 0.2544,
      "step": 7590
    },
    {
      "epoch": 1.56,
      "grad_norm": 3.298307418823242,
      "learning_rate": 4.4501383622014964e-06,
      "loss": 0.3083,
      "step": 7591
    },
    {
      "epoch": 1.56,
      "grad_norm": 1.9275709390640259,
      "learning_rate": 4.4480885518089574e-06,
      "loss": 0.4245,
      "step": 7592
    },
    {
      "epoch": 1.56,
      "grad_norm": 1.1983082294464111,
      "learning_rate": 4.446038741416419e-06,
      "loss": 0.3011,
      "step": 7593
    },
    {
      "epoch": 1.56,
      "grad_norm": 1.6657748222351074,
      "learning_rate": 4.44398893102388e-06,
      "loss": 0.3166,
      "step": 7594
    },
    {
      "epoch": 1.56,
      "grad_norm": 1.8783299922943115,
      "learning_rate": 4.441939120631341e-06,
      "loss": 0.314,
      "step": 7595
    },
    {
      "epoch": 1.56,
      "grad_norm": 1.1870288848876953,
      "learning_rate": 4.439889310238803e-06,
      "loss": 0.2537,
      "step": 7596
    },
    {
      "epoch": 1.56,
      "grad_norm": 0.702899694442749,
      "learning_rate": 4.437839499846265e-06,
      "loss": 0.2553,
      "step": 7597
    },
    {
      "epoch": 1.56,
      "grad_norm": 2.1735854148864746,
      "learning_rate": 4.435789689453726e-06,
      "loss": 0.3816,
      "step": 7598
    },
    {
      "epoch": 1.56,
      "grad_norm": 0.8672336339950562,
      "learning_rate": 4.433739879061187e-06,
      "loss": 0.387,
      "step": 7599
    },
    {
      "epoch": 1.56,
      "grad_norm": 0.8088432550430298,
      "learning_rate": 4.431690068668649e-06,
      "loss": 0.3934,
      "step": 7600
    },
    {
      "epoch": 1.56,
      "grad_norm": 0.924281895160675,
      "learning_rate": 4.42964025827611e-06,
      "loss": 0.3145,
      "step": 7601
    },
    {
      "epoch": 1.56,
      "grad_norm": 1.2030171155929565,
      "learning_rate": 4.427590447883571e-06,
      "loss": 0.2353,
      "step": 7602
    },
    {
      "epoch": 1.56,
      "grad_norm": 1.396124243736267,
      "learning_rate": 4.425540637491033e-06,
      "loss": 0.3529,
      "step": 7603
    },
    {
      "epoch": 1.56,
      "grad_norm": 1.0812758207321167,
      "learning_rate": 4.423490827098494e-06,
      "loss": 0.2613,
      "step": 7604
    },
    {
      "epoch": 1.56,
      "grad_norm": 0.8618074655532837,
      "learning_rate": 4.421441016705955e-06,
      "loss": 0.3076,
      "step": 7605
    },
    {
      "epoch": 1.56,
      "grad_norm": 1.1249943971633911,
      "learning_rate": 4.419391206313417e-06,
      "loss": 0.3972,
      "step": 7606
    },
    {
      "epoch": 1.56,
      "grad_norm": 0.9568947553634644,
      "learning_rate": 4.417341395920878e-06,
      "loss": 0.345,
      "step": 7607
    },
    {
      "epoch": 1.56,
      "grad_norm": 1.1872570514678955,
      "learning_rate": 4.415291585528339e-06,
      "loss": 0.3585,
      "step": 7608
    },
    {
      "epoch": 1.56,
      "grad_norm": 1.2248021364212036,
      "learning_rate": 4.4132417751358005e-06,
      "loss": 0.3765,
      "step": 7609
    },
    {
      "epoch": 1.56,
      "grad_norm": 1.730485439300537,
      "learning_rate": 4.4111919647432615e-06,
      "loss": 0.2971,
      "step": 7610
    },
    {
      "epoch": 1.56,
      "grad_norm": 0.9161443710327148,
      "learning_rate": 4.4091421543507225e-06,
      "loss": 0.3406,
      "step": 7611
    },
    {
      "epoch": 1.56,
      "grad_norm": 0.9710341691970825,
      "learning_rate": 4.407092343958184e-06,
      "loss": 0.2854,
      "step": 7612
    },
    {
      "epoch": 1.56,
      "grad_norm": 0.9631935358047485,
      "learning_rate": 4.405042533565645e-06,
      "loss": 0.2503,
      "step": 7613
    },
    {
      "epoch": 1.56,
      "grad_norm": 1.3325293064117432,
      "learning_rate": 4.402992723173106e-06,
      "loss": 0.3102,
      "step": 7614
    },
    {
      "epoch": 1.56,
      "grad_norm": 1.153212308883667,
      "learning_rate": 4.400942912780568e-06,
      "loss": 0.2641,
      "step": 7615
    },
    {
      "epoch": 1.56,
      "grad_norm": 1.1071922779083252,
      "learning_rate": 4.398893102388029e-06,
      "loss": 0.3597,
      "step": 7616
    },
    {
      "epoch": 1.56,
      "grad_norm": 1.0990251302719116,
      "learning_rate": 4.39684329199549e-06,
      "loss": 0.2084,
      "step": 7617
    },
    {
      "epoch": 1.56,
      "grad_norm": 1.0704354047775269,
      "learning_rate": 4.394793481602952e-06,
      "loss": 0.2989,
      "step": 7618
    },
    {
      "epoch": 1.56,
      "grad_norm": 1.289241909980774,
      "learning_rate": 4.392743671210413e-06,
      "loss": 0.4033,
      "step": 7619
    },
    {
      "epoch": 1.56,
      "grad_norm": 1.1081814765930176,
      "learning_rate": 4.390693860817874e-06,
      "loss": 0.2692,
      "step": 7620
    },
    {
      "epoch": 1.56,
      "grad_norm": 1.4018526077270508,
      "learning_rate": 4.388644050425336e-06,
      "loss": 0.4812,
      "step": 7621
    },
    {
      "epoch": 1.56,
      "grad_norm": 1.4493212699890137,
      "learning_rate": 4.386594240032797e-06,
      "loss": 0.332,
      "step": 7622
    },
    {
      "epoch": 1.56,
      "grad_norm": 1.0100393295288086,
      "learning_rate": 4.384544429640258e-06,
      "loss": 0.3209,
      "step": 7623
    },
    {
      "epoch": 1.56,
      "grad_norm": 1.768211841583252,
      "learning_rate": 4.38249461924772e-06,
      "loss": 0.3768,
      "step": 7624
    },
    {
      "epoch": 1.56,
      "grad_norm": 1.0031386613845825,
      "learning_rate": 4.380444808855182e-06,
      "loss": 0.4221,
      "step": 7625
    },
    {
      "epoch": 1.56,
      "grad_norm": 1.4216285943984985,
      "learning_rate": 4.378394998462643e-06,
      "loss": 0.4261,
      "step": 7626
    },
    {
      "epoch": 1.56,
      "grad_norm": 1.7735450267791748,
      "learning_rate": 4.376345188070104e-06,
      "loss": 0.3789,
      "step": 7627
    },
    {
      "epoch": 1.56,
      "grad_norm": 1.3818479776382446,
      "learning_rate": 4.374295377677566e-06,
      "loss": 0.3854,
      "step": 7628
    },
    {
      "epoch": 1.56,
      "grad_norm": 1.1079139709472656,
      "learning_rate": 4.372245567285027e-06,
      "loss": 0.2366,
      "step": 7629
    },
    {
      "epoch": 1.56,
      "grad_norm": 1.2009357213974,
      "learning_rate": 4.370195756892488e-06,
      "loss": 0.2802,
      "step": 7630
    },
    {
      "epoch": 1.56,
      "grad_norm": 1.2278047800064087,
      "learning_rate": 4.3681459464999495e-06,
      "loss": 0.4477,
      "step": 7631
    },
    {
      "epoch": 1.56,
      "grad_norm": 1.1580090522766113,
      "learning_rate": 4.3660961361074105e-06,
      "loss": 0.4463,
      "step": 7632
    },
    {
      "epoch": 1.56,
      "grad_norm": 1.0720776319503784,
      "learning_rate": 4.3640463257148715e-06,
      "loss": 0.2617,
      "step": 7633
    },
    {
      "epoch": 1.56,
      "grad_norm": 0.8939587473869324,
      "learning_rate": 4.361996515322333e-06,
      "loss": 0.3799,
      "step": 7634
    },
    {
      "epoch": 1.56,
      "grad_norm": 1.1028332710266113,
      "learning_rate": 4.359946704929794e-06,
      "loss": 0.1903,
      "step": 7635
    },
    {
      "epoch": 1.56,
      "grad_norm": 1.2946923971176147,
      "learning_rate": 4.357896894537255e-06,
      "loss": 0.3041,
      "step": 7636
    },
    {
      "epoch": 1.56,
      "grad_norm": 1.1640105247497559,
      "learning_rate": 4.355847084144717e-06,
      "loss": 0.3547,
      "step": 7637
    },
    {
      "epoch": 1.56,
      "grad_norm": 2.386117696762085,
      "learning_rate": 4.353797273752178e-06,
      "loss": 0.3909,
      "step": 7638
    },
    {
      "epoch": 1.57,
      "grad_norm": 1.4043540954589844,
      "learning_rate": 4.351747463359639e-06,
      "loss": 0.3174,
      "step": 7639
    },
    {
      "epoch": 1.57,
      "grad_norm": 1.4425314664840698,
      "learning_rate": 4.349697652967101e-06,
      "loss": 0.5202,
      "step": 7640
    },
    {
      "epoch": 1.57,
      "grad_norm": 1.1077055931091309,
      "learning_rate": 4.347647842574562e-06,
      "loss": 0.3215,
      "step": 7641
    },
    {
      "epoch": 1.57,
      "grad_norm": 1.8006020784378052,
      "learning_rate": 4.345598032182023e-06,
      "loss": 0.3748,
      "step": 7642
    },
    {
      "epoch": 1.57,
      "grad_norm": 1.6754575967788696,
      "learning_rate": 4.343548221789485e-06,
      "loss": 0.318,
      "step": 7643
    },
    {
      "epoch": 1.57,
      "grad_norm": 1.0566693544387817,
      "learning_rate": 4.341498411396946e-06,
      "loss": 0.3092,
      "step": 7644
    },
    {
      "epoch": 1.57,
      "grad_norm": 1.31010901927948,
      "learning_rate": 4.339448601004407e-06,
      "loss": 0.3205,
      "step": 7645
    },
    {
      "epoch": 1.57,
      "grad_norm": 1.123445987701416,
      "learning_rate": 4.337398790611869e-06,
      "loss": 0.221,
      "step": 7646
    },
    {
      "epoch": 1.57,
      "grad_norm": 0.9360756278038025,
      "learning_rate": 4.33534898021933e-06,
      "loss": 0.2925,
      "step": 7647
    },
    {
      "epoch": 1.57,
      "grad_norm": 0.8339033126831055,
      "learning_rate": 4.333299169826791e-06,
      "loss": 0.3334,
      "step": 7648
    },
    {
      "epoch": 1.57,
      "grad_norm": 0.7215871810913086,
      "learning_rate": 4.331249359434253e-06,
      "loss": 0.1889,
      "step": 7649
    },
    {
      "epoch": 1.57,
      "grad_norm": 1.2062249183654785,
      "learning_rate": 4.329199549041714e-06,
      "loss": 0.3019,
      "step": 7650
    },
    {
      "epoch": 1.57,
      "grad_norm": 1.3786616325378418,
      "learning_rate": 4.327149738649175e-06,
      "loss": 0.3797,
      "step": 7651
    },
    {
      "epoch": 1.57,
      "grad_norm": 1.813720703125,
      "learning_rate": 4.325099928256637e-06,
      "loss": 0.4579,
      "step": 7652
    },
    {
      "epoch": 1.57,
      "grad_norm": 1.389186978340149,
      "learning_rate": 4.323050117864098e-06,
      "loss": 0.2212,
      "step": 7653
    },
    {
      "epoch": 1.57,
      "grad_norm": 1.2809460163116455,
      "learning_rate": 4.321000307471559e-06,
      "loss": 0.3353,
      "step": 7654
    },
    {
      "epoch": 1.57,
      "grad_norm": 1.394948124885559,
      "learning_rate": 4.3189504970790205e-06,
      "loss": 0.3026,
      "step": 7655
    },
    {
      "epoch": 1.57,
      "grad_norm": 1.3889870643615723,
      "learning_rate": 4.316900686686482e-06,
      "loss": 0.3116,
      "step": 7656
    },
    {
      "epoch": 1.57,
      "grad_norm": 1.3587119579315186,
      "learning_rate": 4.314850876293943e-06,
      "loss": 0.4183,
      "step": 7657
    },
    {
      "epoch": 1.57,
      "grad_norm": 0.7207481861114502,
      "learning_rate": 4.312801065901404e-06,
      "loss": 0.2706,
      "step": 7658
    },
    {
      "epoch": 1.57,
      "grad_norm": 1.4585055112838745,
      "learning_rate": 4.310751255508866e-06,
      "loss": 0.2388,
      "step": 7659
    },
    {
      "epoch": 1.57,
      "grad_norm": 1.4825010299682617,
      "learning_rate": 4.308701445116327e-06,
      "loss": 0.4917,
      "step": 7660
    },
    {
      "epoch": 1.57,
      "grad_norm": 1.3282932043075562,
      "learning_rate": 4.306651634723788e-06,
      "loss": 0.3218,
      "step": 7661
    },
    {
      "epoch": 1.57,
      "grad_norm": 1.332239031791687,
      "learning_rate": 4.30460182433125e-06,
      "loss": 0.3575,
      "step": 7662
    },
    {
      "epoch": 1.57,
      "grad_norm": 0.9749230146408081,
      "learning_rate": 4.302552013938711e-06,
      "loss": 0.2157,
      "step": 7663
    },
    {
      "epoch": 1.57,
      "grad_norm": 2.1019608974456787,
      "learning_rate": 4.300502203546172e-06,
      "loss": 0.2365,
      "step": 7664
    },
    {
      "epoch": 1.57,
      "grad_norm": 1.513330340385437,
      "learning_rate": 4.298452393153634e-06,
      "loss": 0.2983,
      "step": 7665
    },
    {
      "epoch": 1.57,
      "grad_norm": 1.6658579111099243,
      "learning_rate": 4.296402582761095e-06,
      "loss": 0.2349,
      "step": 7666
    },
    {
      "epoch": 1.57,
      "grad_norm": 1.102112054824829,
      "learning_rate": 4.294352772368556e-06,
      "loss": 0.3698,
      "step": 7667
    },
    {
      "epoch": 1.57,
      "grad_norm": 1.4975051879882812,
      "learning_rate": 4.292302961976018e-06,
      "loss": 0.2608,
      "step": 7668
    },
    {
      "epoch": 1.57,
      "grad_norm": 1.655820369720459,
      "learning_rate": 4.290253151583479e-06,
      "loss": 0.339,
      "step": 7669
    },
    {
      "epoch": 1.57,
      "grad_norm": 1.248597264289856,
      "learning_rate": 4.28820334119094e-06,
      "loss": 0.3194,
      "step": 7670
    },
    {
      "epoch": 1.57,
      "grad_norm": 0.8564786911010742,
      "learning_rate": 4.286153530798402e-06,
      "loss": 0.2453,
      "step": 7671
    },
    {
      "epoch": 1.57,
      "grad_norm": 1.1988670825958252,
      "learning_rate": 4.284103720405863e-06,
      "loss": 0.257,
      "step": 7672
    },
    {
      "epoch": 1.57,
      "grad_norm": 2.098875045776367,
      "learning_rate": 4.282053910013324e-06,
      "loss": 0.4561,
      "step": 7673
    },
    {
      "epoch": 1.57,
      "grad_norm": 1.0451303720474243,
      "learning_rate": 4.280004099620786e-06,
      "loss": 0.3652,
      "step": 7674
    },
    {
      "epoch": 1.57,
      "grad_norm": 0.9151553511619568,
      "learning_rate": 4.277954289228247e-06,
      "loss": 0.3537,
      "step": 7675
    },
    {
      "epoch": 1.57,
      "grad_norm": 0.9924449920654297,
      "learning_rate": 4.275904478835708e-06,
      "loss": 0.4457,
      "step": 7676
    },
    {
      "epoch": 1.57,
      "grad_norm": 1.6156030893325806,
      "learning_rate": 4.2738546684431695e-06,
      "loss": 0.3064,
      "step": 7677
    },
    {
      "epoch": 1.57,
      "grad_norm": 1.1721001863479614,
      "learning_rate": 4.2718048580506305e-06,
      "loss": 0.2978,
      "step": 7678
    },
    {
      "epoch": 1.57,
      "grad_norm": 0.7419863939285278,
      "learning_rate": 4.2697550476580915e-06,
      "loss": 0.1754,
      "step": 7679
    },
    {
      "epoch": 1.57,
      "grad_norm": 1.1361836194992065,
      "learning_rate": 4.267705237265553e-06,
      "loss": 0.3919,
      "step": 7680
    },
    {
      "epoch": 1.57,
      "grad_norm": 1.339772343635559,
      "learning_rate": 4.265655426873014e-06,
      "loss": 0.316,
      "step": 7681
    },
    {
      "epoch": 1.57,
      "grad_norm": 1.1851798295974731,
      "learning_rate": 4.263605616480475e-06,
      "loss": 0.3005,
      "step": 7682
    },
    {
      "epoch": 1.57,
      "grad_norm": 1.3162827491760254,
      "learning_rate": 4.261555806087937e-06,
      "loss": 0.2241,
      "step": 7683
    },
    {
      "epoch": 1.57,
      "grad_norm": 0.9130593538284302,
      "learning_rate": 4.259505995695399e-06,
      "loss": 0.4281,
      "step": 7684
    },
    {
      "epoch": 1.57,
      "grad_norm": 0.7475820779800415,
      "learning_rate": 4.25745618530286e-06,
      "loss": 0.358,
      "step": 7685
    },
    {
      "epoch": 1.57,
      "grad_norm": 1.312193512916565,
      "learning_rate": 4.255406374910321e-06,
      "loss": 0.3903,
      "step": 7686
    },
    {
      "epoch": 1.57,
      "grad_norm": 1.829503059387207,
      "learning_rate": 4.253356564517783e-06,
      "loss": 0.4208,
      "step": 7687
    },
    {
      "epoch": 1.58,
      "grad_norm": 1.1841957569122314,
      "learning_rate": 4.251306754125244e-06,
      "loss": 0.4416,
      "step": 7688
    },
    {
      "epoch": 1.58,
      "grad_norm": 1.1536164283752441,
      "learning_rate": 4.249256943732705e-06,
      "loss": 0.4165,
      "step": 7689
    },
    {
      "epoch": 1.58,
      "grad_norm": 0.9305976629257202,
      "learning_rate": 4.247207133340167e-06,
      "loss": 0.2965,
      "step": 7690
    },
    {
      "epoch": 1.58,
      "grad_norm": 0.9205854535102844,
      "learning_rate": 4.245157322947628e-06,
      "loss": 0.2341,
      "step": 7691
    },
    {
      "epoch": 1.58,
      "grad_norm": 1.0099608898162842,
      "learning_rate": 4.243107512555089e-06,
      "loss": 0.3211,
      "step": 7692
    },
    {
      "epoch": 1.58,
      "grad_norm": 1.2143406867980957,
      "learning_rate": 4.241057702162551e-06,
      "loss": 0.3555,
      "step": 7693
    },
    {
      "epoch": 1.58,
      "grad_norm": 1.0463842153549194,
      "learning_rate": 4.239007891770012e-06,
      "loss": 0.3914,
      "step": 7694
    },
    {
      "epoch": 1.58,
      "grad_norm": 1.2891496419906616,
      "learning_rate": 4.236958081377473e-06,
      "loss": 0.3248,
      "step": 7695
    },
    {
      "epoch": 1.58,
      "grad_norm": 0.9577926993370056,
      "learning_rate": 4.234908270984935e-06,
      "loss": 0.3385,
      "step": 7696
    },
    {
      "epoch": 1.58,
      "grad_norm": 1.2181696891784668,
      "learning_rate": 4.232858460592396e-06,
      "loss": 0.3494,
      "step": 7697
    },
    {
      "epoch": 1.58,
      "grad_norm": 1.2897098064422607,
      "learning_rate": 4.230808650199857e-06,
      "loss": 0.2963,
      "step": 7698
    },
    {
      "epoch": 1.58,
      "grad_norm": 2.1131362915039062,
      "learning_rate": 4.2287588398073185e-06,
      "loss": 0.4081,
      "step": 7699
    },
    {
      "epoch": 1.58,
      "grad_norm": 1.3900357484817505,
      "learning_rate": 4.2267090294147795e-06,
      "loss": 0.3444,
      "step": 7700
    },
    {
      "epoch": 1.58,
      "grad_norm": 0.9004114866256714,
      "learning_rate": 4.2246592190222405e-06,
      "loss": 0.5065,
      "step": 7701
    },
    {
      "epoch": 1.58,
      "grad_norm": 1.013360619544983,
      "learning_rate": 4.222609408629702e-06,
      "loss": 0.2922,
      "step": 7702
    },
    {
      "epoch": 1.58,
      "grad_norm": 1.808095097541809,
      "learning_rate": 4.220559598237163e-06,
      "loss": 0.3091,
      "step": 7703
    },
    {
      "epoch": 1.58,
      "grad_norm": 2.4491918087005615,
      "learning_rate": 4.218509787844624e-06,
      "loss": 0.485,
      "step": 7704
    },
    {
      "epoch": 1.58,
      "grad_norm": 0.7195093631744385,
      "learning_rate": 4.216459977452086e-06,
      "loss": 0.2409,
      "step": 7705
    },
    {
      "epoch": 1.58,
      "grad_norm": 1.334861159324646,
      "learning_rate": 4.214410167059547e-06,
      "loss": 0.3844,
      "step": 7706
    },
    {
      "epoch": 1.58,
      "grad_norm": 1.2364325523376465,
      "learning_rate": 4.212360356667008e-06,
      "loss": 0.5139,
      "step": 7707
    },
    {
      "epoch": 1.58,
      "grad_norm": 1.3659989833831787,
      "learning_rate": 4.21031054627447e-06,
      "loss": 0.3577,
      "step": 7708
    },
    {
      "epoch": 1.58,
      "grad_norm": 1.6270983219146729,
      "learning_rate": 4.208260735881931e-06,
      "loss": 0.341,
      "step": 7709
    },
    {
      "epoch": 1.58,
      "grad_norm": 1.2791041135787964,
      "learning_rate": 4.206210925489392e-06,
      "loss": 0.2293,
      "step": 7710
    },
    {
      "epoch": 1.58,
      "grad_norm": 0.9827255606651306,
      "learning_rate": 4.204161115096854e-06,
      "loss": 0.343,
      "step": 7711
    },
    {
      "epoch": 1.58,
      "grad_norm": 1.0559587478637695,
      "learning_rate": 4.202111304704315e-06,
      "loss": 0.3676,
      "step": 7712
    },
    {
      "epoch": 1.58,
      "grad_norm": 1.5909878015518188,
      "learning_rate": 4.200061494311776e-06,
      "loss": 0.2804,
      "step": 7713
    },
    {
      "epoch": 1.58,
      "grad_norm": 1.3858659267425537,
      "learning_rate": 4.198011683919238e-06,
      "loss": 0.2228,
      "step": 7714
    },
    {
      "epoch": 1.58,
      "grad_norm": 0.9753801226615906,
      "learning_rate": 4.1959618735267e-06,
      "loss": 0.384,
      "step": 7715
    },
    {
      "epoch": 1.58,
      "grad_norm": 1.0867527723312378,
      "learning_rate": 4.193912063134161e-06,
      "loss": 0.3844,
      "step": 7716
    },
    {
      "epoch": 1.58,
      "grad_norm": 1.4762392044067383,
      "learning_rate": 4.191862252741622e-06,
      "loss": 0.4176,
      "step": 7717
    },
    {
      "epoch": 1.58,
      "grad_norm": 1.3415733575820923,
      "learning_rate": 4.189812442349084e-06,
      "loss": 0.4044,
      "step": 7718
    },
    {
      "epoch": 1.58,
      "grad_norm": 1.2807174921035767,
      "learning_rate": 4.187762631956545e-06,
      "loss": 0.2987,
      "step": 7719
    },
    {
      "epoch": 1.58,
      "grad_norm": 0.9994998574256897,
      "learning_rate": 4.185712821564006e-06,
      "loss": 0.331,
      "step": 7720
    },
    {
      "epoch": 1.58,
      "grad_norm": 1.0838606357574463,
      "learning_rate": 4.1836630111714675e-06,
      "loss": 0.3275,
      "step": 7721
    },
    {
      "epoch": 1.58,
      "grad_norm": 1.5811899900436401,
      "learning_rate": 4.1816132007789285e-06,
      "loss": 0.322,
      "step": 7722
    },
    {
      "epoch": 1.58,
      "grad_norm": 1.1021785736083984,
      "learning_rate": 4.1795633903863895e-06,
      "loss": 0.2417,
      "step": 7723
    },
    {
      "epoch": 1.58,
      "grad_norm": 1.2679998874664307,
      "learning_rate": 4.177513579993851e-06,
      "loss": 0.2816,
      "step": 7724
    },
    {
      "epoch": 1.58,
      "grad_norm": 1.2381614446640015,
      "learning_rate": 4.175463769601312e-06,
      "loss": 0.4691,
      "step": 7725
    },
    {
      "epoch": 1.58,
      "grad_norm": 1.0031769275665283,
      "learning_rate": 4.173413959208773e-06,
      "loss": 0.3341,
      "step": 7726
    },
    {
      "epoch": 1.58,
      "grad_norm": 1.1168127059936523,
      "learning_rate": 4.171364148816235e-06,
      "loss": 0.239,
      "step": 7727
    },
    {
      "epoch": 1.58,
      "grad_norm": 1.237660527229309,
      "learning_rate": 4.169314338423696e-06,
      "loss": 0.3525,
      "step": 7728
    },
    {
      "epoch": 1.58,
      "grad_norm": 1.1802643537521362,
      "learning_rate": 4.167264528031157e-06,
      "loss": 0.4444,
      "step": 7729
    },
    {
      "epoch": 1.58,
      "grad_norm": 1.2389006614685059,
      "learning_rate": 4.165214717638619e-06,
      "loss": 0.2841,
      "step": 7730
    },
    {
      "epoch": 1.58,
      "grad_norm": 1.204764723777771,
      "learning_rate": 4.16316490724608e-06,
      "loss": 0.4484,
      "step": 7731
    },
    {
      "epoch": 1.58,
      "grad_norm": 1.9163140058517456,
      "learning_rate": 4.161115096853541e-06,
      "loss": 0.2978,
      "step": 7732
    },
    {
      "epoch": 1.58,
      "grad_norm": 1.2934117317199707,
      "learning_rate": 4.159065286461003e-06,
      "loss": 0.2508,
      "step": 7733
    },
    {
      "epoch": 1.58,
      "grad_norm": 1.3456907272338867,
      "learning_rate": 4.157015476068464e-06,
      "loss": 0.4424,
      "step": 7734
    },
    {
      "epoch": 1.58,
      "grad_norm": 1.122084617614746,
      "learning_rate": 4.154965665675925e-06,
      "loss": 0.2797,
      "step": 7735
    },
    {
      "epoch": 1.58,
      "grad_norm": 1.4819546937942505,
      "learning_rate": 4.152915855283387e-06,
      "loss": 0.3065,
      "step": 7736
    },
    {
      "epoch": 1.59,
      "grad_norm": 2.073387384414673,
      "learning_rate": 4.150866044890848e-06,
      "loss": 0.4204,
      "step": 7737
    },
    {
      "epoch": 1.59,
      "grad_norm": 1.4961566925048828,
      "learning_rate": 4.148816234498309e-06,
      "loss": 0.2807,
      "step": 7738
    },
    {
      "epoch": 1.59,
      "grad_norm": 0.9117379784584045,
      "learning_rate": 4.146766424105771e-06,
      "loss": 0.4584,
      "step": 7739
    },
    {
      "epoch": 1.59,
      "grad_norm": 1.884801983833313,
      "learning_rate": 4.144716613713232e-06,
      "loss": 0.3204,
      "step": 7740
    },
    {
      "epoch": 1.59,
      "grad_norm": 1.6265292167663574,
      "learning_rate": 4.142666803320693e-06,
      "loss": 0.3802,
      "step": 7741
    },
    {
      "epoch": 1.59,
      "grad_norm": 1.043420672416687,
      "learning_rate": 4.140616992928155e-06,
      "loss": 0.3454,
      "step": 7742
    },
    {
      "epoch": 1.59,
      "grad_norm": 1.0999752283096313,
      "learning_rate": 4.1385671825356164e-06,
      "loss": 0.3685,
      "step": 7743
    },
    {
      "epoch": 1.59,
      "grad_norm": 1.161703109741211,
      "learning_rate": 4.1365173721430775e-06,
      "loss": 0.4706,
      "step": 7744
    },
    {
      "epoch": 1.59,
      "grad_norm": 1.2002723217010498,
      "learning_rate": 4.1344675617505385e-06,
      "loss": 0.4273,
      "step": 7745
    },
    {
      "epoch": 1.59,
      "grad_norm": 1.9399229288101196,
      "learning_rate": 4.132417751358e-06,
      "loss": 0.3919,
      "step": 7746
    },
    {
      "epoch": 1.59,
      "grad_norm": 1.5525696277618408,
      "learning_rate": 4.130367940965461e-06,
      "loss": 0.2687,
      "step": 7747
    },
    {
      "epoch": 1.59,
      "grad_norm": 2.0085532665252686,
      "learning_rate": 4.128318130572922e-06,
      "loss": 0.1959,
      "step": 7748
    },
    {
      "epoch": 1.59,
      "grad_norm": 1.5469393730163574,
      "learning_rate": 4.126268320180384e-06,
      "loss": 0.2755,
      "step": 7749
    },
    {
      "epoch": 1.59,
      "grad_norm": 1.362067699432373,
      "learning_rate": 4.124218509787845e-06,
      "loss": 0.281,
      "step": 7750
    },
    {
      "epoch": 1.59,
      "grad_norm": 1.1176280975341797,
      "learning_rate": 4.122168699395306e-06,
      "loss": 0.556,
      "step": 7751
    },
    {
      "epoch": 1.59,
      "grad_norm": 0.9758085608482361,
      "learning_rate": 4.120118889002768e-06,
      "loss": 0.189,
      "step": 7752
    },
    {
      "epoch": 1.59,
      "grad_norm": 1.0661689043045044,
      "learning_rate": 4.118069078610229e-06,
      "loss": 0.253,
      "step": 7753
    },
    {
      "epoch": 1.59,
      "grad_norm": 1.1272592544555664,
      "learning_rate": 4.11601926821769e-06,
      "loss": 0.4026,
      "step": 7754
    },
    {
      "epoch": 1.59,
      "grad_norm": 1.5139245986938477,
      "learning_rate": 4.113969457825152e-06,
      "loss": 0.4346,
      "step": 7755
    },
    {
      "epoch": 1.59,
      "grad_norm": 1.6598706245422363,
      "learning_rate": 4.111919647432613e-06,
      "loss": 0.4076,
      "step": 7756
    },
    {
      "epoch": 1.59,
      "grad_norm": 1.1742390394210815,
      "learning_rate": 4.109869837040074e-06,
      "loss": 0.2387,
      "step": 7757
    },
    {
      "epoch": 1.59,
      "grad_norm": 1.4183189868927002,
      "learning_rate": 4.107820026647536e-06,
      "loss": 0.4107,
      "step": 7758
    },
    {
      "epoch": 1.59,
      "grad_norm": 1.2273674011230469,
      "learning_rate": 4.105770216254997e-06,
      "loss": 0.2803,
      "step": 7759
    },
    {
      "epoch": 1.59,
      "grad_norm": 2.5550663471221924,
      "learning_rate": 4.103720405862458e-06,
      "loss": 0.3574,
      "step": 7760
    },
    {
      "epoch": 1.59,
      "grad_norm": 0.7136833667755127,
      "learning_rate": 4.10167059546992e-06,
      "loss": 0.215,
      "step": 7761
    },
    {
      "epoch": 1.59,
      "grad_norm": 1.0239036083221436,
      "learning_rate": 4.099620785077381e-06,
      "loss": 0.3541,
      "step": 7762
    },
    {
      "epoch": 1.59,
      "grad_norm": 1.220877766609192,
      "learning_rate": 4.097570974684842e-06,
      "loss": 0.4489,
      "step": 7763
    },
    {
      "epoch": 1.59,
      "grad_norm": 1.133655309677124,
      "learning_rate": 4.0955211642923036e-06,
      "loss": 0.4042,
      "step": 7764
    },
    {
      "epoch": 1.59,
      "grad_norm": 1.310383915901184,
      "learning_rate": 4.093471353899765e-06,
      "loss": 0.2574,
      "step": 7765
    },
    {
      "epoch": 1.59,
      "grad_norm": 1.1681841611862183,
      "learning_rate": 4.091421543507226e-06,
      "loss": 0.4087,
      "step": 7766
    },
    {
      "epoch": 1.59,
      "grad_norm": 1.1304371356964111,
      "learning_rate": 4.0893717331146874e-06,
      "loss": 0.419,
      "step": 7767
    },
    {
      "epoch": 1.59,
      "grad_norm": 1.571960687637329,
      "learning_rate": 4.0873219227221485e-06,
      "loss": 0.3436,
      "step": 7768
    },
    {
      "epoch": 1.59,
      "grad_norm": 1.0280827283859253,
      "learning_rate": 4.0852721123296095e-06,
      "loss": 0.4026,
      "step": 7769
    },
    {
      "epoch": 1.59,
      "grad_norm": 1.2259899377822876,
      "learning_rate": 4.083222301937071e-06,
      "loss": 0.3759,
      "step": 7770
    },
    {
      "epoch": 1.59,
      "grad_norm": 0.8649718165397644,
      "learning_rate": 4.081172491544532e-06,
      "loss": 0.2839,
      "step": 7771
    },
    {
      "epoch": 1.59,
      "grad_norm": 1.0803505182266235,
      "learning_rate": 4.079122681151993e-06,
      "loss": 0.4283,
      "step": 7772
    },
    {
      "epoch": 1.59,
      "grad_norm": 2.0232248306274414,
      "learning_rate": 4.077072870759455e-06,
      "loss": 0.2923,
      "step": 7773
    },
    {
      "epoch": 1.59,
      "grad_norm": 1.1073224544525146,
      "learning_rate": 4.075023060366917e-06,
      "loss": 0.316,
      "step": 7774
    },
    {
      "epoch": 1.59,
      "grad_norm": 1.0591048002243042,
      "learning_rate": 4.072973249974378e-06,
      "loss": 0.2939,
      "step": 7775
    },
    {
      "epoch": 1.59,
      "grad_norm": 1.4099609851837158,
      "learning_rate": 4.070923439581839e-06,
      "loss": 0.4482,
      "step": 7776
    },
    {
      "epoch": 1.59,
      "grad_norm": 1.8368310928344727,
      "learning_rate": 4.068873629189301e-06,
      "loss": 0.2812,
      "step": 7777
    },
    {
      "epoch": 1.59,
      "grad_norm": 2.1161391735076904,
      "learning_rate": 4.066823818796762e-06,
      "loss": 0.3871,
      "step": 7778
    },
    {
      "epoch": 1.59,
      "grad_norm": 1.4613460302352905,
      "learning_rate": 4.064774008404223e-06,
      "loss": 0.2335,
      "step": 7779
    },
    {
      "epoch": 1.59,
      "grad_norm": 0.8866045475006104,
      "learning_rate": 4.062724198011685e-06,
      "loss": 0.3663,
      "step": 7780
    },
    {
      "epoch": 1.59,
      "grad_norm": 1.1115856170654297,
      "learning_rate": 4.060674387619146e-06,
      "loss": 0.3342,
      "step": 7781
    },
    {
      "epoch": 1.59,
      "grad_norm": 1.2327944040298462,
      "learning_rate": 4.058624577226607e-06,
      "loss": 0.4053,
      "step": 7782
    },
    {
      "epoch": 1.59,
      "grad_norm": 2.1255156993865967,
      "learning_rate": 4.056574766834069e-06,
      "loss": 0.3757,
      "step": 7783
    },
    {
      "epoch": 1.59,
      "grad_norm": 0.8956343531608582,
      "learning_rate": 4.05452495644153e-06,
      "loss": 0.3601,
      "step": 7784
    },
    {
      "epoch": 1.59,
      "grad_norm": 1.738092064857483,
      "learning_rate": 4.052475146048991e-06,
      "loss": 0.2869,
      "step": 7785
    },
    {
      "epoch": 1.6,
      "grad_norm": 1.7851102352142334,
      "learning_rate": 4.0504253356564526e-06,
      "loss": 0.2617,
      "step": 7786
    },
    {
      "epoch": 1.6,
      "grad_norm": 1.0621734857559204,
      "learning_rate": 4.0483755252639136e-06,
      "loss": 0.3932,
      "step": 7787
    },
    {
      "epoch": 1.6,
      "grad_norm": 1.3332582712173462,
      "learning_rate": 4.0463257148713746e-06,
      "loss": 0.3364,
      "step": 7788
    },
    {
      "epoch": 1.6,
      "grad_norm": 1.2072033882141113,
      "learning_rate": 4.044275904478836e-06,
      "loss": 0.3178,
      "step": 7789
    },
    {
      "epoch": 1.6,
      "grad_norm": 1.6850519180297852,
      "learning_rate": 4.0422260940862974e-06,
      "loss": 0.4465,
      "step": 7790
    },
    {
      "epoch": 1.6,
      "grad_norm": 1.8902915716171265,
      "learning_rate": 4.0401762836937584e-06,
      "loss": 0.2465,
      "step": 7791
    },
    {
      "epoch": 1.6,
      "grad_norm": 2.392275810241699,
      "learning_rate": 4.0381264733012195e-06,
      "loss": 0.4065,
      "step": 7792
    },
    {
      "epoch": 1.6,
      "grad_norm": 1.102317214012146,
      "learning_rate": 4.036076662908681e-06,
      "loss": 0.3945,
      "step": 7793
    },
    {
      "epoch": 1.6,
      "grad_norm": 0.8682568073272705,
      "learning_rate": 4.034026852516142e-06,
      "loss": 0.1266,
      "step": 7794
    },
    {
      "epoch": 1.6,
      "grad_norm": 1.0679923295974731,
      "learning_rate": 4.031977042123603e-06,
      "loss": 0.2183,
      "step": 7795
    },
    {
      "epoch": 1.6,
      "grad_norm": 1.8561437129974365,
      "learning_rate": 4.029927231731065e-06,
      "loss": 0.4906,
      "step": 7796
    },
    {
      "epoch": 1.6,
      "grad_norm": 1.5259227752685547,
      "learning_rate": 4.027877421338526e-06,
      "loss": 0.3478,
      "step": 7797
    },
    {
      "epoch": 1.6,
      "grad_norm": 1.2302926778793335,
      "learning_rate": 4.025827610945987e-06,
      "loss": 0.3396,
      "step": 7798
    },
    {
      "epoch": 1.6,
      "grad_norm": 1.3678280115127563,
      "learning_rate": 4.023777800553449e-06,
      "loss": 0.3909,
      "step": 7799
    },
    {
      "epoch": 1.6,
      "grad_norm": 2.622579336166382,
      "learning_rate": 4.02172799016091e-06,
      "loss": 0.3891,
      "step": 7800
    },
    {
      "epoch": 1.6,
      "grad_norm": 1.0448293685913086,
      "learning_rate": 4.019678179768371e-06,
      "loss": 0.2582,
      "step": 7801
    },
    {
      "epoch": 1.6,
      "grad_norm": 1.0069501399993896,
      "learning_rate": 4.017628369375833e-06,
      "loss": 0.3414,
      "step": 7802
    },
    {
      "epoch": 1.6,
      "grad_norm": 0.8254122734069824,
      "learning_rate": 4.015578558983295e-06,
      "loss": 0.3628,
      "step": 7803
    },
    {
      "epoch": 1.6,
      "grad_norm": 1.2548919916152954,
      "learning_rate": 4.013528748590756e-06,
      "loss": 0.3542,
      "step": 7804
    },
    {
      "epoch": 1.6,
      "grad_norm": 1.1423898935317993,
      "learning_rate": 4.011478938198217e-06,
      "loss": 0.3838,
      "step": 7805
    },
    {
      "epoch": 1.6,
      "grad_norm": 1.0106076002120972,
      "learning_rate": 4.009429127805679e-06,
      "loss": 0.2733,
      "step": 7806
    },
    {
      "epoch": 1.6,
      "grad_norm": 1.0991830825805664,
      "learning_rate": 4.00737931741314e-06,
      "loss": 0.3984,
      "step": 7807
    },
    {
      "epoch": 1.6,
      "grad_norm": 1.176455020904541,
      "learning_rate": 4.005329507020601e-06,
      "loss": 0.2174,
      "step": 7808
    },
    {
      "epoch": 1.6,
      "grad_norm": 1.1661114692687988,
      "learning_rate": 4.0032796966280625e-06,
      "loss": 0.4063,
      "step": 7809
    },
    {
      "epoch": 1.6,
      "grad_norm": 1.3791557550430298,
      "learning_rate": 4.0012298862355236e-06,
      "loss": 0.3323,
      "step": 7810
    },
    {
      "epoch": 1.6,
      "grad_norm": 1.3658167123794556,
      "learning_rate": 3.9991800758429846e-06,
      "loss": 0.4114,
      "step": 7811
    },
    {
      "epoch": 1.6,
      "grad_norm": 1.5452845096588135,
      "learning_rate": 3.997130265450446e-06,
      "loss": 0.4568,
      "step": 7812
    },
    {
      "epoch": 1.6,
      "grad_norm": 3.0932016372680664,
      "learning_rate": 3.9950804550579074e-06,
      "loss": 0.3413,
      "step": 7813
    },
    {
      "epoch": 1.6,
      "grad_norm": 1.8358895778656006,
      "learning_rate": 3.9930306446653684e-06,
      "loss": 0.3872,
      "step": 7814
    },
    {
      "epoch": 1.6,
      "grad_norm": 0.8268651366233826,
      "learning_rate": 3.99098083427283e-06,
      "loss": 0.2667,
      "step": 7815
    },
    {
      "epoch": 1.6,
      "grad_norm": 1.3681623935699463,
      "learning_rate": 3.988931023880291e-06,
      "loss": 0.2537,
      "step": 7816
    },
    {
      "epoch": 1.6,
      "grad_norm": 2.019728183746338,
      "learning_rate": 3.986881213487752e-06,
      "loss": 0.2676,
      "step": 7817
    },
    {
      "epoch": 1.6,
      "grad_norm": 2.1901156902313232,
      "learning_rate": 3.984831403095214e-06,
      "loss": 0.4562,
      "step": 7818
    },
    {
      "epoch": 1.6,
      "grad_norm": 1.2052332162857056,
      "learning_rate": 3.982781592702675e-06,
      "loss": 0.3367,
      "step": 7819
    },
    {
      "epoch": 1.6,
      "grad_norm": 1.7266427278518677,
      "learning_rate": 3.980731782310136e-06,
      "loss": 0.3378,
      "step": 7820
    },
    {
      "epoch": 1.6,
      "grad_norm": 2.510406732559204,
      "learning_rate": 3.978681971917598e-06,
      "loss": 0.297,
      "step": 7821
    },
    {
      "epoch": 1.6,
      "grad_norm": 2.424367904663086,
      "learning_rate": 3.976632161525059e-06,
      "loss": 0.2492,
      "step": 7822
    },
    {
      "epoch": 1.6,
      "grad_norm": 1.3033305406570435,
      "learning_rate": 3.97458235113252e-06,
      "loss": 0.2991,
      "step": 7823
    },
    {
      "epoch": 1.6,
      "grad_norm": 0.7963339686393738,
      "learning_rate": 3.972532540739982e-06,
      "loss": 0.2653,
      "step": 7824
    },
    {
      "epoch": 1.6,
      "grad_norm": 1.4402283430099487,
      "learning_rate": 3.970482730347443e-06,
      "loss": 0.2589,
      "step": 7825
    },
    {
      "epoch": 1.6,
      "grad_norm": 2.0967538356781006,
      "learning_rate": 3.968432919954904e-06,
      "loss": 0.3039,
      "step": 7826
    },
    {
      "epoch": 1.6,
      "grad_norm": 2.5174899101257324,
      "learning_rate": 3.966383109562366e-06,
      "loss": 0.2346,
      "step": 7827
    },
    {
      "epoch": 1.6,
      "grad_norm": 1.403167724609375,
      "learning_rate": 3.964333299169827e-06,
      "loss": 0.3468,
      "step": 7828
    },
    {
      "epoch": 1.6,
      "grad_norm": 1.8736017942428589,
      "learning_rate": 3.962283488777288e-06,
      "loss": 0.5247,
      "step": 7829
    },
    {
      "epoch": 1.6,
      "grad_norm": 1.3675957918167114,
      "learning_rate": 3.96023367838475e-06,
      "loss": 0.3069,
      "step": 7830
    },
    {
      "epoch": 1.6,
      "grad_norm": 0.9484166502952576,
      "learning_rate": 3.958183867992211e-06,
      "loss": 0.3401,
      "step": 7831
    },
    {
      "epoch": 1.6,
      "grad_norm": 2.076298236846924,
      "learning_rate": 3.9561340575996725e-06,
      "loss": 0.2723,
      "step": 7832
    },
    {
      "epoch": 1.6,
      "grad_norm": 1.050432562828064,
      "learning_rate": 3.9540842472071335e-06,
      "loss": 0.313,
      "step": 7833
    },
    {
      "epoch": 1.6,
      "grad_norm": 1.3877184391021729,
      "learning_rate": 3.952034436814595e-06,
      "loss": 0.3828,
      "step": 7834
    },
    {
      "epoch": 1.61,
      "grad_norm": 1.6672279834747314,
      "learning_rate": 3.949984626422056e-06,
      "loss": 0.357,
      "step": 7835
    },
    {
      "epoch": 1.61,
      "grad_norm": 2.6942126750946045,
      "learning_rate": 3.947934816029517e-06,
      "loss": 0.3724,
      "step": 7836
    },
    {
      "epoch": 1.61,
      "grad_norm": 1.5071392059326172,
      "learning_rate": 3.945885005636979e-06,
      "loss": 0.372,
      "step": 7837
    },
    {
      "epoch": 1.61,
      "grad_norm": 1.1312991380691528,
      "learning_rate": 3.94383519524444e-06,
      "loss": 0.3555,
      "step": 7838
    },
    {
      "epoch": 1.61,
      "grad_norm": 1.2929905652999878,
      "learning_rate": 3.941785384851901e-06,
      "loss": 0.389,
      "step": 7839
    },
    {
      "epoch": 1.61,
      "grad_norm": 2.3863372802734375,
      "learning_rate": 3.939735574459363e-06,
      "loss": 0.4222,
      "step": 7840
    },
    {
      "epoch": 1.61,
      "grad_norm": 3.47808575630188,
      "learning_rate": 3.937685764066824e-06,
      "loss": 0.2688,
      "step": 7841
    },
    {
      "epoch": 1.61,
      "grad_norm": 1.7839717864990234,
      "learning_rate": 3.935635953674285e-06,
      "loss": 0.2714,
      "step": 7842
    },
    {
      "epoch": 1.61,
      "grad_norm": 1.293825626373291,
      "learning_rate": 3.933586143281747e-06,
      "loss": 0.3851,
      "step": 7843
    },
    {
      "epoch": 1.61,
      "grad_norm": 2.2503502368927,
      "learning_rate": 3.931536332889208e-06,
      "loss": 0.3004,
      "step": 7844
    },
    {
      "epoch": 1.61,
      "grad_norm": 2.009383201599121,
      "learning_rate": 3.929486522496669e-06,
      "loss": 0.2633,
      "step": 7845
    },
    {
      "epoch": 1.61,
      "grad_norm": 1.270182728767395,
      "learning_rate": 3.927436712104131e-06,
      "loss": 0.1901,
      "step": 7846
    },
    {
      "epoch": 1.61,
      "grad_norm": 0.8187792301177979,
      "learning_rate": 3.925386901711592e-06,
      "loss": 0.4356,
      "step": 7847
    },
    {
      "epoch": 1.61,
      "grad_norm": 1.0167256593704224,
      "learning_rate": 3.923337091319053e-06,
      "loss": 0.2586,
      "step": 7848
    },
    {
      "epoch": 1.61,
      "grad_norm": 3.1991636753082275,
      "learning_rate": 3.921287280926515e-06,
      "loss": 0.2677,
      "step": 7849
    },
    {
      "epoch": 1.61,
      "grad_norm": 1.1746842861175537,
      "learning_rate": 3.919237470533976e-06,
      "loss": 0.2709,
      "step": 7850
    },
    {
      "epoch": 1.61,
      "grad_norm": 1.2378599643707275,
      "learning_rate": 3.917187660141437e-06,
      "loss": 0.3959,
      "step": 7851
    },
    {
      "epoch": 1.61,
      "grad_norm": 1.1185048818588257,
      "learning_rate": 3.915137849748899e-06,
      "loss": 0.345,
      "step": 7852
    },
    {
      "epoch": 1.61,
      "grad_norm": 1.4313442707061768,
      "learning_rate": 3.91308803935636e-06,
      "loss": 0.335,
      "step": 7853
    },
    {
      "epoch": 1.61,
      "grad_norm": 1.3143088817596436,
      "learning_rate": 3.911038228963821e-06,
      "loss": 0.2598,
      "step": 7854
    },
    {
      "epoch": 1.61,
      "grad_norm": 3.7298665046691895,
      "learning_rate": 3.9089884185712825e-06,
      "loss": 0.2494,
      "step": 7855
    },
    {
      "epoch": 1.61,
      "grad_norm": 1.4695351123809814,
      "learning_rate": 3.9069386081787435e-06,
      "loss": 0.2923,
      "step": 7856
    },
    {
      "epoch": 1.61,
      "grad_norm": 1.1812984943389893,
      "learning_rate": 3.9048887977862045e-06,
      "loss": 0.225,
      "step": 7857
    },
    {
      "epoch": 1.61,
      "grad_norm": 1.1754772663116455,
      "learning_rate": 3.902838987393666e-06,
      "loss": 0.4263,
      "step": 7858
    },
    {
      "epoch": 1.61,
      "grad_norm": 1.8376377820968628,
      "learning_rate": 3.900789177001127e-06,
      "loss": 0.3518,
      "step": 7859
    },
    {
      "epoch": 1.61,
      "grad_norm": 1.1892814636230469,
      "learning_rate": 3.898739366608588e-06,
      "loss": 0.2814,
      "step": 7860
    },
    {
      "epoch": 1.61,
      "grad_norm": 1.104349136352539,
      "learning_rate": 3.89668955621605e-06,
      "loss": 0.2362,
      "step": 7861
    },
    {
      "epoch": 1.61,
      "grad_norm": 0.9936031103134155,
      "learning_rate": 3.894639745823512e-06,
      "loss": 0.2085,
      "step": 7862
    },
    {
      "epoch": 1.61,
      "grad_norm": 1.6091228723526,
      "learning_rate": 3.892589935430973e-06,
      "loss": 0.3289,
      "step": 7863
    },
    {
      "epoch": 1.61,
      "grad_norm": 2.0902085304260254,
      "learning_rate": 3.890540125038434e-06,
      "loss": 0.398,
      "step": 7864
    },
    {
      "epoch": 1.61,
      "grad_norm": 2.1904537677764893,
      "learning_rate": 3.888490314645896e-06,
      "loss": 0.1877,
      "step": 7865
    },
    {
      "epoch": 1.61,
      "grad_norm": 2.158724069595337,
      "learning_rate": 3.886440504253357e-06,
      "loss": 0.4096,
      "step": 7866
    },
    {
      "epoch": 1.61,
      "grad_norm": 1.1730002164840698,
      "learning_rate": 3.884390693860818e-06,
      "loss": 0.3728,
      "step": 7867
    },
    {
      "epoch": 1.61,
      "grad_norm": 0.9899126887321472,
      "learning_rate": 3.88234088346828e-06,
      "loss": 0.4031,
      "step": 7868
    },
    {
      "epoch": 1.61,
      "grad_norm": 1.4502227306365967,
      "learning_rate": 3.880291073075741e-06,
      "loss": 0.367,
      "step": 7869
    },
    {
      "epoch": 1.61,
      "grad_norm": 4.2882795333862305,
      "learning_rate": 3.878241262683202e-06,
      "loss": 0.2468,
      "step": 7870
    },
    {
      "epoch": 1.61,
      "grad_norm": 3.455501079559326,
      "learning_rate": 3.876191452290664e-06,
      "loss": 0.3757,
      "step": 7871
    },
    {
      "epoch": 1.61,
      "grad_norm": 1.437598466873169,
      "learning_rate": 3.874141641898125e-06,
      "loss": 0.6042,
      "step": 7872
    },
    {
      "epoch": 1.61,
      "grad_norm": 1.4091050624847412,
      "learning_rate": 3.872091831505586e-06,
      "loss": 0.201,
      "step": 7873
    },
    {
      "epoch": 1.61,
      "grad_norm": 2.1276814937591553,
      "learning_rate": 3.870042021113048e-06,
      "loss": 0.3733,
      "step": 7874
    },
    {
      "epoch": 1.61,
      "grad_norm": 1.1111140251159668,
      "learning_rate": 3.867992210720509e-06,
      "loss": 0.4291,
      "step": 7875
    },
    {
      "epoch": 1.61,
      "grad_norm": 3.2275073528289795,
      "learning_rate": 3.86594240032797e-06,
      "loss": 0.4096,
      "step": 7876
    },
    {
      "epoch": 1.61,
      "grad_norm": 2.060811996459961,
      "learning_rate": 3.8638925899354315e-06,
      "loss": 0.2883,
      "step": 7877
    },
    {
      "epoch": 1.61,
      "grad_norm": 1.736068606376648,
      "learning_rate": 3.8618427795428925e-06,
      "loss": 0.4847,
      "step": 7878
    },
    {
      "epoch": 1.61,
      "grad_norm": 0.991081953048706,
      "learning_rate": 3.8597929691503535e-06,
      "loss": 0.327,
      "step": 7879
    },
    {
      "epoch": 1.61,
      "grad_norm": 1.2778294086456299,
      "learning_rate": 3.857743158757815e-06,
      "loss": 0.3788,
      "step": 7880
    },
    {
      "epoch": 1.61,
      "grad_norm": 2.419348955154419,
      "learning_rate": 3.855693348365276e-06,
      "loss": 0.3113,
      "step": 7881
    },
    {
      "epoch": 1.61,
      "grad_norm": 0.8107959032058716,
      "learning_rate": 3.853643537972737e-06,
      "loss": 0.3669,
      "step": 7882
    },
    {
      "epoch": 1.62,
      "grad_norm": 1.725539207458496,
      "learning_rate": 3.851593727580199e-06,
      "loss": 0.421,
      "step": 7883
    },
    {
      "epoch": 1.62,
      "grad_norm": 1.097296953201294,
      "learning_rate": 3.84954391718766e-06,
      "loss": 0.4108,
      "step": 7884
    },
    {
      "epoch": 1.62,
      "grad_norm": 1.8176982402801514,
      "learning_rate": 3.847494106795121e-06,
      "loss": 0.3499,
      "step": 7885
    },
    {
      "epoch": 1.62,
      "grad_norm": 1.0208643674850464,
      "learning_rate": 3.845444296402583e-06,
      "loss": 0.3251,
      "step": 7886
    },
    {
      "epoch": 1.62,
      "grad_norm": 1.45878267288208,
      "learning_rate": 3.843394486010044e-06,
      "loss": 0.2927,
      "step": 7887
    },
    {
      "epoch": 1.62,
      "grad_norm": 0.7883877754211426,
      "learning_rate": 3.841344675617505e-06,
      "loss": 0.3044,
      "step": 7888
    },
    {
      "epoch": 1.62,
      "grad_norm": 1.348618984222412,
      "learning_rate": 3.839294865224967e-06,
      "loss": 0.3457,
      "step": 7889
    },
    {
      "epoch": 1.62,
      "grad_norm": 0.8580400943756104,
      "learning_rate": 3.837245054832428e-06,
      "loss": 0.1988,
      "step": 7890
    },
    {
      "epoch": 1.62,
      "grad_norm": 1.2593506574630737,
      "learning_rate": 3.83519524443989e-06,
      "loss": 0.4214,
      "step": 7891
    },
    {
      "epoch": 1.62,
      "grad_norm": 0.8687012791633606,
      "learning_rate": 3.833145434047351e-06,
      "loss": 0.3163,
      "step": 7892
    },
    {
      "epoch": 1.62,
      "grad_norm": 1.098332405090332,
      "learning_rate": 3.831095623654813e-06,
      "loss": 0.2436,
      "step": 7893
    },
    {
      "epoch": 1.62,
      "grad_norm": 1.2042638063430786,
      "learning_rate": 3.829045813262274e-06,
      "loss": 0.3262,
      "step": 7894
    },
    {
      "epoch": 1.62,
      "grad_norm": 1.512622356414795,
      "learning_rate": 3.826996002869735e-06,
      "loss": 0.3777,
      "step": 7895
    },
    {
      "epoch": 1.62,
      "grad_norm": 1.0935115814208984,
      "learning_rate": 3.824946192477197e-06,
      "loss": 0.3219,
      "step": 7896
    },
    {
      "epoch": 1.62,
      "grad_norm": 1.88546621799469,
      "learning_rate": 3.822896382084658e-06,
      "loss": 0.2881,
      "step": 7897
    },
    {
      "epoch": 1.62,
      "grad_norm": 1.144149661064148,
      "learning_rate": 3.820846571692119e-06,
      "loss": 0.3945,
      "step": 7898
    },
    {
      "epoch": 1.62,
      "grad_norm": 1.2208162546157837,
      "learning_rate": 3.8187967612995805e-06,
      "loss": 0.3077,
      "step": 7899
    },
    {
      "epoch": 1.62,
      "grad_norm": 1.520839810371399,
      "learning_rate": 3.8167469509070415e-06,
      "loss": 0.5142,
      "step": 7900
    },
    {
      "epoch": 1.62,
      "grad_norm": 1.0826950073242188,
      "learning_rate": 3.814697140514503e-06,
      "loss": 0.2511,
      "step": 7901
    },
    {
      "epoch": 1.62,
      "grad_norm": 1.1094765663146973,
      "learning_rate": 3.812647330121964e-06,
      "loss": 0.365,
      "step": 7902
    },
    {
      "epoch": 1.62,
      "grad_norm": 1.0129518508911133,
      "learning_rate": 3.8105975197294254e-06,
      "loss": 0.4838,
      "step": 7903
    },
    {
      "epoch": 1.62,
      "grad_norm": 1.3433881998062134,
      "learning_rate": 3.808547709336887e-06,
      "loss": 0.3236,
      "step": 7904
    },
    {
      "epoch": 1.62,
      "grad_norm": 0.990803062915802,
      "learning_rate": 3.806497898944348e-06,
      "loss": 0.2666,
      "step": 7905
    },
    {
      "epoch": 1.62,
      "grad_norm": 1.3292145729064941,
      "learning_rate": 3.8044480885518093e-06,
      "loss": 0.2229,
      "step": 7906
    },
    {
      "epoch": 1.62,
      "grad_norm": 1.538211703300476,
      "learning_rate": 3.8023982781592707e-06,
      "loss": 0.3508,
      "step": 7907
    },
    {
      "epoch": 1.62,
      "grad_norm": 1.0422745943069458,
      "learning_rate": 3.8003484677667317e-06,
      "loss": 0.3106,
      "step": 7908
    },
    {
      "epoch": 1.62,
      "grad_norm": 1.5211440324783325,
      "learning_rate": 3.798298657374193e-06,
      "loss": 0.4662,
      "step": 7909
    },
    {
      "epoch": 1.62,
      "grad_norm": 1.139552354812622,
      "learning_rate": 3.7962488469816546e-06,
      "loss": 0.314,
      "step": 7910
    },
    {
      "epoch": 1.62,
      "grad_norm": 0.7999612092971802,
      "learning_rate": 3.7941990365891156e-06,
      "loss": 0.3664,
      "step": 7911
    },
    {
      "epoch": 1.62,
      "grad_norm": 1.1806668043136597,
      "learning_rate": 3.792149226196577e-06,
      "loss": 0.3687,
      "step": 7912
    },
    {
      "epoch": 1.62,
      "grad_norm": 0.7545848488807678,
      "learning_rate": 3.7900994158040384e-06,
      "loss": 0.355,
      "step": 7913
    },
    {
      "epoch": 1.62,
      "grad_norm": 1.3012744188308716,
      "learning_rate": 3.7880496054114994e-06,
      "loss": 0.4526,
      "step": 7914
    },
    {
      "epoch": 1.62,
      "grad_norm": 1.1174290180206299,
      "learning_rate": 3.785999795018961e-06,
      "loss": 0.3438,
      "step": 7915
    },
    {
      "epoch": 1.62,
      "grad_norm": 0.9781910181045532,
      "learning_rate": 3.7839499846264223e-06,
      "loss": 0.2661,
      "step": 7916
    },
    {
      "epoch": 1.62,
      "grad_norm": 1.5013158321380615,
      "learning_rate": 3.7819001742338833e-06,
      "loss": 0.4392,
      "step": 7917
    },
    {
      "epoch": 1.62,
      "grad_norm": 1.1243330240249634,
      "learning_rate": 3.7798503638413448e-06,
      "loss": 0.411,
      "step": 7918
    },
    {
      "epoch": 1.62,
      "grad_norm": 1.1446863412857056,
      "learning_rate": 3.777800553448806e-06,
      "loss": 0.3776,
      "step": 7919
    },
    {
      "epoch": 1.62,
      "grad_norm": 0.9862629771232605,
      "learning_rate": 3.775750743056268e-06,
      "loss": 0.3634,
      "step": 7920
    },
    {
      "epoch": 1.62,
      "grad_norm": 1.488640546798706,
      "learning_rate": 3.773700932663729e-06,
      "loss": 0.3613,
      "step": 7921
    },
    {
      "epoch": 1.62,
      "grad_norm": 1.0864644050598145,
      "learning_rate": 3.7716511222711905e-06,
      "loss": 0.3626,
      "step": 7922
    },
    {
      "epoch": 1.62,
      "grad_norm": 1.154654860496521,
      "learning_rate": 3.769601311878652e-06,
      "loss": 0.3297,
      "step": 7923
    },
    {
      "epoch": 1.62,
      "grad_norm": 1.376777172088623,
      "learning_rate": 3.767551501486113e-06,
      "loss": 0.2881,
      "step": 7924
    },
    {
      "epoch": 1.62,
      "grad_norm": 1.0434578657150269,
      "learning_rate": 3.7655016910935744e-06,
      "loss": 0.3027,
      "step": 7925
    },
    {
      "epoch": 1.62,
      "grad_norm": 0.9753662943840027,
      "learning_rate": 3.763451880701036e-06,
      "loss": 0.4529,
      "step": 7926
    },
    {
      "epoch": 1.62,
      "grad_norm": 1.4010884761810303,
      "learning_rate": 3.761402070308497e-06,
      "loss": 0.3099,
      "step": 7927
    },
    {
      "epoch": 1.62,
      "grad_norm": 1.2462568283081055,
      "learning_rate": 3.7593522599159582e-06,
      "loss": 0.3939,
      "step": 7928
    },
    {
      "epoch": 1.62,
      "grad_norm": 1.181337833404541,
      "learning_rate": 3.7573024495234197e-06,
      "loss": 0.3332,
      "step": 7929
    },
    {
      "epoch": 1.62,
      "grad_norm": 0.7189793586730957,
      "learning_rate": 3.7552526391308807e-06,
      "loss": 0.3049,
      "step": 7930
    },
    {
      "epoch": 1.62,
      "grad_norm": 1.1073287725448608,
      "learning_rate": 3.753202828738342e-06,
      "loss": 0.2479,
      "step": 7931
    },
    {
      "epoch": 1.63,
      "grad_norm": 0.6986597776412964,
      "learning_rate": 3.7511530183458035e-06,
      "loss": 0.1932,
      "step": 7932
    },
    {
      "epoch": 1.63,
      "grad_norm": 1.3683161735534668,
      "learning_rate": 3.7491032079532646e-06,
      "loss": 0.4353,
      "step": 7933
    },
    {
      "epoch": 1.63,
      "grad_norm": 1.182485580444336,
      "learning_rate": 3.747053397560726e-06,
      "loss": 0.3283,
      "step": 7934
    },
    {
      "epoch": 1.63,
      "grad_norm": 0.8594739437103271,
      "learning_rate": 3.7450035871681874e-06,
      "loss": 0.2703,
      "step": 7935
    },
    {
      "epoch": 1.63,
      "grad_norm": 1.1314078569412231,
      "learning_rate": 3.7429537767756484e-06,
      "loss": 0.433,
      "step": 7936
    },
    {
      "epoch": 1.63,
      "grad_norm": 1.011108636856079,
      "learning_rate": 3.74090396638311e-06,
      "loss": 0.3424,
      "step": 7937
    },
    {
      "epoch": 1.63,
      "grad_norm": 1.6441783905029297,
      "learning_rate": 3.7388541559905713e-06,
      "loss": 0.4441,
      "step": 7938
    },
    {
      "epoch": 1.63,
      "grad_norm": 1.1866708993911743,
      "learning_rate": 3.7368043455980323e-06,
      "loss": 0.3745,
      "step": 7939
    },
    {
      "epoch": 1.63,
      "grad_norm": 1.2293941974639893,
      "learning_rate": 3.7347545352054937e-06,
      "loss": 0.4516,
      "step": 7940
    },
    {
      "epoch": 1.63,
      "grad_norm": 2.1426806449890137,
      "learning_rate": 3.732704724812955e-06,
      "loss": 0.3566,
      "step": 7941
    },
    {
      "epoch": 1.63,
      "grad_norm": 1.1076768636703491,
      "learning_rate": 3.730654914420416e-06,
      "loss": 0.3742,
      "step": 7942
    },
    {
      "epoch": 1.63,
      "grad_norm": 1.1504753828048706,
      "learning_rate": 3.7286051040278776e-06,
      "loss": 0.3981,
      "step": 7943
    },
    {
      "epoch": 1.63,
      "grad_norm": 1.1139743328094482,
      "learning_rate": 3.726555293635339e-06,
      "loss": 0.2391,
      "step": 7944
    },
    {
      "epoch": 1.63,
      "grad_norm": 1.0548263788223267,
      "learning_rate": 3.7245054832428e-06,
      "loss": 0.3302,
      "step": 7945
    },
    {
      "epoch": 1.63,
      "grad_norm": 1.3144971132278442,
      "learning_rate": 3.7224556728502615e-06,
      "loss": 0.3642,
      "step": 7946
    },
    {
      "epoch": 1.63,
      "grad_norm": 1.4535696506500244,
      "learning_rate": 3.720405862457723e-06,
      "loss": 0.3776,
      "step": 7947
    },
    {
      "epoch": 1.63,
      "grad_norm": 0.8981310129165649,
      "learning_rate": 3.718356052065184e-06,
      "loss": 0.2041,
      "step": 7948
    },
    {
      "epoch": 1.63,
      "grad_norm": 1.3493369817733765,
      "learning_rate": 3.7163062416726454e-06,
      "loss": 0.5048,
      "step": 7949
    },
    {
      "epoch": 1.63,
      "grad_norm": 1.3221505880355835,
      "learning_rate": 3.7142564312801072e-06,
      "loss": 0.2618,
      "step": 7950
    },
    {
      "epoch": 1.63,
      "grad_norm": 1.1356253623962402,
      "learning_rate": 3.7122066208875686e-06,
      "loss": 0.3531,
      "step": 7951
    },
    {
      "epoch": 1.63,
      "grad_norm": 1.5676815509796143,
      "learning_rate": 3.7101568104950297e-06,
      "loss": 0.359,
      "step": 7952
    },
    {
      "epoch": 1.63,
      "grad_norm": 1.4347573518753052,
      "learning_rate": 3.708107000102491e-06,
      "loss": 0.4005,
      "step": 7953
    },
    {
      "epoch": 1.63,
      "grad_norm": 1.4045031070709229,
      "learning_rate": 3.7060571897099525e-06,
      "loss": 0.308,
      "step": 7954
    },
    {
      "epoch": 1.63,
      "grad_norm": 3.7611923217773438,
      "learning_rate": 3.7040073793174135e-06,
      "loss": 0.4007,
      "step": 7955
    },
    {
      "epoch": 1.63,
      "grad_norm": 2.4829518795013428,
      "learning_rate": 3.701957568924875e-06,
      "loss": 0.3202,
      "step": 7956
    },
    {
      "epoch": 1.63,
      "grad_norm": 1.4753237962722778,
      "learning_rate": 3.6999077585323364e-06,
      "loss": 0.3593,
      "step": 7957
    },
    {
      "epoch": 1.63,
      "grad_norm": 1.1041172742843628,
      "learning_rate": 3.6978579481397974e-06,
      "loss": 0.4325,
      "step": 7958
    },
    {
      "epoch": 1.63,
      "grad_norm": 1.2737977504730225,
      "learning_rate": 3.695808137747259e-06,
      "loss": 0.2292,
      "step": 7959
    },
    {
      "epoch": 1.63,
      "grad_norm": 1.5277619361877441,
      "learning_rate": 3.6937583273547203e-06,
      "loss": 0.2717,
      "step": 7960
    },
    {
      "epoch": 1.63,
      "grad_norm": 1.6980736255645752,
      "learning_rate": 3.6917085169621813e-06,
      "loss": 0.2624,
      "step": 7961
    },
    {
      "epoch": 1.63,
      "grad_norm": 1.2789140939712524,
      "learning_rate": 3.6896587065696427e-06,
      "loss": 0.3363,
      "step": 7962
    },
    {
      "epoch": 1.63,
      "grad_norm": 1.893426775932312,
      "learning_rate": 3.6876088961771037e-06,
      "loss": 0.4764,
      "step": 7963
    },
    {
      "epoch": 1.63,
      "grad_norm": 2.1033291816711426,
      "learning_rate": 3.685559085784565e-06,
      "loss": 0.2693,
      "step": 7964
    },
    {
      "epoch": 1.63,
      "grad_norm": 2.657042980194092,
      "learning_rate": 3.6835092753920266e-06,
      "loss": 0.3735,
      "step": 7965
    },
    {
      "epoch": 1.63,
      "grad_norm": 2.3893110752105713,
      "learning_rate": 3.6814594649994876e-06,
      "loss": 0.3715,
      "step": 7966
    },
    {
      "epoch": 1.63,
      "grad_norm": 0.878427267074585,
      "learning_rate": 3.679409654606949e-06,
      "loss": 0.2858,
      "step": 7967
    },
    {
      "epoch": 1.63,
      "grad_norm": 0.960861325263977,
      "learning_rate": 3.6773598442144105e-06,
      "loss": 0.402,
      "step": 7968
    },
    {
      "epoch": 1.63,
      "grad_norm": 4.380918025970459,
      "learning_rate": 3.6753100338218715e-06,
      "loss": 0.3647,
      "step": 7969
    },
    {
      "epoch": 1.63,
      "grad_norm": 1.5203139781951904,
      "learning_rate": 3.673260223429333e-06,
      "loss": 0.4492,
      "step": 7970
    },
    {
      "epoch": 1.63,
      "grad_norm": 2.6711885929107666,
      "learning_rate": 3.6712104130367943e-06,
      "loss": 0.3222,
      "step": 7971
    },
    {
      "epoch": 1.63,
      "grad_norm": 2.672196626663208,
      "learning_rate": 3.6691606026442554e-06,
      "loss": 0.4005,
      "step": 7972
    },
    {
      "epoch": 1.63,
      "grad_norm": 1.1459887027740479,
      "learning_rate": 3.6671107922517168e-06,
      "loss": 0.3761,
      "step": 7973
    },
    {
      "epoch": 1.63,
      "grad_norm": 1.7003488540649414,
      "learning_rate": 3.6650609818591782e-06,
      "loss": 0.357,
      "step": 7974
    },
    {
      "epoch": 1.63,
      "grad_norm": 2.423823833465576,
      "learning_rate": 3.6630111714666392e-06,
      "loss": 0.3068,
      "step": 7975
    },
    {
      "epoch": 1.63,
      "grad_norm": 2.4397714138031006,
      "learning_rate": 3.6609613610741007e-06,
      "loss": 0.4525,
      "step": 7976
    },
    {
      "epoch": 1.63,
      "grad_norm": 3.5736827850341797,
      "learning_rate": 3.658911550681562e-06,
      "loss": 0.3163,
      "step": 7977
    },
    {
      "epoch": 1.63,
      "grad_norm": 3.1068027019500732,
      "learning_rate": 3.656861740289023e-06,
      "loss": 0.4642,
      "step": 7978
    },
    {
      "epoch": 1.63,
      "grad_norm": 0.9753471612930298,
      "learning_rate": 3.654811929896485e-06,
      "loss": 0.3208,
      "step": 7979
    },
    {
      "epoch": 1.63,
      "grad_norm": 2.772886037826538,
      "learning_rate": 3.6527621195039464e-06,
      "loss": 0.27,
      "step": 7980
    },
    {
      "epoch": 1.64,
      "grad_norm": 2.889416217803955,
      "learning_rate": 3.650712309111408e-06,
      "loss": 0.4005,
      "step": 7981
    },
    {
      "epoch": 1.64,
      "grad_norm": 3.4625842571258545,
      "learning_rate": 3.648662498718869e-06,
      "loss": 0.3316,
      "step": 7982
    },
    {
      "epoch": 1.64,
      "grad_norm": 3.0745997428894043,
      "learning_rate": 3.6466126883263303e-06,
      "loss": 0.3028,
      "step": 7983
    },
    {
      "epoch": 1.64,
      "grad_norm": 1.2508105039596558,
      "learning_rate": 3.6445628779337917e-06,
      "loss": 0.4977,
      "step": 7984
    },
    {
      "epoch": 1.64,
      "grad_norm": 1.82333242893219,
      "learning_rate": 3.6425130675412527e-06,
      "loss": 0.2893,
      "step": 7985
    },
    {
      "epoch": 1.64,
      "grad_norm": 1.484472393989563,
      "learning_rate": 3.640463257148714e-06,
      "loss": 0.3571,
      "step": 7986
    },
    {
      "epoch": 1.64,
      "grad_norm": 1.6015862226486206,
      "learning_rate": 3.6384134467561756e-06,
      "loss": 0.2804,
      "step": 7987
    },
    {
      "epoch": 1.64,
      "grad_norm": 1.4291993379592896,
      "learning_rate": 3.6363636363636366e-06,
      "loss": 0.5864,
      "step": 7988
    },
    {
      "epoch": 1.64,
      "grad_norm": 1.2006300687789917,
      "learning_rate": 3.634313825971098e-06,
      "loss": 0.3784,
      "step": 7989
    },
    {
      "epoch": 1.64,
      "grad_norm": 1.1772092580795288,
      "learning_rate": 3.6322640155785594e-06,
      "loss": 0.3399,
      "step": 7990
    },
    {
      "epoch": 1.64,
      "grad_norm": 1.0393704175949097,
      "learning_rate": 3.6302142051860205e-06,
      "loss": 0.3201,
      "step": 7991
    },
    {
      "epoch": 1.64,
      "grad_norm": 1.5576376914978027,
      "learning_rate": 3.628164394793482e-06,
      "loss": 0.3997,
      "step": 7992
    },
    {
      "epoch": 1.64,
      "grad_norm": 2.540093421936035,
      "learning_rate": 3.6261145844009433e-06,
      "loss": 0.3042,
      "step": 7993
    },
    {
      "epoch": 1.64,
      "grad_norm": 1.3811702728271484,
      "learning_rate": 3.6240647740084043e-06,
      "loss": 0.327,
      "step": 7994
    },
    {
      "epoch": 1.64,
      "grad_norm": 1.1839158535003662,
      "learning_rate": 3.6220149636158658e-06,
      "loss": 0.3234,
      "step": 7995
    },
    {
      "epoch": 1.64,
      "grad_norm": 1.0229928493499756,
      "learning_rate": 3.619965153223327e-06,
      "loss": 0.2838,
      "step": 7996
    },
    {
      "epoch": 1.64,
      "grad_norm": 1.514564871788025,
      "learning_rate": 3.617915342830788e-06,
      "loss": 0.3678,
      "step": 7997
    },
    {
      "epoch": 1.64,
      "grad_norm": 1.152125597000122,
      "learning_rate": 3.6158655324382496e-06,
      "loss": 0.2628,
      "step": 7998
    },
    {
      "epoch": 1.64,
      "grad_norm": 2.571502447128296,
      "learning_rate": 3.613815722045711e-06,
      "loss": 0.2982,
      "step": 7999
    },
    {
      "epoch": 1.64,
      "grad_norm": 1.1043604612350464,
      "learning_rate": 3.611765911653172e-06,
      "loss": 0.1402,
      "step": 8000
    },
    {
      "epoch": 1.64,
      "eval_loss": 0.335635781288147,
      "eval_runtime": 671.1771,
      "eval_samples_per_second": 14.899,
      "eval_steps_per_second": 1.862,
      "step": 8000
    },
    {
      "epoch": 1.64,
      "grad_norm": 1.215621829032898,
      "learning_rate": 3.6097161012606335e-06,
      "loss": 0.2619,
      "step": 8001
    },
    {
      "epoch": 1.64,
      "grad_norm": 2.2829527854919434,
      "learning_rate": 3.607666290868095e-06,
      "loss": 0.2871,
      "step": 8002
    },
    {
      "epoch": 1.64,
      "grad_norm": 1.9310595989227295,
      "learning_rate": 3.605616480475556e-06,
      "loss": 0.3725,
      "step": 8003
    },
    {
      "epoch": 1.64,
      "grad_norm": 0.9671750664710999,
      "learning_rate": 3.6035666700830174e-06,
      "loss": 0.3711,
      "step": 8004
    },
    {
      "epoch": 1.64,
      "grad_norm": 1.6338063478469849,
      "learning_rate": 3.601516859690479e-06,
      "loss": 0.3552,
      "step": 8005
    },
    {
      "epoch": 1.64,
      "grad_norm": 0.8172534108161926,
      "learning_rate": 3.59946704929794e-06,
      "loss": 0.1739,
      "step": 8006
    },
    {
      "epoch": 1.64,
      "grad_norm": 1.8963027000427246,
      "learning_rate": 3.5974172389054013e-06,
      "loss": 0.3744,
      "step": 8007
    },
    {
      "epoch": 1.64,
      "grad_norm": 3.27425479888916,
      "learning_rate": 3.5953674285128627e-06,
      "loss": 0.3734,
      "step": 8008
    },
    {
      "epoch": 1.64,
      "grad_norm": 2.4527666568756104,
      "learning_rate": 3.5933176181203246e-06,
      "loss": 0.2787,
      "step": 8009
    },
    {
      "epoch": 1.64,
      "grad_norm": 1.1041127443313599,
      "learning_rate": 3.5912678077277856e-06,
      "loss": 0.3627,
      "step": 8010
    },
    {
      "epoch": 1.64,
      "grad_norm": 1.3937791585922241,
      "learning_rate": 3.589217997335247e-06,
      "loss": 0.252,
      "step": 8011
    },
    {
      "epoch": 1.64,
      "grad_norm": 1.6419042348861694,
      "learning_rate": 3.5871681869427084e-06,
      "loss": 0.3592,
      "step": 8012
    },
    {
      "epoch": 1.64,
      "grad_norm": 1.179512858390808,
      "learning_rate": 3.5851183765501694e-06,
      "loss": 0.3648,
      "step": 8013
    },
    {
      "epoch": 1.64,
      "grad_norm": 1.566910743713379,
      "learning_rate": 3.583068566157631e-06,
      "loss": 0.3775,
      "step": 8014
    },
    {
      "epoch": 1.64,
      "grad_norm": 1.1663124561309814,
      "learning_rate": 3.5810187557650923e-06,
      "loss": 0.2868,
      "step": 8015
    },
    {
      "epoch": 1.64,
      "grad_norm": 1.5001217126846313,
      "learning_rate": 3.5789689453725533e-06,
      "loss": 0.2255,
      "step": 8016
    },
    {
      "epoch": 1.64,
      "grad_norm": 1.5195492506027222,
      "learning_rate": 3.5769191349800147e-06,
      "loss": 0.2623,
      "step": 8017
    },
    {
      "epoch": 1.64,
      "grad_norm": 1.862790822982788,
      "learning_rate": 3.574869324587476e-06,
      "loss": 0.3567,
      "step": 8018
    },
    {
      "epoch": 1.64,
      "grad_norm": 1.1735771894454956,
      "learning_rate": 3.572819514194937e-06,
      "loss": 0.402,
      "step": 8019
    },
    {
      "epoch": 1.64,
      "grad_norm": 1.244307041168213,
      "learning_rate": 3.5707697038023986e-06,
      "loss": 0.3509,
      "step": 8020
    },
    {
      "epoch": 1.64,
      "grad_norm": 1.0672613382339478,
      "learning_rate": 3.56871989340986e-06,
      "loss": 0.2447,
      "step": 8021
    },
    {
      "epoch": 1.64,
      "grad_norm": 1.610164761543274,
      "learning_rate": 3.566670083017321e-06,
      "loss": 0.2036,
      "step": 8022
    },
    {
      "epoch": 1.64,
      "grad_norm": 0.7731977105140686,
      "learning_rate": 3.5646202726247825e-06,
      "loss": 0.2909,
      "step": 8023
    },
    {
      "epoch": 1.64,
      "grad_norm": 1.1954174041748047,
      "learning_rate": 3.562570462232244e-06,
      "loss": 0.5241,
      "step": 8024
    },
    {
      "epoch": 1.64,
      "grad_norm": 1.1206108331680298,
      "learning_rate": 3.560520651839705e-06,
      "loss": 0.3223,
      "step": 8025
    },
    {
      "epoch": 1.64,
      "grad_norm": 2.241292953491211,
      "learning_rate": 3.5584708414471664e-06,
      "loss": 0.4844,
      "step": 8026
    },
    {
      "epoch": 1.64,
      "grad_norm": 1.2613948583602905,
      "learning_rate": 3.556421031054628e-06,
      "loss": 0.3691,
      "step": 8027
    },
    {
      "epoch": 1.64,
      "grad_norm": 1.8346065282821655,
      "learning_rate": 3.554371220662089e-06,
      "loss": 0.3396,
      "step": 8028
    },
    {
      "epoch": 1.64,
      "grad_norm": 2.2801151275634766,
      "learning_rate": 3.5523214102695503e-06,
      "loss": 0.356,
      "step": 8029
    },
    {
      "epoch": 1.65,
      "grad_norm": 1.6046741008758545,
      "learning_rate": 3.5502715998770117e-06,
      "loss": 0.2099,
      "step": 8030
    },
    {
      "epoch": 1.65,
      "grad_norm": 1.3015570640563965,
      "learning_rate": 3.5482217894844727e-06,
      "loss": 0.2979,
      "step": 8031
    },
    {
      "epoch": 1.65,
      "grad_norm": 1.5344327688217163,
      "learning_rate": 3.546171979091934e-06,
      "loss": 0.2309,
      "step": 8032
    },
    {
      "epoch": 1.65,
      "grad_norm": 1.297435998916626,
      "learning_rate": 3.5441221686993956e-06,
      "loss": 0.3282,
      "step": 8033
    },
    {
      "epoch": 1.65,
      "grad_norm": 1.1069998741149902,
      "learning_rate": 3.5420723583068566e-06,
      "loss": 0.4084,
      "step": 8034
    },
    {
      "epoch": 1.65,
      "grad_norm": 1.6169538497924805,
      "learning_rate": 3.540022547914318e-06,
      "loss": 0.4895,
      "step": 8035
    },
    {
      "epoch": 1.65,
      "grad_norm": 1.7199324369430542,
      "learning_rate": 3.5379727375217794e-06,
      "loss": 0.236,
      "step": 8036
    },
    {
      "epoch": 1.65,
      "grad_norm": 1.168792486190796,
      "learning_rate": 3.5359229271292404e-06,
      "loss": 0.4312,
      "step": 8037
    },
    {
      "epoch": 1.65,
      "grad_norm": 1.3105499744415283,
      "learning_rate": 3.5338731167367023e-06,
      "loss": 0.3297,
      "step": 8038
    },
    {
      "epoch": 1.65,
      "grad_norm": 0.7249237895011902,
      "learning_rate": 3.5318233063441637e-06,
      "loss": 0.2517,
      "step": 8039
    },
    {
      "epoch": 1.65,
      "grad_norm": 1.4932830333709717,
      "learning_rate": 3.529773495951625e-06,
      "loss": 0.4235,
      "step": 8040
    },
    {
      "epoch": 1.65,
      "grad_norm": 1.253993034362793,
      "learning_rate": 3.527723685559086e-06,
      "loss": 0.3381,
      "step": 8041
    },
    {
      "epoch": 1.65,
      "grad_norm": 0.8290151953697205,
      "learning_rate": 3.5256738751665476e-06,
      "loss": 0.2312,
      "step": 8042
    },
    {
      "epoch": 1.65,
      "grad_norm": 1.0327517986297607,
      "learning_rate": 3.523624064774009e-06,
      "loss": 0.3545,
      "step": 8043
    },
    {
      "epoch": 1.65,
      "grad_norm": 2.0512850284576416,
      "learning_rate": 3.52157425438147e-06,
      "loss": 0.2598,
      "step": 8044
    },
    {
      "epoch": 1.65,
      "grad_norm": 1.658651351928711,
      "learning_rate": 3.5195244439889315e-06,
      "loss": 0.2408,
      "step": 8045
    },
    {
      "epoch": 1.65,
      "grad_norm": 3.0162482261657715,
      "learning_rate": 3.517474633596393e-06,
      "loss": 0.4218,
      "step": 8046
    },
    {
      "epoch": 1.65,
      "grad_norm": 1.1182966232299805,
      "learning_rate": 3.515424823203854e-06,
      "loss": 0.3469,
      "step": 8047
    },
    {
      "epoch": 1.65,
      "grad_norm": 1.35504150390625,
      "learning_rate": 3.5133750128113154e-06,
      "loss": 0.4178,
      "step": 8048
    },
    {
      "epoch": 1.65,
      "grad_norm": 2.147747039794922,
      "learning_rate": 3.511325202418777e-06,
      "loss": 0.3808,
      "step": 8049
    },
    {
      "epoch": 1.65,
      "grad_norm": 1.2376713752746582,
      "learning_rate": 3.509275392026238e-06,
      "loss": 0.2091,
      "step": 8050
    },
    {
      "epoch": 1.65,
      "grad_norm": 1.0386542081832886,
      "learning_rate": 3.5072255816336992e-06,
      "loss": 0.3123,
      "step": 8051
    },
    {
      "epoch": 1.65,
      "grad_norm": 1.1944259405136108,
      "learning_rate": 3.5051757712411607e-06,
      "loss": 0.5759,
      "step": 8052
    },
    {
      "epoch": 1.65,
      "grad_norm": 1.3780608177185059,
      "learning_rate": 3.5031259608486217e-06,
      "loss": 0.3566,
      "step": 8053
    },
    {
      "epoch": 1.65,
      "grad_norm": 1.828600525856018,
      "learning_rate": 3.501076150456083e-06,
      "loss": 0.3238,
      "step": 8054
    },
    {
      "epoch": 1.65,
      "grad_norm": 1.4333971738815308,
      "learning_rate": 3.4990263400635445e-06,
      "loss": 0.3815,
      "step": 8055
    },
    {
      "epoch": 1.65,
      "grad_norm": 1.212218165397644,
      "learning_rate": 3.4969765296710056e-06,
      "loss": 0.3645,
      "step": 8056
    },
    {
      "epoch": 1.65,
      "grad_norm": 1.0174946784973145,
      "learning_rate": 3.494926719278467e-06,
      "loss": 0.2416,
      "step": 8057
    },
    {
      "epoch": 1.65,
      "grad_norm": 0.8772192597389221,
      "learning_rate": 3.4928769088859284e-06,
      "loss": 0.1685,
      "step": 8058
    },
    {
      "epoch": 1.65,
      "grad_norm": 1.1021428108215332,
      "learning_rate": 3.4908270984933894e-06,
      "loss": 0.3004,
      "step": 8059
    },
    {
      "epoch": 1.65,
      "grad_norm": 1.3906095027923584,
      "learning_rate": 3.488777288100851e-06,
      "loss": 0.5284,
      "step": 8060
    },
    {
      "epoch": 1.65,
      "grad_norm": 1.3466569185256958,
      "learning_rate": 3.4867274777083123e-06,
      "loss": 0.5004,
      "step": 8061
    },
    {
      "epoch": 1.65,
      "grad_norm": 1.9478455781936646,
      "learning_rate": 3.4846776673157733e-06,
      "loss": 0.3101,
      "step": 8062
    },
    {
      "epoch": 1.65,
      "grad_norm": 1.4579740762710571,
      "learning_rate": 3.4826278569232347e-06,
      "loss": 0.3303,
      "step": 8063
    },
    {
      "epoch": 1.65,
      "grad_norm": 1.1046210527420044,
      "learning_rate": 3.480578046530696e-06,
      "loss": 0.4495,
      "step": 8064
    },
    {
      "epoch": 1.65,
      "grad_norm": 1.176810383796692,
      "learning_rate": 3.478528236138157e-06,
      "loss": 0.3883,
      "step": 8065
    },
    {
      "epoch": 1.65,
      "grad_norm": 0.9697279334068298,
      "learning_rate": 3.4764784257456186e-06,
      "loss": 0.3232,
      "step": 8066
    },
    {
      "epoch": 1.65,
      "grad_norm": 1.05018949508667,
      "learning_rate": 3.47442861535308e-06,
      "loss": 0.4131,
      "step": 8067
    },
    {
      "epoch": 1.65,
      "grad_norm": 1.0004403591156006,
      "learning_rate": 3.472378804960542e-06,
      "loss": 0.3393,
      "step": 8068
    },
    {
      "epoch": 1.65,
      "grad_norm": 0.7859222292900085,
      "learning_rate": 3.470328994568003e-06,
      "loss": 0.2338,
      "step": 8069
    },
    {
      "epoch": 1.65,
      "grad_norm": 1.0931209325790405,
      "learning_rate": 3.4682791841754643e-06,
      "loss": 0.3841,
      "step": 8070
    },
    {
      "epoch": 1.65,
      "grad_norm": 1.2502607107162476,
      "learning_rate": 3.4662293737829258e-06,
      "loss": 0.399,
      "step": 8071
    },
    {
      "epoch": 1.65,
      "grad_norm": 0.9780668020248413,
      "learning_rate": 3.4641795633903868e-06,
      "loss": 0.4419,
      "step": 8072
    },
    {
      "epoch": 1.65,
      "grad_norm": 1.4163144826889038,
      "learning_rate": 3.4621297529978482e-06,
      "loss": 0.399,
      "step": 8073
    },
    {
      "epoch": 1.65,
      "grad_norm": 2.083644151687622,
      "learning_rate": 3.4600799426053096e-06,
      "loss": 0.3481,
      "step": 8074
    },
    {
      "epoch": 1.65,
      "grad_norm": 1.3902713060379028,
      "learning_rate": 3.4580301322127707e-06,
      "loss": 0.2586,
      "step": 8075
    },
    {
      "epoch": 1.65,
      "grad_norm": 1.3309540748596191,
      "learning_rate": 3.455980321820232e-06,
      "loss": 0.2561,
      "step": 8076
    },
    {
      "epoch": 1.65,
      "grad_norm": 0.9515267014503479,
      "learning_rate": 3.453930511427693e-06,
      "loss": 0.3684,
      "step": 8077
    },
    {
      "epoch": 1.65,
      "grad_norm": 0.9898625612258911,
      "learning_rate": 3.4518807010351545e-06,
      "loss": 0.5894,
      "step": 8078
    },
    {
      "epoch": 1.66,
      "grad_norm": 1.0818376541137695,
      "learning_rate": 3.449830890642616e-06,
      "loss": 0.3532,
      "step": 8079
    },
    {
      "epoch": 1.66,
      "grad_norm": 0.80668705701828,
      "learning_rate": 3.447781080250077e-06,
      "loss": 0.1898,
      "step": 8080
    },
    {
      "epoch": 1.66,
      "grad_norm": 1.1790887117385864,
      "learning_rate": 3.4457312698575384e-06,
      "loss": 0.3144,
      "step": 8081
    },
    {
      "epoch": 1.66,
      "grad_norm": 1.1702470779418945,
      "learning_rate": 3.443681459465e-06,
      "loss": 0.2415,
      "step": 8082
    },
    {
      "epoch": 1.66,
      "grad_norm": 1.0549722909927368,
      "learning_rate": 3.441631649072461e-06,
      "loss": 0.3907,
      "step": 8083
    },
    {
      "epoch": 1.66,
      "grad_norm": 1.1130098104476929,
      "learning_rate": 3.4395818386799223e-06,
      "loss": 0.3753,
      "step": 8084
    },
    {
      "epoch": 1.66,
      "grad_norm": 1.8541744947433472,
      "learning_rate": 3.4375320282873837e-06,
      "loss": 0.2691,
      "step": 8085
    },
    {
      "epoch": 1.66,
      "grad_norm": 1.418830394744873,
      "learning_rate": 3.4354822178948447e-06,
      "loss": 0.2898,
      "step": 8086
    },
    {
      "epoch": 1.66,
      "grad_norm": 1.0614469051361084,
      "learning_rate": 3.433432407502306e-06,
      "loss": 0.3537,
      "step": 8087
    },
    {
      "epoch": 1.66,
      "grad_norm": 0.81854248046875,
      "learning_rate": 3.4313825971097676e-06,
      "loss": 0.2855,
      "step": 8088
    },
    {
      "epoch": 1.66,
      "grad_norm": 1.1259046792984009,
      "learning_rate": 3.4293327867172286e-06,
      "loss": 0.539,
      "step": 8089
    },
    {
      "epoch": 1.66,
      "grad_norm": 0.8687669634819031,
      "learning_rate": 3.42728297632469e-06,
      "loss": 0.2837,
      "step": 8090
    },
    {
      "epoch": 1.66,
      "grad_norm": 2.2554891109466553,
      "learning_rate": 3.4252331659321515e-06,
      "loss": 0.4307,
      "step": 8091
    },
    {
      "epoch": 1.66,
      "grad_norm": 1.0254573822021484,
      "learning_rate": 3.4231833555396125e-06,
      "loss": 0.3721,
      "step": 8092
    },
    {
      "epoch": 1.66,
      "grad_norm": 1.0501104593276978,
      "learning_rate": 3.421133545147074e-06,
      "loss": 0.4355,
      "step": 8093
    },
    {
      "epoch": 1.66,
      "grad_norm": 2.326523542404175,
      "learning_rate": 3.4190837347545353e-06,
      "loss": 0.3958,
      "step": 8094
    },
    {
      "epoch": 1.66,
      "grad_norm": 1.532884955406189,
      "learning_rate": 3.4170339243619964e-06,
      "loss": 0.2933,
      "step": 8095
    },
    {
      "epoch": 1.66,
      "grad_norm": 1.0536373853683472,
      "learning_rate": 3.4149841139694578e-06,
      "loss": 0.2507,
      "step": 8096
    },
    {
      "epoch": 1.66,
      "grad_norm": 0.9101070761680603,
      "learning_rate": 3.4129343035769196e-06,
      "loss": 0.2071,
      "step": 8097
    },
    {
      "epoch": 1.66,
      "grad_norm": 0.8676990270614624,
      "learning_rate": 3.410884493184381e-06,
      "loss": 0.3058,
      "step": 8098
    },
    {
      "epoch": 1.66,
      "grad_norm": 1.589702844619751,
      "learning_rate": 3.408834682791842e-06,
      "loss": 0.3948,
      "step": 8099
    },
    {
      "epoch": 1.66,
      "grad_norm": 1.3861315250396729,
      "learning_rate": 3.4067848723993035e-06,
      "loss": 0.4596,
      "step": 8100
    },
    {
      "epoch": 1.66,
      "grad_norm": 1.917942762374878,
      "learning_rate": 3.404735062006765e-06,
      "loss": 0.4559,
      "step": 8101
    },
    {
      "epoch": 1.66,
      "grad_norm": 1.2731056213378906,
      "learning_rate": 3.402685251614226e-06,
      "loss": 0.3256,
      "step": 8102
    },
    {
      "epoch": 1.66,
      "grad_norm": 1.9535411596298218,
      "learning_rate": 3.4006354412216874e-06,
      "loss": 0.3161,
      "step": 8103
    },
    {
      "epoch": 1.66,
      "grad_norm": 2.428370475769043,
      "learning_rate": 3.398585630829149e-06,
      "loss": 0.4752,
      "step": 8104
    },
    {
      "epoch": 1.66,
      "grad_norm": 1.9253778457641602,
      "learning_rate": 3.39653582043661e-06,
      "loss": 0.3484,
      "step": 8105
    },
    {
      "epoch": 1.66,
      "grad_norm": 1.3998219966888428,
      "learning_rate": 3.3944860100440713e-06,
      "loss": 0.3169,
      "step": 8106
    },
    {
      "epoch": 1.66,
      "grad_norm": 0.9137298464775085,
      "learning_rate": 3.3924361996515327e-06,
      "loss": 0.2595,
      "step": 8107
    },
    {
      "epoch": 1.66,
      "grad_norm": 1.5490357875823975,
      "learning_rate": 3.3903863892589937e-06,
      "loss": 0.2567,
      "step": 8108
    },
    {
      "epoch": 1.66,
      "grad_norm": 1.4602952003479004,
      "learning_rate": 3.388336578866455e-06,
      "loss": 0.4011,
      "step": 8109
    },
    {
      "epoch": 1.66,
      "grad_norm": 1.8266303539276123,
      "learning_rate": 3.3862867684739166e-06,
      "loss": 0.3693,
      "step": 8110
    },
    {
      "epoch": 1.66,
      "grad_norm": 1.324299931526184,
      "learning_rate": 3.3842369580813776e-06,
      "loss": 0.3391,
      "step": 8111
    },
    {
      "epoch": 1.66,
      "grad_norm": 1.0733009576797485,
      "learning_rate": 3.382187147688839e-06,
      "loss": 0.335,
      "step": 8112
    },
    {
      "epoch": 1.66,
      "grad_norm": 0.9727407693862915,
      "learning_rate": 3.3801373372963004e-06,
      "loss": 0.3092,
      "step": 8113
    },
    {
      "epoch": 1.66,
      "grad_norm": 1.8689264059066772,
      "learning_rate": 3.3780875269037615e-06,
      "loss": 0.2897,
      "step": 8114
    },
    {
      "epoch": 1.66,
      "grad_norm": 1.1988935470581055,
      "learning_rate": 3.376037716511223e-06,
      "loss": 0.3297,
      "step": 8115
    },
    {
      "epoch": 1.66,
      "grad_norm": 0.9054604172706604,
      "learning_rate": 3.3739879061186843e-06,
      "loss": 0.3242,
      "step": 8116
    },
    {
      "epoch": 1.66,
      "grad_norm": 1.0601533651351929,
      "learning_rate": 3.3719380957261453e-06,
      "loss": 0.5027,
      "step": 8117
    },
    {
      "epoch": 1.66,
      "grad_norm": 2.087798833847046,
      "learning_rate": 3.3698882853336068e-06,
      "loss": 0.2098,
      "step": 8118
    },
    {
      "epoch": 1.66,
      "grad_norm": 1.767113208770752,
      "learning_rate": 3.367838474941068e-06,
      "loss": 0.2083,
      "step": 8119
    },
    {
      "epoch": 1.66,
      "grad_norm": 1.8252609968185425,
      "learning_rate": 3.365788664548529e-06,
      "loss": 0.3155,
      "step": 8120
    },
    {
      "epoch": 1.66,
      "grad_norm": 1.4824285507202148,
      "learning_rate": 3.3637388541559906e-06,
      "loss": 0.3916,
      "step": 8121
    },
    {
      "epoch": 1.66,
      "grad_norm": 0.8877735733985901,
      "learning_rate": 3.361689043763452e-06,
      "loss": 0.3179,
      "step": 8122
    },
    {
      "epoch": 1.66,
      "grad_norm": 1.6212931871414185,
      "learning_rate": 3.359639233370913e-06,
      "loss": 0.2598,
      "step": 8123
    },
    {
      "epoch": 1.66,
      "grad_norm": 1.0769307613372803,
      "learning_rate": 3.3575894229783745e-06,
      "loss": 0.4158,
      "step": 8124
    },
    {
      "epoch": 1.66,
      "grad_norm": 1.1675776243209839,
      "learning_rate": 3.355539612585836e-06,
      "loss": 0.1571,
      "step": 8125
    },
    {
      "epoch": 1.66,
      "grad_norm": 1.0905290842056274,
      "learning_rate": 3.353489802193297e-06,
      "loss": 0.2342,
      "step": 8126
    },
    {
      "epoch": 1.67,
      "grad_norm": 0.9409646987915039,
      "learning_rate": 3.351439991800759e-06,
      "loss": 0.322,
      "step": 8127
    },
    {
      "epoch": 1.67,
      "grad_norm": 1.7429317235946655,
      "learning_rate": 3.3493901814082202e-06,
      "loss": 0.3224,
      "step": 8128
    },
    {
      "epoch": 1.67,
      "grad_norm": 0.9231034517288208,
      "learning_rate": 3.3473403710156817e-06,
      "loss": 0.2757,
      "step": 8129
    },
    {
      "epoch": 1.67,
      "grad_norm": 0.8511722683906555,
      "learning_rate": 3.3452905606231427e-06,
      "loss": 0.2055,
      "step": 8130
    },
    {
      "epoch": 1.67,
      "grad_norm": 1.1044689416885376,
      "learning_rate": 3.343240750230604e-06,
      "loss": 0.2468,
      "step": 8131
    },
    {
      "epoch": 1.67,
      "grad_norm": 1.284409761428833,
      "learning_rate": 3.3411909398380656e-06,
      "loss": 0.3141,
      "step": 8132
    },
    {
      "epoch": 1.67,
      "grad_norm": 1.2164944410324097,
      "learning_rate": 3.3391411294455266e-06,
      "loss": 0.3662,
      "step": 8133
    },
    {
      "epoch": 1.67,
      "grad_norm": 1.657759189605713,
      "learning_rate": 3.337091319052988e-06,
      "loss": 0.4078,
      "step": 8134
    },
    {
      "epoch": 1.67,
      "grad_norm": 0.9124917984008789,
      "learning_rate": 3.3350415086604494e-06,
      "loss": 0.2865,
      "step": 8135
    },
    {
      "epoch": 1.67,
      "grad_norm": 0.9457700848579407,
      "learning_rate": 3.3329916982679104e-06,
      "loss": 0.3867,
      "step": 8136
    },
    {
      "epoch": 1.67,
      "grad_norm": 1.6798880100250244,
      "learning_rate": 3.330941887875372e-06,
      "loss": 0.4351,
      "step": 8137
    },
    {
      "epoch": 1.67,
      "grad_norm": 1.5679484605789185,
      "learning_rate": 3.3288920774828333e-06,
      "loss": 0.3691,
      "step": 8138
    },
    {
      "epoch": 1.67,
      "grad_norm": 0.7035538554191589,
      "learning_rate": 3.3268422670902943e-06,
      "loss": 0.1875,
      "step": 8139
    },
    {
      "epoch": 1.67,
      "grad_norm": 1.0316162109375,
      "learning_rate": 3.3247924566977557e-06,
      "loss": 0.3131,
      "step": 8140
    },
    {
      "epoch": 1.67,
      "grad_norm": 1.279948115348816,
      "learning_rate": 3.322742646305217e-06,
      "loss": 0.3777,
      "step": 8141
    },
    {
      "epoch": 1.67,
      "grad_norm": 0.9920613765716553,
      "learning_rate": 3.320692835912678e-06,
      "loss": 0.2819,
      "step": 8142
    },
    {
      "epoch": 1.67,
      "grad_norm": 2.149402379989624,
      "learning_rate": 3.3186430255201396e-06,
      "loss": 0.4203,
      "step": 8143
    },
    {
      "epoch": 1.67,
      "grad_norm": 1.5743300914764404,
      "learning_rate": 3.316593215127601e-06,
      "loss": 0.328,
      "step": 8144
    },
    {
      "epoch": 1.67,
      "grad_norm": 1.2035530805587769,
      "learning_rate": 3.314543404735062e-06,
      "loss": 0.3249,
      "step": 8145
    },
    {
      "epoch": 1.67,
      "grad_norm": 1.319671869277954,
      "learning_rate": 3.3124935943425235e-06,
      "loss": 0.3133,
      "step": 8146
    },
    {
      "epoch": 1.67,
      "grad_norm": 1.3321682214736938,
      "learning_rate": 3.310443783949985e-06,
      "loss": 0.3881,
      "step": 8147
    },
    {
      "epoch": 1.67,
      "grad_norm": 2.178953170776367,
      "learning_rate": 3.308393973557446e-06,
      "loss": 0.3935,
      "step": 8148
    },
    {
      "epoch": 1.67,
      "grad_norm": 1.2518404722213745,
      "learning_rate": 3.3063441631649074e-06,
      "loss": 0.4828,
      "step": 8149
    },
    {
      "epoch": 1.67,
      "grad_norm": 1.9850513935089111,
      "learning_rate": 3.304294352772369e-06,
      "loss": 0.3809,
      "step": 8150
    },
    {
      "epoch": 1.67,
      "grad_norm": 1.223703384399414,
      "learning_rate": 3.30224454237983e-06,
      "loss": 0.3047,
      "step": 8151
    },
    {
      "epoch": 1.67,
      "grad_norm": 1.4177061319351196,
      "learning_rate": 3.3001947319872912e-06,
      "loss": 0.3437,
      "step": 8152
    },
    {
      "epoch": 1.67,
      "grad_norm": 1.0666757822036743,
      "learning_rate": 3.2981449215947527e-06,
      "loss": 0.3052,
      "step": 8153
    },
    {
      "epoch": 1.67,
      "grad_norm": 1.5789676904678345,
      "learning_rate": 3.2960951112022137e-06,
      "loss": 0.392,
      "step": 8154
    },
    {
      "epoch": 1.67,
      "grad_norm": 1.7610149383544922,
      "learning_rate": 3.294045300809675e-06,
      "loss": 0.3041,
      "step": 8155
    },
    {
      "epoch": 1.67,
      "grad_norm": 1.1544455289840698,
      "learning_rate": 3.291995490417137e-06,
      "loss": 0.3341,
      "step": 8156
    },
    {
      "epoch": 1.67,
      "grad_norm": 1.2556953430175781,
      "learning_rate": 3.2899456800245984e-06,
      "loss": 0.3223,
      "step": 8157
    },
    {
      "epoch": 1.67,
      "grad_norm": 1.6257762908935547,
      "learning_rate": 3.2878958696320594e-06,
      "loss": 0.2806,
      "step": 8158
    },
    {
      "epoch": 1.67,
      "grad_norm": 1.2511277198791504,
      "learning_rate": 3.285846059239521e-06,
      "loss": 0.255,
      "step": 8159
    },
    {
      "epoch": 1.67,
      "grad_norm": 1.5162231922149658,
      "learning_rate": 3.2837962488469823e-06,
      "loss": 0.3048,
      "step": 8160
    },
    {
      "epoch": 1.67,
      "grad_norm": 1.2856470346450806,
      "learning_rate": 3.2817464384544433e-06,
      "loss": 0.3383,
      "step": 8161
    },
    {
      "epoch": 1.67,
      "grad_norm": 1.3489199876785278,
      "learning_rate": 3.2796966280619047e-06,
      "loss": 0.4728,
      "step": 8162
    },
    {
      "epoch": 1.67,
      "grad_norm": 1.018118977546692,
      "learning_rate": 3.277646817669366e-06,
      "loss": 0.2802,
      "step": 8163
    },
    {
      "epoch": 1.67,
      "grad_norm": 0.9008721709251404,
      "learning_rate": 3.275597007276827e-06,
      "loss": 0.2324,
      "step": 8164
    },
    {
      "epoch": 1.67,
      "grad_norm": 1.414859652519226,
      "learning_rate": 3.2735471968842886e-06,
      "loss": 0.4097,
      "step": 8165
    },
    {
      "epoch": 1.67,
      "grad_norm": 1.3480886220932007,
      "learning_rate": 3.27149738649175e-06,
      "loss": 0.3722,
      "step": 8166
    },
    {
      "epoch": 1.67,
      "grad_norm": 1.318284511566162,
      "learning_rate": 3.269447576099211e-06,
      "loss": 0.4337,
      "step": 8167
    },
    {
      "epoch": 1.67,
      "grad_norm": 0.7889459133148193,
      "learning_rate": 3.2673977657066725e-06,
      "loss": 0.2508,
      "step": 8168
    },
    {
      "epoch": 1.67,
      "grad_norm": 1.6600180864334106,
      "learning_rate": 3.265347955314134e-06,
      "loss": 0.5207,
      "step": 8169
    },
    {
      "epoch": 1.67,
      "grad_norm": 1.1443854570388794,
      "learning_rate": 3.263298144921595e-06,
      "loss": 0.3022,
      "step": 8170
    },
    {
      "epoch": 1.67,
      "grad_norm": 0.9492584466934204,
      "learning_rate": 3.2612483345290564e-06,
      "loss": 0.3335,
      "step": 8171
    },
    {
      "epoch": 1.67,
      "grad_norm": 1.0642070770263672,
      "learning_rate": 3.259198524136518e-06,
      "loss": 0.3675,
      "step": 8172
    },
    {
      "epoch": 1.67,
      "grad_norm": 1.524471640586853,
      "learning_rate": 3.257148713743979e-06,
      "loss": 0.3378,
      "step": 8173
    },
    {
      "epoch": 1.67,
      "grad_norm": 0.9923441410064697,
      "learning_rate": 3.2550989033514402e-06,
      "loss": 0.3595,
      "step": 8174
    },
    {
      "epoch": 1.67,
      "grad_norm": 0.970220148563385,
      "learning_rate": 3.2530490929589017e-06,
      "loss": 0.2817,
      "step": 8175
    },
    {
      "epoch": 1.68,
      "grad_norm": 1.2872527837753296,
      "learning_rate": 3.2509992825663627e-06,
      "loss": 0.2926,
      "step": 8176
    },
    {
      "epoch": 1.68,
      "grad_norm": 1.5456445217132568,
      "learning_rate": 3.248949472173824e-06,
      "loss": 0.4946,
      "step": 8177
    },
    {
      "epoch": 1.68,
      "grad_norm": 1.2631410360336304,
      "learning_rate": 3.2468996617812855e-06,
      "loss": 0.3329,
      "step": 8178
    },
    {
      "epoch": 1.68,
      "grad_norm": 1.3839892148971558,
      "learning_rate": 3.2448498513887465e-06,
      "loss": 0.3747,
      "step": 8179
    },
    {
      "epoch": 1.68,
      "grad_norm": 1.1630096435546875,
      "learning_rate": 3.242800040996208e-06,
      "loss": 0.4005,
      "step": 8180
    },
    {
      "epoch": 1.68,
      "grad_norm": 1.1517715454101562,
      "learning_rate": 3.2407502306036694e-06,
      "loss": 0.4067,
      "step": 8181
    },
    {
      "epoch": 1.68,
      "grad_norm": 1.1827805042266846,
      "learning_rate": 3.2387004202111304e-06,
      "loss": 0.3886,
      "step": 8182
    },
    {
      "epoch": 1.68,
      "grad_norm": 1.238015055656433,
      "learning_rate": 3.236650609818592e-06,
      "loss": 0.3243,
      "step": 8183
    },
    {
      "epoch": 1.68,
      "grad_norm": 1.4001232385635376,
      "learning_rate": 3.2346007994260533e-06,
      "loss": 0.3559,
      "step": 8184
    },
    {
      "epoch": 1.68,
      "grad_norm": 1.010130524635315,
      "learning_rate": 3.232550989033515e-06,
      "loss": 0.2565,
      "step": 8185
    },
    {
      "epoch": 1.68,
      "grad_norm": 1.2238757610321045,
      "learning_rate": 3.230501178640976e-06,
      "loss": 0.5367,
      "step": 8186
    },
    {
      "epoch": 1.68,
      "grad_norm": 1.2016669511795044,
      "learning_rate": 3.2284513682484376e-06,
      "loss": 0.3501,
      "step": 8187
    },
    {
      "epoch": 1.68,
      "grad_norm": 1.115495204925537,
      "learning_rate": 3.226401557855899e-06,
      "loss": 0.4111,
      "step": 8188
    },
    {
      "epoch": 1.68,
      "grad_norm": 1.3352634906768799,
      "learning_rate": 3.22435174746336e-06,
      "loss": 0.4634,
      "step": 8189
    },
    {
      "epoch": 1.68,
      "grad_norm": 0.9442581534385681,
      "learning_rate": 3.2223019370708215e-06,
      "loss": 0.3178,
      "step": 8190
    },
    {
      "epoch": 1.68,
      "grad_norm": 0.860927164554596,
      "learning_rate": 3.220252126678283e-06,
      "loss": 0.2566,
      "step": 8191
    },
    {
      "epoch": 1.68,
      "grad_norm": 0.9356008768081665,
      "learning_rate": 3.218202316285744e-06,
      "loss": 0.3931,
      "step": 8192
    },
    {
      "epoch": 1.68,
      "grad_norm": 1.1353689432144165,
      "learning_rate": 3.2161525058932053e-06,
      "loss": 0.3553,
      "step": 8193
    },
    {
      "epoch": 1.68,
      "grad_norm": 1.0205299854278564,
      "learning_rate": 3.2141026955006663e-06,
      "loss": 0.4767,
      "step": 8194
    },
    {
      "epoch": 1.68,
      "grad_norm": 1.4948073625564575,
      "learning_rate": 3.2120528851081278e-06,
      "loss": 0.3962,
      "step": 8195
    },
    {
      "epoch": 1.68,
      "grad_norm": 1.1815917491912842,
      "learning_rate": 3.2100030747155892e-06,
      "loss": 0.3738,
      "step": 8196
    },
    {
      "epoch": 1.68,
      "grad_norm": 0.8761774301528931,
      "learning_rate": 3.2079532643230502e-06,
      "loss": 0.269,
      "step": 8197
    },
    {
      "epoch": 1.68,
      "grad_norm": 1.050972819328308,
      "learning_rate": 3.2059034539305117e-06,
      "loss": 0.3066,
      "step": 8198
    },
    {
      "epoch": 1.68,
      "grad_norm": 1.286400556564331,
      "learning_rate": 3.203853643537973e-06,
      "loss": 0.3685,
      "step": 8199
    },
    {
      "epoch": 1.68,
      "grad_norm": 0.8657203912734985,
      "learning_rate": 3.201803833145434e-06,
      "loss": 0.3635,
      "step": 8200
    },
    {
      "epoch": 1.68,
      "grad_norm": 1.1906729936599731,
      "learning_rate": 3.1997540227528955e-06,
      "loss": 0.3344,
      "step": 8201
    },
    {
      "epoch": 1.68,
      "grad_norm": 0.933958113193512,
      "learning_rate": 3.197704212360357e-06,
      "loss": 0.4241,
      "step": 8202
    },
    {
      "epoch": 1.68,
      "grad_norm": 0.8893387913703918,
      "learning_rate": 3.195654401967818e-06,
      "loss": 0.3542,
      "step": 8203
    },
    {
      "epoch": 1.68,
      "grad_norm": 0.958530604839325,
      "learning_rate": 3.1936045915752794e-06,
      "loss": 0.2094,
      "step": 8204
    },
    {
      "epoch": 1.68,
      "grad_norm": 0.8858405947685242,
      "learning_rate": 3.191554781182741e-06,
      "loss": 0.2734,
      "step": 8205
    },
    {
      "epoch": 1.68,
      "grad_norm": 1.326627492904663,
      "learning_rate": 3.189504970790202e-06,
      "loss": 0.2219,
      "step": 8206
    },
    {
      "epoch": 1.68,
      "grad_norm": 1.0658038854599,
      "learning_rate": 3.1874551603976633e-06,
      "loss": 0.3177,
      "step": 8207
    },
    {
      "epoch": 1.68,
      "grad_norm": 1.6196939945220947,
      "learning_rate": 3.1854053500051247e-06,
      "loss": 0.4584,
      "step": 8208
    },
    {
      "epoch": 1.68,
      "grad_norm": 1.7354246377944946,
      "learning_rate": 3.1833555396125857e-06,
      "loss": 0.4292,
      "step": 8209
    },
    {
      "epoch": 1.68,
      "grad_norm": 1.8855140209197998,
      "learning_rate": 3.181305729220047e-06,
      "loss": 0.4207,
      "step": 8210
    },
    {
      "epoch": 1.68,
      "grad_norm": 1.4947049617767334,
      "learning_rate": 3.1792559188275086e-06,
      "loss": 0.4969,
      "step": 8211
    },
    {
      "epoch": 1.68,
      "grad_norm": 1.640887975692749,
      "learning_rate": 3.1772061084349696e-06,
      "loss": 0.4616,
      "step": 8212
    },
    {
      "epoch": 1.68,
      "grad_norm": 0.8543856143951416,
      "learning_rate": 3.175156298042431e-06,
      "loss": 0.3469,
      "step": 8213
    },
    {
      "epoch": 1.68,
      "grad_norm": 1.1964178085327148,
      "learning_rate": 3.1731064876498925e-06,
      "loss": 0.2469,
      "step": 8214
    },
    {
      "epoch": 1.68,
      "grad_norm": 1.053142786026001,
      "learning_rate": 3.1710566772573543e-06,
      "loss": 0.2871,
      "step": 8215
    },
    {
      "epoch": 1.68,
      "grad_norm": 1.179550051689148,
      "learning_rate": 3.1690068668648153e-06,
      "loss": 0.2239,
      "step": 8216
    },
    {
      "epoch": 1.68,
      "grad_norm": 1.3470298051834106,
      "learning_rate": 3.1669570564722768e-06,
      "loss": 0.478,
      "step": 8217
    },
    {
      "epoch": 1.68,
      "grad_norm": 1.135693073272705,
      "learning_rate": 3.164907246079738e-06,
      "loss": 0.217,
      "step": 8218
    },
    {
      "epoch": 1.68,
      "grad_norm": 1.4657081365585327,
      "learning_rate": 3.162857435687199e-06,
      "loss": 0.4289,
      "step": 8219
    },
    {
      "epoch": 1.68,
      "grad_norm": 1.478756308555603,
      "learning_rate": 3.1608076252946606e-06,
      "loss": 0.2104,
      "step": 8220
    },
    {
      "epoch": 1.68,
      "grad_norm": 1.2627474069595337,
      "learning_rate": 3.158757814902122e-06,
      "loss": 0.3278,
      "step": 8221
    },
    {
      "epoch": 1.68,
      "grad_norm": 1.4698772430419922,
      "learning_rate": 3.156708004509583e-06,
      "loss": 0.3504,
      "step": 8222
    },
    {
      "epoch": 1.68,
      "grad_norm": 1.141777515411377,
      "learning_rate": 3.1546581941170445e-06,
      "loss": 0.2094,
      "step": 8223
    },
    {
      "epoch": 1.68,
      "grad_norm": 1.221892237663269,
      "learning_rate": 3.152608383724506e-06,
      "loss": 0.2815,
      "step": 8224
    },
    {
      "epoch": 1.69,
      "grad_norm": 1.0438308715820312,
      "learning_rate": 3.150558573331967e-06,
      "loss": 0.3635,
      "step": 8225
    },
    {
      "epoch": 1.69,
      "grad_norm": 1.176485300064087,
      "learning_rate": 3.1485087629394284e-06,
      "loss": 0.3409,
      "step": 8226
    },
    {
      "epoch": 1.69,
      "grad_norm": 1.402479887008667,
      "learning_rate": 3.14645895254689e-06,
      "loss": 0.4103,
      "step": 8227
    },
    {
      "epoch": 1.69,
      "grad_norm": 1.148682713508606,
      "learning_rate": 3.144409142154351e-06,
      "loss": 0.3157,
      "step": 8228
    },
    {
      "epoch": 1.69,
      "grad_norm": 0.8842675089836121,
      "learning_rate": 3.1423593317618123e-06,
      "loss": 0.2987,
      "step": 8229
    },
    {
      "epoch": 1.69,
      "grad_norm": 1.1394423246383667,
      "learning_rate": 3.1403095213692737e-06,
      "loss": 0.4337,
      "step": 8230
    },
    {
      "epoch": 1.69,
      "grad_norm": 1.8071943521499634,
      "learning_rate": 3.1382597109767347e-06,
      "loss": 0.4297,
      "step": 8231
    },
    {
      "epoch": 1.69,
      "grad_norm": 0.9019967317581177,
      "learning_rate": 3.136209900584196e-06,
      "loss": 0.4106,
      "step": 8232
    },
    {
      "epoch": 1.69,
      "grad_norm": 1.4384982585906982,
      "learning_rate": 3.1341600901916576e-06,
      "loss": 0.4456,
      "step": 8233
    },
    {
      "epoch": 1.69,
      "grad_norm": 0.9997215270996094,
      "learning_rate": 3.1321102797991186e-06,
      "loss": 0.3376,
      "step": 8234
    },
    {
      "epoch": 1.69,
      "grad_norm": 1.5545963048934937,
      "learning_rate": 3.13006046940658e-06,
      "loss": 0.3106,
      "step": 8235
    },
    {
      "epoch": 1.69,
      "grad_norm": 0.9750339388847351,
      "learning_rate": 3.1280106590140414e-06,
      "loss": 0.1912,
      "step": 8236
    },
    {
      "epoch": 1.69,
      "grad_norm": 1.2900609970092773,
      "learning_rate": 3.1259608486215025e-06,
      "loss": 0.4221,
      "step": 8237
    },
    {
      "epoch": 1.69,
      "grad_norm": 1.176062822341919,
      "learning_rate": 3.123911038228964e-06,
      "loss": 0.3003,
      "step": 8238
    },
    {
      "epoch": 1.69,
      "grad_norm": 0.9057784080505371,
      "learning_rate": 3.1218612278364253e-06,
      "loss": 0.3032,
      "step": 8239
    },
    {
      "epoch": 1.69,
      "grad_norm": 0.8601168394088745,
      "learning_rate": 3.1198114174438863e-06,
      "loss": 0.4169,
      "step": 8240
    },
    {
      "epoch": 1.69,
      "grad_norm": 2.2009804248809814,
      "learning_rate": 3.1177616070513478e-06,
      "loss": 0.4198,
      "step": 8241
    },
    {
      "epoch": 1.69,
      "grad_norm": 1.0756583213806152,
      "learning_rate": 3.115711796658809e-06,
      "loss": 0.3987,
      "step": 8242
    },
    {
      "epoch": 1.69,
      "grad_norm": 1.5497474670410156,
      "learning_rate": 3.11366198626627e-06,
      "loss": 0.3093,
      "step": 8243
    },
    {
      "epoch": 1.69,
      "grad_norm": 0.7071263194084167,
      "learning_rate": 3.111612175873732e-06,
      "loss": 0.2881,
      "step": 8244
    },
    {
      "epoch": 1.69,
      "grad_norm": 1.3282864093780518,
      "learning_rate": 3.1095623654811935e-06,
      "loss": 0.3729,
      "step": 8245
    },
    {
      "epoch": 1.69,
      "grad_norm": 0.9872320294380188,
      "learning_rate": 3.107512555088655e-06,
      "loss": 0.2245,
      "step": 8246
    },
    {
      "epoch": 1.69,
      "grad_norm": 0.9328522682189941,
      "learning_rate": 3.105462744696116e-06,
      "loss": 0.2644,
      "step": 8247
    },
    {
      "epoch": 1.69,
      "grad_norm": 1.0926262140274048,
      "learning_rate": 3.1034129343035774e-06,
      "loss": 0.3381,
      "step": 8248
    },
    {
      "epoch": 1.69,
      "grad_norm": 1.07415771484375,
      "learning_rate": 3.101363123911039e-06,
      "loss": 0.3853,
      "step": 8249
    },
    {
      "epoch": 1.69,
      "grad_norm": 1.23570716381073,
      "learning_rate": 3.0993133135185e-06,
      "loss": 0.3869,
      "step": 8250
    },
    {
      "epoch": 1.69,
      "grad_norm": 1.0476621389389038,
      "learning_rate": 3.0972635031259612e-06,
      "loss": 0.2532,
      "step": 8251
    },
    {
      "epoch": 1.69,
      "grad_norm": 1.0401111841201782,
      "learning_rate": 3.0952136927334227e-06,
      "loss": 0.2631,
      "step": 8252
    },
    {
      "epoch": 1.69,
      "grad_norm": 1.2931387424468994,
      "learning_rate": 3.0931638823408837e-06,
      "loss": 0.3082,
      "step": 8253
    },
    {
      "epoch": 1.69,
      "grad_norm": 1.2581249475479126,
      "learning_rate": 3.091114071948345e-06,
      "loss": 0.3796,
      "step": 8254
    },
    {
      "epoch": 1.69,
      "grad_norm": 1.116720199584961,
      "learning_rate": 3.0890642615558066e-06,
      "loss": 0.2795,
      "step": 8255
    },
    {
      "epoch": 1.69,
      "grad_norm": 1.469862937927246,
      "learning_rate": 3.0870144511632676e-06,
      "loss": 0.3239,
      "step": 8256
    },
    {
      "epoch": 1.69,
      "grad_norm": 1.7295159101486206,
      "learning_rate": 3.084964640770729e-06,
      "loss": 0.2777,
      "step": 8257
    },
    {
      "epoch": 1.69,
      "grad_norm": 1.5485494136810303,
      "learning_rate": 3.0829148303781904e-06,
      "loss": 0.2537,
      "step": 8258
    },
    {
      "epoch": 1.69,
      "grad_norm": 2.225942373275757,
      "learning_rate": 3.0808650199856514e-06,
      "loss": 0.343,
      "step": 8259
    },
    {
      "epoch": 1.69,
      "grad_norm": 1.1237854957580566,
      "learning_rate": 3.078815209593113e-06,
      "loss": 0.3854,
      "step": 8260
    },
    {
      "epoch": 1.69,
      "grad_norm": 1.2356500625610352,
      "learning_rate": 3.0767653992005743e-06,
      "loss": 0.5455,
      "step": 8261
    },
    {
      "epoch": 1.69,
      "grad_norm": 3.146188974380493,
      "learning_rate": 3.0747155888080353e-06,
      "loss": 0.2766,
      "step": 8262
    },
    {
      "epoch": 1.69,
      "grad_norm": 2.532979726791382,
      "learning_rate": 3.0726657784154967e-06,
      "loss": 0.2976,
      "step": 8263
    },
    {
      "epoch": 1.69,
      "grad_norm": 2.0553739070892334,
      "learning_rate": 3.070615968022958e-06,
      "loss": 0.5217,
      "step": 8264
    },
    {
      "epoch": 1.69,
      "grad_norm": 1.1581579446792603,
      "learning_rate": 3.068566157630419e-06,
      "loss": 0.3649,
      "step": 8265
    },
    {
      "epoch": 1.69,
      "grad_norm": 1.321269154548645,
      "learning_rate": 3.0665163472378806e-06,
      "loss": 0.317,
      "step": 8266
    },
    {
      "epoch": 1.69,
      "grad_norm": 1.3425828218460083,
      "learning_rate": 3.064466536845342e-06,
      "loss": 0.3262,
      "step": 8267
    },
    {
      "epoch": 1.69,
      "grad_norm": 1.2352092266082764,
      "learning_rate": 3.062416726452803e-06,
      "loss": 0.293,
      "step": 8268
    },
    {
      "epoch": 1.69,
      "grad_norm": 1.190865159034729,
      "learning_rate": 3.0603669160602645e-06,
      "loss": 0.4378,
      "step": 8269
    },
    {
      "epoch": 1.69,
      "grad_norm": 1.1376420259475708,
      "learning_rate": 3.058317105667726e-06,
      "loss": 0.2791,
      "step": 8270
    },
    {
      "epoch": 1.69,
      "grad_norm": 1.180249571800232,
      "learning_rate": 3.056267295275187e-06,
      "loss": 0.2549,
      "step": 8271
    },
    {
      "epoch": 1.69,
      "grad_norm": 0.9296690821647644,
      "learning_rate": 3.0542174848826484e-06,
      "loss": 0.3849,
      "step": 8272
    },
    {
      "epoch": 1.69,
      "grad_norm": 1.1485565900802612,
      "learning_rate": 3.05216767449011e-06,
      "loss": 0.4409,
      "step": 8273
    },
    {
      "epoch": 1.7,
      "grad_norm": 1.6248183250427246,
      "learning_rate": 3.0501178640975717e-06,
      "loss": 0.3834,
      "step": 8274
    },
    {
      "epoch": 1.7,
      "grad_norm": 1.5624299049377441,
      "learning_rate": 3.0480680537050327e-06,
      "loss": 0.3533,
      "step": 8275
    },
    {
      "epoch": 1.7,
      "grad_norm": 1.1671644449234009,
      "learning_rate": 3.046018243312494e-06,
      "loss": 0.3388,
      "step": 8276
    },
    {
      "epoch": 1.7,
      "grad_norm": 2.327868700027466,
      "learning_rate": 3.0439684329199555e-06,
      "loss": 0.415,
      "step": 8277
    },
    {
      "epoch": 1.7,
      "grad_norm": 1.6066994667053223,
      "learning_rate": 3.0419186225274165e-06,
      "loss": 0.2787,
      "step": 8278
    },
    {
      "epoch": 1.7,
      "grad_norm": 1.3388742208480835,
      "learning_rate": 3.039868812134878e-06,
      "loss": 0.4239,
      "step": 8279
    },
    {
      "epoch": 1.7,
      "grad_norm": 1.0336651802062988,
      "learning_rate": 3.0378190017423394e-06,
      "loss": 0.3662,
      "step": 8280
    },
    {
      "epoch": 1.7,
      "grad_norm": 1.1207072734832764,
      "learning_rate": 3.0357691913498004e-06,
      "loss": 0.2893,
      "step": 8281
    },
    {
      "epoch": 1.7,
      "grad_norm": 2.43735408782959,
      "learning_rate": 3.033719380957262e-06,
      "loss": 0.2927,
      "step": 8282
    },
    {
      "epoch": 1.7,
      "grad_norm": 3.299314022064209,
      "learning_rate": 3.0316695705647233e-06,
      "loss": 0.3383,
      "step": 8283
    },
    {
      "epoch": 1.7,
      "grad_norm": 2.065445899963379,
      "learning_rate": 3.0296197601721843e-06,
      "loss": 0.2934,
      "step": 8284
    },
    {
      "epoch": 1.7,
      "grad_norm": 1.4407336711883545,
      "learning_rate": 3.0275699497796457e-06,
      "loss": 0.3671,
      "step": 8285
    },
    {
      "epoch": 1.7,
      "grad_norm": 0.9178458452224731,
      "learning_rate": 3.025520139387107e-06,
      "loss": 0.4604,
      "step": 8286
    },
    {
      "epoch": 1.7,
      "grad_norm": 2.12151837348938,
      "learning_rate": 3.023470328994568e-06,
      "loss": 0.4249,
      "step": 8287
    },
    {
      "epoch": 1.7,
      "grad_norm": 2.835383892059326,
      "learning_rate": 3.0214205186020296e-06,
      "loss": 0.345,
      "step": 8288
    },
    {
      "epoch": 1.7,
      "grad_norm": 3.4954471588134766,
      "learning_rate": 3.019370708209491e-06,
      "loss": 0.303,
      "step": 8289
    },
    {
      "epoch": 1.7,
      "grad_norm": 1.0592386722564697,
      "learning_rate": 3.017320897816952e-06,
      "loss": 0.4515,
      "step": 8290
    },
    {
      "epoch": 1.7,
      "grad_norm": 1.676598310470581,
      "learning_rate": 3.0152710874244135e-06,
      "loss": 0.3704,
      "step": 8291
    },
    {
      "epoch": 1.7,
      "grad_norm": 1.0661256313323975,
      "learning_rate": 3.013221277031875e-06,
      "loss": 0.4052,
      "step": 8292
    },
    {
      "epoch": 1.7,
      "grad_norm": 0.954117476940155,
      "learning_rate": 3.011171466639336e-06,
      "loss": 0.3059,
      "step": 8293
    },
    {
      "epoch": 1.7,
      "grad_norm": 1.9728164672851562,
      "learning_rate": 3.0091216562467974e-06,
      "loss": 0.4614,
      "step": 8294
    },
    {
      "epoch": 1.7,
      "grad_norm": 0.959517776966095,
      "learning_rate": 3.007071845854259e-06,
      "loss": 0.3103,
      "step": 8295
    },
    {
      "epoch": 1.7,
      "grad_norm": 2.7641003131866455,
      "learning_rate": 3.00502203546172e-06,
      "loss": 0.2582,
      "step": 8296
    },
    {
      "epoch": 1.7,
      "grad_norm": 1.4768872261047363,
      "learning_rate": 3.0029722250691812e-06,
      "loss": 0.4614,
      "step": 8297
    },
    {
      "epoch": 1.7,
      "grad_norm": 1.2238144874572754,
      "learning_rate": 3.0009224146766427e-06,
      "loss": 0.3281,
      "step": 8298
    },
    {
      "epoch": 1.7,
      "grad_norm": 1.6565302610397339,
      "learning_rate": 2.9988726042841037e-06,
      "loss": 0.4449,
      "step": 8299
    },
    {
      "epoch": 1.7,
      "grad_norm": 1.3000245094299316,
      "learning_rate": 2.996822793891565e-06,
      "loss": 0.3339,
      "step": 8300
    },
    {
      "epoch": 1.7,
      "grad_norm": 1.0066499710083008,
      "learning_rate": 2.9947729834990265e-06,
      "loss": 0.2534,
      "step": 8301
    },
    {
      "epoch": 1.7,
      "grad_norm": 1.071921467781067,
      "learning_rate": 2.9927231731064875e-06,
      "loss": 0.2338,
      "step": 8302
    },
    {
      "epoch": 1.7,
      "grad_norm": 1.0424407720565796,
      "learning_rate": 2.9906733627139494e-06,
      "loss": 0.2949,
      "step": 8303
    },
    {
      "epoch": 1.7,
      "grad_norm": 1.1125175952911377,
      "learning_rate": 2.988623552321411e-06,
      "loss": 0.3316,
      "step": 8304
    },
    {
      "epoch": 1.7,
      "grad_norm": 2.6106696128845215,
      "learning_rate": 2.9865737419288723e-06,
      "loss": 0.4693,
      "step": 8305
    },
    {
      "epoch": 1.7,
      "grad_norm": 1.1299101114273071,
      "learning_rate": 2.9845239315363333e-06,
      "loss": 0.2833,
      "step": 8306
    },
    {
      "epoch": 1.7,
      "grad_norm": 1.071926474571228,
      "learning_rate": 2.9824741211437947e-06,
      "loss": 0.2366,
      "step": 8307
    },
    {
      "epoch": 1.7,
      "grad_norm": 1.2749767303466797,
      "learning_rate": 2.9804243107512557e-06,
      "loss": 0.4504,
      "step": 8308
    },
    {
      "epoch": 1.7,
      "grad_norm": 1.0988218784332275,
      "learning_rate": 2.978374500358717e-06,
      "loss": 0.2791,
      "step": 8309
    },
    {
      "epoch": 1.7,
      "grad_norm": 0.8700575232505798,
      "learning_rate": 2.9763246899661786e-06,
      "loss": 0.429,
      "step": 8310
    },
    {
      "epoch": 1.7,
      "grad_norm": 0.6502669453620911,
      "learning_rate": 2.9742748795736396e-06,
      "loss": 0.1627,
      "step": 8311
    },
    {
      "epoch": 1.7,
      "grad_norm": 1.080642580986023,
      "learning_rate": 2.972225069181101e-06,
      "loss": 0.3595,
      "step": 8312
    },
    {
      "epoch": 1.7,
      "grad_norm": 1.5276654958724976,
      "learning_rate": 2.9701752587885625e-06,
      "loss": 0.2854,
      "step": 8313
    },
    {
      "epoch": 1.7,
      "grad_norm": 1.061258316040039,
      "learning_rate": 2.9681254483960235e-06,
      "loss": 0.3397,
      "step": 8314
    },
    {
      "epoch": 1.7,
      "grad_norm": 0.7930666208267212,
      "learning_rate": 2.966075638003485e-06,
      "loss": 0.3447,
      "step": 8315
    },
    {
      "epoch": 1.7,
      "grad_norm": 0.812615692615509,
      "learning_rate": 2.9640258276109463e-06,
      "loss": 0.2492,
      "step": 8316
    },
    {
      "epoch": 1.7,
      "grad_norm": 2.332974433898926,
      "learning_rate": 2.9619760172184073e-06,
      "loss": 0.4034,
      "step": 8317
    },
    {
      "epoch": 1.7,
      "grad_norm": 1.7138265371322632,
      "learning_rate": 2.9599262068258688e-06,
      "loss": 0.2685,
      "step": 8318
    },
    {
      "epoch": 1.7,
      "grad_norm": 0.7608845233917236,
      "learning_rate": 2.9578763964333302e-06,
      "loss": 0.2084,
      "step": 8319
    },
    {
      "epoch": 1.7,
      "grad_norm": 1.0022435188293457,
      "learning_rate": 2.9558265860407912e-06,
      "loss": 0.3597,
      "step": 8320
    },
    {
      "epoch": 1.7,
      "grad_norm": 1.116876244544983,
      "learning_rate": 2.9537767756482527e-06,
      "loss": 0.3184,
      "step": 8321
    },
    {
      "epoch": 1.7,
      "grad_norm": 1.0733113288879395,
      "learning_rate": 2.951726965255714e-06,
      "loss": 0.3569,
      "step": 8322
    },
    {
      "epoch": 1.71,
      "grad_norm": 1.0931744575500488,
      "learning_rate": 2.949677154863175e-06,
      "loss": 0.3576,
      "step": 8323
    },
    {
      "epoch": 1.71,
      "grad_norm": 1.0175275802612305,
      "learning_rate": 2.9476273444706365e-06,
      "loss": 0.3973,
      "step": 8324
    },
    {
      "epoch": 1.71,
      "grad_norm": 1.348915457725525,
      "learning_rate": 2.945577534078098e-06,
      "loss": 0.369,
      "step": 8325
    },
    {
      "epoch": 1.71,
      "grad_norm": 1.9711021184921265,
      "learning_rate": 2.943527723685559e-06,
      "loss": 0.3572,
      "step": 8326
    },
    {
      "epoch": 1.71,
      "grad_norm": 1.1954727172851562,
      "learning_rate": 2.9414779132930204e-06,
      "loss": 0.4314,
      "step": 8327
    },
    {
      "epoch": 1.71,
      "grad_norm": 1.7505759000778198,
      "learning_rate": 2.939428102900482e-06,
      "loss": 0.4618,
      "step": 8328
    },
    {
      "epoch": 1.71,
      "grad_norm": 0.7939024567604065,
      "learning_rate": 2.937378292507943e-06,
      "loss": 0.2088,
      "step": 8329
    },
    {
      "epoch": 1.71,
      "grad_norm": 1.1410601139068604,
      "learning_rate": 2.9353284821154043e-06,
      "loss": 0.3843,
      "step": 8330
    },
    {
      "epoch": 1.71,
      "grad_norm": 0.9575479626655579,
      "learning_rate": 2.9332786717228657e-06,
      "loss": 0.3647,
      "step": 8331
    },
    {
      "epoch": 1.71,
      "grad_norm": 1.4919617176055908,
      "learning_rate": 2.9312288613303267e-06,
      "loss": 0.3558,
      "step": 8332
    },
    {
      "epoch": 1.71,
      "grad_norm": 1.09568452835083,
      "learning_rate": 2.9291790509377886e-06,
      "loss": 0.3604,
      "step": 8333
    },
    {
      "epoch": 1.71,
      "grad_norm": 1.1003568172454834,
      "learning_rate": 2.92712924054525e-06,
      "loss": 0.2524,
      "step": 8334
    },
    {
      "epoch": 1.71,
      "grad_norm": 1.0995030403137207,
      "learning_rate": 2.9250794301527114e-06,
      "loss": 0.3034,
      "step": 8335
    },
    {
      "epoch": 1.71,
      "grad_norm": 0.7284312844276428,
      "learning_rate": 2.9230296197601725e-06,
      "loss": 0.2273,
      "step": 8336
    },
    {
      "epoch": 1.71,
      "grad_norm": 1.426039457321167,
      "learning_rate": 2.920979809367634e-06,
      "loss": 0.2304,
      "step": 8337
    },
    {
      "epoch": 1.71,
      "grad_norm": 0.8347621560096741,
      "learning_rate": 2.9189299989750953e-06,
      "loss": 0.29,
      "step": 8338
    },
    {
      "epoch": 1.71,
      "grad_norm": 1.2858046293258667,
      "learning_rate": 2.9168801885825563e-06,
      "loss": 0.2394,
      "step": 8339
    },
    {
      "epoch": 1.71,
      "grad_norm": 2.0527467727661133,
      "learning_rate": 2.9148303781900178e-06,
      "loss": 0.1988,
      "step": 8340
    },
    {
      "epoch": 1.71,
      "grad_norm": 0.9749580025672913,
      "learning_rate": 2.912780567797479e-06,
      "loss": 0.3404,
      "step": 8341
    },
    {
      "epoch": 1.71,
      "grad_norm": 0.8095377087593079,
      "learning_rate": 2.91073075740494e-06,
      "loss": 0.3179,
      "step": 8342
    },
    {
      "epoch": 1.71,
      "grad_norm": 1.1641124486923218,
      "learning_rate": 2.9086809470124016e-06,
      "loss": 0.3042,
      "step": 8343
    },
    {
      "epoch": 1.71,
      "grad_norm": 0.932979941368103,
      "learning_rate": 2.906631136619863e-06,
      "loss": 0.265,
      "step": 8344
    },
    {
      "epoch": 1.71,
      "grad_norm": 0.9371810555458069,
      "learning_rate": 2.904581326227324e-06,
      "loss": 0.2959,
      "step": 8345
    },
    {
      "epoch": 1.71,
      "grad_norm": 2.0067248344421387,
      "learning_rate": 2.9025315158347855e-06,
      "loss": 0.3265,
      "step": 8346
    },
    {
      "epoch": 1.71,
      "grad_norm": 0.9998496770858765,
      "learning_rate": 2.900481705442247e-06,
      "loss": 0.446,
      "step": 8347
    },
    {
      "epoch": 1.71,
      "grad_norm": 1.162241816520691,
      "learning_rate": 2.898431895049708e-06,
      "loss": 0.3628,
      "step": 8348
    },
    {
      "epoch": 1.71,
      "grad_norm": 1.1506377458572388,
      "learning_rate": 2.8963820846571694e-06,
      "loss": 0.3928,
      "step": 8349
    },
    {
      "epoch": 1.71,
      "grad_norm": 1.8364441394805908,
      "learning_rate": 2.894332274264631e-06,
      "loss": 0.4434,
      "step": 8350
    },
    {
      "epoch": 1.71,
      "grad_norm": 2.2683563232421875,
      "learning_rate": 2.892282463872092e-06,
      "loss": 0.3087,
      "step": 8351
    },
    {
      "epoch": 1.71,
      "grad_norm": 1.0972744226455688,
      "learning_rate": 2.8902326534795533e-06,
      "loss": 0.3157,
      "step": 8352
    },
    {
      "epoch": 1.71,
      "grad_norm": 1.1697145700454712,
      "learning_rate": 2.8881828430870147e-06,
      "loss": 0.2728,
      "step": 8353
    },
    {
      "epoch": 1.71,
      "grad_norm": 1.0879186391830444,
      "learning_rate": 2.8861330326944757e-06,
      "loss": 0.2883,
      "step": 8354
    },
    {
      "epoch": 1.71,
      "grad_norm": 1.3369454145431519,
      "learning_rate": 2.884083222301937e-06,
      "loss": 0.2156,
      "step": 8355
    },
    {
      "epoch": 1.71,
      "grad_norm": 1.1415387392044067,
      "learning_rate": 2.8820334119093986e-06,
      "loss": 0.1863,
      "step": 8356
    },
    {
      "epoch": 1.71,
      "grad_norm": 0.9416122436523438,
      "learning_rate": 2.8799836015168596e-06,
      "loss": 0.2837,
      "step": 8357
    },
    {
      "epoch": 1.71,
      "grad_norm": 0.9555462002754211,
      "learning_rate": 2.877933791124321e-06,
      "loss": 0.3245,
      "step": 8358
    },
    {
      "epoch": 1.71,
      "grad_norm": 1.1346240043640137,
      "learning_rate": 2.8758839807317824e-06,
      "loss": 0.4728,
      "step": 8359
    },
    {
      "epoch": 1.71,
      "grad_norm": 1.9427241086959839,
      "learning_rate": 2.8738341703392435e-06,
      "loss": 0.313,
      "step": 8360
    },
    {
      "epoch": 1.71,
      "grad_norm": 1.0615805387496948,
      "learning_rate": 2.871784359946705e-06,
      "loss": 0.3961,
      "step": 8361
    },
    {
      "epoch": 1.71,
      "grad_norm": 1.2366820573806763,
      "learning_rate": 2.8697345495541667e-06,
      "loss": 0.2985,
      "step": 8362
    },
    {
      "epoch": 1.71,
      "grad_norm": 0.8120084404945374,
      "learning_rate": 2.867684739161628e-06,
      "loss": 0.2941,
      "step": 8363
    },
    {
      "epoch": 1.71,
      "grad_norm": 0.8981217741966248,
      "learning_rate": 2.865634928769089e-06,
      "loss": 0.3165,
      "step": 8364
    },
    {
      "epoch": 1.71,
      "grad_norm": 0.9917736649513245,
      "learning_rate": 2.8635851183765506e-06,
      "loss": 0.2776,
      "step": 8365
    },
    {
      "epoch": 1.71,
      "grad_norm": 1.466302752494812,
      "learning_rate": 2.861535307984012e-06,
      "loss": 0.4392,
      "step": 8366
    },
    {
      "epoch": 1.71,
      "grad_norm": 0.805854082107544,
      "learning_rate": 2.859485497591473e-06,
      "loss": 0.3204,
      "step": 8367
    },
    {
      "epoch": 1.71,
      "grad_norm": 1.2649579048156738,
      "learning_rate": 2.8574356871989345e-06,
      "loss": 0.2235,
      "step": 8368
    },
    {
      "epoch": 1.71,
      "grad_norm": 2.4454855918884277,
      "learning_rate": 2.855385876806396e-06,
      "loss": 0.5397,
      "step": 8369
    },
    {
      "epoch": 1.71,
      "grad_norm": 1.5099092721939087,
      "learning_rate": 2.853336066413857e-06,
      "loss": 0.3128,
      "step": 8370
    },
    {
      "epoch": 1.72,
      "grad_norm": 2.362046718597412,
      "learning_rate": 2.8512862560213184e-06,
      "loss": 0.3798,
      "step": 8371
    },
    {
      "epoch": 1.72,
      "grad_norm": 1.6916414499282837,
      "learning_rate": 2.84923644562878e-06,
      "loss": 0.2943,
      "step": 8372
    },
    {
      "epoch": 1.72,
      "grad_norm": 1.3409348726272583,
      "learning_rate": 2.847186635236241e-06,
      "loss": 0.3412,
      "step": 8373
    },
    {
      "epoch": 1.72,
      "grad_norm": 0.8759554028511047,
      "learning_rate": 2.8451368248437022e-06,
      "loss": 0.2524,
      "step": 8374
    },
    {
      "epoch": 1.72,
      "grad_norm": 1.316659927368164,
      "learning_rate": 2.8430870144511637e-06,
      "loss": 0.3354,
      "step": 8375
    },
    {
      "epoch": 1.72,
      "grad_norm": 1.848693609237671,
      "learning_rate": 2.8410372040586247e-06,
      "loss": 0.2799,
      "step": 8376
    },
    {
      "epoch": 1.72,
      "grad_norm": 1.5842608213424683,
      "learning_rate": 2.838987393666086e-06,
      "loss": 0.3718,
      "step": 8377
    },
    {
      "epoch": 1.72,
      "grad_norm": 1.2248384952545166,
      "learning_rate": 2.8369375832735476e-06,
      "loss": 0.3679,
      "step": 8378
    },
    {
      "epoch": 1.72,
      "grad_norm": 0.8837701678276062,
      "learning_rate": 2.8348877728810086e-06,
      "loss": 0.2913,
      "step": 8379
    },
    {
      "epoch": 1.72,
      "grad_norm": 1.0260567665100098,
      "learning_rate": 2.83283796248847e-06,
      "loss": 0.2743,
      "step": 8380
    },
    {
      "epoch": 1.72,
      "grad_norm": 1.7161533832550049,
      "learning_rate": 2.8307881520959314e-06,
      "loss": 0.3269,
      "step": 8381
    },
    {
      "epoch": 1.72,
      "grad_norm": 1.2100948095321655,
      "learning_rate": 2.8287383417033924e-06,
      "loss": 0.295,
      "step": 8382
    },
    {
      "epoch": 1.72,
      "grad_norm": 0.8752740621566772,
      "learning_rate": 2.826688531310854e-06,
      "loss": 0.2269,
      "step": 8383
    },
    {
      "epoch": 1.72,
      "grad_norm": 0.9401921629905701,
      "learning_rate": 2.8246387209183153e-06,
      "loss": 0.2656,
      "step": 8384
    },
    {
      "epoch": 1.72,
      "grad_norm": 1.6504534482955933,
      "learning_rate": 2.8225889105257763e-06,
      "loss": 0.2602,
      "step": 8385
    },
    {
      "epoch": 1.72,
      "grad_norm": 1.1803697347640991,
      "learning_rate": 2.8205391001332377e-06,
      "loss": 0.3111,
      "step": 8386
    },
    {
      "epoch": 1.72,
      "grad_norm": 1.1089162826538086,
      "learning_rate": 2.818489289740699e-06,
      "loss": 0.3587,
      "step": 8387
    },
    {
      "epoch": 1.72,
      "grad_norm": 0.8936041593551636,
      "learning_rate": 2.81643947934816e-06,
      "loss": 0.2623,
      "step": 8388
    },
    {
      "epoch": 1.72,
      "grad_norm": 1.0372639894485474,
      "learning_rate": 2.8143896689556216e-06,
      "loss": 0.3416,
      "step": 8389
    },
    {
      "epoch": 1.72,
      "grad_norm": 1.1121478080749512,
      "learning_rate": 2.812339858563083e-06,
      "loss": 0.4005,
      "step": 8390
    },
    {
      "epoch": 1.72,
      "grad_norm": 1.2631988525390625,
      "learning_rate": 2.810290048170544e-06,
      "loss": 0.294,
      "step": 8391
    },
    {
      "epoch": 1.72,
      "grad_norm": 1.4242982864379883,
      "learning_rate": 2.808240237778006e-06,
      "loss": 0.4403,
      "step": 8392
    },
    {
      "epoch": 1.72,
      "grad_norm": 1.0113085508346558,
      "learning_rate": 2.8061904273854674e-06,
      "loss": 0.3615,
      "step": 8393
    },
    {
      "epoch": 1.72,
      "grad_norm": 1.2568460702896118,
      "learning_rate": 2.8041406169929288e-06,
      "loss": 0.3948,
      "step": 8394
    },
    {
      "epoch": 1.72,
      "grad_norm": 1.3724921941757202,
      "learning_rate": 2.80209080660039e-06,
      "loss": 0.307,
      "step": 8395
    },
    {
      "epoch": 1.72,
      "grad_norm": 1.0279630422592163,
      "learning_rate": 2.8000409962078512e-06,
      "loss": 0.3484,
      "step": 8396
    },
    {
      "epoch": 1.72,
      "grad_norm": 0.9594146609306335,
      "learning_rate": 2.7979911858153127e-06,
      "loss": 0.2542,
      "step": 8397
    },
    {
      "epoch": 1.72,
      "grad_norm": 0.9700533151626587,
      "learning_rate": 2.7959413754227737e-06,
      "loss": 0.1992,
      "step": 8398
    },
    {
      "epoch": 1.72,
      "grad_norm": 1.3856254816055298,
      "learning_rate": 2.793891565030235e-06,
      "loss": 0.368,
      "step": 8399
    },
    {
      "epoch": 1.72,
      "grad_norm": 1.1076496839523315,
      "learning_rate": 2.7918417546376965e-06,
      "loss": 0.42,
      "step": 8400
    },
    {
      "epoch": 1.72,
      "grad_norm": 1.0215836763381958,
      "learning_rate": 2.7897919442451575e-06,
      "loss": 0.2887,
      "step": 8401
    },
    {
      "epoch": 1.72,
      "grad_norm": 1.0126076936721802,
      "learning_rate": 2.787742133852619e-06,
      "loss": 0.3526,
      "step": 8402
    },
    {
      "epoch": 1.72,
      "grad_norm": 1.2637859582901,
      "learning_rate": 2.7856923234600804e-06,
      "loss": 0.3397,
      "step": 8403
    },
    {
      "epoch": 1.72,
      "grad_norm": 0.9095145463943481,
      "learning_rate": 2.7836425130675414e-06,
      "loss": 0.2984,
      "step": 8404
    },
    {
      "epoch": 1.72,
      "grad_norm": 1.178829550743103,
      "learning_rate": 2.781592702675003e-06,
      "loss": 0.3533,
      "step": 8405
    },
    {
      "epoch": 1.72,
      "grad_norm": 1.429265022277832,
      "learning_rate": 2.7795428922824643e-06,
      "loss": 0.4164,
      "step": 8406
    },
    {
      "epoch": 1.72,
      "grad_norm": 1.9998358488082886,
      "learning_rate": 2.7774930818899253e-06,
      "loss": 0.3668,
      "step": 8407
    },
    {
      "epoch": 1.72,
      "grad_norm": 1.326999306678772,
      "learning_rate": 2.7754432714973867e-06,
      "loss": 0.2911,
      "step": 8408
    },
    {
      "epoch": 1.72,
      "grad_norm": 0.8617606163024902,
      "learning_rate": 2.773393461104848e-06,
      "loss": 0.3921,
      "step": 8409
    },
    {
      "epoch": 1.72,
      "grad_norm": 1.2463935613632202,
      "learning_rate": 2.771343650712309e-06,
      "loss": 0.3186,
      "step": 8410
    },
    {
      "epoch": 1.72,
      "grad_norm": 1.440982460975647,
      "learning_rate": 2.7692938403197706e-06,
      "loss": 0.1744,
      "step": 8411
    },
    {
      "epoch": 1.72,
      "grad_norm": 1.3746589422225952,
      "learning_rate": 2.767244029927232e-06,
      "loss": 0.4034,
      "step": 8412
    },
    {
      "epoch": 1.72,
      "grad_norm": 1.1371972560882568,
      "learning_rate": 2.765194219534693e-06,
      "loss": 0.3677,
      "step": 8413
    },
    {
      "epoch": 1.72,
      "grad_norm": 1.4198355674743652,
      "learning_rate": 2.7631444091421545e-06,
      "loss": 0.3942,
      "step": 8414
    },
    {
      "epoch": 1.72,
      "grad_norm": 1.715510606765747,
      "learning_rate": 2.761094598749616e-06,
      "loss": 0.3382,
      "step": 8415
    },
    {
      "epoch": 1.72,
      "grad_norm": 1.5546526908874512,
      "learning_rate": 2.759044788357077e-06,
      "loss": 0.263,
      "step": 8416
    },
    {
      "epoch": 1.72,
      "grad_norm": 1.3263691663742065,
      "learning_rate": 2.7569949779645384e-06,
      "loss": 0.3338,
      "step": 8417
    },
    {
      "epoch": 1.72,
      "grad_norm": 2.765080451965332,
      "learning_rate": 2.7549451675719998e-06,
      "loss": 0.4512,
      "step": 8418
    },
    {
      "epoch": 1.72,
      "grad_norm": 1.116418480873108,
      "learning_rate": 2.752895357179461e-06,
      "loss": 0.361,
      "step": 8419
    },
    {
      "epoch": 1.73,
      "grad_norm": 1.2551621198654175,
      "learning_rate": 2.7508455467869222e-06,
      "loss": 0.3516,
      "step": 8420
    },
    {
      "epoch": 1.73,
      "grad_norm": 1.5254753828048706,
      "learning_rate": 2.748795736394384e-06,
      "loss": 0.3946,
      "step": 8421
    },
    {
      "epoch": 1.73,
      "grad_norm": 0.7586336731910706,
      "learning_rate": 2.7467459260018455e-06,
      "loss": 0.3571,
      "step": 8422
    },
    {
      "epoch": 1.73,
      "grad_norm": 1.158881664276123,
      "learning_rate": 2.7446961156093065e-06,
      "loss": 0.2652,
      "step": 8423
    },
    {
      "epoch": 1.73,
      "grad_norm": 0.917518138885498,
      "learning_rate": 2.742646305216768e-06,
      "loss": 0.3246,
      "step": 8424
    },
    {
      "epoch": 1.73,
      "grad_norm": 0.9433670043945312,
      "learning_rate": 2.740596494824229e-06,
      "loss": 0.3569,
      "step": 8425
    },
    {
      "epoch": 1.73,
      "grad_norm": 0.9105364084243774,
      "learning_rate": 2.7385466844316904e-06,
      "loss": 0.2316,
      "step": 8426
    },
    {
      "epoch": 1.73,
      "grad_norm": 1.561486840248108,
      "learning_rate": 2.736496874039152e-06,
      "loss": 0.3985,
      "step": 8427
    },
    {
      "epoch": 1.73,
      "grad_norm": 0.9333156943321228,
      "learning_rate": 2.734447063646613e-06,
      "loss": 0.2136,
      "step": 8428
    },
    {
      "epoch": 1.73,
      "grad_norm": 0.7414950728416443,
      "learning_rate": 2.7323972532540743e-06,
      "loss": 0.2031,
      "step": 8429
    },
    {
      "epoch": 1.73,
      "grad_norm": 0.914868175983429,
      "learning_rate": 2.7303474428615357e-06,
      "loss": 0.275,
      "step": 8430
    },
    {
      "epoch": 1.73,
      "grad_norm": 1.3637877702713013,
      "learning_rate": 2.7282976324689967e-06,
      "loss": 0.319,
      "step": 8431
    },
    {
      "epoch": 1.73,
      "grad_norm": 1.1545817852020264,
      "learning_rate": 2.726247822076458e-06,
      "loss": 0.2413,
      "step": 8432
    },
    {
      "epoch": 1.73,
      "grad_norm": 1.3368958234786987,
      "learning_rate": 2.7241980116839196e-06,
      "loss": 0.2853,
      "step": 8433
    },
    {
      "epoch": 1.73,
      "grad_norm": 1.2673499584197998,
      "learning_rate": 2.7221482012913806e-06,
      "loss": 0.4912,
      "step": 8434
    },
    {
      "epoch": 1.73,
      "grad_norm": 1.6983238458633423,
      "learning_rate": 2.720098390898842e-06,
      "loss": 0.3639,
      "step": 8435
    },
    {
      "epoch": 1.73,
      "grad_norm": 1.028923511505127,
      "learning_rate": 2.7180485805063035e-06,
      "loss": 0.3624,
      "step": 8436
    },
    {
      "epoch": 1.73,
      "grad_norm": 1.187994360923767,
      "learning_rate": 2.7159987701137645e-06,
      "loss": 0.3592,
      "step": 8437
    },
    {
      "epoch": 1.73,
      "grad_norm": 1.2602968215942383,
      "learning_rate": 2.713948959721226e-06,
      "loss": 0.3345,
      "step": 8438
    },
    {
      "epoch": 1.73,
      "grad_norm": 0.8378428220748901,
      "learning_rate": 2.7118991493286873e-06,
      "loss": 0.3882,
      "step": 8439
    },
    {
      "epoch": 1.73,
      "grad_norm": 1.6809035539627075,
      "learning_rate": 2.7098493389361483e-06,
      "loss": 0.27,
      "step": 8440
    },
    {
      "epoch": 1.73,
      "grad_norm": 1.309497594833374,
      "learning_rate": 2.7077995285436098e-06,
      "loss": 0.4625,
      "step": 8441
    },
    {
      "epoch": 1.73,
      "grad_norm": 1.1421056985855103,
      "learning_rate": 2.7057497181510712e-06,
      "loss": 0.2996,
      "step": 8442
    },
    {
      "epoch": 1.73,
      "grad_norm": 1.01142156124115,
      "learning_rate": 2.7036999077585322e-06,
      "loss": 0.2936,
      "step": 8443
    },
    {
      "epoch": 1.73,
      "grad_norm": 1.207709789276123,
      "learning_rate": 2.7016500973659937e-06,
      "loss": 0.2322,
      "step": 8444
    },
    {
      "epoch": 1.73,
      "grad_norm": 1.633139967918396,
      "learning_rate": 2.699600286973455e-06,
      "loss": 0.2859,
      "step": 8445
    },
    {
      "epoch": 1.73,
      "grad_norm": 0.7553206086158752,
      "learning_rate": 2.697550476580916e-06,
      "loss": 0.4078,
      "step": 8446
    },
    {
      "epoch": 1.73,
      "grad_norm": 1.2746403217315674,
      "learning_rate": 2.6955006661883775e-06,
      "loss": 0.3422,
      "step": 8447
    },
    {
      "epoch": 1.73,
      "grad_norm": 1.0507776737213135,
      "learning_rate": 2.693450855795839e-06,
      "loss": 0.3003,
      "step": 8448
    },
    {
      "epoch": 1.73,
      "grad_norm": 1.685095191001892,
      "learning_rate": 2.6914010454033e-06,
      "loss": 0.3281,
      "step": 8449
    },
    {
      "epoch": 1.73,
      "grad_norm": 1.0654637813568115,
      "learning_rate": 2.6893512350107614e-06,
      "loss": 0.4518,
      "step": 8450
    },
    {
      "epoch": 1.73,
      "grad_norm": 0.6686097383499146,
      "learning_rate": 2.6873014246182233e-06,
      "loss": 0.2648,
      "step": 8451
    },
    {
      "epoch": 1.73,
      "grad_norm": 0.8923633694648743,
      "learning_rate": 2.6852516142256847e-06,
      "loss": 0.3461,
      "step": 8452
    },
    {
      "epoch": 1.73,
      "grad_norm": 0.661675751209259,
      "learning_rate": 2.6832018038331457e-06,
      "loss": 0.3333,
      "step": 8453
    },
    {
      "epoch": 1.73,
      "grad_norm": 1.1447278261184692,
      "learning_rate": 2.681151993440607e-06,
      "loss": 0.4379,
      "step": 8454
    },
    {
      "epoch": 1.73,
      "grad_norm": 0.9201496243476868,
      "learning_rate": 2.6791021830480686e-06,
      "loss": 0.1345,
      "step": 8455
    },
    {
      "epoch": 1.73,
      "grad_norm": 1.0152286291122437,
      "learning_rate": 2.6770523726555296e-06,
      "loss": 0.3092,
      "step": 8456
    },
    {
      "epoch": 1.73,
      "grad_norm": 1.102533221244812,
      "learning_rate": 2.675002562262991e-06,
      "loss": 0.3138,
      "step": 8457
    },
    {
      "epoch": 1.73,
      "grad_norm": 1.178490400314331,
      "learning_rate": 2.6729527518704524e-06,
      "loss": 0.352,
      "step": 8458
    },
    {
      "epoch": 1.73,
      "grad_norm": 1.0415747165679932,
      "learning_rate": 2.6709029414779135e-06,
      "loss": 0.2023,
      "step": 8459
    },
    {
      "epoch": 1.73,
      "grad_norm": 0.975435197353363,
      "learning_rate": 2.668853131085375e-06,
      "loss": 0.3653,
      "step": 8460
    },
    {
      "epoch": 1.73,
      "grad_norm": 1.2299859523773193,
      "learning_rate": 2.6668033206928363e-06,
      "loss": 0.3622,
      "step": 8461
    },
    {
      "epoch": 1.73,
      "grad_norm": 0.797208845615387,
      "learning_rate": 2.6647535103002973e-06,
      "loss": 0.2483,
      "step": 8462
    },
    {
      "epoch": 1.73,
      "grad_norm": 1.2771883010864258,
      "learning_rate": 2.6627036999077588e-06,
      "loss": 0.2976,
      "step": 8463
    },
    {
      "epoch": 1.73,
      "grad_norm": 1.1214990615844727,
      "learning_rate": 2.66065388951522e-06,
      "loss": 0.3695,
      "step": 8464
    },
    {
      "epoch": 1.73,
      "grad_norm": 1.207773208618164,
      "learning_rate": 2.658604079122681e-06,
      "loss": 0.3418,
      "step": 8465
    },
    {
      "epoch": 1.73,
      "grad_norm": 1.6518203020095825,
      "learning_rate": 2.6565542687301426e-06,
      "loss": 0.2751,
      "step": 8466
    },
    {
      "epoch": 1.73,
      "grad_norm": 1.185661792755127,
      "learning_rate": 2.654504458337604e-06,
      "loss": 0.3815,
      "step": 8467
    },
    {
      "epoch": 1.73,
      "grad_norm": 1.0786861181259155,
      "learning_rate": 2.652454647945065e-06,
      "loss": 0.2419,
      "step": 8468
    },
    {
      "epoch": 1.74,
      "grad_norm": 2.031482219696045,
      "learning_rate": 2.6504048375525265e-06,
      "loss": 0.39,
      "step": 8469
    },
    {
      "epoch": 1.74,
      "grad_norm": 1.967254877090454,
      "learning_rate": 2.648355027159988e-06,
      "loss": 0.3365,
      "step": 8470
    },
    {
      "epoch": 1.74,
      "grad_norm": 0.79954993724823,
      "learning_rate": 2.646305216767449e-06,
      "loss": 0.296,
      "step": 8471
    },
    {
      "epoch": 1.74,
      "grad_norm": 1.1088378429412842,
      "learning_rate": 2.6442554063749104e-06,
      "loss": 0.2906,
      "step": 8472
    },
    {
      "epoch": 1.74,
      "grad_norm": 0.8107657432556152,
      "learning_rate": 2.642205595982372e-06,
      "loss": 0.2395,
      "step": 8473
    },
    {
      "epoch": 1.74,
      "grad_norm": 1.2301467657089233,
      "learning_rate": 2.640155785589833e-06,
      "loss": 0.3211,
      "step": 8474
    },
    {
      "epoch": 1.74,
      "grad_norm": 1.0894653797149658,
      "learning_rate": 2.6381059751972943e-06,
      "loss": 0.3554,
      "step": 8475
    },
    {
      "epoch": 1.74,
      "grad_norm": 0.8314040303230286,
      "learning_rate": 2.6360561648047557e-06,
      "loss": 0.1944,
      "step": 8476
    },
    {
      "epoch": 1.74,
      "grad_norm": 1.0042058229446411,
      "learning_rate": 2.6340063544122167e-06,
      "loss": 0.2713,
      "step": 8477
    },
    {
      "epoch": 1.74,
      "grad_norm": 1.0227952003479004,
      "learning_rate": 2.631956544019678e-06,
      "loss": 0.3587,
      "step": 8478
    },
    {
      "epoch": 1.74,
      "grad_norm": 0.8852282762527466,
      "learning_rate": 2.6299067336271396e-06,
      "loss": 0.2745,
      "step": 8479
    },
    {
      "epoch": 1.74,
      "grad_norm": 1.5671191215515137,
      "learning_rate": 2.6278569232346014e-06,
      "loss": 0.3723,
      "step": 8480
    },
    {
      "epoch": 1.74,
      "grad_norm": 1.231411099433899,
      "learning_rate": 2.6258071128420624e-06,
      "loss": 0.3277,
      "step": 8481
    },
    {
      "epoch": 1.74,
      "grad_norm": 1.1327626705169678,
      "learning_rate": 2.623757302449524e-06,
      "loss": 0.4067,
      "step": 8482
    },
    {
      "epoch": 1.74,
      "grad_norm": 1.065549612045288,
      "learning_rate": 2.6217074920569853e-06,
      "loss": 0.3723,
      "step": 8483
    },
    {
      "epoch": 1.74,
      "grad_norm": 1.013206124305725,
      "learning_rate": 2.6196576816644463e-06,
      "loss": 0.2872,
      "step": 8484
    },
    {
      "epoch": 1.74,
      "grad_norm": 1.2299035787582397,
      "learning_rate": 2.6176078712719077e-06,
      "loss": 0.3947,
      "step": 8485
    },
    {
      "epoch": 1.74,
      "grad_norm": 1.9932827949523926,
      "learning_rate": 2.615558060879369e-06,
      "loss": 0.3055,
      "step": 8486
    },
    {
      "epoch": 1.74,
      "grad_norm": 1.1938890218734741,
      "learning_rate": 2.61350825048683e-06,
      "loss": 0.4361,
      "step": 8487
    },
    {
      "epoch": 1.74,
      "grad_norm": 1.356842279434204,
      "learning_rate": 2.6114584400942916e-06,
      "loss": 0.3187,
      "step": 8488
    },
    {
      "epoch": 1.74,
      "grad_norm": 0.804465651512146,
      "learning_rate": 2.609408629701753e-06,
      "loss": 0.2512,
      "step": 8489
    },
    {
      "epoch": 1.74,
      "grad_norm": 1.8628754615783691,
      "learning_rate": 2.607358819309214e-06,
      "loss": 0.2803,
      "step": 8490
    },
    {
      "epoch": 1.74,
      "grad_norm": 1.1892277002334595,
      "learning_rate": 2.6053090089166755e-06,
      "loss": 0.6013,
      "step": 8491
    },
    {
      "epoch": 1.74,
      "grad_norm": 1.092523217201233,
      "learning_rate": 2.603259198524137e-06,
      "loss": 0.456,
      "step": 8492
    },
    {
      "epoch": 1.74,
      "grad_norm": 1.3034977912902832,
      "learning_rate": 2.601209388131598e-06,
      "loss": 0.3867,
      "step": 8493
    },
    {
      "epoch": 1.74,
      "grad_norm": 1.490181803703308,
      "learning_rate": 2.5991595777390594e-06,
      "loss": 0.3816,
      "step": 8494
    },
    {
      "epoch": 1.74,
      "grad_norm": 1.1377605199813843,
      "learning_rate": 2.597109767346521e-06,
      "loss": 0.2841,
      "step": 8495
    },
    {
      "epoch": 1.74,
      "grad_norm": 0.7749255895614624,
      "learning_rate": 2.595059956953982e-06,
      "loss": 0.2738,
      "step": 8496
    },
    {
      "epoch": 1.74,
      "grad_norm": 0.9279217720031738,
      "learning_rate": 2.5930101465614432e-06,
      "loss": 0.3617,
      "step": 8497
    },
    {
      "epoch": 1.74,
      "grad_norm": 1.1254924535751343,
      "learning_rate": 2.5909603361689047e-06,
      "loss": 0.3127,
      "step": 8498
    },
    {
      "epoch": 1.74,
      "grad_norm": 0.8383240699768066,
      "learning_rate": 2.5889105257763657e-06,
      "loss": 0.367,
      "step": 8499
    },
    {
      "epoch": 1.74,
      "grad_norm": 1.1135799884796143,
      "learning_rate": 2.586860715383827e-06,
      "loss": 0.2941,
      "step": 8500
    },
    {
      "epoch": 1.74,
      "grad_norm": 1.2655609846115112,
      "learning_rate": 2.5848109049912886e-06,
      "loss": 0.3012,
      "step": 8501
    },
    {
      "epoch": 1.74,
      "grad_norm": 1.3024656772613525,
      "learning_rate": 2.5827610945987496e-06,
      "loss": 0.3514,
      "step": 8502
    },
    {
      "epoch": 1.74,
      "grad_norm": 1.3060302734375,
      "learning_rate": 2.580711284206211e-06,
      "loss": 0.3749,
      "step": 8503
    },
    {
      "epoch": 1.74,
      "grad_norm": 0.9738313555717468,
      "learning_rate": 2.5786614738136724e-06,
      "loss": 0.4202,
      "step": 8504
    },
    {
      "epoch": 1.74,
      "grad_norm": 0.9556823968887329,
      "learning_rate": 2.5766116634211334e-06,
      "loss": 0.3565,
      "step": 8505
    },
    {
      "epoch": 1.74,
      "grad_norm": 0.7239353656768799,
      "learning_rate": 2.574561853028595e-06,
      "loss": 0.4158,
      "step": 8506
    },
    {
      "epoch": 1.74,
      "grad_norm": 1.4673329591751099,
      "learning_rate": 2.5725120426360563e-06,
      "loss": 0.2095,
      "step": 8507
    },
    {
      "epoch": 1.74,
      "grad_norm": 1.1720792055130005,
      "learning_rate": 2.5704622322435173e-06,
      "loss": 0.2306,
      "step": 8508
    },
    {
      "epoch": 1.74,
      "grad_norm": 1.1152372360229492,
      "learning_rate": 2.5684124218509787e-06,
      "loss": 0.2815,
      "step": 8509
    },
    {
      "epoch": 1.74,
      "grad_norm": 1.3815017938613892,
      "learning_rate": 2.5663626114584406e-06,
      "loss": 0.3717,
      "step": 8510
    },
    {
      "epoch": 1.74,
      "grad_norm": 1.2494935989379883,
      "learning_rate": 2.564312801065902e-06,
      "loss": 0.3372,
      "step": 8511
    },
    {
      "epoch": 1.74,
      "grad_norm": 1.3745193481445312,
      "learning_rate": 2.562262990673363e-06,
      "loss": 0.5438,
      "step": 8512
    },
    {
      "epoch": 1.74,
      "grad_norm": 0.9052248597145081,
      "learning_rate": 2.5602131802808245e-06,
      "loss": 0.3156,
      "step": 8513
    },
    {
      "epoch": 1.74,
      "grad_norm": 1.012251377105713,
      "learning_rate": 2.558163369888286e-06,
      "loss": 0.3117,
      "step": 8514
    },
    {
      "epoch": 1.74,
      "grad_norm": 1.2471140623092651,
      "learning_rate": 2.556113559495747e-06,
      "loss": 0.2572,
      "step": 8515
    },
    {
      "epoch": 1.74,
      "grad_norm": 0.9759513139724731,
      "learning_rate": 2.5540637491032084e-06,
      "loss": 0.3175,
      "step": 8516
    },
    {
      "epoch": 1.74,
      "grad_norm": 1.1541980504989624,
      "learning_rate": 2.5520139387106698e-06,
      "loss": 0.223,
      "step": 8517
    },
    {
      "epoch": 1.75,
      "grad_norm": 1.0223685503005981,
      "learning_rate": 2.549964128318131e-06,
      "loss": 0.274,
      "step": 8518
    },
    {
      "epoch": 1.75,
      "grad_norm": 3.0108492374420166,
      "learning_rate": 2.5479143179255922e-06,
      "loss": 0.3937,
      "step": 8519
    },
    {
      "epoch": 1.75,
      "grad_norm": 1.1512423753738403,
      "learning_rate": 2.5458645075330537e-06,
      "loss": 0.3806,
      "step": 8520
    },
    {
      "epoch": 1.75,
      "grad_norm": 1.629543423652649,
      "learning_rate": 2.5438146971405147e-06,
      "loss": 0.1751,
      "step": 8521
    },
    {
      "epoch": 1.75,
      "grad_norm": 0.8754722476005554,
      "learning_rate": 2.541764886747976e-06,
      "loss": 0.2997,
      "step": 8522
    },
    {
      "epoch": 1.75,
      "grad_norm": 1.8133413791656494,
      "learning_rate": 2.5397150763554375e-06,
      "loss": 0.2563,
      "step": 8523
    },
    {
      "epoch": 1.75,
      "grad_norm": 0.8730423450469971,
      "learning_rate": 2.5376652659628985e-06,
      "loss": 0.2974,
      "step": 8524
    },
    {
      "epoch": 1.75,
      "grad_norm": 0.8437402248382568,
      "learning_rate": 2.53561545557036e-06,
      "loss": 0.2918,
      "step": 8525
    },
    {
      "epoch": 1.75,
      "grad_norm": 1.0305017232894897,
      "learning_rate": 2.5335656451778214e-06,
      "loss": 0.2866,
      "step": 8526
    },
    {
      "epoch": 1.75,
      "grad_norm": 2.336775302886963,
      "learning_rate": 2.5315158347852824e-06,
      "loss": 0.2928,
      "step": 8527
    },
    {
      "epoch": 1.75,
      "grad_norm": 1.3806610107421875,
      "learning_rate": 2.529466024392744e-06,
      "loss": 0.2876,
      "step": 8528
    },
    {
      "epoch": 1.75,
      "grad_norm": 1.1140564680099487,
      "learning_rate": 2.5274162140002053e-06,
      "loss": 0.3844,
      "step": 8529
    },
    {
      "epoch": 1.75,
      "grad_norm": 1.1740186214447021,
      "learning_rate": 2.5253664036076663e-06,
      "loss": 0.3255,
      "step": 8530
    },
    {
      "epoch": 1.75,
      "grad_norm": 1.0009640455245972,
      "learning_rate": 2.5233165932151277e-06,
      "loss": 0.2935,
      "step": 8531
    },
    {
      "epoch": 1.75,
      "grad_norm": 3.043815851211548,
      "learning_rate": 2.521266782822589e-06,
      "loss": 0.4509,
      "step": 8532
    },
    {
      "epoch": 1.75,
      "grad_norm": 1.210508942604065,
      "learning_rate": 2.51921697243005e-06,
      "loss": 0.3475,
      "step": 8533
    },
    {
      "epoch": 1.75,
      "grad_norm": 0.7694219350814819,
      "learning_rate": 2.5171671620375116e-06,
      "loss": 0.3435,
      "step": 8534
    },
    {
      "epoch": 1.75,
      "grad_norm": 1.5112025737762451,
      "learning_rate": 2.515117351644973e-06,
      "loss": 0.3701,
      "step": 8535
    },
    {
      "epoch": 1.75,
      "grad_norm": 1.0681307315826416,
      "learning_rate": 2.513067541252434e-06,
      "loss": 0.2481,
      "step": 8536
    },
    {
      "epoch": 1.75,
      "grad_norm": 1.2374448776245117,
      "learning_rate": 2.5110177308598955e-06,
      "loss": 0.3727,
      "step": 8537
    },
    {
      "epoch": 1.75,
      "grad_norm": 1.1598241329193115,
      "learning_rate": 2.508967920467357e-06,
      "loss": 0.2881,
      "step": 8538
    },
    {
      "epoch": 1.75,
      "grad_norm": 0.8740276098251343,
      "learning_rate": 2.5069181100748183e-06,
      "loss": 0.2407,
      "step": 8539
    },
    {
      "epoch": 1.75,
      "grad_norm": 1.157922387123108,
      "learning_rate": 2.5048682996822798e-06,
      "loss": 0.4123,
      "step": 8540
    },
    {
      "epoch": 1.75,
      "grad_norm": 0.807059645652771,
      "learning_rate": 2.502818489289741e-06,
      "loss": 0.1887,
      "step": 8541
    },
    {
      "epoch": 1.75,
      "grad_norm": 1.2190011739730835,
      "learning_rate": 2.5007686788972022e-06,
      "loss": 0.4499,
      "step": 8542
    },
    {
      "epoch": 1.75,
      "grad_norm": 0.9048990607261658,
      "learning_rate": 2.4987188685046637e-06,
      "loss": 0.184,
      "step": 8543
    },
    {
      "epoch": 1.75,
      "grad_norm": 0.9230152368545532,
      "learning_rate": 2.4966690581121247e-06,
      "loss": 0.3976,
      "step": 8544
    },
    {
      "epoch": 1.75,
      "grad_norm": 1.2677689790725708,
      "learning_rate": 2.494619247719586e-06,
      "loss": 0.3389,
      "step": 8545
    },
    {
      "epoch": 1.75,
      "grad_norm": 1.1446236371994019,
      "learning_rate": 2.492569437327047e-06,
      "loss": 0.4324,
      "step": 8546
    },
    {
      "epoch": 1.75,
      "grad_norm": 1.1621959209442139,
      "learning_rate": 2.490519626934509e-06,
      "loss": 0.2221,
      "step": 8547
    },
    {
      "epoch": 1.75,
      "grad_norm": 0.9317328333854675,
      "learning_rate": 2.48846981654197e-06,
      "loss": 0.3098,
      "step": 8548
    },
    {
      "epoch": 1.75,
      "grad_norm": 0.6771084070205688,
      "learning_rate": 2.4864200061494314e-06,
      "loss": 0.257,
      "step": 8549
    },
    {
      "epoch": 1.75,
      "grad_norm": 1.3162435293197632,
      "learning_rate": 2.484370195756893e-06,
      "loss": 0.3442,
      "step": 8550
    },
    {
      "epoch": 1.75,
      "grad_norm": 1.086709976196289,
      "learning_rate": 2.482320385364354e-06,
      "loss": 0.3563,
      "step": 8551
    },
    {
      "epoch": 1.75,
      "grad_norm": 0.9946567416191101,
      "learning_rate": 2.4802705749718153e-06,
      "loss": 0.269,
      "step": 8552
    },
    {
      "epoch": 1.75,
      "grad_norm": 1.08188796043396,
      "learning_rate": 2.4782207645792767e-06,
      "loss": 0.3132,
      "step": 8553
    },
    {
      "epoch": 1.75,
      "grad_norm": 0.8723540306091309,
      "learning_rate": 2.4761709541867377e-06,
      "loss": 0.2293,
      "step": 8554
    },
    {
      "epoch": 1.75,
      "grad_norm": 0.9254596829414368,
      "learning_rate": 2.474121143794199e-06,
      "loss": 0.2328,
      "step": 8555
    },
    {
      "epoch": 1.75,
      "grad_norm": 1.5917919874191284,
      "learning_rate": 2.4720713334016606e-06,
      "loss": 0.3937,
      "step": 8556
    },
    {
      "epoch": 1.75,
      "grad_norm": 0.7709751725196838,
      "learning_rate": 2.4700215230091216e-06,
      "loss": 0.2069,
      "step": 8557
    },
    {
      "epoch": 1.75,
      "grad_norm": 0.9534892439842224,
      "learning_rate": 2.467971712616583e-06,
      "loss": 0.2905,
      "step": 8558
    },
    {
      "epoch": 1.75,
      "grad_norm": 1.0998749732971191,
      "learning_rate": 2.4659219022240445e-06,
      "loss": 0.2766,
      "step": 8559
    },
    {
      "epoch": 1.75,
      "grad_norm": 1.096533179283142,
      "learning_rate": 2.4638720918315055e-06,
      "loss": 0.2606,
      "step": 8560
    },
    {
      "epoch": 1.75,
      "grad_norm": 1.0075849294662476,
      "learning_rate": 2.4618222814389673e-06,
      "loss": 0.2598,
      "step": 8561
    },
    {
      "epoch": 1.75,
      "grad_norm": 0.9150142669677734,
      "learning_rate": 2.4597724710464283e-06,
      "loss": 0.4205,
      "step": 8562
    },
    {
      "epoch": 1.75,
      "grad_norm": 1.3549884557724,
      "learning_rate": 2.4577226606538898e-06,
      "loss": 0.3932,
      "step": 8563
    },
    {
      "epoch": 1.75,
      "grad_norm": 0.880238950252533,
      "learning_rate": 2.455672850261351e-06,
      "loss": 0.2628,
      "step": 8564
    },
    {
      "epoch": 1.75,
      "grad_norm": 1.078566551208496,
      "learning_rate": 2.4536230398688122e-06,
      "loss": 0.2112,
      "step": 8565
    },
    {
      "epoch": 1.75,
      "grad_norm": 1.3715362548828125,
      "learning_rate": 2.4515732294762736e-06,
      "loss": 0.3728,
      "step": 8566
    },
    {
      "epoch": 1.76,
      "grad_norm": 1.3912214040756226,
      "learning_rate": 2.449523419083735e-06,
      "loss": 0.341,
      "step": 8567
    },
    {
      "epoch": 1.76,
      "grad_norm": 0.8524054884910583,
      "learning_rate": 2.447473608691196e-06,
      "loss": 0.409,
      "step": 8568
    },
    {
      "epoch": 1.76,
      "grad_norm": 1.4744410514831543,
      "learning_rate": 2.4454237982986575e-06,
      "loss": 0.4177,
      "step": 8569
    },
    {
      "epoch": 1.76,
      "grad_norm": 1.4379957914352417,
      "learning_rate": 2.443373987906119e-06,
      "loss": 0.3083,
      "step": 8570
    },
    {
      "epoch": 1.76,
      "grad_norm": 1.496470332145691,
      "learning_rate": 2.44132417751358e-06,
      "loss": 0.3215,
      "step": 8571
    },
    {
      "epoch": 1.76,
      "grad_norm": 1.3383415937423706,
      "learning_rate": 2.4392743671210414e-06,
      "loss": 0.4837,
      "step": 8572
    },
    {
      "epoch": 1.76,
      "grad_norm": 1.3209450244903564,
      "learning_rate": 2.437224556728503e-06,
      "loss": 0.3299,
      "step": 8573
    },
    {
      "epoch": 1.76,
      "grad_norm": 0.9299907684326172,
      "learning_rate": 2.435174746335964e-06,
      "loss": 0.3076,
      "step": 8574
    },
    {
      "epoch": 1.76,
      "grad_norm": 1.1478543281555176,
      "learning_rate": 2.4331249359434253e-06,
      "loss": 0.4604,
      "step": 8575
    },
    {
      "epoch": 1.76,
      "grad_norm": 1.0397589206695557,
      "learning_rate": 2.4310751255508867e-06,
      "loss": 0.3738,
      "step": 8576
    },
    {
      "epoch": 1.76,
      "grad_norm": 1.499146580696106,
      "learning_rate": 2.429025315158348e-06,
      "loss": 0.3336,
      "step": 8577
    },
    {
      "epoch": 1.76,
      "grad_norm": 1.3474820852279663,
      "learning_rate": 2.4269755047658096e-06,
      "loss": 0.3113,
      "step": 8578
    },
    {
      "epoch": 1.76,
      "grad_norm": 1.0750296115875244,
      "learning_rate": 2.4249256943732706e-06,
      "loss": 0.3198,
      "step": 8579
    },
    {
      "epoch": 1.76,
      "grad_norm": 1.071399450302124,
      "learning_rate": 2.422875883980732e-06,
      "loss": 0.2531,
      "step": 8580
    },
    {
      "epoch": 1.76,
      "grad_norm": 1.0007432699203491,
      "learning_rate": 2.4208260735881934e-06,
      "loss": 0.4005,
      "step": 8581
    },
    {
      "epoch": 1.76,
      "grad_norm": 1.1771188974380493,
      "learning_rate": 2.4187762631956545e-06,
      "loss": 0.496,
      "step": 8582
    },
    {
      "epoch": 1.76,
      "grad_norm": 1.049354076385498,
      "learning_rate": 2.416726452803116e-06,
      "loss": 0.2957,
      "step": 8583
    },
    {
      "epoch": 1.76,
      "grad_norm": 1.856882929801941,
      "learning_rate": 2.4146766424105773e-06,
      "loss": 0.3018,
      "step": 8584
    },
    {
      "epoch": 1.76,
      "grad_norm": 1.0938416719436646,
      "learning_rate": 2.4126268320180383e-06,
      "loss": 0.4031,
      "step": 8585
    },
    {
      "epoch": 1.76,
      "grad_norm": 1.1768043041229248,
      "learning_rate": 2.4105770216254998e-06,
      "loss": 0.2269,
      "step": 8586
    },
    {
      "epoch": 1.76,
      "grad_norm": 0.9588361382484436,
      "learning_rate": 2.408527211232961e-06,
      "loss": 0.3631,
      "step": 8587
    },
    {
      "epoch": 1.76,
      "grad_norm": 1.1558815240859985,
      "learning_rate": 2.406477400840422e-06,
      "loss": 0.333,
      "step": 8588
    },
    {
      "epoch": 1.76,
      "grad_norm": 1.9099563360214233,
      "learning_rate": 2.4044275904478836e-06,
      "loss": 0.4546,
      "step": 8589
    },
    {
      "epoch": 1.76,
      "grad_norm": 0.9692218899726868,
      "learning_rate": 2.402377780055345e-06,
      "loss": 0.208,
      "step": 8590
    },
    {
      "epoch": 1.76,
      "grad_norm": 1.3067011833190918,
      "learning_rate": 2.4003279696628065e-06,
      "loss": 0.3158,
      "step": 8591
    },
    {
      "epoch": 1.76,
      "grad_norm": 1.321134328842163,
      "learning_rate": 2.398278159270268e-06,
      "loss": 0.5034,
      "step": 8592
    },
    {
      "epoch": 1.76,
      "grad_norm": 1.7199928760528564,
      "learning_rate": 2.396228348877729e-06,
      "loss": 0.3503,
      "step": 8593
    },
    {
      "epoch": 1.76,
      "grad_norm": 0.9585118889808655,
      "learning_rate": 2.3941785384851904e-06,
      "loss": 0.3347,
      "step": 8594
    },
    {
      "epoch": 1.76,
      "grad_norm": 1.9364289045333862,
      "learning_rate": 2.392128728092652e-06,
      "loss": 0.3636,
      "step": 8595
    },
    {
      "epoch": 1.76,
      "grad_norm": 1.0431708097457886,
      "learning_rate": 2.390078917700113e-06,
      "loss": 0.3281,
      "step": 8596
    },
    {
      "epoch": 1.76,
      "grad_norm": 1.1675517559051514,
      "learning_rate": 2.3880291073075743e-06,
      "loss": 0.1971,
      "step": 8597
    },
    {
      "epoch": 1.76,
      "grad_norm": 0.9336398243904114,
      "learning_rate": 2.3859792969150357e-06,
      "loss": 0.3414,
      "step": 8598
    },
    {
      "epoch": 1.76,
      "grad_norm": 1.4167457818984985,
      "learning_rate": 2.3839294865224967e-06,
      "loss": 0.3397,
      "step": 8599
    },
    {
      "epoch": 1.76,
      "grad_norm": 1.1415897607803345,
      "learning_rate": 2.381879676129958e-06,
      "loss": 0.4174,
      "step": 8600
    },
    {
      "epoch": 1.76,
      "grad_norm": 1.031379222869873,
      "learning_rate": 2.3798298657374196e-06,
      "loss": 0.3695,
      "step": 8601
    },
    {
      "epoch": 1.76,
      "grad_norm": 1.3701249361038208,
      "learning_rate": 2.3777800553448806e-06,
      "loss": 0.5488,
      "step": 8602
    },
    {
      "epoch": 1.76,
      "grad_norm": 0.795304536819458,
      "learning_rate": 2.375730244952342e-06,
      "loss": 0.2241,
      "step": 8603
    },
    {
      "epoch": 1.76,
      "grad_norm": 1.057603120803833,
      "learning_rate": 2.3736804345598034e-06,
      "loss": 0.3807,
      "step": 8604
    },
    {
      "epoch": 1.76,
      "grad_norm": 0.8938121199607849,
      "learning_rate": 2.3716306241672644e-06,
      "loss": 0.1426,
      "step": 8605
    },
    {
      "epoch": 1.76,
      "grad_norm": 1.0806573629379272,
      "learning_rate": 2.3695808137747263e-06,
      "loss": 0.2403,
      "step": 8606
    },
    {
      "epoch": 1.76,
      "grad_norm": 1.192013144493103,
      "learning_rate": 2.3675310033821873e-06,
      "loss": 0.3328,
      "step": 8607
    },
    {
      "epoch": 1.76,
      "grad_norm": 1.002167820930481,
      "learning_rate": 2.3654811929896487e-06,
      "loss": 0.2385,
      "step": 8608
    },
    {
      "epoch": 1.76,
      "grad_norm": 1.284780502319336,
      "learning_rate": 2.36343138259711e-06,
      "loss": 0.2808,
      "step": 8609
    },
    {
      "epoch": 1.76,
      "grad_norm": 0.8673009872436523,
      "learning_rate": 2.361381572204571e-06,
      "loss": 0.271,
      "step": 8610
    },
    {
      "epoch": 1.76,
      "grad_norm": 0.8672088980674744,
      "learning_rate": 2.3593317618120326e-06,
      "loss": 0.1915,
      "step": 8611
    },
    {
      "epoch": 1.76,
      "grad_norm": 0.8508719801902771,
      "learning_rate": 2.357281951419494e-06,
      "loss": 0.2358,
      "step": 8612
    },
    {
      "epoch": 1.76,
      "grad_norm": 2.1458187103271484,
      "learning_rate": 2.355232141026955e-06,
      "loss": 0.4231,
      "step": 8613
    },
    {
      "epoch": 1.76,
      "grad_norm": 0.8223287463188171,
      "learning_rate": 2.3531823306344165e-06,
      "loss": 0.3887,
      "step": 8614
    },
    {
      "epoch": 1.77,
      "grad_norm": 1.253926157951355,
      "learning_rate": 2.351132520241878e-06,
      "loss": 0.3417,
      "step": 8615
    },
    {
      "epoch": 1.77,
      "grad_norm": 0.8689088225364685,
      "learning_rate": 2.349082709849339e-06,
      "loss": 0.2791,
      "step": 8616
    },
    {
      "epoch": 1.77,
      "grad_norm": 0.8688772916793823,
      "learning_rate": 2.3470328994568004e-06,
      "loss": 0.2868,
      "step": 8617
    },
    {
      "epoch": 1.77,
      "grad_norm": 1.2061381340026855,
      "learning_rate": 2.344983089064262e-06,
      "loss": 0.4136,
      "step": 8618
    },
    {
      "epoch": 1.77,
      "grad_norm": 0.9578347206115723,
      "learning_rate": 2.342933278671723e-06,
      "loss": 0.2862,
      "step": 8619
    },
    {
      "epoch": 1.77,
      "grad_norm": 0.8960731029510498,
      "learning_rate": 2.3408834682791847e-06,
      "loss": 0.291,
      "step": 8620
    },
    {
      "epoch": 1.77,
      "grad_norm": 0.9003883004188538,
      "learning_rate": 2.3388336578866457e-06,
      "loss": 0.3086,
      "step": 8621
    },
    {
      "epoch": 1.77,
      "grad_norm": 1.18329918384552,
      "learning_rate": 2.336783847494107e-06,
      "loss": 0.4265,
      "step": 8622
    },
    {
      "epoch": 1.77,
      "grad_norm": 0.902769923210144,
      "learning_rate": 2.3347340371015685e-06,
      "loss": 0.3115,
      "step": 8623
    },
    {
      "epoch": 1.77,
      "grad_norm": 0.8634538054466248,
      "learning_rate": 2.3326842267090296e-06,
      "loss": 0.2559,
      "step": 8624
    },
    {
      "epoch": 1.77,
      "grad_norm": 0.9730284810066223,
      "learning_rate": 2.330634416316491e-06,
      "loss": 0.382,
      "step": 8625
    },
    {
      "epoch": 1.77,
      "grad_norm": 1.1074943542480469,
      "learning_rate": 2.3285846059239524e-06,
      "loss": 0.5215,
      "step": 8626
    },
    {
      "epoch": 1.77,
      "grad_norm": 1.1895403861999512,
      "learning_rate": 2.3265347955314134e-06,
      "loss": 0.3186,
      "step": 8627
    },
    {
      "epoch": 1.77,
      "grad_norm": 0.8923985958099365,
      "learning_rate": 2.324484985138875e-06,
      "loss": 0.3083,
      "step": 8628
    },
    {
      "epoch": 1.77,
      "grad_norm": 1.1182997226715088,
      "learning_rate": 2.3224351747463363e-06,
      "loss": 0.3257,
      "step": 8629
    },
    {
      "epoch": 1.77,
      "grad_norm": 1.4803893566131592,
      "learning_rate": 2.3203853643537973e-06,
      "loss": 0.3144,
      "step": 8630
    },
    {
      "epoch": 1.77,
      "grad_norm": 1.7005008459091187,
      "learning_rate": 2.3183355539612587e-06,
      "loss": 0.344,
      "step": 8631
    },
    {
      "epoch": 1.77,
      "grad_norm": 1.021791696548462,
      "learning_rate": 2.31628574356872e-06,
      "loss": 0.2935,
      "step": 8632
    },
    {
      "epoch": 1.77,
      "grad_norm": 1.0206923484802246,
      "learning_rate": 2.314235933176181e-06,
      "loss": 0.373,
      "step": 8633
    },
    {
      "epoch": 1.77,
      "grad_norm": 0.7484654784202576,
      "learning_rate": 2.3121861227836426e-06,
      "loss": 0.3323,
      "step": 8634
    },
    {
      "epoch": 1.77,
      "grad_norm": 1.1132112741470337,
      "learning_rate": 2.310136312391104e-06,
      "loss": 0.262,
      "step": 8635
    },
    {
      "epoch": 1.77,
      "grad_norm": 2.0706050395965576,
      "learning_rate": 2.3080865019985655e-06,
      "loss": 0.4331,
      "step": 8636
    },
    {
      "epoch": 1.77,
      "grad_norm": 0.9446951150894165,
      "learning_rate": 2.306036691606027e-06,
      "loss": 0.3753,
      "step": 8637
    },
    {
      "epoch": 1.77,
      "grad_norm": 1.0568708181381226,
      "learning_rate": 2.303986881213488e-06,
      "loss": 0.4545,
      "step": 8638
    },
    {
      "epoch": 1.77,
      "grad_norm": 1.0568758249282837,
      "learning_rate": 2.3019370708209494e-06,
      "loss": 0.3864,
      "step": 8639
    },
    {
      "epoch": 1.77,
      "grad_norm": 1.1710879802703857,
      "learning_rate": 2.2998872604284108e-06,
      "loss": 0.3842,
      "step": 8640
    },
    {
      "epoch": 1.77,
      "grad_norm": 1.0117398500442505,
      "learning_rate": 2.297837450035872e-06,
      "loss": 0.2851,
      "step": 8641
    },
    {
      "epoch": 1.77,
      "grad_norm": 0.7963273525238037,
      "learning_rate": 2.2957876396433332e-06,
      "loss": 0.2591,
      "step": 8642
    },
    {
      "epoch": 1.77,
      "grad_norm": 1.9291216135025024,
      "learning_rate": 2.2937378292507947e-06,
      "loss": 0.305,
      "step": 8643
    },
    {
      "epoch": 1.77,
      "grad_norm": 1.4125524759292603,
      "learning_rate": 2.2916880188582557e-06,
      "loss": 0.4306,
      "step": 8644
    },
    {
      "epoch": 1.77,
      "grad_norm": 1.1132961511611938,
      "learning_rate": 2.289638208465717e-06,
      "loss": 0.386,
      "step": 8645
    },
    {
      "epoch": 1.77,
      "grad_norm": 1.0444269180297852,
      "learning_rate": 2.2875883980731785e-06,
      "loss": 0.2533,
      "step": 8646
    },
    {
      "epoch": 1.77,
      "grad_norm": 1.29517662525177,
      "learning_rate": 2.2855385876806395e-06,
      "loss": 0.4341,
      "step": 8647
    },
    {
      "epoch": 1.77,
      "grad_norm": 0.9780049920082092,
      "learning_rate": 2.283488777288101e-06,
      "loss": 0.2532,
      "step": 8648
    },
    {
      "epoch": 1.77,
      "grad_norm": 0.9804586172103882,
      "learning_rate": 2.2814389668955624e-06,
      "loss": 0.2289,
      "step": 8649
    },
    {
      "epoch": 1.77,
      "grad_norm": 0.9351639747619629,
      "learning_rate": 2.279389156503024e-06,
      "loss": 0.3639,
      "step": 8650
    },
    {
      "epoch": 1.77,
      "grad_norm": 1.0488213300704956,
      "learning_rate": 2.2773393461104853e-06,
      "loss": 0.2238,
      "step": 8651
    },
    {
      "epoch": 1.77,
      "grad_norm": 1.185114860534668,
      "learning_rate": 2.2752895357179463e-06,
      "loss": 0.2664,
      "step": 8652
    },
    {
      "epoch": 1.77,
      "grad_norm": 0.9341660141944885,
      "learning_rate": 2.2732397253254077e-06,
      "loss": 0.2849,
      "step": 8653
    },
    {
      "epoch": 1.77,
      "grad_norm": 1.5972436666488647,
      "learning_rate": 2.271189914932869e-06,
      "loss": 0.348,
      "step": 8654
    },
    {
      "epoch": 1.77,
      "grad_norm": 1.0356850624084473,
      "learning_rate": 2.26914010454033e-06,
      "loss": 0.3247,
      "step": 8655
    },
    {
      "epoch": 1.77,
      "grad_norm": 1.2310830354690552,
      "learning_rate": 2.2670902941477916e-06,
      "loss": 0.3898,
      "step": 8656
    },
    {
      "epoch": 1.77,
      "grad_norm": 1.0082383155822754,
      "learning_rate": 2.265040483755253e-06,
      "loss": 0.3507,
      "step": 8657
    },
    {
      "epoch": 1.77,
      "grad_norm": 1.0496960878372192,
      "learning_rate": 2.262990673362714e-06,
      "loss": 0.2293,
      "step": 8658
    },
    {
      "epoch": 1.77,
      "grad_norm": 1.0547597408294678,
      "learning_rate": 2.2609408629701755e-06,
      "loss": 0.2248,
      "step": 8659
    },
    {
      "epoch": 1.77,
      "grad_norm": 1.360809564590454,
      "learning_rate": 2.2588910525776365e-06,
      "loss": 0.2712,
      "step": 8660
    },
    {
      "epoch": 1.77,
      "grad_norm": 0.6936392784118652,
      "learning_rate": 2.256841242185098e-06,
      "loss": 0.2578,
      "step": 8661
    },
    {
      "epoch": 1.77,
      "grad_norm": 0.8547390103340149,
      "learning_rate": 2.2547914317925593e-06,
      "loss": 0.2748,
      "step": 8662
    },
    {
      "epoch": 1.77,
      "grad_norm": 1.249976396560669,
      "learning_rate": 2.2527416214000204e-06,
      "loss": 0.4464,
      "step": 8663
    },
    {
      "epoch": 1.78,
      "grad_norm": 1.560368299484253,
      "learning_rate": 2.250691811007482e-06,
      "loss": 0.3009,
      "step": 8664
    },
    {
      "epoch": 1.78,
      "grad_norm": 1.4862761497497559,
      "learning_rate": 2.2486420006149432e-06,
      "loss": 0.2602,
      "step": 8665
    },
    {
      "epoch": 1.78,
      "grad_norm": 1.0407615900039673,
      "learning_rate": 2.2465921902224047e-06,
      "loss": 0.3144,
      "step": 8666
    },
    {
      "epoch": 1.78,
      "grad_norm": 1.5471972227096558,
      "learning_rate": 2.244542379829866e-06,
      "loss": 0.3567,
      "step": 8667
    },
    {
      "epoch": 1.78,
      "grad_norm": 2.0503828525543213,
      "learning_rate": 2.242492569437327e-06,
      "loss": 0.2541,
      "step": 8668
    },
    {
      "epoch": 1.78,
      "grad_norm": 1.6977267265319824,
      "learning_rate": 2.2404427590447885e-06,
      "loss": 0.3349,
      "step": 8669
    },
    {
      "epoch": 1.78,
      "grad_norm": 0.8935823440551758,
      "learning_rate": 2.23839294865225e-06,
      "loss": 0.281,
      "step": 8670
    },
    {
      "epoch": 1.78,
      "grad_norm": 1.1390419006347656,
      "learning_rate": 2.236343138259711e-06,
      "loss": 0.3169,
      "step": 8671
    },
    {
      "epoch": 1.78,
      "grad_norm": 1.241793155670166,
      "learning_rate": 2.2342933278671724e-06,
      "loss": 0.3155,
      "step": 8672
    },
    {
      "epoch": 1.78,
      "grad_norm": 1.2654509544372559,
      "learning_rate": 2.232243517474634e-06,
      "loss": 0.3098,
      "step": 8673
    },
    {
      "epoch": 1.78,
      "grad_norm": 1.2373335361480713,
      "learning_rate": 2.230193707082095e-06,
      "loss": 0.3232,
      "step": 8674
    },
    {
      "epoch": 1.78,
      "grad_norm": 1.3699761629104614,
      "learning_rate": 2.2281438966895563e-06,
      "loss": 0.3091,
      "step": 8675
    },
    {
      "epoch": 1.78,
      "grad_norm": 1.147210717201233,
      "learning_rate": 2.2260940862970177e-06,
      "loss": 0.4061,
      "step": 8676
    },
    {
      "epoch": 1.78,
      "grad_norm": 1.231200098991394,
      "learning_rate": 2.2240442759044787e-06,
      "loss": 0.4457,
      "step": 8677
    },
    {
      "epoch": 1.78,
      "grad_norm": 0.9461061358451843,
      "learning_rate": 2.22199446551194e-06,
      "loss": 0.263,
      "step": 8678
    },
    {
      "epoch": 1.78,
      "grad_norm": 1.1205708980560303,
      "learning_rate": 2.2199446551194016e-06,
      "loss": 0.2518,
      "step": 8679
    },
    {
      "epoch": 1.78,
      "grad_norm": 0.7493864297866821,
      "learning_rate": 2.217894844726863e-06,
      "loss": 0.2792,
      "step": 8680
    },
    {
      "epoch": 1.78,
      "grad_norm": 1.2335940599441528,
      "learning_rate": 2.2158450343343245e-06,
      "loss": 0.3747,
      "step": 8681
    },
    {
      "epoch": 1.78,
      "grad_norm": 1.3369957208633423,
      "learning_rate": 2.2137952239417855e-06,
      "loss": 0.4087,
      "step": 8682
    },
    {
      "epoch": 1.78,
      "grad_norm": 1.247546911239624,
      "learning_rate": 2.211745413549247e-06,
      "loss": 0.3619,
      "step": 8683
    },
    {
      "epoch": 1.78,
      "grad_norm": 1.032441258430481,
      "learning_rate": 2.2096956031567083e-06,
      "loss": 0.3321,
      "step": 8684
    },
    {
      "epoch": 1.78,
      "grad_norm": 1.2094484567642212,
      "learning_rate": 2.2076457927641693e-06,
      "loss": 0.2701,
      "step": 8685
    },
    {
      "epoch": 1.78,
      "grad_norm": 0.993157684803009,
      "learning_rate": 2.2055959823716308e-06,
      "loss": 0.1869,
      "step": 8686
    },
    {
      "epoch": 1.78,
      "grad_norm": 1.8513621091842651,
      "learning_rate": 2.203546171979092e-06,
      "loss": 0.3824,
      "step": 8687
    },
    {
      "epoch": 1.78,
      "grad_norm": 1.0832695960998535,
      "learning_rate": 2.201496361586553e-06,
      "loss": 0.2652,
      "step": 8688
    },
    {
      "epoch": 1.78,
      "grad_norm": 1.1464245319366455,
      "learning_rate": 2.1994465511940146e-06,
      "loss": 0.248,
      "step": 8689
    },
    {
      "epoch": 1.78,
      "grad_norm": 1.1468812227249146,
      "learning_rate": 2.197396740801476e-06,
      "loss": 0.265,
      "step": 8690
    },
    {
      "epoch": 1.78,
      "grad_norm": 1.0857034921646118,
      "learning_rate": 2.195346930408937e-06,
      "loss": 0.2805,
      "step": 8691
    },
    {
      "epoch": 1.78,
      "grad_norm": 1.092200517654419,
      "learning_rate": 2.1932971200163985e-06,
      "loss": 0.2861,
      "step": 8692
    },
    {
      "epoch": 1.78,
      "grad_norm": 0.9167724847793579,
      "learning_rate": 2.19124730962386e-06,
      "loss": 0.3384,
      "step": 8693
    },
    {
      "epoch": 1.78,
      "grad_norm": 1.5350866317749023,
      "learning_rate": 2.1891974992313214e-06,
      "loss": 0.2264,
      "step": 8694
    },
    {
      "epoch": 1.78,
      "grad_norm": 0.7636049389839172,
      "learning_rate": 2.187147688838783e-06,
      "loss": 0.3557,
      "step": 8695
    },
    {
      "epoch": 1.78,
      "grad_norm": 1.0650228261947632,
      "learning_rate": 2.185097878446244e-06,
      "loss": 0.5421,
      "step": 8696
    },
    {
      "epoch": 1.78,
      "grad_norm": 0.9773148894309998,
      "learning_rate": 2.1830480680537053e-06,
      "loss": 0.2395,
      "step": 8697
    },
    {
      "epoch": 1.78,
      "grad_norm": 1.0438880920410156,
      "learning_rate": 2.1809982576611667e-06,
      "loss": 0.3865,
      "step": 8698
    },
    {
      "epoch": 1.78,
      "grad_norm": 1.3902336359024048,
      "learning_rate": 2.1789484472686277e-06,
      "loss": 0.4023,
      "step": 8699
    },
    {
      "epoch": 1.78,
      "grad_norm": 1.100245714187622,
      "learning_rate": 2.176898636876089e-06,
      "loss": 0.3183,
      "step": 8700
    },
    {
      "epoch": 1.78,
      "grad_norm": 1.1318179368972778,
      "learning_rate": 2.1748488264835506e-06,
      "loss": 0.346,
      "step": 8701
    },
    {
      "epoch": 1.78,
      "grad_norm": 1.440195918083191,
      "learning_rate": 2.1727990160910116e-06,
      "loss": 0.441,
      "step": 8702
    },
    {
      "epoch": 1.78,
      "grad_norm": 1.2956717014312744,
      "learning_rate": 2.170749205698473e-06,
      "loss": 0.3398,
      "step": 8703
    },
    {
      "epoch": 1.78,
      "grad_norm": 1.2052538394927979,
      "learning_rate": 2.1686993953059344e-06,
      "loss": 0.3986,
      "step": 8704
    },
    {
      "epoch": 1.78,
      "grad_norm": 1.411073923110962,
      "learning_rate": 2.1666495849133955e-06,
      "loss": 0.3518,
      "step": 8705
    },
    {
      "epoch": 1.78,
      "grad_norm": 1.106947898864746,
      "learning_rate": 2.164599774520857e-06,
      "loss": 0.3228,
      "step": 8706
    },
    {
      "epoch": 1.78,
      "grad_norm": 1.161603569984436,
      "learning_rate": 2.1625499641283183e-06,
      "loss": 0.3453,
      "step": 8707
    },
    {
      "epoch": 1.78,
      "grad_norm": 1.0415226221084595,
      "learning_rate": 2.1605001537357793e-06,
      "loss": 0.263,
      "step": 8708
    },
    {
      "epoch": 1.78,
      "grad_norm": 1.1035315990447998,
      "learning_rate": 2.158450343343241e-06,
      "loss": 0.3915,
      "step": 8709
    },
    {
      "epoch": 1.78,
      "grad_norm": 0.9660553932189941,
      "learning_rate": 2.156400532950702e-06,
      "loss": 0.4025,
      "step": 8710
    },
    {
      "epoch": 1.78,
      "grad_norm": 1.225003957748413,
      "learning_rate": 2.1543507225581636e-06,
      "loss": 0.3526,
      "step": 8711
    },
    {
      "epoch": 1.78,
      "grad_norm": 0.955572783946991,
      "learning_rate": 2.152300912165625e-06,
      "loss": 0.3162,
      "step": 8712
    },
    {
      "epoch": 1.79,
      "grad_norm": 2.036867380142212,
      "learning_rate": 2.150251101773086e-06,
      "loss": 0.3579,
      "step": 8713
    },
    {
      "epoch": 1.79,
      "grad_norm": 1.0957000255584717,
      "learning_rate": 2.1482012913805475e-06,
      "loss": 0.4081,
      "step": 8714
    },
    {
      "epoch": 1.79,
      "grad_norm": 1.344793438911438,
      "learning_rate": 2.146151480988009e-06,
      "loss": 0.3299,
      "step": 8715
    },
    {
      "epoch": 1.79,
      "grad_norm": 0.7942884564399719,
      "learning_rate": 2.14410167059547e-06,
      "loss": 0.2306,
      "step": 8716
    },
    {
      "epoch": 1.79,
      "grad_norm": 1.3096466064453125,
      "learning_rate": 2.1420518602029314e-06,
      "loss": 0.3555,
      "step": 8717
    },
    {
      "epoch": 1.79,
      "grad_norm": 0.9610587358474731,
      "learning_rate": 2.140002049810393e-06,
      "loss": 0.29,
      "step": 8718
    },
    {
      "epoch": 1.79,
      "grad_norm": 1.3055483102798462,
      "learning_rate": 2.137952239417854e-06,
      "loss": 0.2258,
      "step": 8719
    },
    {
      "epoch": 1.79,
      "grad_norm": 1.2631466388702393,
      "learning_rate": 2.1359024290253153e-06,
      "loss": 0.3921,
      "step": 8720
    },
    {
      "epoch": 1.79,
      "grad_norm": 1.412639856338501,
      "learning_rate": 2.1338526186327767e-06,
      "loss": 0.3303,
      "step": 8721
    },
    {
      "epoch": 1.79,
      "grad_norm": 0.9641905426979065,
      "learning_rate": 2.1318028082402377e-06,
      "loss": 0.3667,
      "step": 8722
    },
    {
      "epoch": 1.79,
      "grad_norm": 0.6722317337989807,
      "learning_rate": 2.1297529978476996e-06,
      "loss": 0.2592,
      "step": 8723
    },
    {
      "epoch": 1.79,
      "grad_norm": 0.6073193550109863,
      "learning_rate": 2.1277031874551606e-06,
      "loss": 0.2241,
      "step": 8724
    },
    {
      "epoch": 1.79,
      "grad_norm": 0.7252627015113831,
      "learning_rate": 2.125653377062622e-06,
      "loss": 0.2751,
      "step": 8725
    },
    {
      "epoch": 1.79,
      "grad_norm": 1.401370644569397,
      "learning_rate": 2.1236035666700834e-06,
      "loss": 0.3481,
      "step": 8726
    },
    {
      "epoch": 1.79,
      "grad_norm": 1.0857774019241333,
      "learning_rate": 2.1215537562775444e-06,
      "loss": 0.3521,
      "step": 8727
    },
    {
      "epoch": 1.79,
      "grad_norm": 1.1404950618743896,
      "learning_rate": 2.119503945885006e-06,
      "loss": 0.2934,
      "step": 8728
    },
    {
      "epoch": 1.79,
      "grad_norm": 0.7948206663131714,
      "learning_rate": 2.1174541354924673e-06,
      "loss": 0.2966,
      "step": 8729
    },
    {
      "epoch": 1.79,
      "grad_norm": 0.6358070373535156,
      "learning_rate": 2.1154043250999283e-06,
      "loss": 0.1308,
      "step": 8730
    },
    {
      "epoch": 1.79,
      "grad_norm": 0.8208582401275635,
      "learning_rate": 2.1133545147073897e-06,
      "loss": 0.2615,
      "step": 8731
    },
    {
      "epoch": 1.79,
      "grad_norm": 1.1009280681610107,
      "learning_rate": 2.111304704314851e-06,
      "loss": 0.3291,
      "step": 8732
    },
    {
      "epoch": 1.79,
      "grad_norm": 0.9366503953933716,
      "learning_rate": 2.109254893922312e-06,
      "loss": 0.241,
      "step": 8733
    },
    {
      "epoch": 1.79,
      "grad_norm": 0.9732041954994202,
      "learning_rate": 2.1072050835297736e-06,
      "loss": 0.3045,
      "step": 8734
    },
    {
      "epoch": 1.79,
      "grad_norm": 1.2476545572280884,
      "learning_rate": 2.105155273137235e-06,
      "loss": 0.3566,
      "step": 8735
    },
    {
      "epoch": 1.79,
      "grad_norm": 1.0827031135559082,
      "learning_rate": 2.103105462744696e-06,
      "loss": 0.3963,
      "step": 8736
    },
    {
      "epoch": 1.79,
      "grad_norm": 1.1648675203323364,
      "learning_rate": 2.1010556523521575e-06,
      "loss": 0.377,
      "step": 8737
    },
    {
      "epoch": 1.79,
      "grad_norm": 1.3893015384674072,
      "learning_rate": 2.099005841959619e-06,
      "loss": 0.407,
      "step": 8738
    },
    {
      "epoch": 1.79,
      "grad_norm": 1.1130561828613281,
      "learning_rate": 2.0969560315670804e-06,
      "loss": 0.2603,
      "step": 8739
    },
    {
      "epoch": 1.79,
      "grad_norm": 1.379437804222107,
      "learning_rate": 2.094906221174542e-06,
      "loss": 0.4236,
      "step": 8740
    },
    {
      "epoch": 1.79,
      "grad_norm": 0.7758491635322571,
      "learning_rate": 2.092856410782003e-06,
      "loss": 0.2521,
      "step": 8741
    },
    {
      "epoch": 1.79,
      "grad_norm": 0.7841043472290039,
      "learning_rate": 2.0908066003894642e-06,
      "loss": 0.2774,
      "step": 8742
    },
    {
      "epoch": 1.79,
      "grad_norm": 1.121207356452942,
      "learning_rate": 2.0887567899969257e-06,
      "loss": 0.4285,
      "step": 8743
    },
    {
      "epoch": 1.79,
      "grad_norm": 1.077409029006958,
      "learning_rate": 2.0867069796043867e-06,
      "loss": 0.4112,
      "step": 8744
    },
    {
      "epoch": 1.79,
      "grad_norm": 1.1826049089431763,
      "learning_rate": 2.084657169211848e-06,
      "loss": 0.4801,
      "step": 8745
    },
    {
      "epoch": 1.79,
      "grad_norm": 1.0499281883239746,
      "learning_rate": 2.0826073588193095e-06,
      "loss": 0.4393,
      "step": 8746
    },
    {
      "epoch": 1.79,
      "grad_norm": 1.1601752042770386,
      "learning_rate": 2.0805575484267706e-06,
      "loss": 0.445,
      "step": 8747
    },
    {
      "epoch": 1.79,
      "grad_norm": 1.0733311176300049,
      "learning_rate": 2.078507738034232e-06,
      "loss": 0.3305,
      "step": 8748
    },
    {
      "epoch": 1.79,
      "grad_norm": 1.623060703277588,
      "learning_rate": 2.0764579276416934e-06,
      "loss": 0.2904,
      "step": 8749
    },
    {
      "epoch": 1.79,
      "grad_norm": 1.9830119609832764,
      "learning_rate": 2.0744081172491544e-06,
      "loss": 0.3961,
      "step": 8750
    },
    {
      "epoch": 1.79,
      "grad_norm": 1.1055272817611694,
      "learning_rate": 2.072358306856616e-06,
      "loss": 0.3235,
      "step": 8751
    },
    {
      "epoch": 1.79,
      "grad_norm": 1.3938943147659302,
      "learning_rate": 2.0703084964640773e-06,
      "loss": 0.4415,
      "step": 8752
    },
    {
      "epoch": 1.79,
      "grad_norm": 1.0858306884765625,
      "learning_rate": 2.0682586860715387e-06,
      "loss": 0.2965,
      "step": 8753
    },
    {
      "epoch": 1.79,
      "grad_norm": 0.8911011815071106,
      "learning_rate": 2.066208875679e-06,
      "loss": 0.3905,
      "step": 8754
    },
    {
      "epoch": 1.79,
      "grad_norm": 1.4094998836517334,
      "learning_rate": 2.064159065286461e-06,
      "loss": 0.4094,
      "step": 8755
    },
    {
      "epoch": 1.79,
      "grad_norm": 1.2745208740234375,
      "learning_rate": 2.0621092548939226e-06,
      "loss": 0.319,
      "step": 8756
    },
    {
      "epoch": 1.79,
      "grad_norm": 1.3910439014434814,
      "learning_rate": 2.060059444501384e-06,
      "loss": 0.5132,
      "step": 8757
    },
    {
      "epoch": 1.79,
      "grad_norm": 1.4121719598770142,
      "learning_rate": 2.058009634108845e-06,
      "loss": 0.5127,
      "step": 8758
    },
    {
      "epoch": 1.79,
      "grad_norm": 0.9911755919456482,
      "learning_rate": 2.0559598237163065e-06,
      "loss": 0.375,
      "step": 8759
    },
    {
      "epoch": 1.79,
      "grad_norm": 1.1677989959716797,
      "learning_rate": 2.053910013323768e-06,
      "loss": 0.4137,
      "step": 8760
    },
    {
      "epoch": 1.79,
      "grad_norm": 0.7592908143997192,
      "learning_rate": 2.051860202931229e-06,
      "loss": 0.3173,
      "step": 8761
    },
    {
      "epoch": 1.8,
      "grad_norm": 1.127155065536499,
      "learning_rate": 2.0498103925386904e-06,
      "loss": 0.3464,
      "step": 8762
    },
    {
      "epoch": 1.8,
      "grad_norm": 1.3591248989105225,
      "learning_rate": 2.0477605821461518e-06,
      "loss": 0.4725,
      "step": 8763
    },
    {
      "epoch": 1.8,
      "grad_norm": 1.4993433952331543,
      "learning_rate": 2.045710771753613e-06,
      "loss": 0.3749,
      "step": 8764
    },
    {
      "epoch": 1.8,
      "grad_norm": 1.1428991556167603,
      "learning_rate": 2.0436609613610742e-06,
      "loss": 0.4636,
      "step": 8765
    },
    {
      "epoch": 1.8,
      "grad_norm": 1.2133667469024658,
      "learning_rate": 2.0416111509685357e-06,
      "loss": 0.4372,
      "step": 8766
    },
    {
      "epoch": 1.8,
      "grad_norm": 1.143425464630127,
      "learning_rate": 2.0395613405759967e-06,
      "loss": 0.2312,
      "step": 8767
    },
    {
      "epoch": 1.8,
      "grad_norm": 0.7968416213989258,
      "learning_rate": 2.0375115301834585e-06,
      "loss": 0.2456,
      "step": 8768
    },
    {
      "epoch": 1.8,
      "grad_norm": 0.9458740949630737,
      "learning_rate": 2.0354617197909195e-06,
      "loss": 0.3316,
      "step": 8769
    },
    {
      "epoch": 1.8,
      "grad_norm": 1.2436316013336182,
      "learning_rate": 2.033411909398381e-06,
      "loss": 0.5325,
      "step": 8770
    },
    {
      "epoch": 1.8,
      "grad_norm": 1.2049411535263062,
      "learning_rate": 2.0313620990058424e-06,
      "loss": 0.3799,
      "step": 8771
    },
    {
      "epoch": 1.8,
      "grad_norm": 0.9305760264396667,
      "learning_rate": 2.0293122886133034e-06,
      "loss": 0.1668,
      "step": 8772
    },
    {
      "epoch": 1.8,
      "grad_norm": 1.6429924964904785,
      "learning_rate": 2.027262478220765e-06,
      "loss": 0.4982,
      "step": 8773
    },
    {
      "epoch": 1.8,
      "grad_norm": 0.9526392221450806,
      "learning_rate": 2.0252126678282263e-06,
      "loss": 0.2745,
      "step": 8774
    },
    {
      "epoch": 1.8,
      "grad_norm": 1.0370256900787354,
      "learning_rate": 2.0231628574356873e-06,
      "loss": 0.3234,
      "step": 8775
    },
    {
      "epoch": 1.8,
      "grad_norm": 1.5932729244232178,
      "learning_rate": 2.0211130470431487e-06,
      "loss": 0.3364,
      "step": 8776
    },
    {
      "epoch": 1.8,
      "grad_norm": 1.3343441486358643,
      "learning_rate": 2.0190632366506097e-06,
      "loss": 0.2959,
      "step": 8777
    },
    {
      "epoch": 1.8,
      "grad_norm": 1.9158384799957275,
      "learning_rate": 2.017013426258071e-06,
      "loss": 0.3145,
      "step": 8778
    },
    {
      "epoch": 1.8,
      "grad_norm": 2.2524237632751465,
      "learning_rate": 2.0149636158655326e-06,
      "loss": 0.453,
      "step": 8779
    },
    {
      "epoch": 1.8,
      "grad_norm": 0.9475584030151367,
      "learning_rate": 2.0129138054729936e-06,
      "loss": 0.2296,
      "step": 8780
    },
    {
      "epoch": 1.8,
      "grad_norm": 0.9339419603347778,
      "learning_rate": 2.010863995080455e-06,
      "loss": 0.2409,
      "step": 8781
    },
    {
      "epoch": 1.8,
      "grad_norm": 1.418138861656189,
      "learning_rate": 2.0088141846879165e-06,
      "loss": 0.3326,
      "step": 8782
    },
    {
      "epoch": 1.8,
      "grad_norm": 1.7546560764312744,
      "learning_rate": 2.006764374295378e-06,
      "loss": 0.2551,
      "step": 8783
    },
    {
      "epoch": 1.8,
      "grad_norm": 1.314579963684082,
      "learning_rate": 2.0047145639028393e-06,
      "loss": 0.244,
      "step": 8784
    },
    {
      "epoch": 1.8,
      "grad_norm": 1.3731187582015991,
      "learning_rate": 2.0026647535103003e-06,
      "loss": 0.3147,
      "step": 8785
    },
    {
      "epoch": 1.8,
      "grad_norm": 1.2519091367721558,
      "learning_rate": 2.0006149431177618e-06,
      "loss": 0.3377,
      "step": 8786
    },
    {
      "epoch": 1.8,
      "grad_norm": 1.149208664894104,
      "learning_rate": 1.998565132725223e-06,
      "loss": 0.3928,
      "step": 8787
    },
    {
      "epoch": 1.8,
      "grad_norm": 1.4825955629348755,
      "learning_rate": 1.9965153223326842e-06,
      "loss": 0.3044,
      "step": 8788
    },
    {
      "epoch": 1.8,
      "grad_norm": 0.9497030377388,
      "learning_rate": 1.9944655119401457e-06,
      "loss": 0.4283,
      "step": 8789
    },
    {
      "epoch": 1.8,
      "grad_norm": 2.828477144241333,
      "learning_rate": 1.992415701547607e-06,
      "loss": 0.4214,
      "step": 8790
    },
    {
      "epoch": 1.8,
      "grad_norm": 1.587809443473816,
      "learning_rate": 1.990365891155068e-06,
      "loss": 0.4134,
      "step": 8791
    },
    {
      "epoch": 1.8,
      "grad_norm": 1.4902186393737793,
      "learning_rate": 1.9883160807625295e-06,
      "loss": 0.3232,
      "step": 8792
    },
    {
      "epoch": 1.8,
      "grad_norm": 1.286866307258606,
      "learning_rate": 1.986266270369991e-06,
      "loss": 0.507,
      "step": 8793
    },
    {
      "epoch": 1.8,
      "grad_norm": 1.2593377828598022,
      "learning_rate": 1.984216459977452e-06,
      "loss": 0.3243,
      "step": 8794
    },
    {
      "epoch": 1.8,
      "grad_norm": 1.4336647987365723,
      "learning_rate": 1.9821666495849134e-06,
      "loss": 0.3106,
      "step": 8795
    },
    {
      "epoch": 1.8,
      "grad_norm": 1.5943835973739624,
      "learning_rate": 1.980116839192375e-06,
      "loss": 0.3119,
      "step": 8796
    },
    {
      "epoch": 1.8,
      "grad_norm": 1.5536168813705444,
      "learning_rate": 1.9780670287998363e-06,
      "loss": 0.4575,
      "step": 8797
    },
    {
      "epoch": 1.8,
      "grad_norm": 1.364722728729248,
      "learning_rate": 1.9760172184072977e-06,
      "loss": 0.3292,
      "step": 8798
    },
    {
      "epoch": 1.8,
      "grad_norm": 1.3272565603256226,
      "learning_rate": 1.9739674080147587e-06,
      "loss": 0.5418,
      "step": 8799
    },
    {
      "epoch": 1.8,
      "grad_norm": 1.6995025873184204,
      "learning_rate": 1.97191759762222e-06,
      "loss": 0.4642,
      "step": 8800
    },
    {
      "epoch": 1.8,
      "grad_norm": 1.1551116704940796,
      "learning_rate": 1.9698677872296816e-06,
      "loss": 0.3838,
      "step": 8801
    },
    {
      "epoch": 1.8,
      "grad_norm": 2.0628936290740967,
      "learning_rate": 1.9678179768371426e-06,
      "loss": 0.5479,
      "step": 8802
    },
    {
      "epoch": 1.8,
      "grad_norm": 1.2842142581939697,
      "learning_rate": 1.965768166444604e-06,
      "loss": 0.4474,
      "step": 8803
    },
    {
      "epoch": 1.8,
      "grad_norm": 1.280876874923706,
      "learning_rate": 1.9637183560520655e-06,
      "loss": 0.4377,
      "step": 8804
    },
    {
      "epoch": 1.8,
      "grad_norm": 0.9448161721229553,
      "learning_rate": 1.9616685456595265e-06,
      "loss": 0.3075,
      "step": 8805
    },
    {
      "epoch": 1.8,
      "grad_norm": 1.6418838500976562,
      "learning_rate": 1.959618735266988e-06,
      "loss": 0.4352,
      "step": 8806
    },
    {
      "epoch": 1.8,
      "grad_norm": 1.373184084892273,
      "learning_rate": 1.9575689248744493e-06,
      "loss": 0.3227,
      "step": 8807
    },
    {
      "epoch": 1.8,
      "grad_norm": 1.4290131330490112,
      "learning_rate": 1.9555191144819103e-06,
      "loss": 0.2649,
      "step": 8808
    },
    {
      "epoch": 1.8,
      "grad_norm": 1.5011860132217407,
      "learning_rate": 1.9534693040893718e-06,
      "loss": 0.3923,
      "step": 8809
    },
    {
      "epoch": 1.8,
      "grad_norm": 0.9014175534248352,
      "learning_rate": 1.951419493696833e-06,
      "loss": 0.2566,
      "step": 8810
    },
    {
      "epoch": 1.81,
      "grad_norm": 1.1107312440872192,
      "learning_rate": 1.949369683304294e-06,
      "loss": 0.438,
      "step": 8811
    },
    {
      "epoch": 1.81,
      "grad_norm": 0.862134575843811,
      "learning_rate": 1.947319872911756e-06,
      "loss": 0.326,
      "step": 8812
    },
    {
      "epoch": 1.81,
      "grad_norm": 0.8861181139945984,
      "learning_rate": 1.945270062519217e-06,
      "loss": 0.2605,
      "step": 8813
    },
    {
      "epoch": 1.81,
      "grad_norm": 1.5172547101974487,
      "learning_rate": 1.9432202521266785e-06,
      "loss": 0.2153,
      "step": 8814
    },
    {
      "epoch": 1.81,
      "grad_norm": 1.5826904773712158,
      "learning_rate": 1.94117044173414e-06,
      "loss": 0.3345,
      "step": 8815
    },
    {
      "epoch": 1.81,
      "grad_norm": 1.1598163843154907,
      "learning_rate": 1.939120631341601e-06,
      "loss": 0.2984,
      "step": 8816
    },
    {
      "epoch": 1.81,
      "grad_norm": 1.3405895233154297,
      "learning_rate": 1.9370708209490624e-06,
      "loss": 0.361,
      "step": 8817
    },
    {
      "epoch": 1.81,
      "grad_norm": 0.9867703318595886,
      "learning_rate": 1.935021010556524e-06,
      "loss": 0.2554,
      "step": 8818
    },
    {
      "epoch": 1.81,
      "grad_norm": 1.0335335731506348,
      "learning_rate": 1.932971200163985e-06,
      "loss": 0.2603,
      "step": 8819
    },
    {
      "epoch": 1.81,
      "grad_norm": 1.0782705545425415,
      "learning_rate": 1.9309213897714463e-06,
      "loss": 0.3539,
      "step": 8820
    },
    {
      "epoch": 1.81,
      "grad_norm": 0.8487699627876282,
      "learning_rate": 1.9288715793789077e-06,
      "loss": 0.2349,
      "step": 8821
    },
    {
      "epoch": 1.81,
      "grad_norm": 1.3058634996414185,
      "learning_rate": 1.9268217689863687e-06,
      "loss": 0.3768,
      "step": 8822
    },
    {
      "epoch": 1.81,
      "grad_norm": 1.0919123888015747,
      "learning_rate": 1.92477195859383e-06,
      "loss": 0.3292,
      "step": 8823
    },
    {
      "epoch": 1.81,
      "grad_norm": 1.314538598060608,
      "learning_rate": 1.9227221482012916e-06,
      "loss": 0.3134,
      "step": 8824
    },
    {
      "epoch": 1.81,
      "grad_norm": 1.961303472518921,
      "learning_rate": 1.9206723378087526e-06,
      "loss": 0.3846,
      "step": 8825
    },
    {
      "epoch": 1.81,
      "grad_norm": 1.1163028478622437,
      "learning_rate": 1.918622527416214e-06,
      "loss": 0.1884,
      "step": 8826
    },
    {
      "epoch": 1.81,
      "grad_norm": 1.2735480070114136,
      "learning_rate": 1.9165727170236754e-06,
      "loss": 0.4159,
      "step": 8827
    },
    {
      "epoch": 1.81,
      "grad_norm": 0.7638701796531677,
      "learning_rate": 1.914522906631137e-06,
      "loss": 0.3014,
      "step": 8828
    },
    {
      "epoch": 1.81,
      "grad_norm": 1.1589778661727905,
      "learning_rate": 1.9124730962385983e-06,
      "loss": 0.3672,
      "step": 8829
    },
    {
      "epoch": 1.81,
      "grad_norm": 1.1894878149032593,
      "learning_rate": 1.9104232858460593e-06,
      "loss": 0.3333,
      "step": 8830
    },
    {
      "epoch": 1.81,
      "grad_norm": 0.7490519881248474,
      "learning_rate": 1.9083734754535208e-06,
      "loss": 0.2351,
      "step": 8831
    },
    {
      "epoch": 1.81,
      "grad_norm": 0.9062681794166565,
      "learning_rate": 1.906323665060982e-06,
      "loss": 0.2632,
      "step": 8832
    },
    {
      "epoch": 1.81,
      "grad_norm": 0.5013147592544556,
      "learning_rate": 1.9042738546684434e-06,
      "loss": 0.1709,
      "step": 8833
    },
    {
      "epoch": 1.81,
      "grad_norm": 0.972834587097168,
      "learning_rate": 1.9022240442759046e-06,
      "loss": 0.3651,
      "step": 8834
    },
    {
      "epoch": 1.81,
      "grad_norm": 0.9189212322235107,
      "learning_rate": 1.9001742338833658e-06,
      "loss": 0.4102,
      "step": 8835
    },
    {
      "epoch": 1.81,
      "grad_norm": 0.8481299877166748,
      "learning_rate": 1.8981244234908273e-06,
      "loss": 0.3306,
      "step": 8836
    },
    {
      "epoch": 1.81,
      "grad_norm": 1.5013725757598877,
      "learning_rate": 1.8960746130982885e-06,
      "loss": 0.318,
      "step": 8837
    },
    {
      "epoch": 1.81,
      "grad_norm": 0.7010247707366943,
      "learning_rate": 1.8940248027057497e-06,
      "loss": 0.2207,
      "step": 8838
    },
    {
      "epoch": 1.81,
      "grad_norm": 0.8695366978645325,
      "learning_rate": 1.8919749923132112e-06,
      "loss": 0.2711,
      "step": 8839
    },
    {
      "epoch": 1.81,
      "grad_norm": 1.0003808736801147,
      "learning_rate": 1.8899251819206724e-06,
      "loss": 0.2638,
      "step": 8840
    },
    {
      "epoch": 1.81,
      "grad_norm": 1.1427322626113892,
      "learning_rate": 1.887875371528134e-06,
      "loss": 0.3815,
      "step": 8841
    },
    {
      "epoch": 1.81,
      "grad_norm": 1.6050838232040405,
      "learning_rate": 1.8858255611355952e-06,
      "loss": 0.3968,
      "step": 8842
    },
    {
      "epoch": 1.81,
      "grad_norm": 0.9644786715507507,
      "learning_rate": 1.8837757507430565e-06,
      "loss": 0.2198,
      "step": 8843
    },
    {
      "epoch": 1.81,
      "grad_norm": 0.9705821871757507,
      "learning_rate": 1.881725940350518e-06,
      "loss": 0.3938,
      "step": 8844
    },
    {
      "epoch": 1.81,
      "grad_norm": 0.933416485786438,
      "learning_rate": 1.8796761299579791e-06,
      "loss": 0.2952,
      "step": 8845
    },
    {
      "epoch": 1.81,
      "grad_norm": 0.8195677399635315,
      "learning_rate": 1.8776263195654403e-06,
      "loss": 0.307,
      "step": 8846
    },
    {
      "epoch": 1.81,
      "grad_norm": 1.1086640357971191,
      "learning_rate": 1.8755765091729018e-06,
      "loss": 0.31,
      "step": 8847
    },
    {
      "epoch": 1.81,
      "grad_norm": 1.232896327972412,
      "learning_rate": 1.873526698780363e-06,
      "loss": 0.3111,
      "step": 8848
    },
    {
      "epoch": 1.81,
      "grad_norm": 1.004761815071106,
      "learning_rate": 1.8714768883878242e-06,
      "loss": 0.2679,
      "step": 8849
    },
    {
      "epoch": 1.81,
      "grad_norm": 1.2816239595413208,
      "learning_rate": 1.8694270779952856e-06,
      "loss": 0.3736,
      "step": 8850
    },
    {
      "epoch": 1.81,
      "grad_norm": 1.0097042322158813,
      "learning_rate": 1.8673772676027469e-06,
      "loss": 0.2614,
      "step": 8851
    },
    {
      "epoch": 1.81,
      "grad_norm": 1.1349619626998901,
      "learning_rate": 1.865327457210208e-06,
      "loss": 0.513,
      "step": 8852
    },
    {
      "epoch": 1.81,
      "grad_norm": 1.149947166442871,
      "learning_rate": 1.8632776468176695e-06,
      "loss": 0.358,
      "step": 8853
    },
    {
      "epoch": 1.81,
      "grad_norm": 1.1359515190124512,
      "learning_rate": 1.8612278364251307e-06,
      "loss": 0.3551,
      "step": 8854
    },
    {
      "epoch": 1.81,
      "grad_norm": 0.9835177063941956,
      "learning_rate": 1.859178026032592e-06,
      "loss": 0.3367,
      "step": 8855
    },
    {
      "epoch": 1.81,
      "grad_norm": 0.9218027591705322,
      "learning_rate": 1.8571282156400536e-06,
      "loss": 0.3208,
      "step": 8856
    },
    {
      "epoch": 1.81,
      "grad_norm": 1.358749270439148,
      "learning_rate": 1.8550784052475148e-06,
      "loss": 0.4699,
      "step": 8857
    },
    {
      "epoch": 1.81,
      "grad_norm": 0.9001771211624146,
      "learning_rate": 1.8530285948549763e-06,
      "loss": 0.3853,
      "step": 8858
    },
    {
      "epoch": 1.81,
      "grad_norm": 1.1615185737609863,
      "learning_rate": 1.8509787844624375e-06,
      "loss": 0.3222,
      "step": 8859
    },
    {
      "epoch": 1.82,
      "grad_norm": 1.7322266101837158,
      "learning_rate": 1.8489289740698987e-06,
      "loss": 0.3771,
      "step": 8860
    },
    {
      "epoch": 1.82,
      "grad_norm": 0.8531635999679565,
      "learning_rate": 1.8468791636773601e-06,
      "loss": 0.27,
      "step": 8861
    },
    {
      "epoch": 1.82,
      "grad_norm": 0.8396581411361694,
      "learning_rate": 1.8448293532848214e-06,
      "loss": 0.1923,
      "step": 8862
    },
    {
      "epoch": 1.82,
      "grad_norm": 1.1480849981307983,
      "learning_rate": 1.8427795428922826e-06,
      "loss": 0.333,
      "step": 8863
    },
    {
      "epoch": 1.82,
      "grad_norm": 1.2569622993469238,
      "learning_rate": 1.8407297324997438e-06,
      "loss": 0.3233,
      "step": 8864
    },
    {
      "epoch": 1.82,
      "grad_norm": 1.0466747283935547,
      "learning_rate": 1.8386799221072052e-06,
      "loss": 0.2835,
      "step": 8865
    },
    {
      "epoch": 1.82,
      "grad_norm": 1.0151182413101196,
      "learning_rate": 1.8366301117146665e-06,
      "loss": 0.3639,
      "step": 8866
    },
    {
      "epoch": 1.82,
      "grad_norm": 1.0318001508712769,
      "learning_rate": 1.8345803013221277e-06,
      "loss": 0.281,
      "step": 8867
    },
    {
      "epoch": 1.82,
      "grad_norm": 0.8360934853553772,
      "learning_rate": 1.8325304909295891e-06,
      "loss": 0.2595,
      "step": 8868
    },
    {
      "epoch": 1.82,
      "grad_norm": 1.0230313539505005,
      "learning_rate": 1.8304806805370503e-06,
      "loss": 0.26,
      "step": 8869
    },
    {
      "epoch": 1.82,
      "grad_norm": 1.2350530624389648,
      "learning_rate": 1.8284308701445116e-06,
      "loss": 0.2632,
      "step": 8870
    },
    {
      "epoch": 1.82,
      "grad_norm": 1.2397781610488892,
      "learning_rate": 1.8263810597519732e-06,
      "loss": 0.4469,
      "step": 8871
    },
    {
      "epoch": 1.82,
      "grad_norm": 0.7446741461753845,
      "learning_rate": 1.8243312493594344e-06,
      "loss": 0.2358,
      "step": 8872
    },
    {
      "epoch": 1.82,
      "grad_norm": 0.9298070669174194,
      "learning_rate": 1.8222814389668958e-06,
      "loss": 0.3687,
      "step": 8873
    },
    {
      "epoch": 1.82,
      "grad_norm": 1.5494353771209717,
      "learning_rate": 1.820231628574357e-06,
      "loss": 0.4692,
      "step": 8874
    },
    {
      "epoch": 1.82,
      "grad_norm": 1.1284356117248535,
      "learning_rate": 1.8181818181818183e-06,
      "loss": 0.3213,
      "step": 8875
    },
    {
      "epoch": 1.82,
      "grad_norm": 1.3768712282180786,
      "learning_rate": 1.8161320077892797e-06,
      "loss": 0.3765,
      "step": 8876
    },
    {
      "epoch": 1.82,
      "grad_norm": 1.2969675064086914,
      "learning_rate": 1.814082197396741e-06,
      "loss": 0.1969,
      "step": 8877
    },
    {
      "epoch": 1.82,
      "grad_norm": 1.2823818922042847,
      "learning_rate": 1.8120323870042022e-06,
      "loss": 0.3548,
      "step": 8878
    },
    {
      "epoch": 1.82,
      "grad_norm": 0.9586048126220703,
      "learning_rate": 1.8099825766116636e-06,
      "loss": 0.2982,
      "step": 8879
    },
    {
      "epoch": 1.82,
      "grad_norm": 1.1664785146713257,
      "learning_rate": 1.8079327662191248e-06,
      "loss": 0.449,
      "step": 8880
    },
    {
      "epoch": 1.82,
      "grad_norm": 1.374017357826233,
      "learning_rate": 1.805882955826586e-06,
      "loss": 0.3454,
      "step": 8881
    },
    {
      "epoch": 1.82,
      "grad_norm": 1.0768871307373047,
      "learning_rate": 1.8038331454340475e-06,
      "loss": 0.3104,
      "step": 8882
    },
    {
      "epoch": 1.82,
      "grad_norm": 1.1331396102905273,
      "learning_rate": 1.8017833350415087e-06,
      "loss": 0.2805,
      "step": 8883
    },
    {
      "epoch": 1.82,
      "grad_norm": 0.6785762310028076,
      "learning_rate": 1.79973352464897e-06,
      "loss": 0.2671,
      "step": 8884
    },
    {
      "epoch": 1.82,
      "grad_norm": 1.1327688694000244,
      "learning_rate": 1.7976837142564314e-06,
      "loss": 0.264,
      "step": 8885
    },
    {
      "epoch": 1.82,
      "grad_norm": 1.1529024839401245,
      "learning_rate": 1.7956339038638928e-06,
      "loss": 0.3438,
      "step": 8886
    },
    {
      "epoch": 1.82,
      "grad_norm": 1.0530363321304321,
      "learning_rate": 1.7935840934713542e-06,
      "loss": 0.4558,
      "step": 8887
    },
    {
      "epoch": 1.82,
      "grad_norm": 1.1909117698669434,
      "learning_rate": 1.7915342830788154e-06,
      "loss": 0.3946,
      "step": 8888
    },
    {
      "epoch": 1.82,
      "grad_norm": 1.081196665763855,
      "learning_rate": 1.7894844726862767e-06,
      "loss": 0.3701,
      "step": 8889
    },
    {
      "epoch": 1.82,
      "grad_norm": 1.346264362335205,
      "learning_rate": 1.787434662293738e-06,
      "loss": 0.4952,
      "step": 8890
    },
    {
      "epoch": 1.82,
      "grad_norm": 1.047298789024353,
      "learning_rate": 1.7853848519011993e-06,
      "loss": 0.4144,
      "step": 8891
    },
    {
      "epoch": 1.82,
      "grad_norm": 1.0820480585098267,
      "learning_rate": 1.7833350415086605e-06,
      "loss": 0.4137,
      "step": 8892
    },
    {
      "epoch": 1.82,
      "grad_norm": 1.525989294052124,
      "learning_rate": 1.781285231116122e-06,
      "loss": 0.2678,
      "step": 8893
    },
    {
      "epoch": 1.82,
      "grad_norm": 1.274367332458496,
      "learning_rate": 1.7792354207235832e-06,
      "loss": 0.3817,
      "step": 8894
    },
    {
      "epoch": 1.82,
      "grad_norm": 1.2522388696670532,
      "learning_rate": 1.7771856103310444e-06,
      "loss": 0.3498,
      "step": 8895
    },
    {
      "epoch": 1.82,
      "grad_norm": 1.090165376663208,
      "learning_rate": 1.7751357999385058e-06,
      "loss": 0.2814,
      "step": 8896
    },
    {
      "epoch": 1.82,
      "grad_norm": 1.2484102249145508,
      "learning_rate": 1.773085989545967e-06,
      "loss": 0.311,
      "step": 8897
    },
    {
      "epoch": 1.82,
      "grad_norm": 2.0775880813598633,
      "learning_rate": 1.7710361791534283e-06,
      "loss": 0.3464,
      "step": 8898
    },
    {
      "epoch": 1.82,
      "grad_norm": 1.6767358779907227,
      "learning_rate": 1.7689863687608897e-06,
      "loss": 0.2682,
      "step": 8899
    },
    {
      "epoch": 1.82,
      "grad_norm": 1.190540075302124,
      "learning_rate": 1.7669365583683511e-06,
      "loss": 0.4143,
      "step": 8900
    },
    {
      "epoch": 1.82,
      "grad_norm": 1.5082908868789673,
      "learning_rate": 1.7648867479758126e-06,
      "loss": 0.4108,
      "step": 8901
    },
    {
      "epoch": 1.82,
      "grad_norm": 1.046625018119812,
      "learning_rate": 1.7628369375832738e-06,
      "loss": 0.2678,
      "step": 8902
    },
    {
      "epoch": 1.82,
      "grad_norm": 1.1451539993286133,
      "learning_rate": 1.760787127190735e-06,
      "loss": 0.4013,
      "step": 8903
    },
    {
      "epoch": 1.82,
      "grad_norm": 1.1639803647994995,
      "learning_rate": 1.7587373167981965e-06,
      "loss": 0.2834,
      "step": 8904
    },
    {
      "epoch": 1.82,
      "grad_norm": 1.1812740564346313,
      "learning_rate": 1.7566875064056577e-06,
      "loss": 0.3658,
      "step": 8905
    },
    {
      "epoch": 1.82,
      "grad_norm": 2.114222764968872,
      "learning_rate": 1.754637696013119e-06,
      "loss": 0.4512,
      "step": 8906
    },
    {
      "epoch": 1.82,
      "grad_norm": 1.4407519102096558,
      "learning_rate": 1.7525878856205803e-06,
      "loss": 0.3708,
      "step": 8907
    },
    {
      "epoch": 1.83,
      "grad_norm": 1.8166258335113525,
      "learning_rate": 1.7505380752280416e-06,
      "loss": 0.3581,
      "step": 8908
    },
    {
      "epoch": 1.83,
      "grad_norm": 1.6062613725662231,
      "learning_rate": 1.7484882648355028e-06,
      "loss": 0.4638,
      "step": 8909
    },
    {
      "epoch": 1.83,
      "grad_norm": 1.2163137197494507,
      "learning_rate": 1.7464384544429642e-06,
      "loss": 0.2396,
      "step": 8910
    },
    {
      "epoch": 1.83,
      "grad_norm": 0.9090337157249451,
      "learning_rate": 1.7443886440504254e-06,
      "loss": 0.2743,
      "step": 8911
    },
    {
      "epoch": 1.83,
      "grad_norm": 0.9169377684593201,
      "learning_rate": 1.7423388336578867e-06,
      "loss": 0.3033,
      "step": 8912
    },
    {
      "epoch": 1.83,
      "grad_norm": 1.0401753187179565,
      "learning_rate": 1.740289023265348e-06,
      "loss": 0.367,
      "step": 8913
    },
    {
      "epoch": 1.83,
      "grad_norm": 0.9963712096214294,
      "learning_rate": 1.7382392128728093e-06,
      "loss": 0.1941,
      "step": 8914
    },
    {
      "epoch": 1.83,
      "grad_norm": 0.8650415539741516,
      "learning_rate": 1.736189402480271e-06,
      "loss": 0.4158,
      "step": 8915
    },
    {
      "epoch": 1.83,
      "grad_norm": 1.5509611368179321,
      "learning_rate": 1.7341395920877322e-06,
      "loss": 0.2986,
      "step": 8916
    },
    {
      "epoch": 1.83,
      "grad_norm": 1.6234842538833618,
      "learning_rate": 1.7320897816951934e-06,
      "loss": 0.3804,
      "step": 8917
    },
    {
      "epoch": 1.83,
      "grad_norm": 0.8248385787010193,
      "learning_rate": 1.7300399713026548e-06,
      "loss": 0.1926,
      "step": 8918
    },
    {
      "epoch": 1.83,
      "grad_norm": 0.9970594048500061,
      "learning_rate": 1.727990160910116e-06,
      "loss": 0.3492,
      "step": 8919
    },
    {
      "epoch": 1.83,
      "grad_norm": 1.0363801717758179,
      "learning_rate": 1.7259403505175773e-06,
      "loss": 0.2154,
      "step": 8920
    },
    {
      "epoch": 1.83,
      "grad_norm": 1.1365567445755005,
      "learning_rate": 1.7238905401250385e-06,
      "loss": 0.3817,
      "step": 8921
    },
    {
      "epoch": 1.83,
      "grad_norm": 1.4240180253982544,
      "learning_rate": 1.7218407297325e-06,
      "loss": 0.226,
      "step": 8922
    },
    {
      "epoch": 1.83,
      "grad_norm": 1.0770694017410278,
      "learning_rate": 1.7197909193399611e-06,
      "loss": 0.4326,
      "step": 8923
    },
    {
      "epoch": 1.83,
      "grad_norm": 1.123457431793213,
      "learning_rate": 1.7177411089474224e-06,
      "loss": 0.2637,
      "step": 8924
    },
    {
      "epoch": 1.83,
      "grad_norm": 1.5485316514968872,
      "learning_rate": 1.7156912985548838e-06,
      "loss": 0.2881,
      "step": 8925
    },
    {
      "epoch": 1.83,
      "grad_norm": 1.603367567062378,
      "learning_rate": 1.713641488162345e-06,
      "loss": 0.288,
      "step": 8926
    },
    {
      "epoch": 1.83,
      "grad_norm": 0.9903500080108643,
      "learning_rate": 1.7115916777698062e-06,
      "loss": 0.3072,
      "step": 8927
    },
    {
      "epoch": 1.83,
      "grad_norm": 1.247375249862671,
      "learning_rate": 1.7095418673772677e-06,
      "loss": 0.3569,
      "step": 8928
    },
    {
      "epoch": 1.83,
      "grad_norm": 0.5323713421821594,
      "learning_rate": 1.7074920569847289e-06,
      "loss": 0.1816,
      "step": 8929
    },
    {
      "epoch": 1.83,
      "grad_norm": 1.3501992225646973,
      "learning_rate": 1.7054422465921905e-06,
      "loss": 0.3587,
      "step": 8930
    },
    {
      "epoch": 1.83,
      "grad_norm": 0.8797938823699951,
      "learning_rate": 1.7033924361996518e-06,
      "loss": 0.303,
      "step": 8931
    },
    {
      "epoch": 1.83,
      "grad_norm": 1.5256147384643555,
      "learning_rate": 1.701342625807113e-06,
      "loss": 0.375,
      "step": 8932
    },
    {
      "epoch": 1.83,
      "grad_norm": 1.2517478466033936,
      "learning_rate": 1.6992928154145744e-06,
      "loss": 0.3889,
      "step": 8933
    },
    {
      "epoch": 1.83,
      "grad_norm": 1.1809353828430176,
      "learning_rate": 1.6972430050220356e-06,
      "loss": 0.4026,
      "step": 8934
    },
    {
      "epoch": 1.83,
      "grad_norm": 0.9187437891960144,
      "learning_rate": 1.6951931946294969e-06,
      "loss": 0.2321,
      "step": 8935
    },
    {
      "epoch": 1.83,
      "grad_norm": 1.2251609563827515,
      "learning_rate": 1.6931433842369583e-06,
      "loss": 0.3561,
      "step": 8936
    },
    {
      "epoch": 1.83,
      "grad_norm": 1.0738837718963623,
      "learning_rate": 1.6910935738444195e-06,
      "loss": 0.507,
      "step": 8937
    },
    {
      "epoch": 1.83,
      "grad_norm": 1.101845622062683,
      "learning_rate": 1.6890437634518807e-06,
      "loss": 0.3592,
      "step": 8938
    },
    {
      "epoch": 1.83,
      "grad_norm": 1.317201852798462,
      "learning_rate": 1.6869939530593422e-06,
      "loss": 0.3547,
      "step": 8939
    },
    {
      "epoch": 1.83,
      "grad_norm": 1.0563058853149414,
      "learning_rate": 1.6849441426668034e-06,
      "loss": 0.3641,
      "step": 8940
    },
    {
      "epoch": 1.83,
      "grad_norm": 1.793160319328308,
      "learning_rate": 1.6828943322742646e-06,
      "loss": 0.4468,
      "step": 8941
    },
    {
      "epoch": 1.83,
      "grad_norm": 0.7817380428314209,
      "learning_rate": 1.680844521881726e-06,
      "loss": 0.3377,
      "step": 8942
    },
    {
      "epoch": 1.83,
      "grad_norm": 1.271544098854065,
      "learning_rate": 1.6787947114891873e-06,
      "loss": 0.3056,
      "step": 8943
    },
    {
      "epoch": 1.83,
      "grad_norm": 1.3612645864486694,
      "learning_rate": 1.6767449010966485e-06,
      "loss": 0.4267,
      "step": 8944
    },
    {
      "epoch": 1.83,
      "grad_norm": 1.1318200826644897,
      "learning_rate": 1.6746950907041101e-06,
      "loss": 0.275,
      "step": 8945
    },
    {
      "epoch": 1.83,
      "grad_norm": 1.156983494758606,
      "learning_rate": 1.6726452803115713e-06,
      "loss": 0.4004,
      "step": 8946
    },
    {
      "epoch": 1.83,
      "grad_norm": 1.2668782472610474,
      "learning_rate": 1.6705954699190328e-06,
      "loss": 0.2605,
      "step": 8947
    },
    {
      "epoch": 1.83,
      "grad_norm": 1.0256354808807373,
      "learning_rate": 1.668545659526494e-06,
      "loss": 0.2818,
      "step": 8948
    },
    {
      "epoch": 1.83,
      "grad_norm": 1.0316581726074219,
      "learning_rate": 1.6664958491339552e-06,
      "loss": 0.3032,
      "step": 8949
    },
    {
      "epoch": 1.83,
      "grad_norm": 1.1069626808166504,
      "learning_rate": 1.6644460387414167e-06,
      "loss": 0.3749,
      "step": 8950
    },
    {
      "epoch": 1.83,
      "grad_norm": 1.086567997932434,
      "learning_rate": 1.6623962283488779e-06,
      "loss": 0.3964,
      "step": 8951
    },
    {
      "epoch": 1.83,
      "grad_norm": 1.068742036819458,
      "learning_rate": 1.660346417956339e-06,
      "loss": 0.3846,
      "step": 8952
    },
    {
      "epoch": 1.83,
      "grad_norm": 1.3410475254058838,
      "learning_rate": 1.6582966075638005e-06,
      "loss": 0.3057,
      "step": 8953
    },
    {
      "epoch": 1.83,
      "grad_norm": 0.9570497870445251,
      "learning_rate": 1.6562467971712617e-06,
      "loss": 0.3163,
      "step": 8954
    },
    {
      "epoch": 1.83,
      "grad_norm": 1.2849630117416382,
      "learning_rate": 1.654196986778723e-06,
      "loss": 0.3804,
      "step": 8955
    },
    {
      "epoch": 1.83,
      "grad_norm": 1.5451842546463013,
      "learning_rate": 1.6521471763861844e-06,
      "loss": 0.3479,
      "step": 8956
    },
    {
      "epoch": 1.84,
      "grad_norm": 0.9323618412017822,
      "learning_rate": 1.6500973659936456e-06,
      "loss": 0.3364,
      "step": 8957
    },
    {
      "epoch": 1.84,
      "grad_norm": 0.9229024648666382,
      "learning_rate": 1.6480475556011068e-06,
      "loss": 0.3784,
      "step": 8958
    },
    {
      "epoch": 1.84,
      "grad_norm": 2.2941501140594482,
      "learning_rate": 1.6459977452085685e-06,
      "loss": 0.3936,
      "step": 8959
    },
    {
      "epoch": 1.84,
      "grad_norm": 1.6933523416519165,
      "learning_rate": 1.6439479348160297e-06,
      "loss": 0.4217,
      "step": 8960
    },
    {
      "epoch": 1.84,
      "grad_norm": 1.4052934646606445,
      "learning_rate": 1.6418981244234911e-06,
      "loss": 0.3822,
      "step": 8961
    },
    {
      "epoch": 1.84,
      "grad_norm": 1.349974513053894,
      "learning_rate": 1.6398483140309524e-06,
      "loss": 0.3613,
      "step": 8962
    },
    {
      "epoch": 1.84,
      "grad_norm": 0.9532063603401184,
      "learning_rate": 1.6377985036384136e-06,
      "loss": 0.3961,
      "step": 8963
    },
    {
      "epoch": 1.84,
      "grad_norm": 1.7286007404327393,
      "learning_rate": 1.635748693245875e-06,
      "loss": 0.4817,
      "step": 8964
    },
    {
      "epoch": 1.84,
      "grad_norm": 0.9941510558128357,
      "learning_rate": 1.6336988828533362e-06,
      "loss": 0.3657,
      "step": 8965
    },
    {
      "epoch": 1.84,
      "grad_norm": 0.841164767742157,
      "learning_rate": 1.6316490724607975e-06,
      "loss": 0.3989,
      "step": 8966
    },
    {
      "epoch": 1.84,
      "grad_norm": 1.1576372385025024,
      "learning_rate": 1.629599262068259e-06,
      "loss": 0.3173,
      "step": 8967
    },
    {
      "epoch": 1.84,
      "grad_norm": 1.1357676982879639,
      "learning_rate": 1.6275494516757201e-06,
      "loss": 0.3376,
      "step": 8968
    },
    {
      "epoch": 1.84,
      "grad_norm": 0.965250551700592,
      "learning_rate": 1.6254996412831813e-06,
      "loss": 0.2925,
      "step": 8969
    },
    {
      "epoch": 1.84,
      "grad_norm": 0.9434505105018616,
      "learning_rate": 1.6234498308906428e-06,
      "loss": 0.3595,
      "step": 8970
    },
    {
      "epoch": 1.84,
      "grad_norm": 1.1638457775115967,
      "learning_rate": 1.621400020498104e-06,
      "loss": 0.2563,
      "step": 8971
    },
    {
      "epoch": 1.84,
      "grad_norm": 0.8983545303344727,
      "learning_rate": 1.6193502101055652e-06,
      "loss": 0.3372,
      "step": 8972
    },
    {
      "epoch": 1.84,
      "grad_norm": 1.0625407695770264,
      "learning_rate": 1.6173003997130266e-06,
      "loss": 0.4395,
      "step": 8973
    },
    {
      "epoch": 1.84,
      "grad_norm": 0.9352653622627258,
      "learning_rate": 1.615250589320488e-06,
      "loss": 0.3403,
      "step": 8974
    },
    {
      "epoch": 1.84,
      "grad_norm": 1.1260417699813843,
      "learning_rate": 1.6132007789279495e-06,
      "loss": 0.3521,
      "step": 8975
    },
    {
      "epoch": 1.84,
      "grad_norm": 0.9203993082046509,
      "learning_rate": 1.6111509685354107e-06,
      "loss": 0.3447,
      "step": 8976
    },
    {
      "epoch": 1.84,
      "grad_norm": 1.3525575399398804,
      "learning_rate": 1.609101158142872e-06,
      "loss": 0.3559,
      "step": 8977
    },
    {
      "epoch": 1.84,
      "grad_norm": 1.214296817779541,
      "learning_rate": 1.6070513477503332e-06,
      "loss": 0.3691,
      "step": 8978
    },
    {
      "epoch": 1.84,
      "grad_norm": 1.123630166053772,
      "learning_rate": 1.6050015373577946e-06,
      "loss": 0.3375,
      "step": 8979
    },
    {
      "epoch": 1.84,
      "grad_norm": 1.1232019662857056,
      "learning_rate": 1.6029517269652558e-06,
      "loss": 0.3251,
      "step": 8980
    },
    {
      "epoch": 1.84,
      "grad_norm": 1.3691505193710327,
      "learning_rate": 1.600901916572717e-06,
      "loss": 0.5857,
      "step": 8981
    },
    {
      "epoch": 1.84,
      "grad_norm": 1.0484280586242676,
      "learning_rate": 1.5988521061801785e-06,
      "loss": 0.2622,
      "step": 8982
    },
    {
      "epoch": 1.84,
      "grad_norm": 1.0005460977554321,
      "learning_rate": 1.5968022957876397e-06,
      "loss": 0.3407,
      "step": 8983
    },
    {
      "epoch": 1.84,
      "grad_norm": 0.9261671304702759,
      "learning_rate": 1.594752485395101e-06,
      "loss": 0.3696,
      "step": 8984
    },
    {
      "epoch": 1.84,
      "grad_norm": 1.0897798538208008,
      "learning_rate": 1.5927026750025624e-06,
      "loss": 0.1749,
      "step": 8985
    },
    {
      "epoch": 1.84,
      "grad_norm": 1.0451996326446533,
      "learning_rate": 1.5906528646100236e-06,
      "loss": 0.4491,
      "step": 8986
    },
    {
      "epoch": 1.84,
      "grad_norm": 0.8373561501502991,
      "learning_rate": 1.5886030542174848e-06,
      "loss": 0.2766,
      "step": 8987
    },
    {
      "epoch": 1.84,
      "grad_norm": 0.947401762008667,
      "learning_rate": 1.5865532438249462e-06,
      "loss": 0.211,
      "step": 8988
    },
    {
      "epoch": 1.84,
      "grad_norm": 1.0641428232192993,
      "learning_rate": 1.5845034334324077e-06,
      "loss": 0.4467,
      "step": 8989
    },
    {
      "epoch": 1.84,
      "grad_norm": 1.162975788116455,
      "learning_rate": 1.582453623039869e-06,
      "loss": 0.2131,
      "step": 8990
    },
    {
      "epoch": 1.84,
      "grad_norm": 0.9797021746635437,
      "learning_rate": 1.5804038126473303e-06,
      "loss": 0.2331,
      "step": 8991
    },
    {
      "epoch": 1.84,
      "grad_norm": 1.2968292236328125,
      "learning_rate": 1.5783540022547915e-06,
      "loss": 0.4043,
      "step": 8992
    },
    {
      "epoch": 1.84,
      "grad_norm": 0.8527608513832092,
      "learning_rate": 1.576304191862253e-06,
      "loss": 0.3248,
      "step": 8993
    },
    {
      "epoch": 1.84,
      "grad_norm": 1.1073552370071411,
      "learning_rate": 1.5742543814697142e-06,
      "loss": 0.3557,
      "step": 8994
    },
    {
      "epoch": 1.84,
      "grad_norm": 1.1592937707901,
      "learning_rate": 1.5722045710771754e-06,
      "loss": 0.2096,
      "step": 8995
    },
    {
      "epoch": 1.84,
      "grad_norm": 1.153663992881775,
      "learning_rate": 1.5701547606846368e-06,
      "loss": 0.4794,
      "step": 8996
    },
    {
      "epoch": 1.84,
      "grad_norm": 0.7478634119033813,
      "learning_rate": 1.568104950292098e-06,
      "loss": 0.2543,
      "step": 8997
    },
    {
      "epoch": 1.84,
      "grad_norm": 0.7164692282676697,
      "learning_rate": 1.5660551398995593e-06,
      "loss": 0.208,
      "step": 8998
    },
    {
      "epoch": 1.84,
      "grad_norm": 1.2426629066467285,
      "learning_rate": 1.5640053295070207e-06,
      "loss": 0.2584,
      "step": 8999
    },
    {
      "epoch": 1.84,
      "grad_norm": 1.4083902835845947,
      "learning_rate": 1.561955519114482e-06,
      "loss": 0.4482,
      "step": 9000
    },
    {
      "epoch": 1.84,
      "eval_loss": 0.3302425146102905,
      "eval_runtime": 673.2098,
      "eval_samples_per_second": 14.854,
      "eval_steps_per_second": 1.857,
      "step": 9000
    }
  ],
  "logging_steps": 1,
  "max_steps": 9762,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 2,
  "save_steps": 1000,
  "total_flos": 1.166961729705345e+18,
  "train_batch_size": 16,
  "trial_name": null,
  "trial_params": null
}
