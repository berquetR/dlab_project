{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 0.2048760499897562,
  "eval_steps": 1000,
  "global_step": 1000,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.0,
      "grad_norm": 0.14801645278930664,
      "learning_rate": 4.000000000000001e-06,
      "loss": 2.1156,
      "step": 1
    },
    {
      "epoch": 0.0,
      "grad_norm": 0.13493788242340088,
      "learning_rate": 8.000000000000001e-06,
      "loss": 1.9722,
      "step": 2
    },
    {
      "epoch": 0.0,
      "grad_norm": 0.15431340038776398,
      "learning_rate": 1.2e-05,
      "loss": 1.9869,
      "step": 3
    },
    {
      "epoch": 0.0,
      "grad_norm": 0.16262447834014893,
      "learning_rate": 1.6000000000000003e-05,
      "loss": 2.1135,
      "step": 4
    },
    {
      "epoch": 0.0,
      "grad_norm": 0.17303526401519775,
      "learning_rate": 2e-05,
      "loss": 2.1664,
      "step": 5
    },
    {
      "epoch": 0.0,
      "grad_norm": 0.13639616966247559,
      "learning_rate": 1.9997950189607462e-05,
      "loss": 1.9903,
      "step": 6
    },
    {
      "epoch": 0.0,
      "grad_norm": 0.18173938989639282,
      "learning_rate": 1.9995900379214925e-05,
      "loss": 2.11,
      "step": 7
    },
    {
      "epoch": 0.0,
      "grad_norm": 0.14924438297748566,
      "learning_rate": 1.9993850568822386e-05,
      "loss": 2.0583,
      "step": 8
    },
    {
      "epoch": 0.0,
      "grad_norm": 0.13676227629184723,
      "learning_rate": 1.9991800758429846e-05,
      "loss": 2.0033,
      "step": 9
    },
    {
      "epoch": 0.0,
      "grad_norm": 0.16084697842597961,
      "learning_rate": 1.998975094803731e-05,
      "loss": 2.0674,
      "step": 10
    },
    {
      "epoch": 0.0,
      "grad_norm": 0.14938215911388397,
      "learning_rate": 1.998770113764477e-05,
      "loss": 2.1082,
      "step": 11
    },
    {
      "epoch": 0.0,
      "grad_norm": 0.17698830366134644,
      "learning_rate": 1.998565132725223e-05,
      "loss": 2.0683,
      "step": 12
    },
    {
      "epoch": 0.0,
      "grad_norm": 0.13263039290905,
      "learning_rate": 1.9983601516859693e-05,
      "loss": 1.9721,
      "step": 13
    },
    {
      "epoch": 0.0,
      "grad_norm": 0.16003204882144928,
      "learning_rate": 1.9981551706467153e-05,
      "loss": 2.0803,
      "step": 14
    },
    {
      "epoch": 0.0,
      "grad_norm": 0.17213737964630127,
      "learning_rate": 1.9979501896074617e-05,
      "loss": 2.1332,
      "step": 15
    },
    {
      "epoch": 0.0,
      "grad_norm": 0.16287054121494293,
      "learning_rate": 1.9977452085682077e-05,
      "loss": 2.0457,
      "step": 16
    },
    {
      "epoch": 0.0,
      "grad_norm": 0.15758869051933289,
      "learning_rate": 1.9975402275289537e-05,
      "loss": 2.0446,
      "step": 17
    },
    {
      "epoch": 0.0,
      "grad_norm": 0.1473529189825058,
      "learning_rate": 1.9973352464896997e-05,
      "loss": 2.027,
      "step": 18
    },
    {
      "epoch": 0.0,
      "grad_norm": 0.1683863401412964,
      "learning_rate": 1.997130265450446e-05,
      "loss": 2.0824,
      "step": 19
    },
    {
      "epoch": 0.0,
      "grad_norm": 0.1586163491010666,
      "learning_rate": 1.996925284411192e-05,
      "loss": 2.0198,
      "step": 20
    },
    {
      "epoch": 0.0,
      "grad_norm": 0.18549537658691406,
      "learning_rate": 1.996720303371938e-05,
      "loss": 2.1358,
      "step": 21
    },
    {
      "epoch": 0.0,
      "grad_norm": 0.14019063115119934,
      "learning_rate": 1.996515322332684e-05,
      "loss": 1.946,
      "step": 22
    },
    {
      "epoch": 0.0,
      "grad_norm": 0.1625114232301712,
      "learning_rate": 1.9963103412934305e-05,
      "loss": 2.0389,
      "step": 23
    },
    {
      "epoch": 0.0,
      "grad_norm": 0.1410573571920395,
      "learning_rate": 1.9961053602541765e-05,
      "loss": 1.8371,
      "step": 24
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.17715804278850555,
      "learning_rate": 1.995900379214923e-05,
      "loss": 2.0748,
      "step": 25
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.15705814957618713,
      "learning_rate": 1.995695398175669e-05,
      "loss": 1.9581,
      "step": 26
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.15306861698627472,
      "learning_rate": 1.9954904171364152e-05,
      "loss": 2.0346,
      "step": 27
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.16421838104724884,
      "learning_rate": 1.9952854360971612e-05,
      "loss": 1.9285,
      "step": 28
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.19836336374282837,
      "learning_rate": 1.9950804550579073e-05,
      "loss": 2.138,
      "step": 29
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.15860317647457123,
      "learning_rate": 1.9948754740186533e-05,
      "loss": 1.9731,
      "step": 30
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.13702386617660522,
      "learning_rate": 1.9946704929793996e-05,
      "loss": 1.8985,
      "step": 31
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.1636829376220703,
      "learning_rate": 1.9944655119401457e-05,
      "loss": 1.9295,
      "step": 32
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.1686127483844757,
      "learning_rate": 1.9942605309008917e-05,
      "loss": 1.9191,
      "step": 33
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.1804673671722412,
      "learning_rate": 1.9940555498616377e-05,
      "loss": 2.0491,
      "step": 34
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.16746807098388672,
      "learning_rate": 1.993850568822384e-05,
      "loss": 1.9798,
      "step": 35
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.16413995623588562,
      "learning_rate": 1.99364558778313e-05,
      "loss": 1.9326,
      "step": 36
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.1710110306739807,
      "learning_rate": 1.9934406067438764e-05,
      "loss": 1.8972,
      "step": 37
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.1396317183971405,
      "learning_rate": 1.9932356257046224e-05,
      "loss": 1.7885,
      "step": 38
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.1601867973804474,
      "learning_rate": 1.9930306446653688e-05,
      "loss": 1.9425,
      "step": 39
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.19330692291259766,
      "learning_rate": 1.9928256636261148e-05,
      "loss": 2.0239,
      "step": 40
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.16724620759487152,
      "learning_rate": 1.9926206825868608e-05,
      "loss": 1.9578,
      "step": 41
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.18211016058921814,
      "learning_rate": 1.992415701547607e-05,
      "loss": 2.0056,
      "step": 42
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.1630667746067047,
      "learning_rate": 1.9922107205083532e-05,
      "loss": 1.888,
      "step": 43
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.17010371387004852,
      "learning_rate": 1.9920057394690992e-05,
      "loss": 1.9167,
      "step": 44
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.18148313462734222,
      "learning_rate": 1.9918007584298452e-05,
      "loss": 1.9331,
      "step": 45
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.17127348482608795,
      "learning_rate": 1.9915957773905916e-05,
      "loss": 1.9477,
      "step": 46
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.19184516370296478,
      "learning_rate": 1.9913907963513376e-05,
      "loss": 1.9724,
      "step": 47
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.198837548494339,
      "learning_rate": 1.9911858153120836e-05,
      "loss": 2.0178,
      "step": 48
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.1623743772506714,
      "learning_rate": 1.99098083427283e-05,
      "loss": 1.8263,
      "step": 49
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.18465445935726166,
      "learning_rate": 1.990775853233576e-05,
      "loss": 1.9318,
      "step": 50
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.171209454536438,
      "learning_rate": 1.9905708721943223e-05,
      "loss": 1.7509,
      "step": 51
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.19016167521476746,
      "learning_rate": 1.9903658911550683e-05,
      "loss": 1.8727,
      "step": 52
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.18491792678833008,
      "learning_rate": 1.9901609101158144e-05,
      "loss": 1.8821,
      "step": 53
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.18468356132507324,
      "learning_rate": 1.9899559290765607e-05,
      "loss": 1.8937,
      "step": 54
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.21431516110897064,
      "learning_rate": 1.9897509480373067e-05,
      "loss": 1.9012,
      "step": 55
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.1696908175945282,
      "learning_rate": 1.9895459669980528e-05,
      "loss": 1.8271,
      "step": 56
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.18662254512310028,
      "learning_rate": 1.9893409859587988e-05,
      "loss": 1.8401,
      "step": 57
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.18320439755916595,
      "learning_rate": 1.989136004919545e-05,
      "loss": 1.861,
      "step": 58
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.18744365870952606,
      "learning_rate": 1.988931023880291e-05,
      "loss": 1.819,
      "step": 59
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.19097080826759338,
      "learning_rate": 1.988726042841037e-05,
      "loss": 1.8648,
      "step": 60
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.2096877545118332,
      "learning_rate": 1.9885210618017835e-05,
      "loss": 1.8725,
      "step": 61
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.1833464652299881,
      "learning_rate": 1.9883160807625295e-05,
      "loss": 1.8123,
      "step": 62
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.19815221428871155,
      "learning_rate": 1.988111099723276e-05,
      "loss": 1.8688,
      "step": 63
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.18720459938049316,
      "learning_rate": 1.987906118684022e-05,
      "loss": 1.7887,
      "step": 64
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.19058774411678314,
      "learning_rate": 1.9877011376447683e-05,
      "loss": 1.7693,
      "step": 65
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.2042541801929474,
      "learning_rate": 1.9874961566055143e-05,
      "loss": 1.7754,
      "step": 66
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.19555921852588654,
      "learning_rate": 1.9872911755662603e-05,
      "loss": 1.8329,
      "step": 67
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.23826687037944794,
      "learning_rate": 1.9870861945270063e-05,
      "loss": 1.8735,
      "step": 68
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.2317931056022644,
      "learning_rate": 1.9868812134877527e-05,
      "loss": 1.842,
      "step": 69
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.20384418964385986,
      "learning_rate": 1.9866762324484987e-05,
      "loss": 1.8198,
      "step": 70
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.1949259638786316,
      "learning_rate": 1.9864712514092447e-05,
      "loss": 1.7972,
      "step": 71
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.20163820683956146,
      "learning_rate": 1.9862662703699907e-05,
      "loss": 1.7857,
      "step": 72
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.21081550419330597,
      "learning_rate": 1.986061289330737e-05,
      "loss": 1.7535,
      "step": 73
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.21124212443828583,
      "learning_rate": 1.985856308291483e-05,
      "loss": 1.8161,
      "step": 74
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.2058476358652115,
      "learning_rate": 1.9856513272522294e-05,
      "loss": 1.755,
      "step": 75
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.18506187200546265,
      "learning_rate": 1.9854463462129754e-05,
      "loss": 1.7332,
      "step": 76
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.2168685644865036,
      "learning_rate": 1.9852413651737218e-05,
      "loss": 1.6861,
      "step": 77
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.21537922322750092,
      "learning_rate": 1.9850363841344678e-05,
      "loss": 1.7469,
      "step": 78
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.2310929298400879,
      "learning_rate": 1.984831403095214e-05,
      "loss": 1.7004,
      "step": 79
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.20755332708358765,
      "learning_rate": 1.98462642205596e-05,
      "loss": 1.6774,
      "step": 80
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.24066269397735596,
      "learning_rate": 1.9844214410167062e-05,
      "loss": 1.7278,
      "step": 81
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.28124022483825684,
      "learning_rate": 1.9842164599774522e-05,
      "loss": 1.77,
      "step": 82
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.24270261824131012,
      "learning_rate": 1.9840114789381982e-05,
      "loss": 1.7361,
      "step": 83
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.24854214489459991,
      "learning_rate": 1.9838064978989443e-05,
      "loss": 1.7097,
      "step": 84
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.22556163370609283,
      "learning_rate": 1.9836015168596906e-05,
      "loss": 1.6638,
      "step": 85
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.2117660939693451,
      "learning_rate": 1.9833965358204366e-05,
      "loss": 1.6118,
      "step": 86
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.20034928619861603,
      "learning_rate": 1.983191554781183e-05,
      "loss": 1.5845,
      "step": 87
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.2204093635082245,
      "learning_rate": 1.982986573741929e-05,
      "loss": 1.6252,
      "step": 88
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.20167583227157593,
      "learning_rate": 1.9827815927026754e-05,
      "loss": 1.6278,
      "step": 89
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.21437273919582367,
      "learning_rate": 1.9825766116634214e-05,
      "loss": 1.6432,
      "step": 90
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.2567161023616791,
      "learning_rate": 1.9823716306241674e-05,
      "loss": 1.6778,
      "step": 91
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.25239065289497375,
      "learning_rate": 1.9821666495849134e-05,
      "loss": 1.5851,
      "step": 92
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.25855380296707153,
      "learning_rate": 1.9819616685456598e-05,
      "loss": 1.5773,
      "step": 93
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.257782518863678,
      "learning_rate": 1.9817566875064058e-05,
      "loss": 1.6409,
      "step": 94
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.22905093431472778,
      "learning_rate": 1.9815517064671518e-05,
      "loss": 1.6085,
      "step": 95
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.2462063729763031,
      "learning_rate": 1.981346725427898e-05,
      "loss": 1.6255,
      "step": 96
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.26769962906837463,
      "learning_rate": 1.981141744388644e-05,
      "loss": 1.5624,
      "step": 97
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.2332739233970642,
      "learning_rate": 1.9809367633493902e-05,
      "loss": 1.5514,
      "step": 98
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.25260525941848755,
      "learning_rate": 1.9807317823101365e-05,
      "loss": 1.4679,
      "step": 99
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.29149627685546875,
      "learning_rate": 1.9805268012708825e-05,
      "loss": 1.5599,
      "step": 100
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.27089405059814453,
      "learning_rate": 1.980321820231629e-05,
      "loss": 1.6006,
      "step": 101
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.32050687074661255,
      "learning_rate": 1.980116839192375e-05,
      "loss": 1.5926,
      "step": 102
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.27958133816719055,
      "learning_rate": 1.979911858153121e-05,
      "loss": 1.5207,
      "step": 103
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.37188512086868286,
      "learning_rate": 1.9797068771138673e-05,
      "loss": 1.5203,
      "step": 104
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.32037055492401123,
      "learning_rate": 1.9795018960746133e-05,
      "loss": 1.4723,
      "step": 105
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.30734193325042725,
      "learning_rate": 1.9792969150353593e-05,
      "loss": 1.4439,
      "step": 106
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.3082571029663086,
      "learning_rate": 1.9790919339961053e-05,
      "loss": 1.5258,
      "step": 107
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.32039952278137207,
      "learning_rate": 1.9788869529568517e-05,
      "loss": 1.4197,
      "step": 108
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.4001242220401764,
      "learning_rate": 1.9786819719175977e-05,
      "loss": 1.4193,
      "step": 109
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.4055688977241516,
      "learning_rate": 1.9784769908783437e-05,
      "loss": 1.4226,
      "step": 110
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.33153218030929565,
      "learning_rate": 1.97827200983909e-05,
      "loss": 1.4295,
      "step": 111
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.35445675253868103,
      "learning_rate": 1.978067028799836e-05,
      "loss": 1.3796,
      "step": 112
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.40358075499534607,
      "learning_rate": 1.9778620477605825e-05,
      "loss": 1.4212,
      "step": 113
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.32602494955062866,
      "learning_rate": 1.9776570667213285e-05,
      "loss": 1.3807,
      "step": 114
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.3186560869216919,
      "learning_rate": 1.9774520856820745e-05,
      "loss": 1.3732,
      "step": 115
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.3246791958808899,
      "learning_rate": 1.977247104642821e-05,
      "loss": 1.4181,
      "step": 116
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.34996339678764343,
      "learning_rate": 1.977042123603567e-05,
      "loss": 1.2769,
      "step": 117
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.36430859565734863,
      "learning_rate": 1.976837142564313e-05,
      "loss": 1.3138,
      "step": 118
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.3703325092792511,
      "learning_rate": 1.976632161525059e-05,
      "loss": 1.258,
      "step": 119
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.32558107376098633,
      "learning_rate": 1.9764271804858052e-05,
      "loss": 1.3301,
      "step": 120
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.29304394125938416,
      "learning_rate": 1.9762221994465513e-05,
      "loss": 1.285,
      "step": 121
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.3146601915359497,
      "learning_rate": 1.9760172184072973e-05,
      "loss": 1.2781,
      "step": 122
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.32576581835746765,
      "learning_rate": 1.9758122373680436e-05,
      "loss": 1.332,
      "step": 123
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.3251970410346985,
      "learning_rate": 1.9756072563287896e-05,
      "loss": 1.204,
      "step": 124
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.2914409637451172,
      "learning_rate": 1.975402275289536e-05,
      "loss": 1.3544,
      "step": 125
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.28793925046920776,
      "learning_rate": 1.975197294250282e-05,
      "loss": 1.2734,
      "step": 126
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.34051278233528137,
      "learning_rate": 1.9749923132110284e-05,
      "loss": 1.1765,
      "step": 127
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.33435994386672974,
      "learning_rate": 1.9747873321717744e-05,
      "loss": 1.1906,
      "step": 128
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.2535462975502014,
      "learning_rate": 1.9745823511325204e-05,
      "loss": 1.2022,
      "step": 129
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.29028981924057007,
      "learning_rate": 1.9743773700932664e-05,
      "loss": 1.1626,
      "step": 130
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.3011995255947113,
      "learning_rate": 1.9741723890540128e-05,
      "loss": 1.1972,
      "step": 131
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.37259697914123535,
      "learning_rate": 1.9739674080147588e-05,
      "loss": 1.0717,
      "step": 132
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.2607201039791107,
      "learning_rate": 1.9737624269755048e-05,
      "loss": 1.1827,
      "step": 133
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.33192381262779236,
      "learning_rate": 1.9735574459362508e-05,
      "loss": 1.1224,
      "step": 134
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.3566271662712097,
      "learning_rate": 1.9733524648969972e-05,
      "loss": 1.0128,
      "step": 135
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.291311651468277,
      "learning_rate": 1.9731474838577432e-05,
      "loss": 1.1411,
      "step": 136
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.2526525557041168,
      "learning_rate": 1.9729425028184896e-05,
      "loss": 1.1177,
      "step": 137
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.26152029633522034,
      "learning_rate": 1.9727375217792356e-05,
      "loss": 1.1124,
      "step": 138
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.2161748707294464,
      "learning_rate": 1.972532540739982e-05,
      "loss": 1.2616,
      "step": 139
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.24315319955348969,
      "learning_rate": 1.972327559700728e-05,
      "loss": 1.0818,
      "step": 140
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.271156370639801,
      "learning_rate": 1.972122578661474e-05,
      "loss": 1.063,
      "step": 141
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.2510625123977661,
      "learning_rate": 1.97191759762222e-05,
      "loss": 0.989,
      "step": 142
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.22746270895004272,
      "learning_rate": 1.9717126165829663e-05,
      "loss": 1.0095,
      "step": 143
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.20309670269489288,
      "learning_rate": 1.9715076355437123e-05,
      "loss": 1.0417,
      "step": 144
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.1951362043619156,
      "learning_rate": 1.9713026545044584e-05,
      "loss": 1.0915,
      "step": 145
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.19874995946884155,
      "learning_rate": 1.9710976734652044e-05,
      "loss": 0.9936,
      "step": 146
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.20301520824432373,
      "learning_rate": 1.9708926924259507e-05,
      "loss": 0.9756,
      "step": 147
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.2011939138174057,
      "learning_rate": 1.9706877113866967e-05,
      "loss": 1.0198,
      "step": 148
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.18404176831245422,
      "learning_rate": 1.970482730347443e-05,
      "loss": 0.9893,
      "step": 149
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.17462767660617828,
      "learning_rate": 1.970277749308189e-05,
      "loss": 0.9749,
      "step": 150
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.20576846599578857,
      "learning_rate": 1.9700727682689355e-05,
      "loss": 0.8421,
      "step": 151
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.16285865008831024,
      "learning_rate": 1.9698677872296815e-05,
      "loss": 1.0332,
      "step": 152
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.14744864404201508,
      "learning_rate": 1.9696628061904275e-05,
      "loss": 1.0171,
      "step": 153
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.17768371105194092,
      "learning_rate": 1.969457825151174e-05,
      "loss": 0.9148,
      "step": 154
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.14266695082187653,
      "learning_rate": 1.96925284411192e-05,
      "loss": 0.9444,
      "step": 155
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.14746293425559998,
      "learning_rate": 1.969047863072666e-05,
      "loss": 0.9451,
      "step": 156
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.14510703086853027,
      "learning_rate": 1.968842882033412e-05,
      "loss": 0.9607,
      "step": 157
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.12286745011806488,
      "learning_rate": 1.9686379009941583e-05,
      "loss": 0.9804,
      "step": 158
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.15423738956451416,
      "learning_rate": 1.9684329199549043e-05,
      "loss": 0.9945,
      "step": 159
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.1409735530614853,
      "learning_rate": 1.9682279389156503e-05,
      "loss": 0.9481,
      "step": 160
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.12786269187927246,
      "learning_rate": 1.9680229578763967e-05,
      "loss": 1.0268,
      "step": 161
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.1277569830417633,
      "learning_rate": 1.9678179768371427e-05,
      "loss": 0.9584,
      "step": 162
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.1338379830121994,
      "learning_rate": 1.967612995797889e-05,
      "loss": 0.8752,
      "step": 163
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.1174040362238884,
      "learning_rate": 1.967408014758635e-05,
      "loss": 0.9657,
      "step": 164
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.11389858275651932,
      "learning_rate": 1.967203033719381e-05,
      "loss": 0.96,
      "step": 165
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.12520524859428406,
      "learning_rate": 1.9669980526801274e-05,
      "loss": 0.981,
      "step": 166
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.11895885318517685,
      "learning_rate": 1.9667930716408734e-05,
      "loss": 0.987,
      "step": 167
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.1287764608860016,
      "learning_rate": 1.9665880906016194e-05,
      "loss": 0.9839,
      "step": 168
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.1140211746096611,
      "learning_rate": 1.9663831095623655e-05,
      "loss": 0.9523,
      "step": 169
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.11723394691944122,
      "learning_rate": 1.9661781285231118e-05,
      "loss": 0.991,
      "step": 170
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.11477658897638321,
      "learning_rate": 1.965973147483858e-05,
      "loss": 0.9453,
      "step": 171
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.11470630764961243,
      "learning_rate": 1.965768166444604e-05,
      "loss": 0.9478,
      "step": 172
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.1085997223854065,
      "learning_rate": 1.9655631854053502e-05,
      "loss": 0.9989,
      "step": 173
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.11751675605773926,
      "learning_rate": 1.9653582043660962e-05,
      "loss": 0.9819,
      "step": 174
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.1253792643547058,
      "learning_rate": 1.9651532233268426e-05,
      "loss": 0.9512,
      "step": 175
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.1224038153886795,
      "learning_rate": 1.9649482422875886e-05,
      "loss": 0.8852,
      "step": 176
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.11550460755825043,
      "learning_rate": 1.9647432612483346e-05,
      "loss": 0.9893,
      "step": 177
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.11173273622989655,
      "learning_rate": 1.964538280209081e-05,
      "loss": 1.0019,
      "step": 178
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.11439226567745209,
      "learning_rate": 1.964333299169827e-05,
      "loss": 0.9285,
      "step": 179
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.12082788348197937,
      "learning_rate": 1.964128318130573e-05,
      "loss": 0.919,
      "step": 180
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.10875578224658966,
      "learning_rate": 1.963923337091319e-05,
      "loss": 1.0091,
      "step": 181
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.11381158977746964,
      "learning_rate": 1.9637183560520654e-05,
      "loss": 0.906,
      "step": 182
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.11693225055932999,
      "learning_rate": 1.9635133750128114e-05,
      "loss": 0.9262,
      "step": 183
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.11422082781791687,
      "learning_rate": 1.9633083939735574e-05,
      "loss": 0.9747,
      "step": 184
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.1133032888174057,
      "learning_rate": 1.9631034129343038e-05,
      "loss": 0.8995,
      "step": 185
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.11655422300100327,
      "learning_rate": 1.9628984318950498e-05,
      "loss": 0.9179,
      "step": 186
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.10629011690616608,
      "learning_rate": 1.962693450855796e-05,
      "loss": 1.0306,
      "step": 187
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.11696868389844894,
      "learning_rate": 1.962488469816542e-05,
      "loss": 0.915,
      "step": 188
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.1107262670993805,
      "learning_rate": 1.9622834887772885e-05,
      "loss": 0.9786,
      "step": 189
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.10548517107963562,
      "learning_rate": 1.9620785077380345e-05,
      "loss": 1.015,
      "step": 190
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.10317640751600266,
      "learning_rate": 1.9618735266987805e-05,
      "loss": 1.0508,
      "step": 191
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.11294328421354294,
      "learning_rate": 1.9616685456595265e-05,
      "loss": 0.9257,
      "step": 192
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.11201515793800354,
      "learning_rate": 1.961463564620273e-05,
      "loss": 0.9707,
      "step": 193
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.12294746190309525,
      "learning_rate": 1.961258583581019e-05,
      "loss": 0.8474,
      "step": 194
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.1048453152179718,
      "learning_rate": 1.961053602541765e-05,
      "loss": 0.9455,
      "step": 195
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.110934779047966,
      "learning_rate": 1.960848621502511e-05,
      "loss": 1.0264,
      "step": 196
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.10872286558151245,
      "learning_rate": 1.9606436404632573e-05,
      "loss": 0.9653,
      "step": 197
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.11702096462249756,
      "learning_rate": 1.9604386594240033e-05,
      "loss": 0.9578,
      "step": 198
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.11133939027786255,
      "learning_rate": 1.9602336783847497e-05,
      "loss": 0.9719,
      "step": 199
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.10960347205400467,
      "learning_rate": 1.9600286973454957e-05,
      "loss": 0.9638,
      "step": 200
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.12970641255378723,
      "learning_rate": 1.959823716306242e-05,
      "loss": 0.8593,
      "step": 201
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.11129017919301987,
      "learning_rate": 1.959618735266988e-05,
      "loss": 0.8625,
      "step": 202
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.12882918119430542,
      "learning_rate": 1.959413754227734e-05,
      "loss": 0.88,
      "step": 203
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.11775669455528259,
      "learning_rate": 1.95920877318848e-05,
      "loss": 0.88,
      "step": 204
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.11505789309740067,
      "learning_rate": 1.9590037921492264e-05,
      "loss": 0.9223,
      "step": 205
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.11349492520093918,
      "learning_rate": 1.9587988111099725e-05,
      "loss": 0.8141,
      "step": 206
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.10728686302900314,
      "learning_rate": 1.9585938300707185e-05,
      "loss": 0.9842,
      "step": 207
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.11916619539260864,
      "learning_rate": 1.9583888490314645e-05,
      "loss": 1.0015,
      "step": 208
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.11149190366268158,
      "learning_rate": 1.958183867992211e-05,
      "loss": 0.8548,
      "step": 209
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.1223873645067215,
      "learning_rate": 1.957978886952957e-05,
      "loss": 0.8721,
      "step": 210
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.10712231695652008,
      "learning_rate": 1.9577739059137032e-05,
      "loss": 0.9053,
      "step": 211
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.1161237582564354,
      "learning_rate": 1.9575689248744492e-05,
      "loss": 0.9305,
      "step": 212
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.10267391800880432,
      "learning_rate": 1.9573639438351956e-05,
      "loss": 0.9361,
      "step": 213
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.10983920097351074,
      "learning_rate": 1.9571589627959416e-05,
      "loss": 0.9442,
      "step": 214
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.12621043622493744,
      "learning_rate": 1.9569539817566876e-05,
      "loss": 0.8717,
      "step": 215
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.11078941076993942,
      "learning_rate": 1.956749000717434e-05,
      "loss": 0.9833,
      "step": 216
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.11060511320829391,
      "learning_rate": 1.95654401967818e-05,
      "loss": 0.975,
      "step": 217
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.11653444916009903,
      "learning_rate": 1.956339038638926e-05,
      "loss": 0.9077,
      "step": 218
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.1080295518040657,
      "learning_rate": 1.956134057599672e-05,
      "loss": 0.9326,
      "step": 219
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.12118266522884369,
      "learning_rate": 1.9559290765604184e-05,
      "loss": 0.8783,
      "step": 220
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.12586797773838043,
      "learning_rate": 1.9557240955211644e-05,
      "loss": 0.7879,
      "step": 221
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.1107342541217804,
      "learning_rate": 1.9555191144819104e-05,
      "loss": 0.9581,
      "step": 222
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.11808457970619202,
      "learning_rate": 1.9553141334426568e-05,
      "loss": 1.0065,
      "step": 223
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.11437413841485977,
      "learning_rate": 1.9551091524034028e-05,
      "loss": 1.0117,
      "step": 224
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.11293333768844604,
      "learning_rate": 1.954904171364149e-05,
      "loss": 0.9254,
      "step": 225
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.11271843314170837,
      "learning_rate": 1.954699190324895e-05,
      "loss": 0.9613,
      "step": 226
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.12039729952812195,
      "learning_rate": 1.9544942092856412e-05,
      "loss": 0.8398,
      "step": 227
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.12387534230947495,
      "learning_rate": 1.9542892282463875e-05,
      "loss": 0.9295,
      "step": 228
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.11054776608943939,
      "learning_rate": 1.9540842472071335e-05,
      "loss": 0.9387,
      "step": 229
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.11459952592849731,
      "learning_rate": 1.9538792661678796e-05,
      "loss": 0.9167,
      "step": 230
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.11788316816091537,
      "learning_rate": 1.9536742851286256e-05,
      "loss": 0.7641,
      "step": 231
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.11313901841640472,
      "learning_rate": 1.953469304089372e-05,
      "loss": 0.9054,
      "step": 232
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.10994742810726166,
      "learning_rate": 1.953264323050118e-05,
      "loss": 0.8754,
      "step": 233
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.10773077607154846,
      "learning_rate": 1.953059342010864e-05,
      "loss": 0.9426,
      "step": 234
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.10124799609184265,
      "learning_rate": 1.9528543609716103e-05,
      "loss": 0.9652,
      "step": 235
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.11278689652681351,
      "learning_rate": 1.9526493799323563e-05,
      "loss": 0.9142,
      "step": 236
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.1191551610827446,
      "learning_rate": 1.9524443988931027e-05,
      "loss": 0.886,
      "step": 237
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.12041749805212021,
      "learning_rate": 1.9522394178538487e-05,
      "loss": 0.9696,
      "step": 238
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.12373056262731552,
      "learning_rate": 1.9520344368145947e-05,
      "loss": 0.8643,
      "step": 239
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.10807184129953384,
      "learning_rate": 1.951829455775341e-05,
      "loss": 0.9088,
      "step": 240
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.10628893226385117,
      "learning_rate": 1.951624474736087e-05,
      "loss": 0.7853,
      "step": 241
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.10586827248334885,
      "learning_rate": 1.951419493696833e-05,
      "loss": 0.8618,
      "step": 242
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.10110622644424438,
      "learning_rate": 1.9512145126575795e-05,
      "loss": 1.0064,
      "step": 243
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.1106470599770546,
      "learning_rate": 1.9510095316183255e-05,
      "loss": 0.9826,
      "step": 244
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.10830700397491455,
      "learning_rate": 1.9508045505790715e-05,
      "loss": 0.7897,
      "step": 245
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.11630983650684357,
      "learning_rate": 1.9505995695398175e-05,
      "loss": 0.8729,
      "step": 246
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.10370375216007233,
      "learning_rate": 1.950394588500564e-05,
      "loss": 0.8206,
      "step": 247
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.10259199887514114,
      "learning_rate": 1.95018960746131e-05,
      "loss": 0.8949,
      "step": 248
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.1160779595375061,
      "learning_rate": 1.9499846264220562e-05,
      "loss": 0.9293,
      "step": 249
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.13695336878299713,
      "learning_rate": 1.9497796453828023e-05,
      "loss": 0.934,
      "step": 250
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.10347066819667816,
      "learning_rate": 1.9495746643435486e-05,
      "loss": 0.9335,
      "step": 251
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.1043834313750267,
      "learning_rate": 1.9493696833042946e-05,
      "loss": 0.8712,
      "step": 252
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.11564145237207413,
      "learning_rate": 1.9491647022650407e-05,
      "loss": 0.9823,
      "step": 253
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.11040244251489639,
      "learning_rate": 1.9489597212257867e-05,
      "loss": 0.9065,
      "step": 254
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.11539418250322342,
      "learning_rate": 1.948754740186533e-05,
      "loss": 0.8888,
      "step": 255
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.11019538342952728,
      "learning_rate": 1.948549759147279e-05,
      "loss": 0.9072,
      "step": 256
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.10494827479124069,
      "learning_rate": 1.948344778108025e-05,
      "loss": 0.9444,
      "step": 257
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.12025714665651321,
      "learning_rate": 1.948139797068771e-05,
      "loss": 0.8477,
      "step": 258
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.10517946630716324,
      "learning_rate": 1.9479348160295174e-05,
      "loss": 0.9468,
      "step": 259
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.10923108458518982,
      "learning_rate": 1.9477298349902634e-05,
      "loss": 0.9021,
      "step": 260
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.11453501880168915,
      "learning_rate": 1.9475248539510098e-05,
      "loss": 0.8489,
      "step": 261
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.11054644733667374,
      "learning_rate": 1.9473198729117558e-05,
      "loss": 1.0493,
      "step": 262
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.1404528021812439,
      "learning_rate": 1.947114891872502e-05,
      "loss": 0.7825,
      "step": 263
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.1030016839504242,
      "learning_rate": 1.9469099108332482e-05,
      "loss": 1.0164,
      "step": 264
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.1058816984295845,
      "learning_rate": 1.9467049297939942e-05,
      "loss": 0.8815,
      "step": 265
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.13101057708263397,
      "learning_rate": 1.9464999487547402e-05,
      "loss": 0.9684,
      "step": 266
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.11438069492578506,
      "learning_rate": 1.9462949677154866e-05,
      "loss": 0.829,
      "step": 267
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.12294495850801468,
      "learning_rate": 1.9460899866762326e-05,
      "loss": 0.9288,
      "step": 268
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.11855403333902359,
      "learning_rate": 1.9458850056369786e-05,
      "loss": 0.8787,
      "step": 269
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.12912406027317047,
      "learning_rate": 1.9456800245977246e-05,
      "loss": 0.873,
      "step": 270
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.10353491455316544,
      "learning_rate": 1.945475043558471e-05,
      "loss": 1.0211,
      "step": 271
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.10573985427618027,
      "learning_rate": 1.945270062519217e-05,
      "loss": 0.837,
      "step": 272
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.1281924545764923,
      "learning_rate": 1.9450650814799633e-05,
      "loss": 0.8037,
      "step": 273
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.12173116207122803,
      "learning_rate": 1.9448601004407094e-05,
      "loss": 0.8795,
      "step": 274
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.12658721208572388,
      "learning_rate": 1.9446551194014557e-05,
      "loss": 0.8383,
      "step": 275
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.11864066869020462,
      "learning_rate": 1.9444501383622017e-05,
      "loss": 0.9236,
      "step": 276
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.11576711386442184,
      "learning_rate": 1.9442451573229478e-05,
      "loss": 0.8528,
      "step": 277
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.10368352383375168,
      "learning_rate": 1.944040176283694e-05,
      "loss": 0.8491,
      "step": 278
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.11558093130588531,
      "learning_rate": 1.94383519524444e-05,
      "loss": 0.8999,
      "step": 279
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.12087540328502655,
      "learning_rate": 1.943630214205186e-05,
      "loss": 0.8675,
      "step": 280
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.10626393556594849,
      "learning_rate": 1.943425233165932e-05,
      "loss": 0.9382,
      "step": 281
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.10891518741846085,
      "learning_rate": 1.9432202521266785e-05,
      "loss": 0.8523,
      "step": 282
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.1174779161810875,
      "learning_rate": 1.9430152710874245e-05,
      "loss": 0.8653,
      "step": 283
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.1285378336906433,
      "learning_rate": 1.9428102900481705e-05,
      "loss": 0.8948,
      "step": 284
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.11372309178113937,
      "learning_rate": 1.942605309008917e-05,
      "loss": 0.8568,
      "step": 285
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.11427725106477737,
      "learning_rate": 1.942400327969663e-05,
      "loss": 0.8225,
      "step": 286
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.14900687336921692,
      "learning_rate": 1.9421953469304093e-05,
      "loss": 1.0323,
      "step": 287
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.11896420270204544,
      "learning_rate": 1.9419903658911553e-05,
      "loss": 0.8158,
      "step": 288
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.1303885281085968,
      "learning_rate": 1.9417853848519013e-05,
      "loss": 0.8579,
      "step": 289
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.12143409997224808,
      "learning_rate": 1.9415804038126477e-05,
      "loss": 0.8813,
      "step": 290
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.11280457675457001,
      "learning_rate": 1.9413754227733937e-05,
      "loss": 0.9227,
      "step": 291
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.11012837290763855,
      "learning_rate": 1.9411704417341397e-05,
      "loss": 0.9447,
      "step": 292
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.1120828315615654,
      "learning_rate": 1.9409654606948857e-05,
      "loss": 0.896,
      "step": 293
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.11666925251483917,
      "learning_rate": 1.940760479655632e-05,
      "loss": 0.7973,
      "step": 294
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.11904400587081909,
      "learning_rate": 1.940555498616378e-05,
      "loss": 0.8774,
      "step": 295
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.12668779492378235,
      "learning_rate": 1.940350517577124e-05,
      "loss": 0.8129,
      "step": 296
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.1139235869050026,
      "learning_rate": 1.9401455365378704e-05,
      "loss": 0.8645,
      "step": 297
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.12778016924858093,
      "learning_rate": 1.9399405554986165e-05,
      "loss": 0.8534,
      "step": 298
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.11882112175226212,
      "learning_rate": 1.9397355744593628e-05,
      "loss": 0.8941,
      "step": 299
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.12609803676605225,
      "learning_rate": 1.939530593420109e-05,
      "loss": 0.8019,
      "step": 300
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.13944514095783234,
      "learning_rate": 1.9393256123808552e-05,
      "loss": 0.8536,
      "step": 301
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.11209560185670853,
      "learning_rate": 1.9391206313416012e-05,
      "loss": 0.8875,
      "step": 302
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.1324322521686554,
      "learning_rate": 1.9389156503023472e-05,
      "loss": 0.7377,
      "step": 303
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.12412051111459732,
      "learning_rate": 1.9387106692630932e-05,
      "loss": 0.8199,
      "step": 304
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.11850414425134659,
      "learning_rate": 1.9385056882238396e-05,
      "loss": 0.8796,
      "step": 305
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.1256149560213089,
      "learning_rate": 1.9383007071845856e-05,
      "loss": 0.6658,
      "step": 306
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.11698953807353973,
      "learning_rate": 1.9380957261453316e-05,
      "loss": 0.7866,
      "step": 307
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.10981995612382889,
      "learning_rate": 1.9378907451060776e-05,
      "loss": 0.8674,
      "step": 308
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.12847840785980225,
      "learning_rate": 1.937685764066824e-05,
      "loss": 0.8973,
      "step": 309
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.13614852726459503,
      "learning_rate": 1.93748078302757e-05,
      "loss": 0.7349,
      "step": 310
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.12398331612348557,
      "learning_rate": 1.9372758019883164e-05,
      "loss": 0.8766,
      "step": 311
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.13640139997005463,
      "learning_rate": 1.9370708209490624e-05,
      "loss": 0.8962,
      "step": 312
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.11832497268915176,
      "learning_rate": 1.9368658399098087e-05,
      "loss": 0.9397,
      "step": 313
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.12573650479316711,
      "learning_rate": 1.9366608588705548e-05,
      "loss": 0.923,
      "step": 314
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.1262044608592987,
      "learning_rate": 1.9364558778313008e-05,
      "loss": 0.8252,
      "step": 315
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.1605004370212555,
      "learning_rate": 1.9362508967920468e-05,
      "loss": 0.8256,
      "step": 316
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.12002827972173691,
      "learning_rate": 1.936045915752793e-05,
      "loss": 0.743,
      "step": 317
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.12373246997594833,
      "learning_rate": 1.935840934713539e-05,
      "loss": 0.921,
      "step": 318
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.1096058115363121,
      "learning_rate": 1.9356359536742852e-05,
      "loss": 0.9311,
      "step": 319
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.12669838964939117,
      "learning_rate": 1.9354309726350312e-05,
      "loss": 0.9184,
      "step": 320
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.12685614824295044,
      "learning_rate": 1.9352259915957775e-05,
      "loss": 0.9086,
      "step": 321
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.15060833096504211,
      "learning_rate": 1.9350210105565236e-05,
      "loss": 0.8455,
      "step": 322
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.12823501229286194,
      "learning_rate": 1.93481602951727e-05,
      "loss": 0.8519,
      "step": 323
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.15130478143692017,
      "learning_rate": 1.934611048478016e-05,
      "loss": 0.7808,
      "step": 324
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.1281290203332901,
      "learning_rate": 1.9344060674387623e-05,
      "loss": 0.8036,
      "step": 325
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.11920052021741867,
      "learning_rate": 1.9342010863995083e-05,
      "loss": 0.9598,
      "step": 326
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.15807418525218964,
      "learning_rate": 1.9339961053602543e-05,
      "loss": 0.9132,
      "step": 327
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.13564768433570862,
      "learning_rate": 1.9337911243210003e-05,
      "loss": 0.9276,
      "step": 328
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.1396510750055313,
      "learning_rate": 1.9335861432817467e-05,
      "loss": 0.8934,
      "step": 329
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.13453885912895203,
      "learning_rate": 1.9333811622424927e-05,
      "loss": 0.8175,
      "step": 330
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.14032770693302155,
      "learning_rate": 1.9331761812032387e-05,
      "loss": 0.8741,
      "step": 331
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.14800895750522614,
      "learning_rate": 1.932971200163985e-05,
      "loss": 0.8674,
      "step": 332
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.1407247930765152,
      "learning_rate": 1.932766219124731e-05,
      "loss": 0.8784,
      "step": 333
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.1337730884552002,
      "learning_rate": 1.932561238085477e-05,
      "loss": 0.8722,
      "step": 334
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.14591968059539795,
      "learning_rate": 1.9323562570462235e-05,
      "loss": 0.8804,
      "step": 335
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.1397637575864792,
      "learning_rate": 1.9321512760069695e-05,
      "loss": 0.8626,
      "step": 336
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.1251293420791626,
      "learning_rate": 1.931946294967716e-05,
      "loss": 0.8343,
      "step": 337
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.14307206869125366,
      "learning_rate": 1.931741313928462e-05,
      "loss": 0.777,
      "step": 338
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.1107073500752449,
      "learning_rate": 1.931536332889208e-05,
      "loss": 0.894,
      "step": 339
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.12038864195346832,
      "learning_rate": 1.9313313518499542e-05,
      "loss": 0.8864,
      "step": 340
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.16119475662708282,
      "learning_rate": 1.9311263708107002e-05,
      "loss": 0.8488,
      "step": 341
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.14547263085842133,
      "learning_rate": 1.9309213897714463e-05,
      "loss": 0.9148,
      "step": 342
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.15499764680862427,
      "learning_rate": 1.9307164087321923e-05,
      "loss": 0.8858,
      "step": 343
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.121903195977211,
      "learning_rate": 1.9305114276929386e-05,
      "loss": 0.8409,
      "step": 344
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.13624075055122375,
      "learning_rate": 1.9303064466536846e-05,
      "loss": 0.8539,
      "step": 345
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.1289665848016739,
      "learning_rate": 1.9301014656144307e-05,
      "loss": 0.8972,
      "step": 346
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.14455804228782654,
      "learning_rate": 1.929896484575177e-05,
      "loss": 0.919,
      "step": 347
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.12730561196804047,
      "learning_rate": 1.929691503535923e-05,
      "loss": 0.9478,
      "step": 348
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.12746407091617584,
      "learning_rate": 1.9294865224966694e-05,
      "loss": 0.7405,
      "step": 349
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.1674691140651703,
      "learning_rate": 1.9292815414574154e-05,
      "loss": 0.8102,
      "step": 350
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.13995179533958435,
      "learning_rate": 1.9290765604181614e-05,
      "loss": 0.8215,
      "step": 351
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.14159509539604187,
      "learning_rate": 1.9288715793789078e-05,
      "loss": 0.8792,
      "step": 352
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.1344442367553711,
      "learning_rate": 1.9286665983396538e-05,
      "loss": 0.9716,
      "step": 353
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.15604564547538757,
      "learning_rate": 1.9284616173003998e-05,
      "loss": 0.8704,
      "step": 354
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.13720914721488953,
      "learning_rate": 1.9282566362611458e-05,
      "loss": 0.8326,
      "step": 355
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.14227120578289032,
      "learning_rate": 1.9280516552218922e-05,
      "loss": 0.8952,
      "step": 356
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.1455276608467102,
      "learning_rate": 1.9278466741826382e-05,
      "loss": 0.8903,
      "step": 357
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.13401660323143005,
      "learning_rate": 1.9276416931433842e-05,
      "loss": 0.8469,
      "step": 358
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.14276866614818573,
      "learning_rate": 1.9274367121041306e-05,
      "loss": 0.7735,
      "step": 359
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.13018949329853058,
      "learning_rate": 1.9272317310648766e-05,
      "loss": 0.9203,
      "step": 360
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.13455694913864136,
      "learning_rate": 1.927026750025623e-05,
      "loss": 0.8779,
      "step": 361
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.13384974002838135,
      "learning_rate": 1.926821768986369e-05,
      "loss": 0.8124,
      "step": 362
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.13184615969657898,
      "learning_rate": 1.9266167879471153e-05,
      "loss": 0.864,
      "step": 363
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.1454877406358719,
      "learning_rate": 1.9264118069078613e-05,
      "loss": 0.9136,
      "step": 364
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.14314337074756622,
      "learning_rate": 1.9262068258686073e-05,
      "loss": 0.8445,
      "step": 365
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.15504486858844757,
      "learning_rate": 1.9260018448293534e-05,
      "loss": 0.8873,
      "step": 366
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.1319129317998886,
      "learning_rate": 1.9257968637900997e-05,
      "loss": 0.8366,
      "step": 367
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.14638902246952057,
      "learning_rate": 1.9255918827508457e-05,
      "loss": 0.9188,
      "step": 368
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.1454022377729416,
      "learning_rate": 1.9253869017115917e-05,
      "loss": 0.8128,
      "step": 369
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.15703995525836945,
      "learning_rate": 1.9251819206723378e-05,
      "loss": 0.8067,
      "step": 370
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.14144857227802277,
      "learning_rate": 1.924976939633084e-05,
      "loss": 0.8696,
      "step": 371
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.17272283136844635,
      "learning_rate": 1.92477195859383e-05,
      "loss": 0.8252,
      "step": 372
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.1407836675643921,
      "learning_rate": 1.9245669775545765e-05,
      "loss": 0.8798,
      "step": 373
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.14374861121177673,
      "learning_rate": 1.9243619965153225e-05,
      "loss": 0.809,
      "step": 374
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.2178298681974411,
      "learning_rate": 1.924157015476069e-05,
      "loss": 0.8097,
      "step": 375
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.1452960968017578,
      "learning_rate": 1.923952034436815e-05,
      "loss": 0.8993,
      "step": 376
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.13822156190872192,
      "learning_rate": 1.923747053397561e-05,
      "loss": 0.8982,
      "step": 377
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.16437716782093048,
      "learning_rate": 1.923542072358307e-05,
      "loss": 0.7987,
      "step": 378
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.15675105154514313,
      "learning_rate": 1.9233370913190533e-05,
      "loss": 0.8576,
      "step": 379
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.1522854119539261,
      "learning_rate": 1.9231321102797993e-05,
      "loss": 0.8943,
      "step": 380
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.16838493943214417,
      "learning_rate": 1.9229271292405453e-05,
      "loss": 0.708,
      "step": 381
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.1511940211057663,
      "learning_rate": 1.9227221482012913e-05,
      "loss": 0.8517,
      "step": 382
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.16562093794345856,
      "learning_rate": 1.9225171671620377e-05,
      "loss": 0.7934,
      "step": 383
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.1492152363061905,
      "learning_rate": 1.9223121861227837e-05,
      "loss": 0.8708,
      "step": 384
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.1480678766965866,
      "learning_rate": 1.92210720508353e-05,
      "loss": 0.9034,
      "step": 385
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.1552446186542511,
      "learning_rate": 1.921902224044276e-05,
      "loss": 0.7942,
      "step": 386
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.14972244203090668,
      "learning_rate": 1.9216972430050224e-05,
      "loss": 0.855,
      "step": 387
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.1446336805820465,
      "learning_rate": 1.9214922619657684e-05,
      "loss": 0.8692,
      "step": 388
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.15611252188682556,
      "learning_rate": 1.9212872809265144e-05,
      "loss": 0.797,
      "step": 389
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.14483509957790375,
      "learning_rate": 1.9210822998872608e-05,
      "loss": 0.8415,
      "step": 390
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.14611844718456268,
      "learning_rate": 1.9208773188480068e-05,
      "loss": 0.8362,
      "step": 391
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.15801045298576355,
      "learning_rate": 1.920672337808753e-05,
      "loss": 0.8965,
      "step": 392
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.14152853190898895,
      "learning_rate": 1.920467356769499e-05,
      "loss": 0.8903,
      "step": 393
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.15904606878757477,
      "learning_rate": 1.9202623757302452e-05,
      "loss": 0.7721,
      "step": 394
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.1708311289548874,
      "learning_rate": 1.9200573946909912e-05,
      "loss": 0.7544,
      "step": 395
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.14611460268497467,
      "learning_rate": 1.9198524136517372e-05,
      "loss": 0.8079,
      "step": 396
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.13924139738082886,
      "learning_rate": 1.9196474326124836e-05,
      "loss": 0.8066,
      "step": 397
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.14339646697044373,
      "learning_rate": 1.9194424515732296e-05,
      "loss": 0.8984,
      "step": 398
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.19476652145385742,
      "learning_rate": 1.919237470533976e-05,
      "loss": 0.721,
      "step": 399
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.14827312529087067,
      "learning_rate": 1.919032489494722e-05,
      "loss": 0.7668,
      "step": 400
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.14345461130142212,
      "learning_rate": 1.918827508455468e-05,
      "loss": 0.8136,
      "step": 401
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.1758970022201538,
      "learning_rate": 1.9186225274162143e-05,
      "loss": 0.8317,
      "step": 402
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.15231788158416748,
      "learning_rate": 1.9184175463769604e-05,
      "loss": 0.8271,
      "step": 403
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.14136990904808044,
      "learning_rate": 1.9182125653377064e-05,
      "loss": 0.8636,
      "step": 404
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.1592167317867279,
      "learning_rate": 1.9180075842984524e-05,
      "loss": 0.8994,
      "step": 405
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.15409733355045319,
      "learning_rate": 1.9178026032591988e-05,
      "loss": 0.8645,
      "step": 406
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.1687871813774109,
      "learning_rate": 1.9175976222199448e-05,
      "loss": 0.7249,
      "step": 407
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.16160649061203003,
      "learning_rate": 1.9173926411806908e-05,
      "loss": 0.8686,
      "step": 408
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.1700599193572998,
      "learning_rate": 1.917187660141437e-05,
      "loss": 0.8008,
      "step": 409
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.17662590742111206,
      "learning_rate": 1.916982679102183e-05,
      "loss": 0.6727,
      "step": 410
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.17508365213871002,
      "learning_rate": 1.9167776980629295e-05,
      "loss": 0.807,
      "step": 411
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.18899306654930115,
      "learning_rate": 1.9165727170236755e-05,
      "loss": 0.7514,
      "step": 412
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.17519474029541016,
      "learning_rate": 1.9163677359844215e-05,
      "loss": 0.7937,
      "step": 413
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.17406079173088074,
      "learning_rate": 1.916162754945168e-05,
      "loss": 0.8598,
      "step": 414
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.1616392880678177,
      "learning_rate": 1.915957773905914e-05,
      "loss": 0.8522,
      "step": 415
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.17864663898944855,
      "learning_rate": 1.91575279286666e-05,
      "loss": 0.8591,
      "step": 416
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.16068516671657562,
      "learning_rate": 1.915547811827406e-05,
      "loss": 0.8761,
      "step": 417
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.16791556775569916,
      "learning_rate": 1.9153428307881523e-05,
      "loss": 0.747,
      "step": 418
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.17416690289974213,
      "learning_rate": 1.9151378497488983e-05,
      "loss": 0.8457,
      "step": 419
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.18067793548107147,
      "learning_rate": 1.9149328687096443e-05,
      "loss": 0.9268,
      "step": 420
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.14490729570388794,
      "learning_rate": 1.9147278876703907e-05,
      "loss": 0.8704,
      "step": 421
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.15132369101047516,
      "learning_rate": 1.9145229066311367e-05,
      "loss": 0.9143,
      "step": 422
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.2017907351255417,
      "learning_rate": 1.914317925591883e-05,
      "loss": 0.8814,
      "step": 423
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.1470775306224823,
      "learning_rate": 1.914112944552629e-05,
      "loss": 0.8234,
      "step": 424
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.19069324433803558,
      "learning_rate": 1.9139079635133754e-05,
      "loss": 0.816,
      "step": 425
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.1687970757484436,
      "learning_rate": 1.9137029824741214e-05,
      "loss": 0.7932,
      "step": 426
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.17496801912784576,
      "learning_rate": 1.9134980014348675e-05,
      "loss": 0.7629,
      "step": 427
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.16465221345424652,
      "learning_rate": 1.9132930203956135e-05,
      "loss": 0.7773,
      "step": 428
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.14980225265026093,
      "learning_rate": 1.91308803935636e-05,
      "loss": 0.9417,
      "step": 429
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.15588514506816864,
      "learning_rate": 1.912883058317106e-05,
      "loss": 0.8836,
      "step": 430
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.17013239860534668,
      "learning_rate": 1.912678077277852e-05,
      "loss": 0.8076,
      "step": 431
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.1522824466228485,
      "learning_rate": 1.912473096238598e-05,
      "loss": 0.8134,
      "step": 432
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.17980511486530304,
      "learning_rate": 1.9122681151993442e-05,
      "loss": 0.8953,
      "step": 433
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.18643483519554138,
      "learning_rate": 1.9120631341600903e-05,
      "loss": 0.7685,
      "step": 434
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.16374269127845764,
      "learning_rate": 1.9118581531208366e-05,
      "loss": 0.8073,
      "step": 435
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.17865963280200958,
      "learning_rate": 1.9116531720815826e-05,
      "loss": 0.8614,
      "step": 436
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.16780543327331543,
      "learning_rate": 1.911448191042329e-05,
      "loss": 0.78,
      "step": 437
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.16059668362140656,
      "learning_rate": 1.911243210003075e-05,
      "loss": 0.8635,
      "step": 438
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.16147461533546448,
      "learning_rate": 1.911038228963821e-05,
      "loss": 0.822,
      "step": 439
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.16893987357616425,
      "learning_rate": 1.910833247924567e-05,
      "loss": 0.8326,
      "step": 440
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.1762782484292984,
      "learning_rate": 1.9106282668853134e-05,
      "loss": 0.922,
      "step": 441
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.16019174456596375,
      "learning_rate": 1.9104232858460594e-05,
      "loss": 0.7339,
      "step": 442
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.22397136688232422,
      "learning_rate": 1.9102183048068054e-05,
      "loss": 0.8098,
      "step": 443
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.1708119511604309,
      "learning_rate": 1.9100133237675514e-05,
      "loss": 0.7452,
      "step": 444
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.16400514543056488,
      "learning_rate": 1.9098083427282978e-05,
      "loss": 0.8448,
      "step": 445
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.17854410409927368,
      "learning_rate": 1.9096033616890438e-05,
      "loss": 0.834,
      "step": 446
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.16905593872070312,
      "learning_rate": 1.90939838064979e-05,
      "loss": 0.8192,
      "step": 447
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.16718362271785736,
      "learning_rate": 1.9091933996105362e-05,
      "loss": 0.8364,
      "step": 448
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.15494103729724884,
      "learning_rate": 1.9089884185712825e-05,
      "loss": 0.9052,
      "step": 449
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.17324014008045197,
      "learning_rate": 1.9087834375320285e-05,
      "loss": 0.8398,
      "step": 450
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.16868022084236145,
      "learning_rate": 1.9085784564927746e-05,
      "loss": 0.8494,
      "step": 451
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.19692480564117432,
      "learning_rate": 1.908373475453521e-05,
      "loss": 0.8049,
      "step": 452
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.20679554343223572,
      "learning_rate": 1.908168494414267e-05,
      "loss": 0.8431,
      "step": 453
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.18304497003555298,
      "learning_rate": 1.907963513375013e-05,
      "loss": 0.7937,
      "step": 454
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.15351274609565735,
      "learning_rate": 1.907758532335759e-05,
      "loss": 0.7754,
      "step": 455
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.1994316279888153,
      "learning_rate": 1.9075535512965053e-05,
      "loss": 0.7174,
      "step": 456
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.2093765139579773,
      "learning_rate": 1.9073485702572513e-05,
      "loss": 0.7251,
      "step": 457
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.18247674405574799,
      "learning_rate": 1.9071435892179974e-05,
      "loss": 0.7514,
      "step": 458
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.20437216758728027,
      "learning_rate": 1.9069386081787437e-05,
      "loss": 0.7908,
      "step": 459
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.1926635354757309,
      "learning_rate": 1.9067336271394897e-05,
      "loss": 0.8769,
      "step": 460
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.1657874584197998,
      "learning_rate": 1.906528646100236e-05,
      "loss": 0.7522,
      "step": 461
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.1918681412935257,
      "learning_rate": 1.906323665060982e-05,
      "loss": 0.8902,
      "step": 462
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.16888751089572906,
      "learning_rate": 1.906118684021728e-05,
      "loss": 0.8086,
      "step": 463
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.18022564053535461,
      "learning_rate": 1.9059137029824745e-05,
      "loss": 0.7946,
      "step": 464
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.18103459477424622,
      "learning_rate": 1.9057087219432205e-05,
      "loss": 0.9281,
      "step": 465
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.17837344110012054,
      "learning_rate": 1.9055037409039665e-05,
      "loss": 0.8222,
      "step": 466
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.20301282405853271,
      "learning_rate": 1.9052987598647125e-05,
      "loss": 0.7211,
      "step": 467
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.18511620163917542,
      "learning_rate": 1.905093778825459e-05,
      "loss": 0.8539,
      "step": 468
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.17245325446128845,
      "learning_rate": 1.904888797786205e-05,
      "loss": 0.8117,
      "step": 469
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.17423871159553528,
      "learning_rate": 1.904683816746951e-05,
      "loss": 0.7473,
      "step": 470
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.19919812679290771,
      "learning_rate": 1.9044788357076973e-05,
      "loss": 0.8494,
      "step": 471
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.21152034401893616,
      "learning_rate": 1.9042738546684433e-05,
      "loss": 0.806,
      "step": 472
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.1872701197862625,
      "learning_rate": 1.9040688736291893e-05,
      "loss": 0.8033,
      "step": 473
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.2077201008796692,
      "learning_rate": 1.9038638925899356e-05,
      "loss": 0.777,
      "step": 474
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.1911279708147049,
      "learning_rate": 1.9036589115506817e-05,
      "loss": 0.8089,
      "step": 475
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.17532692849636078,
      "learning_rate": 1.903453930511428e-05,
      "loss": 0.8318,
      "step": 476
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.2234090119600296,
      "learning_rate": 1.903248949472174e-05,
      "loss": 0.9116,
      "step": 477
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.1920439749956131,
      "learning_rate": 1.90304396843292e-05,
      "loss": 0.8218,
      "step": 478
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.17685282230377197,
      "learning_rate": 1.9028389873936664e-05,
      "loss": 0.737,
      "step": 479
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.1973785012960434,
      "learning_rate": 1.9026340063544124e-05,
      "loss": 0.8184,
      "step": 480
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.21858394145965576,
      "learning_rate": 1.9024290253151584e-05,
      "loss": 0.7031,
      "step": 481
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.20711596310138702,
      "learning_rate": 1.9022240442759045e-05,
      "loss": 0.8233,
      "step": 482
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.19980688393115997,
      "learning_rate": 1.9020190632366508e-05,
      "loss": 0.8404,
      "step": 483
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.2554182708263397,
      "learning_rate": 1.9018140821973968e-05,
      "loss": 0.8242,
      "step": 484
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.2178659737110138,
      "learning_rate": 1.901609101158143e-05,
      "loss": 0.7831,
      "step": 485
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.19421729445457458,
      "learning_rate": 1.9014041201188892e-05,
      "loss": 0.9599,
      "step": 486
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.19006289541721344,
      "learning_rate": 1.9011991390796352e-05,
      "loss": 0.7554,
      "step": 487
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.20694541931152344,
      "learning_rate": 1.9009941580403816e-05,
      "loss": 0.798,
      "step": 488
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.20120131969451904,
      "learning_rate": 1.9007891770011276e-05,
      "loss": 0.8169,
      "step": 489
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.1653985232114792,
      "learning_rate": 1.9005841959618736e-05,
      "loss": 0.8662,
      "step": 490
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.19703707098960876,
      "learning_rate": 1.90037921492262e-05,
      "loss": 0.7897,
      "step": 491
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.2020362764596939,
      "learning_rate": 1.900174233883366e-05,
      "loss": 0.8957,
      "step": 492
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.18726219236850739,
      "learning_rate": 1.899969252844112e-05,
      "loss": 0.8154,
      "step": 493
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.20864568650722504,
      "learning_rate": 1.899764271804858e-05,
      "loss": 0.7117,
      "step": 494
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.1811826080083847,
      "learning_rate": 1.8995592907656044e-05,
      "loss": 0.8568,
      "step": 495
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.18101084232330322,
      "learning_rate": 1.8993543097263504e-05,
      "loss": 0.7961,
      "step": 496
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.21149250864982605,
      "learning_rate": 1.8991493286870964e-05,
      "loss": 0.7622,
      "step": 497
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.18719595670700073,
      "learning_rate": 1.8989443476478427e-05,
      "loss": 0.861,
      "step": 498
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.21494868397712708,
      "learning_rate": 1.8987393666085888e-05,
      "loss": 0.7725,
      "step": 499
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.19059619307518005,
      "learning_rate": 1.898534385569335e-05,
      "loss": 0.7189,
      "step": 500
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.19733569025993347,
      "learning_rate": 1.898329404530081e-05,
      "loss": 0.8581,
      "step": 501
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.18426968157291412,
      "learning_rate": 1.898124423490827e-05,
      "loss": 0.7409,
      "step": 502
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.19410546123981476,
      "learning_rate": 1.8979194424515735e-05,
      "loss": 0.7652,
      "step": 503
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.20012442767620087,
      "learning_rate": 1.8977144614123195e-05,
      "loss": 0.6592,
      "step": 504
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.21452948451042175,
      "learning_rate": 1.8975094803730655e-05,
      "loss": 0.7991,
      "step": 505
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.19325408339500427,
      "learning_rate": 1.8973044993338116e-05,
      "loss": 0.8303,
      "step": 506
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.20319633185863495,
      "learning_rate": 1.897099518294558e-05,
      "loss": 0.7804,
      "step": 507
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.20566116273403168,
      "learning_rate": 1.896894537255304e-05,
      "loss": 0.7449,
      "step": 508
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.20156601071357727,
      "learning_rate": 1.89668955621605e-05,
      "loss": 0.7583,
      "step": 509
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.20419004559516907,
      "learning_rate": 1.8964845751767963e-05,
      "loss": 0.8372,
      "step": 510
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.22958584129810333,
      "learning_rate": 1.8962795941375423e-05,
      "loss": 0.7746,
      "step": 511
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.216570183634758,
      "learning_rate": 1.8960746130982887e-05,
      "loss": 0.7997,
      "step": 512
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.20960162580013275,
      "learning_rate": 1.8958696320590347e-05,
      "loss": 0.8943,
      "step": 513
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.21094997227191925,
      "learning_rate": 1.895664651019781e-05,
      "loss": 0.8548,
      "step": 514
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.18289414048194885,
      "learning_rate": 1.895459669980527e-05,
      "loss": 0.8311,
      "step": 515
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.29864302277565,
      "learning_rate": 1.895254688941273e-05,
      "loss": 0.7515,
      "step": 516
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.25311973690986633,
      "learning_rate": 1.895049707902019e-05,
      "loss": 0.7582,
      "step": 517
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.262350857257843,
      "learning_rate": 1.8948447268627654e-05,
      "loss": 0.8844,
      "step": 518
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.23849861323833466,
      "learning_rate": 1.8946397458235115e-05,
      "loss": 0.6801,
      "step": 519
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.24991253018379211,
      "learning_rate": 1.8944347647842575e-05,
      "loss": 0.7709,
      "step": 520
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.21508775651454926,
      "learning_rate": 1.8942297837450035e-05,
      "loss": 0.865,
      "step": 521
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.22612547874450684,
      "learning_rate": 1.89402480270575e-05,
      "loss": 0.7808,
      "step": 522
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.23175758123397827,
      "learning_rate": 1.893819821666496e-05,
      "loss": 0.736,
      "step": 523
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.20399166643619537,
      "learning_rate": 1.8936148406272422e-05,
      "loss": 0.8919,
      "step": 524
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.23995094001293182,
      "learning_rate": 1.8934098595879882e-05,
      "loss": 0.7918,
      "step": 525
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.22864922881126404,
      "learning_rate": 1.8932048785487346e-05,
      "loss": 0.8403,
      "step": 526
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.22524893283843994,
      "learning_rate": 1.8929998975094806e-05,
      "loss": 0.8413,
      "step": 527
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.19651883840560913,
      "learning_rate": 1.8927949164702266e-05,
      "loss": 0.822,
      "step": 528
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.21977390348911285,
      "learning_rate": 1.8925899354309726e-05,
      "loss": 0.745,
      "step": 529
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.20708025991916656,
      "learning_rate": 1.892384954391719e-05,
      "loss": 0.758,
      "step": 530
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.2496166229248047,
      "learning_rate": 1.892179973352465e-05,
      "loss": 0.8371,
      "step": 531
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.24427592754364014,
      "learning_rate": 1.891974992313211e-05,
      "loss": 0.866,
      "step": 532
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.2351367473602295,
      "learning_rate": 1.891770011273957e-05,
      "loss": 0.7736,
      "step": 533
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.2400284856557846,
      "learning_rate": 1.8915650302347034e-05,
      "loss": 0.7418,
      "step": 534
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.21287386119365692,
      "learning_rate": 1.8913600491954494e-05,
      "loss": 0.7213,
      "step": 535
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.2319117784500122,
      "learning_rate": 1.8911550681561958e-05,
      "loss": 0.8659,
      "step": 536
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.21474748849868774,
      "learning_rate": 1.8909500871169418e-05,
      "loss": 0.7468,
      "step": 537
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.2480355054140091,
      "learning_rate": 1.890745106077688e-05,
      "loss": 0.7826,
      "step": 538
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.1993049830198288,
      "learning_rate": 1.890540125038434e-05,
      "loss": 0.8354,
      "step": 539
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.23135560750961304,
      "learning_rate": 1.8903351439991802e-05,
      "loss": 0.7514,
      "step": 540
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.23334814608097076,
      "learning_rate": 1.8901301629599265e-05,
      "loss": 0.7865,
      "step": 541
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.21762984991073608,
      "learning_rate": 1.8899251819206725e-05,
      "loss": 0.8809,
      "step": 542
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.2144210934638977,
      "learning_rate": 1.8897202008814186e-05,
      "loss": 0.7945,
      "step": 543
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.22259631752967834,
      "learning_rate": 1.8895152198421646e-05,
      "loss": 0.7325,
      "step": 544
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.21477104723453522,
      "learning_rate": 1.889310238802911e-05,
      "loss": 0.857,
      "step": 545
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.21294987201690674,
      "learning_rate": 1.889105257763657e-05,
      "loss": 0.799,
      "step": 546
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.25885850191116333,
      "learning_rate": 1.888900276724403e-05,
      "loss": 0.8143,
      "step": 547
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.21820950508117676,
      "learning_rate": 1.8886952956851493e-05,
      "loss": 0.832,
      "step": 548
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.2264004349708557,
      "learning_rate": 1.8884903146458953e-05,
      "loss": 0.8097,
      "step": 549
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.23316548764705658,
      "learning_rate": 1.8882853336066417e-05,
      "loss": 0.7515,
      "step": 550
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.20102547109127045,
      "learning_rate": 1.8880803525673877e-05,
      "loss": 0.8081,
      "step": 551
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.2040938436985016,
      "learning_rate": 1.8878753715281337e-05,
      "loss": 0.8534,
      "step": 552
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.236019566655159,
      "learning_rate": 1.88767039048888e-05,
      "loss": 0.7682,
      "step": 553
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.3004855811595917,
      "learning_rate": 1.887465409449626e-05,
      "loss": 0.7303,
      "step": 554
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.21686811745166779,
      "learning_rate": 1.887260428410372e-05,
      "loss": 0.8266,
      "step": 555
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.2634103298187256,
      "learning_rate": 1.887055447371118e-05,
      "loss": 0.7901,
      "step": 556
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.22976526618003845,
      "learning_rate": 1.8868504663318645e-05,
      "loss": 0.8512,
      "step": 557
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.296199768781662,
      "learning_rate": 1.8866454852926105e-05,
      "loss": 0.8566,
      "step": 558
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.24860918521881104,
      "learning_rate": 1.8864405042533565e-05,
      "loss": 0.8366,
      "step": 559
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.29074087738990784,
      "learning_rate": 1.886235523214103e-05,
      "loss": 0.7597,
      "step": 560
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.2821865975856781,
      "learning_rate": 1.886030542174849e-05,
      "loss": 0.7746,
      "step": 561
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.26934775710105896,
      "learning_rate": 1.8858255611355952e-05,
      "loss": 0.7584,
      "step": 562
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.2615976631641388,
      "learning_rate": 1.8856205800963413e-05,
      "loss": 0.7606,
      "step": 563
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.24356038868427277,
      "learning_rate": 1.8854155990570873e-05,
      "loss": 0.7066,
      "step": 564
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.2835129201412201,
      "learning_rate": 1.8852106180178336e-05,
      "loss": 0.7063,
      "step": 565
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.2627677321434021,
      "learning_rate": 1.8850056369785796e-05,
      "loss": 0.8881,
      "step": 566
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.2871919870376587,
      "learning_rate": 1.8848006559393257e-05,
      "loss": 0.8213,
      "step": 567
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.25961214303970337,
      "learning_rate": 1.884595674900072e-05,
      "loss": 0.9009,
      "step": 568
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.26552483439445496,
      "learning_rate": 1.884390693860818e-05,
      "loss": 0.834,
      "step": 569
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.24494673311710358,
      "learning_rate": 1.884185712821564e-05,
      "loss": 0.7715,
      "step": 570
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.2400072067975998,
      "learning_rate": 1.88398073178231e-05,
      "loss": 0.8085,
      "step": 571
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.23224161565303802,
      "learning_rate": 1.8837757507430564e-05,
      "loss": 0.7976,
      "step": 572
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.2596319615840912,
      "learning_rate": 1.8835707697038024e-05,
      "loss": 0.7869,
      "step": 573
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.285260409116745,
      "learning_rate": 1.8833657886645488e-05,
      "loss": 0.7651,
      "step": 574
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.26859959959983826,
      "learning_rate": 1.8831608076252948e-05,
      "loss": 0.7573,
      "step": 575
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.25955668091773987,
      "learning_rate": 1.882955826586041e-05,
      "loss": 0.7789,
      "step": 576
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.25042223930358887,
      "learning_rate": 1.8827508455467872e-05,
      "loss": 0.7996,
      "step": 577
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.2487245500087738,
      "learning_rate": 1.8825458645075332e-05,
      "loss": 0.718,
      "step": 578
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.22486095130443573,
      "learning_rate": 1.8823408834682792e-05,
      "loss": 0.7956,
      "step": 579
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.2707049548625946,
      "learning_rate": 1.8821359024290256e-05,
      "loss": 0.6772,
      "step": 580
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.24360224604606628,
      "learning_rate": 1.8819309213897716e-05,
      "loss": 0.806,
      "step": 581
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.26013419032096863,
      "learning_rate": 1.8817259403505176e-05,
      "loss": 0.776,
      "step": 582
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.26571816205978394,
      "learning_rate": 1.8815209593112636e-05,
      "loss": 0.7599,
      "step": 583
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.26651903986930847,
      "learning_rate": 1.88131597827201e-05,
      "loss": 0.8334,
      "step": 584
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.3071249723434448,
      "learning_rate": 1.881110997232756e-05,
      "loss": 0.7747,
      "step": 585
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.30715256929397583,
      "learning_rate": 1.8809060161935023e-05,
      "loss": 0.6903,
      "step": 586
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.23905496299266815,
      "learning_rate": 1.8807010351542484e-05,
      "loss": 0.7866,
      "step": 587
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.24115152657032013,
      "learning_rate": 1.8804960541149947e-05,
      "loss": 0.748,
      "step": 588
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.22978830337524414,
      "learning_rate": 1.8802910730757407e-05,
      "loss": 0.6972,
      "step": 589
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.22623153030872345,
      "learning_rate": 1.8800860920364867e-05,
      "loss": 0.8043,
      "step": 590
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.2673869729042053,
      "learning_rate": 1.8798811109972328e-05,
      "loss": 0.8982,
      "step": 591
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.2301866114139557,
      "learning_rate": 1.879676129957979e-05,
      "loss": 0.7844,
      "step": 592
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.24445998668670654,
      "learning_rate": 1.879471148918725e-05,
      "loss": 0.7336,
      "step": 593
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.23602020740509033,
      "learning_rate": 1.879266167879471e-05,
      "loss": 0.7118,
      "step": 594
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.25433769822120667,
      "learning_rate": 1.8790611868402175e-05,
      "loss": 0.7902,
      "step": 595
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.2582925856113434,
      "learning_rate": 1.8788562058009635e-05,
      "loss": 0.7455,
      "step": 596
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.2507253587245941,
      "learning_rate": 1.8786512247617095e-05,
      "loss": 0.7269,
      "step": 597
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.24637457728385925,
      "learning_rate": 1.878446243722456e-05,
      "loss": 0.7391,
      "step": 598
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.24102479219436646,
      "learning_rate": 1.878241262683202e-05,
      "loss": 0.8535,
      "step": 599
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.30762001872062683,
      "learning_rate": 1.8780362816439483e-05,
      "loss": 0.7081,
      "step": 600
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.2617662847042084,
      "learning_rate": 1.8778313006046943e-05,
      "loss": 0.7538,
      "step": 601
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.2924197018146515,
      "learning_rate": 1.8776263195654403e-05,
      "loss": 0.7402,
      "step": 602
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.25363895297050476,
      "learning_rate": 1.8774213385261867e-05,
      "loss": 0.7425,
      "step": 603
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.26895347237586975,
      "learning_rate": 1.8772163574869327e-05,
      "loss": 0.7969,
      "step": 604
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.28718337416648865,
      "learning_rate": 1.8770113764476787e-05,
      "loss": 0.7708,
      "step": 605
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.2528524100780487,
      "learning_rate": 1.8768063954084247e-05,
      "loss": 0.7702,
      "step": 606
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.2677992582321167,
      "learning_rate": 1.876601414369171e-05,
      "loss": 0.7172,
      "step": 607
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.31523728370666504,
      "learning_rate": 1.876396433329917e-05,
      "loss": 0.7547,
      "step": 608
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.22344838082790375,
      "learning_rate": 1.876191452290663e-05,
      "loss": 0.7414,
      "step": 609
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.26969507336616516,
      "learning_rate": 1.8759864712514094e-05,
      "loss": 0.7992,
      "step": 610
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.39049336314201355,
      "learning_rate": 1.8757814902121555e-05,
      "loss": 0.7956,
      "step": 611
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.26343175768852234,
      "learning_rate": 1.8755765091729018e-05,
      "loss": 0.8465,
      "step": 612
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.2986372113227844,
      "learning_rate": 1.8753715281336478e-05,
      "loss": 0.7476,
      "step": 613
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.26255324482917786,
      "learning_rate": 1.875166547094394e-05,
      "loss": 0.6618,
      "step": 614
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.2755093276500702,
      "learning_rate": 1.8749615660551402e-05,
      "loss": 0.8586,
      "step": 615
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.27989357709884644,
      "learning_rate": 1.8747565850158862e-05,
      "loss": 0.7771,
      "step": 616
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.3005853295326233,
      "learning_rate": 1.8745516039766322e-05,
      "loss": 0.7872,
      "step": 617
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.3140900433063507,
      "learning_rate": 1.8743466229373782e-05,
      "loss": 0.811,
      "step": 618
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.3815363943576813,
      "learning_rate": 1.8741416418981246e-05,
      "loss": 0.7254,
      "step": 619
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.28141000866889954,
      "learning_rate": 1.8739366608588706e-05,
      "loss": 0.6784,
      "step": 620
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.3459838628768921,
      "learning_rate": 1.8737316798196166e-05,
      "loss": 0.7484,
      "step": 621
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.26786547899246216,
      "learning_rate": 1.873526698780363e-05,
      "loss": 0.8363,
      "step": 622
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.33138319849967957,
      "learning_rate": 1.873321717741109e-05,
      "loss": 0.7766,
      "step": 623
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.27499139308929443,
      "learning_rate": 1.8731167367018554e-05,
      "loss": 0.8174,
      "step": 624
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.2671065628528595,
      "learning_rate": 1.8729117556626014e-05,
      "loss": 0.703,
      "step": 625
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.24237236380577087,
      "learning_rate": 1.8727067746233477e-05,
      "loss": 0.7344,
      "step": 626
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.26603057980537415,
      "learning_rate": 1.8725017935840938e-05,
      "loss": 0.6984,
      "step": 627
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.4455318748950958,
      "learning_rate": 1.8722968125448398e-05,
      "loss": 0.7154,
      "step": 628
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.35970625281333923,
      "learning_rate": 1.8720918315055858e-05,
      "loss": 0.6792,
      "step": 629
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.24973182380199432,
      "learning_rate": 1.871886850466332e-05,
      "loss": 0.7959,
      "step": 630
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.3197944164276123,
      "learning_rate": 1.871681869427078e-05,
      "loss": 0.823,
      "step": 631
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.3085663616657257,
      "learning_rate": 1.8714768883878242e-05,
      "loss": 0.7818,
      "step": 632
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.5861884951591492,
      "learning_rate": 1.8712719073485702e-05,
      "loss": 0.736,
      "step": 633
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.31729575991630554,
      "learning_rate": 1.8710669263093165e-05,
      "loss": 0.7858,
      "step": 634
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.24467049539089203,
      "learning_rate": 1.8708619452700626e-05,
      "loss": 0.7231,
      "step": 635
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.3214152157306671,
      "learning_rate": 1.870656964230809e-05,
      "loss": 0.6832,
      "step": 636
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.29062697291374207,
      "learning_rate": 1.870451983191555e-05,
      "loss": 0.7585,
      "step": 637
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.2639349102973938,
      "learning_rate": 1.8702470021523013e-05,
      "loss": 0.8305,
      "step": 638
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.2599736750125885,
      "learning_rate": 1.8700420211130473e-05,
      "loss": 0.741,
      "step": 639
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.28552183508872986,
      "learning_rate": 1.8698370400737933e-05,
      "loss": 0.8023,
      "step": 640
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.30511707067489624,
      "learning_rate": 1.8696320590345393e-05,
      "loss": 0.7845,
      "step": 641
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.28802749514579773,
      "learning_rate": 1.8694270779952857e-05,
      "loss": 0.7299,
      "step": 642
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.2700783610343933,
      "learning_rate": 1.8692220969560317e-05,
      "loss": 0.7752,
      "step": 643
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.357479989528656,
      "learning_rate": 1.8690171159167777e-05,
      "loss": 0.7619,
      "step": 644
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.26713383197784424,
      "learning_rate": 1.8688121348775237e-05,
      "loss": 0.7588,
      "step": 645
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.26902085542678833,
      "learning_rate": 1.86860715383827e-05,
      "loss": 0.8006,
      "step": 646
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.3053898811340332,
      "learning_rate": 1.868402172799016e-05,
      "loss": 0.7074,
      "step": 647
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.30651965737342834,
      "learning_rate": 1.8681971917597625e-05,
      "loss": 0.6776,
      "step": 648
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.30364400148391724,
      "learning_rate": 1.8679922107205085e-05,
      "loss": 0.7094,
      "step": 649
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.45219185948371887,
      "learning_rate": 1.867787229681255e-05,
      "loss": 0.7414,
      "step": 650
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.33632686734199524,
      "learning_rate": 1.867582248642001e-05,
      "loss": 0.8247,
      "step": 651
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.27378049492836,
      "learning_rate": 1.867377267602747e-05,
      "loss": 0.7217,
      "step": 652
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.32606759667396545,
      "learning_rate": 1.867172286563493e-05,
      "loss": 0.9137,
      "step": 653
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.4139516353607178,
      "learning_rate": 1.8669673055242392e-05,
      "loss": 0.6719,
      "step": 654
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.407975971698761,
      "learning_rate": 1.8667623244849853e-05,
      "loss": 0.7217,
      "step": 655
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.31235629320144653,
      "learning_rate": 1.8665573434457313e-05,
      "loss": 0.7938,
      "step": 656
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.306678831577301,
      "learning_rate": 1.8663523624064776e-05,
      "loss": 0.7975,
      "step": 657
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.3054419457912445,
      "learning_rate": 1.8661473813672236e-05,
      "loss": 0.7549,
      "step": 658
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.2784799337387085,
      "learning_rate": 1.8659424003279697e-05,
      "loss": 0.7744,
      "step": 659
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.31096217036247253,
      "learning_rate": 1.865737419288716e-05,
      "loss": 0.8372,
      "step": 660
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.3108414113521576,
      "learning_rate": 1.865532438249462e-05,
      "loss": 0.7821,
      "step": 661
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.3422684073448181,
      "learning_rate": 1.8653274572102084e-05,
      "loss": 0.6332,
      "step": 662
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.27207282185554504,
      "learning_rate": 1.8651224761709544e-05,
      "loss": 0.8161,
      "step": 663
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.32756397128105164,
      "learning_rate": 1.8649174951317004e-05,
      "loss": 0.6827,
      "step": 664
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.35011640191078186,
      "learning_rate": 1.8647125140924468e-05,
      "loss": 0.6699,
      "step": 665
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.33124545216560364,
      "learning_rate": 1.8645075330531928e-05,
      "loss": 0.6844,
      "step": 666
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.3036869466304779,
      "learning_rate": 1.8643025520139388e-05,
      "loss": 0.7202,
      "step": 667
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.4293011724948883,
      "learning_rate": 1.8640975709746848e-05,
      "loss": 0.7756,
      "step": 668
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.4789758324623108,
      "learning_rate": 1.8638925899354312e-05,
      "loss": 0.7574,
      "step": 669
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.33938974142074585,
      "learning_rate": 1.8636876088961772e-05,
      "loss": 0.7449,
      "step": 670
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.2775660753250122,
      "learning_rate": 1.8634826278569232e-05,
      "loss": 0.7933,
      "step": 671
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.28979596495628357,
      "learning_rate": 1.8632776468176696e-05,
      "loss": 0.8205,
      "step": 672
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.2685103118419647,
      "learning_rate": 1.8630726657784156e-05,
      "loss": 0.7204,
      "step": 673
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.4604327380657196,
      "learning_rate": 1.862867684739162e-05,
      "loss": 0.7665,
      "step": 674
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.3960510790348053,
      "learning_rate": 1.862662703699908e-05,
      "loss": 0.8591,
      "step": 675
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.3221500813961029,
      "learning_rate": 1.862457722660654e-05,
      "loss": 0.7863,
      "step": 676
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.29200273752212524,
      "learning_rate": 1.8622527416214003e-05,
      "loss": 0.8267,
      "step": 677
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.3674166798591614,
      "learning_rate": 1.8620477605821463e-05,
      "loss": 0.729,
      "step": 678
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.3679443299770355,
      "learning_rate": 1.8618427795428924e-05,
      "loss": 0.7954,
      "step": 679
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.28557607531547546,
      "learning_rate": 1.8616377985036384e-05,
      "loss": 0.6353,
      "step": 680
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.330252468585968,
      "learning_rate": 1.8614328174643847e-05,
      "loss": 0.765,
      "step": 681
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.33303672075271606,
      "learning_rate": 1.8612278364251307e-05,
      "loss": 0.626,
      "step": 682
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.27430498600006104,
      "learning_rate": 1.8610228553858768e-05,
      "loss": 0.7415,
      "step": 683
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.2744219899177551,
      "learning_rate": 1.860817874346623e-05,
      "loss": 0.7709,
      "step": 684
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.30445465445518494,
      "learning_rate": 1.860612893307369e-05,
      "loss": 0.7008,
      "step": 685
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.2783001959323883,
      "learning_rate": 1.8604079122681155e-05,
      "loss": 0.7687,
      "step": 686
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.3679037094116211,
      "learning_rate": 1.8602029312288615e-05,
      "loss": 0.81,
      "step": 687
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.37763097882270813,
      "learning_rate": 1.859997950189608e-05,
      "loss": 0.6983,
      "step": 688
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.4544643759727478,
      "learning_rate": 1.859792969150354e-05,
      "loss": 0.7667,
      "step": 689
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.2900504171848297,
      "learning_rate": 1.8595879881111e-05,
      "loss": 0.8443,
      "step": 690
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.32240623235702515,
      "learning_rate": 1.859383007071846e-05,
      "loss": 0.7483,
      "step": 691
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.32900500297546387,
      "learning_rate": 1.8591780260325923e-05,
      "loss": 0.6492,
      "step": 692
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.3703707754611969,
      "learning_rate": 1.8589730449933383e-05,
      "loss": 0.7254,
      "step": 693
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.4254625141620636,
      "learning_rate": 1.8587680639540843e-05,
      "loss": 0.6392,
      "step": 694
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.29394441843032837,
      "learning_rate": 1.8585630829148303e-05,
      "loss": 0.7379,
      "step": 695
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.4378385841846466,
      "learning_rate": 1.8583581018755767e-05,
      "loss": 0.7827,
      "step": 696
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.48359277844429016,
      "learning_rate": 1.8581531208363227e-05,
      "loss": 0.6433,
      "step": 697
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.3416093587875366,
      "learning_rate": 1.857948139797069e-05,
      "loss": 0.7242,
      "step": 698
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.30828067660331726,
      "learning_rate": 1.857743158757815e-05,
      "loss": 0.7609,
      "step": 699
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.517676055431366,
      "learning_rate": 1.8575381777185614e-05,
      "loss": 0.7249,
      "step": 700
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.3971892297267914,
      "learning_rate": 1.8573331966793074e-05,
      "loss": 0.7275,
      "step": 701
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.33746176958084106,
      "learning_rate": 1.8571282156400534e-05,
      "loss": 0.7576,
      "step": 702
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.32515254616737366,
      "learning_rate": 1.8569232346007995e-05,
      "loss": 0.8303,
      "step": 703
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.3975939452648163,
      "learning_rate": 1.8567182535615458e-05,
      "loss": 0.7686,
      "step": 704
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.37193068861961365,
      "learning_rate": 1.8565132725222918e-05,
      "loss": 0.6498,
      "step": 705
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.46627968549728394,
      "learning_rate": 1.856308291483038e-05,
      "loss": 0.6542,
      "step": 706
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.32185736298561096,
      "learning_rate": 1.856103310443784e-05,
      "loss": 0.7644,
      "step": 707
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.3419387638568878,
      "learning_rate": 1.8558983294045302e-05,
      "loss": 0.8139,
      "step": 708
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.34390830993652344,
      "learning_rate": 1.8556933483652762e-05,
      "loss": 0.6869,
      "step": 709
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.30676236748695374,
      "learning_rate": 1.8554883673260226e-05,
      "loss": 0.7712,
      "step": 710
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.38774573802948,
      "learning_rate": 1.8552833862867686e-05,
      "loss": 0.6645,
      "step": 711
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.3417278230190277,
      "learning_rate": 1.855078405247515e-05,
      "loss": 0.7311,
      "step": 712
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.31306809186935425,
      "learning_rate": 1.854873424208261e-05,
      "loss": 0.8923,
      "step": 713
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.3018990159034729,
      "learning_rate": 1.854668443169007e-05,
      "loss": 0.8087,
      "step": 714
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.27663567662239075,
      "learning_rate": 1.8544634621297533e-05,
      "loss": 0.8361,
      "step": 715
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.5003049373626709,
      "learning_rate": 1.8542584810904994e-05,
      "loss": 0.6641,
      "step": 716
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.3594311773777008,
      "learning_rate": 1.8540535000512454e-05,
      "loss": 0.6216,
      "step": 717
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.3374612331390381,
      "learning_rate": 1.8538485190119914e-05,
      "loss": 0.7658,
      "step": 718
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.3757317364215851,
      "learning_rate": 1.8536435379727377e-05,
      "loss": 0.7006,
      "step": 719
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.4909655451774597,
      "learning_rate": 1.8534385569334838e-05,
      "loss": 0.7254,
      "step": 720
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.4365713596343994,
      "learning_rate": 1.8532335758942298e-05,
      "loss": 0.7363,
      "step": 721
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.3125793933868408,
      "learning_rate": 1.853028594854976e-05,
      "loss": 0.7207,
      "step": 722
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.4891459047794342,
      "learning_rate": 1.852823613815722e-05,
      "loss": 0.7067,
      "step": 723
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.3163311779499054,
      "learning_rate": 1.8526186327764685e-05,
      "loss": 0.6401,
      "step": 724
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.31483927369117737,
      "learning_rate": 1.8524136517372145e-05,
      "loss": 0.7027,
      "step": 725
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.35486382246017456,
      "learning_rate": 1.8522086706979605e-05,
      "loss": 0.6556,
      "step": 726
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.3418521285057068,
      "learning_rate": 1.852003689658707e-05,
      "loss": 0.7576,
      "step": 727
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.2981542646884918,
      "learning_rate": 1.851798708619453e-05,
      "loss": 0.8013,
      "step": 728
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.3128420412540436,
      "learning_rate": 1.851593727580199e-05,
      "loss": 0.7103,
      "step": 729
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.3254688084125519,
      "learning_rate": 1.851388746540945e-05,
      "loss": 0.728,
      "step": 730
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.31213757395744324,
      "learning_rate": 1.8511837655016913e-05,
      "loss": 0.728,
      "step": 731
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.28854265809059143,
      "learning_rate": 1.8509787844624373e-05,
      "loss": 0.7557,
      "step": 732
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.3398171365261078,
      "learning_rate": 1.8507738034231833e-05,
      "loss": 0.6799,
      "step": 733
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.34003064036369324,
      "learning_rate": 1.8505688223839297e-05,
      "loss": 0.7119,
      "step": 734
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.39870837330818176,
      "learning_rate": 1.8503638413446757e-05,
      "loss": 0.8255,
      "step": 735
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.31319308280944824,
      "learning_rate": 1.850158860305422e-05,
      "loss": 0.8004,
      "step": 736
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.29807278513908386,
      "learning_rate": 1.849953879266168e-05,
      "loss": 0.8058,
      "step": 737
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.4358442425727844,
      "learning_rate": 1.849748898226914e-05,
      "loss": 0.7133,
      "step": 738
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.37343865633010864,
      "learning_rate": 1.8495439171876604e-05,
      "loss": 0.6576,
      "step": 739
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.34897083044052124,
      "learning_rate": 1.8493389361484065e-05,
      "loss": 0.7354,
      "step": 740
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.38121914863586426,
      "learning_rate": 1.8491339551091525e-05,
      "loss": 0.8388,
      "step": 741
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.4444100558757782,
      "learning_rate": 1.848928974069899e-05,
      "loss": 0.6765,
      "step": 742
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.3391948938369751,
      "learning_rate": 1.848723993030645e-05,
      "loss": 0.8228,
      "step": 743
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.3986491858959198,
      "learning_rate": 1.848519011991391e-05,
      "loss": 0.7897,
      "step": 744
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.37333256006240845,
      "learning_rate": 1.848314030952137e-05,
      "loss": 0.7476,
      "step": 745
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.43750837445259094,
      "learning_rate": 1.8481090499128832e-05,
      "loss": 0.7887,
      "step": 746
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.3638215959072113,
      "learning_rate": 1.8479040688736293e-05,
      "loss": 0.7321,
      "step": 747
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.32453709840774536,
      "learning_rate": 1.8476990878343756e-05,
      "loss": 0.6265,
      "step": 748
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.4802641272544861,
      "learning_rate": 1.8474941067951216e-05,
      "loss": 0.7587,
      "step": 749
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.43956223130226135,
      "learning_rate": 1.847289125755868e-05,
      "loss": 0.6881,
      "step": 750
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.32497453689575195,
      "learning_rate": 1.847084144716614e-05,
      "loss": 0.7811,
      "step": 751
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.4412628710269928,
      "learning_rate": 1.84687916367736e-05,
      "loss": 0.6482,
      "step": 752
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.40573760867118835,
      "learning_rate": 1.846674182638106e-05,
      "loss": 0.6994,
      "step": 753
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.5959574580192566,
      "learning_rate": 1.8464692015988524e-05,
      "loss": 0.5326,
      "step": 754
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.3822227418422699,
      "learning_rate": 1.8462642205595984e-05,
      "loss": 0.6461,
      "step": 755
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.3202332854270935,
      "learning_rate": 1.8460592395203444e-05,
      "loss": 0.7033,
      "step": 756
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.5029582381248474,
      "learning_rate": 1.8458542584810904e-05,
      "loss": 0.8372,
      "step": 757
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.35861167311668396,
      "learning_rate": 1.8456492774418368e-05,
      "loss": 0.8276,
      "step": 758
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.5442591905593872,
      "learning_rate": 1.8454442964025828e-05,
      "loss": 0.6844,
      "step": 759
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.3382883071899414,
      "learning_rate": 1.845239315363329e-05,
      "loss": 0.7545,
      "step": 760
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.3822135031223297,
      "learning_rate": 1.8450343343240752e-05,
      "loss": 0.6785,
      "step": 761
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.3524187207221985,
      "learning_rate": 1.8448293532848215e-05,
      "loss": 0.7035,
      "step": 762
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.5718131065368652,
      "learning_rate": 1.8446243722455675e-05,
      "loss": 0.6628,
      "step": 763
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.5670221447944641,
      "learning_rate": 1.8444193912063136e-05,
      "loss": 0.7467,
      "step": 764
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.6257759928703308,
      "learning_rate": 1.8442144101670596e-05,
      "loss": 0.5425,
      "step": 765
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.3476133644580841,
      "learning_rate": 1.844009429127806e-05,
      "loss": 0.7651,
      "step": 766
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.3382849395275116,
      "learning_rate": 1.843804448088552e-05,
      "loss": 0.666,
      "step": 767
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.35760655999183655,
      "learning_rate": 1.843599467049298e-05,
      "loss": 0.7683,
      "step": 768
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.345113068819046,
      "learning_rate": 1.843394486010044e-05,
      "loss": 0.8237,
      "step": 769
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.3445224165916443,
      "learning_rate": 1.8431895049707903e-05,
      "loss": 0.7544,
      "step": 770
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.34835100173950195,
      "learning_rate": 1.8429845239315364e-05,
      "loss": 0.7118,
      "step": 771
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.3312264680862427,
      "learning_rate": 1.8427795428922827e-05,
      "loss": 0.5742,
      "step": 772
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.32391804456710815,
      "learning_rate": 1.8425745618530287e-05,
      "loss": 0.8163,
      "step": 773
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.3408675193786621,
      "learning_rate": 1.842369580813775e-05,
      "loss": 0.7516,
      "step": 774
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.31878426671028137,
      "learning_rate": 1.842164599774521e-05,
      "loss": 0.7788,
      "step": 775
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.35067152976989746,
      "learning_rate": 1.841959618735267e-05,
      "loss": 0.7482,
      "step": 776
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.3820863664150238,
      "learning_rate": 1.8417546376960135e-05,
      "loss": 0.6476,
      "step": 777
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.3818586468696594,
      "learning_rate": 1.8415496566567595e-05,
      "loss": 0.6988,
      "step": 778
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.37748727202415466,
      "learning_rate": 1.8413446756175055e-05,
      "loss": 0.6549,
      "step": 779
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.3882914185523987,
      "learning_rate": 1.8411396945782515e-05,
      "loss": 0.7389,
      "step": 780
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.3661918640136719,
      "learning_rate": 1.840934713538998e-05,
      "loss": 0.7472,
      "step": 781
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.38381168246269226,
      "learning_rate": 1.840729732499744e-05,
      "loss": 0.8291,
      "step": 782
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.38169392943382263,
      "learning_rate": 1.84052475146049e-05,
      "loss": 0.6882,
      "step": 783
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.36396491527557373,
      "learning_rate": 1.8403197704212363e-05,
      "loss": 0.7248,
      "step": 784
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.32172074913978577,
      "learning_rate": 1.8401147893819823e-05,
      "loss": 0.7095,
      "step": 785
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.38077113032341003,
      "learning_rate": 1.8399098083427286e-05,
      "loss": 0.7364,
      "step": 786
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.3368634581565857,
      "learning_rate": 1.8397048273034746e-05,
      "loss": 0.7344,
      "step": 787
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.3104882538318634,
      "learning_rate": 1.8394998462642207e-05,
      "loss": 0.7972,
      "step": 788
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.39613014459609985,
      "learning_rate": 1.839294865224967e-05,
      "loss": 0.6937,
      "step": 789
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.4015425741672516,
      "learning_rate": 1.839089884185713e-05,
      "loss": 0.6905,
      "step": 790
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.4483844041824341,
      "learning_rate": 1.838884903146459e-05,
      "loss": 0.741,
      "step": 791
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.4784570634365082,
      "learning_rate": 1.838679922107205e-05,
      "loss": 0.6994,
      "step": 792
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.38381892442703247,
      "learning_rate": 1.8384749410679514e-05,
      "loss": 0.7228,
      "step": 793
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.5806990265846252,
      "learning_rate": 1.8382699600286974e-05,
      "loss": 0.7639,
      "step": 794
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.4452645778656006,
      "learning_rate": 1.8380649789894435e-05,
      "loss": 0.6363,
      "step": 795
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.38077521324157715,
      "learning_rate": 1.8378599979501898e-05,
      "loss": 0.6264,
      "step": 796
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.6829047799110413,
      "learning_rate": 1.8376550169109358e-05,
      "loss": 0.4541,
      "step": 797
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.3296494781970978,
      "learning_rate": 1.8374500358716822e-05,
      "loss": 0.803,
      "step": 798
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.45602652430534363,
      "learning_rate": 1.8372450548324282e-05,
      "loss": 0.7552,
      "step": 799
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.31666791439056396,
      "learning_rate": 1.8370400737931742e-05,
      "loss": 0.6335,
      "step": 800
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.44298651814460754,
      "learning_rate": 1.8368350927539206e-05,
      "loss": 0.6915,
      "step": 801
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.47092998027801514,
      "learning_rate": 1.8366301117146666e-05,
      "loss": 0.7799,
      "step": 802
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.7840266823768616,
      "learning_rate": 1.8364251306754126e-05,
      "loss": 0.7154,
      "step": 803
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.38121023774147034,
      "learning_rate": 1.836220149636159e-05,
      "loss": 0.7159,
      "step": 804
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.767606794834137,
      "learning_rate": 1.836015168596905e-05,
      "loss": 0.7212,
      "step": 805
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.8547561168670654,
      "learning_rate": 1.835810187557651e-05,
      "loss": 0.7215,
      "step": 806
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.37105560302734375,
      "learning_rate": 1.835605206518397e-05,
      "loss": 0.7077,
      "step": 807
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.49927404522895813,
      "learning_rate": 1.8354002254791434e-05,
      "loss": 0.7616,
      "step": 808
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.7632033228874207,
      "learning_rate": 1.8351952444398894e-05,
      "loss": 0.6147,
      "step": 809
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.6649359464645386,
      "learning_rate": 1.8349902634006357e-05,
      "loss": 0.7497,
      "step": 810
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.5113076567649841,
      "learning_rate": 1.8347852823613817e-05,
      "loss": 0.665,
      "step": 811
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.43120482563972473,
      "learning_rate": 1.834580301322128e-05,
      "loss": 0.5366,
      "step": 812
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.6887221932411194,
      "learning_rate": 1.834375320282874e-05,
      "loss": 0.7336,
      "step": 813
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.5085777640342712,
      "learning_rate": 1.83417033924362e-05,
      "loss": 0.7838,
      "step": 814
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.6687688827514648,
      "learning_rate": 1.833965358204366e-05,
      "loss": 0.6043,
      "step": 815
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.4470117688179016,
      "learning_rate": 1.8337603771651125e-05,
      "loss": 0.7853,
      "step": 816
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.6082642674446106,
      "learning_rate": 1.8335553961258585e-05,
      "loss": 0.6707,
      "step": 817
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.556739091873169,
      "learning_rate": 1.8333504150866045e-05,
      "loss": 0.6384,
      "step": 818
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.593297004699707,
      "learning_rate": 1.8331454340473506e-05,
      "loss": 0.7156,
      "step": 819
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.4088369309902191,
      "learning_rate": 1.832940453008097e-05,
      "loss": 0.6469,
      "step": 820
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.5740868449211121,
      "learning_rate": 1.832735471968843e-05,
      "loss": 0.6262,
      "step": 821
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.4739842414855957,
      "learning_rate": 1.8325304909295893e-05,
      "loss": 0.7095,
      "step": 822
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.5292513966560364,
      "learning_rate": 1.8323255098903353e-05,
      "loss": 0.6413,
      "step": 823
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.3731658458709717,
      "learning_rate": 1.8321205288510816e-05,
      "loss": 0.7914,
      "step": 824
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.39712899923324585,
      "learning_rate": 1.8319155478118277e-05,
      "loss": 0.6274,
      "step": 825
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.4137084484100342,
      "learning_rate": 1.8317105667725737e-05,
      "loss": 0.895,
      "step": 826
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.5887430906295776,
      "learning_rate": 1.8315055857333197e-05,
      "loss": 0.7754,
      "step": 827
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.4509851336479187,
      "learning_rate": 1.831300604694066e-05,
      "loss": 0.7488,
      "step": 828
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.35678544640541077,
      "learning_rate": 1.831095623654812e-05,
      "loss": 0.732,
      "step": 829
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.39582085609436035,
      "learning_rate": 1.830890642615558e-05,
      "loss": 0.7189,
      "step": 830
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.3869258165359497,
      "learning_rate": 1.8306856615763044e-05,
      "loss": 0.8149,
      "step": 831
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.8728341460227966,
      "learning_rate": 1.8304806805370505e-05,
      "loss": 0.719,
      "step": 832
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.39453545212745667,
      "learning_rate": 1.8302756994977965e-05,
      "loss": 0.6269,
      "step": 833
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.39652642607688904,
      "learning_rate": 1.8300707184585428e-05,
      "loss": 0.6767,
      "step": 834
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.5281271934509277,
      "learning_rate": 1.829865737419289e-05,
      "loss": 0.7747,
      "step": 835
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.4026881158351898,
      "learning_rate": 1.8296607563800352e-05,
      "loss": 0.7466,
      "step": 836
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.38571298122406006,
      "learning_rate": 1.8294557753407812e-05,
      "loss": 0.755,
      "step": 837
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.393897145986557,
      "learning_rate": 1.8292507943015272e-05,
      "loss": 0.6925,
      "step": 838
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.3204295337200165,
      "learning_rate": 1.8290458132622736e-05,
      "loss": 0.6842,
      "step": 839
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.6132552623748779,
      "learning_rate": 1.8288408322230196e-05,
      "loss": 0.6335,
      "step": 840
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.4217650592327118,
      "learning_rate": 1.8286358511837656e-05,
      "loss": 0.697,
      "step": 841
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.423797607421875,
      "learning_rate": 1.8284308701445116e-05,
      "loss": 0.7175,
      "step": 842
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.4340386986732483,
      "learning_rate": 1.828225889105258e-05,
      "loss": 0.5318,
      "step": 843
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.5517090559005737,
      "learning_rate": 1.828020908066004e-05,
      "loss": 0.5481,
      "step": 844
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.48700082302093506,
      "learning_rate": 1.82781592702675e-05,
      "loss": 0.6788,
      "step": 845
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.34000372886657715,
      "learning_rate": 1.8276109459874964e-05,
      "loss": 0.7436,
      "step": 846
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.38510167598724365,
      "learning_rate": 1.8274059649482424e-05,
      "loss": 0.6562,
      "step": 847
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.43188080191612244,
      "learning_rate": 1.8272009839089887e-05,
      "loss": 0.7289,
      "step": 848
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.42137399315834045,
      "learning_rate": 1.8269960028697348e-05,
      "loss": 0.7173,
      "step": 849
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.38572052121162415,
      "learning_rate": 1.8267910218304808e-05,
      "loss": 0.7576,
      "step": 850
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.40080949664115906,
      "learning_rate": 1.826586040791227e-05,
      "loss": 0.6614,
      "step": 851
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.3580224812030792,
      "learning_rate": 1.826381059751973e-05,
      "loss": 0.6294,
      "step": 852
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.46862682700157166,
      "learning_rate": 1.8261760787127192e-05,
      "loss": 0.7558,
      "step": 853
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.40485680103302,
      "learning_rate": 1.8259710976734652e-05,
      "loss": 0.7162,
      "step": 854
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.39934080839157104,
      "learning_rate": 1.8257661166342115e-05,
      "loss": 0.7318,
      "step": 855
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.42829325795173645,
      "learning_rate": 1.8255611355949576e-05,
      "loss": 0.7367,
      "step": 856
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.500968337059021,
      "learning_rate": 1.8253561545557036e-05,
      "loss": 0.7091,
      "step": 857
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.3849359452724457,
      "learning_rate": 1.82515117351645e-05,
      "loss": 0.6623,
      "step": 858
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.40085428953170776,
      "learning_rate": 1.824946192477196e-05,
      "loss": 0.6305,
      "step": 859
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.3848453164100647,
      "learning_rate": 1.8247412114379423e-05,
      "loss": 0.6868,
      "step": 860
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.41218090057373047,
      "learning_rate": 1.8245362303986883e-05,
      "loss": 0.6544,
      "step": 861
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.3708559274673462,
      "learning_rate": 1.8243312493594347e-05,
      "loss": 0.6551,
      "step": 862
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.4281514883041382,
      "learning_rate": 1.8241262683201807e-05,
      "loss": 0.5519,
      "step": 863
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.5886114835739136,
      "learning_rate": 1.8239212872809267e-05,
      "loss": 0.4795,
      "step": 864
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.5138920545578003,
      "learning_rate": 1.8237163062416727e-05,
      "loss": 0.7296,
      "step": 865
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.3646332323551178,
      "learning_rate": 1.823511325202419e-05,
      "loss": 0.7963,
      "step": 866
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.34660905599594116,
      "learning_rate": 1.823306344163165e-05,
      "loss": 0.7459,
      "step": 867
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.7398350238800049,
      "learning_rate": 1.823101363123911e-05,
      "loss": 0.6053,
      "step": 868
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.34717774391174316,
      "learning_rate": 1.822896382084657e-05,
      "loss": 0.6942,
      "step": 869
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.4412369728088379,
      "learning_rate": 1.8226914010454035e-05,
      "loss": 0.6657,
      "step": 870
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.44629335403442383,
      "learning_rate": 1.8224864200061495e-05,
      "loss": 0.777,
      "step": 871
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.42369726300239563,
      "learning_rate": 1.822281438966896e-05,
      "loss": 0.745,
      "step": 872
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.3678620755672455,
      "learning_rate": 1.822076457927642e-05,
      "loss": 0.552,
      "step": 873
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.4654993414878845,
      "learning_rate": 1.8218714768883882e-05,
      "loss": 0.6133,
      "step": 874
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.43903836607933044,
      "learning_rate": 1.8216664958491342e-05,
      "loss": 0.6503,
      "step": 875
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.4525679051876068,
      "learning_rate": 1.8214615148098803e-05,
      "loss": 0.6991,
      "step": 876
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.40005528926849365,
      "learning_rate": 1.8212565337706263e-05,
      "loss": 0.6968,
      "step": 877
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.6973149180412292,
      "learning_rate": 1.8210515527313726e-05,
      "loss": 0.6795,
      "step": 878
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.39223435521125793,
      "learning_rate": 1.8208465716921186e-05,
      "loss": 0.5328,
      "step": 879
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.7147462964057922,
      "learning_rate": 1.8206415906528647e-05,
      "loss": 0.6555,
      "step": 880
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.3760982155799866,
      "learning_rate": 1.8204366096136107e-05,
      "loss": 0.7856,
      "step": 881
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.6709074378013611,
      "learning_rate": 1.820231628574357e-05,
      "loss": 0.5288,
      "step": 882
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.3951513171195984,
      "learning_rate": 1.820026647535103e-05,
      "loss": 0.6501,
      "step": 883
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.9724901914596558,
      "learning_rate": 1.8198216664958494e-05,
      "loss": 0.5904,
      "step": 884
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.3793524503707886,
      "learning_rate": 1.8196166854565954e-05,
      "loss": 0.6266,
      "step": 885
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.5935982465744019,
      "learning_rate": 1.8194117044173418e-05,
      "loss": 0.6587,
      "step": 886
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.452092707157135,
      "learning_rate": 1.8192067233780878e-05,
      "loss": 0.7845,
      "step": 887
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.4551563858985901,
      "learning_rate": 1.8190017423388338e-05,
      "loss": 0.6162,
      "step": 888
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.43898817896842957,
      "learning_rate": 1.8187967612995798e-05,
      "loss": 0.5888,
      "step": 889
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.394233375787735,
      "learning_rate": 1.8185917802603262e-05,
      "loss": 0.6493,
      "step": 890
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.4864000678062439,
      "learning_rate": 1.8183867992210722e-05,
      "loss": 0.6861,
      "step": 891
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.5025405883789062,
      "learning_rate": 1.8181818181818182e-05,
      "loss": 0.6503,
      "step": 892
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.4941229522228241,
      "learning_rate": 1.8179768371425646e-05,
      "loss": 0.5629,
      "step": 893
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.40720701217651367,
      "learning_rate": 1.8177718561033106e-05,
      "loss": 0.8052,
      "step": 894
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.42570561170578003,
      "learning_rate": 1.8175668750640566e-05,
      "loss": 0.7186,
      "step": 895
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.43226298689842224,
      "learning_rate": 1.817361894024803e-05,
      "loss": 0.757,
      "step": 896
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.7076277136802673,
      "learning_rate": 1.817156912985549e-05,
      "loss": 0.712,
      "step": 897
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.440159410238266,
      "learning_rate": 1.8169519319462953e-05,
      "loss": 0.7014,
      "step": 898
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.39494553208351135,
      "learning_rate": 1.8167469509070413e-05,
      "loss": 0.7205,
      "step": 899
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.3951118588447571,
      "learning_rate": 1.8165419698677874e-05,
      "loss": 0.6503,
      "step": 900
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.5288782119750977,
      "learning_rate": 1.8163369888285337e-05,
      "loss": 0.6108,
      "step": 901
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.6907683610916138,
      "learning_rate": 1.8161320077892797e-05,
      "loss": 0.6007,
      "step": 902
    },
    {
      "epoch": 0.19,
      "grad_norm": 0.3930463194847107,
      "learning_rate": 1.8159270267500257e-05,
      "loss": 0.6818,
      "step": 903
    },
    {
      "epoch": 0.19,
      "grad_norm": 0.4185275435447693,
      "learning_rate": 1.8157220457107718e-05,
      "loss": 0.7209,
      "step": 904
    },
    {
      "epoch": 0.19,
      "grad_norm": 0.7686632871627808,
      "learning_rate": 1.815517064671518e-05,
      "loss": 0.7527,
      "step": 905
    },
    {
      "epoch": 0.19,
      "grad_norm": 0.5023302435874939,
      "learning_rate": 1.815312083632264e-05,
      "loss": 0.7128,
      "step": 906
    },
    {
      "epoch": 0.19,
      "grad_norm": 0.5007780194282532,
      "learning_rate": 1.81510710259301e-05,
      "loss": 0.608,
      "step": 907
    },
    {
      "epoch": 0.19,
      "grad_norm": 0.6725736856460571,
      "learning_rate": 1.8149021215537565e-05,
      "loss": 0.7584,
      "step": 908
    },
    {
      "epoch": 0.19,
      "grad_norm": 0.931692361831665,
      "learning_rate": 1.8146971405145025e-05,
      "loss": 0.7622,
      "step": 909
    },
    {
      "epoch": 0.19,
      "grad_norm": 0.39940518140792847,
      "learning_rate": 1.814492159475249e-05,
      "loss": 0.7644,
      "step": 910
    },
    {
      "epoch": 0.19,
      "grad_norm": 0.4073428213596344,
      "learning_rate": 1.814287178435995e-05,
      "loss": 0.7916,
      "step": 911
    },
    {
      "epoch": 0.19,
      "grad_norm": 0.7836171388626099,
      "learning_rate": 1.814082197396741e-05,
      "loss": 0.589,
      "step": 912
    },
    {
      "epoch": 0.19,
      "grad_norm": 0.4967021644115448,
      "learning_rate": 1.8138772163574873e-05,
      "loss": 0.6699,
      "step": 913
    },
    {
      "epoch": 0.19,
      "grad_norm": 0.685780942440033,
      "learning_rate": 1.8136722353182333e-05,
      "loss": 0.6944,
      "step": 914
    },
    {
      "epoch": 0.19,
      "grad_norm": 0.45136794447898865,
      "learning_rate": 1.8134672542789793e-05,
      "loss": 0.5489,
      "step": 915
    },
    {
      "epoch": 0.19,
      "grad_norm": 0.47103267908096313,
      "learning_rate": 1.8132622732397253e-05,
      "loss": 0.7089,
      "step": 916
    },
    {
      "epoch": 0.19,
      "grad_norm": 1.4208459854125977,
      "learning_rate": 1.8130572922004717e-05,
      "loss": 0.672,
      "step": 917
    },
    {
      "epoch": 0.19,
      "grad_norm": 0.9348700046539307,
      "learning_rate": 1.8128523111612177e-05,
      "loss": 0.6471,
      "step": 918
    },
    {
      "epoch": 0.19,
      "grad_norm": 0.3924078047275543,
      "learning_rate": 1.8126473301219637e-05,
      "loss": 0.7447,
      "step": 919
    },
    {
      "epoch": 0.19,
      "grad_norm": 0.9750374555587769,
      "learning_rate": 1.81244234908271e-05,
      "loss": 0.7087,
      "step": 920
    },
    {
      "epoch": 0.19,
      "grad_norm": 1.7007211446762085,
      "learning_rate": 1.812237368043456e-05,
      "loss": 0.5351,
      "step": 921
    },
    {
      "epoch": 0.19,
      "grad_norm": 0.442564457654953,
      "learning_rate": 1.8120323870042024e-05,
      "loss": 0.6833,
      "step": 922
    },
    {
      "epoch": 0.19,
      "grad_norm": 0.45591282844543457,
      "learning_rate": 1.8118274059649484e-05,
      "loss": 0.5787,
      "step": 923
    },
    {
      "epoch": 0.19,
      "grad_norm": 1.5567580461502075,
      "learning_rate": 1.8116224249256945e-05,
      "loss": 0.7134,
      "step": 924
    },
    {
      "epoch": 0.19,
      "grad_norm": 1.2040061950683594,
      "learning_rate": 1.8114174438864408e-05,
      "loss": 0.6736,
      "step": 925
    },
    {
      "epoch": 0.19,
      "grad_norm": 0.45492762327194214,
      "learning_rate": 1.8112124628471868e-05,
      "loss": 0.554,
      "step": 926
    },
    {
      "epoch": 0.19,
      "grad_norm": 0.5635227560997009,
      "learning_rate": 1.811007481807933e-05,
      "loss": 0.6058,
      "step": 927
    },
    {
      "epoch": 0.19,
      "grad_norm": 0.49082639813423157,
      "learning_rate": 1.8108025007686792e-05,
      "loss": 0.7288,
      "step": 928
    },
    {
      "epoch": 0.19,
      "grad_norm": 0.4423486888408661,
      "learning_rate": 1.8105975197294252e-05,
      "loss": 0.6226,
      "step": 929
    },
    {
      "epoch": 0.19,
      "grad_norm": 0.4169524610042572,
      "learning_rate": 1.8103925386901712e-05,
      "loss": 0.6772,
      "step": 930
    },
    {
      "epoch": 0.19,
      "grad_norm": 0.5752652287483215,
      "learning_rate": 1.8101875576509172e-05,
      "loss": 0.7031,
      "step": 931
    },
    {
      "epoch": 0.19,
      "grad_norm": 0.5587458610534668,
      "learning_rate": 1.8099825766116636e-05,
      "loss": 0.6021,
      "step": 932
    },
    {
      "epoch": 0.19,
      "grad_norm": 0.45150548219680786,
      "learning_rate": 1.8097775955724096e-05,
      "loss": 0.7215,
      "step": 933
    },
    {
      "epoch": 0.19,
      "grad_norm": 0.867041826248169,
      "learning_rate": 1.809572614533156e-05,
      "loss": 0.6352,
      "step": 934
    },
    {
      "epoch": 0.19,
      "grad_norm": 0.6960977911949158,
      "learning_rate": 1.809367633493902e-05,
      "loss": 0.5963,
      "step": 935
    },
    {
      "epoch": 0.19,
      "grad_norm": 0.44052258133888245,
      "learning_rate": 1.809162652454648e-05,
      "loss": 0.6084,
      "step": 936
    },
    {
      "epoch": 0.19,
      "grad_norm": 0.42431822419166565,
      "learning_rate": 1.8089576714153944e-05,
      "loss": 0.7031,
      "step": 937
    },
    {
      "epoch": 0.19,
      "grad_norm": 0.5878831148147583,
      "learning_rate": 1.8087526903761404e-05,
      "loss": 0.663,
      "step": 938
    },
    {
      "epoch": 0.19,
      "grad_norm": 0.7023143172264099,
      "learning_rate": 1.8085477093368864e-05,
      "loss": 0.7178,
      "step": 939
    },
    {
      "epoch": 0.19,
      "grad_norm": 1.051466703414917,
      "learning_rate": 1.8083427282976327e-05,
      "loss": 0.7182,
      "step": 940
    },
    {
      "epoch": 0.19,
      "grad_norm": 0.44801533222198486,
      "learning_rate": 1.8081377472583788e-05,
      "loss": 0.623,
      "step": 941
    },
    {
      "epoch": 0.19,
      "grad_norm": 0.7694495916366577,
      "learning_rate": 1.8079327662191248e-05,
      "loss": 0.6695,
      "step": 942
    },
    {
      "epoch": 0.19,
      "grad_norm": 1.1408681869506836,
      "learning_rate": 1.8077277851798708e-05,
      "loss": 0.531,
      "step": 943
    },
    {
      "epoch": 0.19,
      "grad_norm": 0.7007236480712891,
      "learning_rate": 1.807522804140617e-05,
      "loss": 0.6049,
      "step": 944
    },
    {
      "epoch": 0.19,
      "grad_norm": 0.49812501668930054,
      "learning_rate": 1.807317823101363e-05,
      "loss": 0.7247,
      "step": 945
    },
    {
      "epoch": 0.19,
      "grad_norm": 0.47634437680244446,
      "learning_rate": 1.8071128420621092e-05,
      "loss": 0.6715,
      "step": 946
    },
    {
      "epoch": 0.19,
      "grad_norm": 0.703545331954956,
      "learning_rate": 1.8069078610228555e-05,
      "loss": 0.6589,
      "step": 947
    },
    {
      "epoch": 0.19,
      "grad_norm": 0.5607951283454895,
      "learning_rate": 1.8067028799836016e-05,
      "loss": 0.7381,
      "step": 948
    },
    {
      "epoch": 0.19,
      "grad_norm": 0.623207688331604,
      "learning_rate": 1.806497898944348e-05,
      "loss": 0.7697,
      "step": 949
    },
    {
      "epoch": 0.19,
      "grad_norm": 0.5086536407470703,
      "learning_rate": 1.806292917905094e-05,
      "loss": 0.6564,
      "step": 950
    },
    {
      "epoch": 0.19,
      "grad_norm": 0.5248609781265259,
      "learning_rate": 1.8060879368658403e-05,
      "loss": 0.6345,
      "step": 951
    },
    {
      "epoch": 0.2,
      "grad_norm": 0.615601658821106,
      "learning_rate": 1.8058829558265863e-05,
      "loss": 0.7065,
      "step": 952
    },
    {
      "epoch": 0.2,
      "grad_norm": 0.6393739581108093,
      "learning_rate": 1.8056779747873323e-05,
      "loss": 0.7671,
      "step": 953
    },
    {
      "epoch": 0.2,
      "grad_norm": 0.5130853056907654,
      "learning_rate": 1.8054729937480783e-05,
      "loss": 0.7325,
      "step": 954
    },
    {
      "epoch": 0.2,
      "grad_norm": 0.43274986743927,
      "learning_rate": 1.8052680127088247e-05,
      "loss": 0.6656,
      "step": 955
    },
    {
      "epoch": 0.2,
      "grad_norm": 0.4293273687362671,
      "learning_rate": 1.8050630316695707e-05,
      "loss": 0.6029,
      "step": 956
    },
    {
      "epoch": 0.2,
      "grad_norm": 0.5159664154052734,
      "learning_rate": 1.8048580506303167e-05,
      "loss": 0.686,
      "step": 957
    },
    {
      "epoch": 0.2,
      "grad_norm": 0.5480853319168091,
      "learning_rate": 1.8046530695910627e-05,
      "loss": 0.6321,
      "step": 958
    },
    {
      "epoch": 0.2,
      "grad_norm": 0.6391343474388123,
      "learning_rate": 1.804448088551809e-05,
      "loss": 0.6256,
      "step": 959
    },
    {
      "epoch": 0.2,
      "grad_norm": 0.4127422869205475,
      "learning_rate": 1.804243107512555e-05,
      "loss": 0.7422,
      "step": 960
    },
    {
      "epoch": 0.2,
      "grad_norm": 0.5759455561637878,
      "learning_rate": 1.8040381264733015e-05,
      "loss": 0.7446,
      "step": 961
    },
    {
      "epoch": 0.2,
      "grad_norm": 1.721444010734558,
      "learning_rate": 1.8038331454340475e-05,
      "loss": 0.6502,
      "step": 962
    },
    {
      "epoch": 0.2,
      "grad_norm": 0.7205697298049927,
      "learning_rate": 1.8036281643947938e-05,
      "loss": 0.6732,
      "step": 963
    },
    {
      "epoch": 0.2,
      "grad_norm": 0.47355058789253235,
      "learning_rate": 1.80342318335554e-05,
      "loss": 0.6802,
      "step": 964
    },
    {
      "epoch": 0.2,
      "grad_norm": 0.42176657915115356,
      "learning_rate": 1.803218202316286e-05,
      "loss": 0.4875,
      "step": 965
    },
    {
      "epoch": 0.2,
      "grad_norm": 0.8192176222801208,
      "learning_rate": 1.803013221277032e-05,
      "loss": 0.6398,
      "step": 966
    },
    {
      "epoch": 0.2,
      "grad_norm": 1.2861359119415283,
      "learning_rate": 1.8028082402377782e-05,
      "loss": 0.5773,
      "step": 967
    },
    {
      "epoch": 0.2,
      "grad_norm": 0.4470946192741394,
      "learning_rate": 1.8026032591985243e-05,
      "loss": 0.5842,
      "step": 968
    },
    {
      "epoch": 0.2,
      "grad_norm": 0.44402486085891724,
      "learning_rate": 1.8023982781592703e-05,
      "loss": 0.665,
      "step": 969
    },
    {
      "epoch": 0.2,
      "grad_norm": 1.1630643606185913,
      "learning_rate": 1.8021932971200163e-05,
      "loss": 0.6535,
      "step": 970
    },
    {
      "epoch": 0.2,
      "grad_norm": 0.7565960884094238,
      "learning_rate": 1.8019883160807626e-05,
      "loss": 0.7613,
      "step": 971
    },
    {
      "epoch": 0.2,
      "grad_norm": 0.6709368228912354,
      "learning_rate": 1.8017833350415087e-05,
      "loss": 0.6905,
      "step": 972
    },
    {
      "epoch": 0.2,
      "grad_norm": 0.5808483958244324,
      "learning_rate": 1.801578354002255e-05,
      "loss": 0.6128,
      "step": 973
    },
    {
      "epoch": 0.2,
      "grad_norm": 0.6312974691390991,
      "learning_rate": 1.801373372963001e-05,
      "loss": 0.479,
      "step": 974
    },
    {
      "epoch": 0.2,
      "grad_norm": 0.8591532111167908,
      "learning_rate": 1.8011683919237474e-05,
      "loss": 0.5951,
      "step": 975
    },
    {
      "epoch": 0.2,
      "grad_norm": 0.9757481217384338,
      "learning_rate": 1.8009634108844934e-05,
      "loss": 0.666,
      "step": 976
    },
    {
      "epoch": 0.2,
      "grad_norm": 0.6285104155540466,
      "learning_rate": 1.8007584298452394e-05,
      "loss": 0.6446,
      "step": 977
    },
    {
      "epoch": 0.2,
      "grad_norm": 0.9877322316169739,
      "learning_rate": 1.8005534488059858e-05,
      "loss": 0.7462,
      "step": 978
    },
    {
      "epoch": 0.2,
      "grad_norm": 1.3466852903366089,
      "learning_rate": 1.8003484677667318e-05,
      "loss": 0.651,
      "step": 979
    },
    {
      "epoch": 0.2,
      "grad_norm": 1.0339725017547607,
      "learning_rate": 1.8001434867274778e-05,
      "loss": 0.6854,
      "step": 980
    },
    {
      "epoch": 0.2,
      "grad_norm": 0.48022592067718506,
      "learning_rate": 1.7999385056882238e-05,
      "loss": 0.6729,
      "step": 981
    },
    {
      "epoch": 0.2,
      "grad_norm": 0.37813159823417664,
      "learning_rate": 1.7997335246489702e-05,
      "loss": 0.5687,
      "step": 982
    },
    {
      "epoch": 0.2,
      "grad_norm": 0.694395124912262,
      "learning_rate": 1.7995285436097162e-05,
      "loss": 0.6738,
      "step": 983
    },
    {
      "epoch": 0.2,
      "grad_norm": 1.1972506046295166,
      "learning_rate": 1.7993235625704622e-05,
      "loss": 0.6039,
      "step": 984
    },
    {
      "epoch": 0.2,
      "grad_norm": 0.6524549126625061,
      "learning_rate": 1.7991185815312086e-05,
      "loss": 0.6084,
      "step": 985
    },
    {
      "epoch": 0.2,
      "grad_norm": 0.46900734305381775,
      "learning_rate": 1.7989136004919546e-05,
      "loss": 0.6232,
      "step": 986
    },
    {
      "epoch": 0.2,
      "grad_norm": 0.4189130663871765,
      "learning_rate": 1.798708619452701e-05,
      "loss": 0.5284,
      "step": 987
    },
    {
      "epoch": 0.2,
      "grad_norm": 0.8869667649269104,
      "learning_rate": 1.798503638413447e-05,
      "loss": 0.7361,
      "step": 988
    },
    {
      "epoch": 0.2,
      "grad_norm": 1.0329676866531372,
      "learning_rate": 1.798298657374193e-05,
      "loss": 0.6531,
      "step": 989
    },
    {
      "epoch": 0.2,
      "grad_norm": 0.5591780543327332,
      "learning_rate": 1.7980936763349393e-05,
      "loss": 0.8548,
      "step": 990
    },
    {
      "epoch": 0.2,
      "grad_norm": 0.5431678891181946,
      "learning_rate": 1.7978886952956853e-05,
      "loss": 0.7422,
      "step": 991
    },
    {
      "epoch": 0.2,
      "grad_norm": 1.1330517530441284,
      "learning_rate": 1.7976837142564314e-05,
      "loss": 0.5918,
      "step": 992
    },
    {
      "epoch": 0.2,
      "grad_norm": 1.392986536026001,
      "learning_rate": 1.7974787332171774e-05,
      "loss": 0.5775,
      "step": 993
    },
    {
      "epoch": 0.2,
      "grad_norm": 0.8402047157287598,
      "learning_rate": 1.7972737521779237e-05,
      "loss": 0.6291,
      "step": 994
    },
    {
      "epoch": 0.2,
      "grad_norm": 1.5754432678222656,
      "learning_rate": 1.7970687711386697e-05,
      "loss": 0.5104,
      "step": 995
    },
    {
      "epoch": 0.2,
      "grad_norm": 1.6208248138427734,
      "learning_rate": 1.7968637900994158e-05,
      "loss": 0.6114,
      "step": 996
    },
    {
      "epoch": 0.2,
      "grad_norm": 1.2679451704025269,
      "learning_rate": 1.796658809060162e-05,
      "loss": 0.602,
      "step": 997
    },
    {
      "epoch": 0.2,
      "grad_norm": 0.7579483389854431,
      "learning_rate": 1.796453828020908e-05,
      "loss": 0.5588,
      "step": 998
    },
    {
      "epoch": 0.2,
      "grad_norm": 0.7470415234565735,
      "learning_rate": 1.7962488469816545e-05,
      "loss": 0.6047,
      "step": 999
    },
    {
      "epoch": 0.2,
      "grad_norm": 2.1790597438812256,
      "learning_rate": 1.7960438659424005e-05,
      "loss": 0.5289,
      "step": 1000
    },
    {
      "epoch": 0.2,
      "eval_loss": 0.6467469334602356,
      "eval_runtime": 657.5713,
      "eval_samples_per_second": 15.207,
      "eval_steps_per_second": 1.901,
      "step": 1000
    }
  ],
  "logging_steps": 1,
  "max_steps": 9762,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 2,
  "save_steps": 1000,
  "total_flos": 1.2967903646672486e+17,
  "train_batch_size": 16,
  "trial_name": null,
  "trial_params": null
}
