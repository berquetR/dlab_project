{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "651adc3c",
   "metadata": {},
   "source": [
    "### Library Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "294bdc29",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "import torch\n",
    "import transformers\n",
    "import json\n",
    "import ast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2ca469aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset, concatenate_datasets\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, Trainer, TrainingArguments\n",
    "from peft import prepare_model_for_kbit_training, LoraConfig, get_peft_model, PeftModel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e391a5f5",
   "metadata": {},
   "source": [
    "### Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "3710484a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_dataset(\"berquetR/dlab_project_optimal_links\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "f588910b",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = dataset['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "264f4cb2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['source', 'target', 'current_page', 'current_page_links', 'next_page', '__index_level_0__'],\n",
       "    num_rows: 26193\n",
       "})"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "1250c978",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_no_prompt = dataset['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "88a8af51",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = dataset['train']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "af89eb53",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_no_prompt = dataset['train']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3be21b8",
   "metadata": {},
   "source": [
    "### Build Prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "463584c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to format a row according to your fine-tuning requirements\n",
    "def format_row(row):\n",
    "    input_data = {\n",
    "        \"Source\": row['current_page'], \n",
    "        \"Candidates\": row['current_page_links'], \n",
    "        \"Target\": row['target']\n",
    "    }\n",
    "    \n",
    "    prompt = f\"\"\"You are a knowledge discovery expert familiar with the Wikipedia link structure and your objective is to play the game of Wikispeedia: https://dlab.epfl.ch/wikispeedia/play/.\n",
    "##Goal \n",
    "Given two Wikipedia articles, a source and a target, your goal is to reach the target article starting from the source article in as few clicks as possible. For the articles you are given this is always possible.\n",
    "\n",
    "##Constraint \n",
    "You should exclusively follow the links present in the articles that you encounter along the way.\n",
    "\n",
    "##Fine-grained instructions \n",
    "1. While the overall goal is to find a path from a source to a target article, you will proceed step by step.\n",
    "2. Given outgoing links from the source article as candidates, you should select the candidate that takes you closer to the target article. Use your knowledge of the \"expected\" Wikipedia link structure and relatedness between articles to identify the candidate that takes you closer to the target.\n",
    "3. Choose **only** from the provided candidates.\n",
    "4. Do not provide an algorithm, code to solve the task, or explanation just provide the link the choose among candidates.\n",
    "6. Even though the proposed links are not related to the target you should **always** choose a link.\n",
    "\n",
    "##Input \n",
    "{json.dumps(input_data, indent=4)}\n",
    "\n",
    "##Output\n",
    "You should only respond in the JSON format as described below\n",
    "Output format:\n",
    "\"thought\": \"<your short thought on what the user should do next, in a single line>\", \"next_article\": \"<chosen article for user to click on>\"\n",
    "\n",
    "This is an example : \n",
    "[USER]: \"source\": \"Animal\", \"target\": \"China\", \"links\": \"Dog;Biology;Eagle;Amazon_Forest\"\n",
    "[ASSISTANT]: \"thought\": \"China has a very strong connection to the United States, and the mascot for the United Statesis the Eagle. There is a link to Eagle on this article, so we should click on it.\", \"next_article\": \"Eagle\"\n",
    "\n",
    "\"\"\"\n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "0dfe5cb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|███████████████████████| 26193/26193 [00:03<00:00, 7934.52 examples/s]\n"
     ]
    }
   ],
   "source": [
    "# Apply the formatting function to each row\n",
    "test_dataset = test_dataset.map(lambda x: {\"text\": format_row(x)})\n",
    "\n",
    "# You might want to remove the old columns and keep only 'text'\n",
    "test_dataset = test_dataset.remove_columns(['source', 'target', 'current_page', 'current_page_links', 'next_page', '__index_level_0__'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "c532de69",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|███████████████████████| 78088/78088 [00:09<00:00, 8095.76 examples/s]\n"
     ]
    }
   ],
   "source": [
    "train_dataset = train_dataset.map(lambda x: {\"text\": format_row(x)})\n",
    "\n",
    "# You might want to remove the old columns and keep only 'text'\n",
    "train_dataset = train_dataset.remove_columns(['source', 'target', 'current_page', 'current_page_links', 'next_page', '__index_level_0__'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16572fcc",
   "metadata": {},
   "source": [
    "### Import model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "dde6135b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\n",
    "\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_use_double_quant=False,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=torch.bfloat16\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6c50e834",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████████████| 3/3 [00:45<00:00, 15.19s/it]\n"
     ]
    }
   ],
   "source": [
    "model_id = \"mistralai/Mistral-7B-Instruct-v0.2\"\n",
    "model = AutoModelForCausalLM.from_pretrained(model_id, quantization_config=bnb_config, device_map=\"auto\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "99a3c493",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_id, add_bos_token=True, trust_remote_code=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7559b20f",
   "metadata": {},
   "source": [
    "### Test finetuned model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "51f4904d",
   "metadata": {},
   "outputs": [],
   "source": [
    "index = 3000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "23d9e1ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "input = test_dataset[index]\n",
    "input_tok = tokenizer([input['text']],return_tensors = \"pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "f6b8998f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are a knowledge discovery expert familiar with the Wikipedia link structure and your objective is to play the game of Wikispeedia: https://dlab.epfl.ch/wikispeedia/play/.\n",
      "##Goal \n",
      "Given two Wikipedia articles, a source and a target, your goal is to reach the target article starting from the source article in as few clicks as possible. For the articles you are given this is always possible.\n",
      "\n",
      "##Constraint \n",
      "You should exclusively follow the links present in the articles that you encounter along the way.\n",
      "\n",
      "##Fine-grained instructions \n",
      "1. While the overall goal is to find a path from a source to a target article, you will proceed step by step.\n",
      "2. Given outgoing links from the source article as candidates, you should select the candidate that takes you closer to the target article. Use your knowledge of the \"expected\" Wikipedia link structure and relatedness between articles to identify the candidate that takes you closer to the target.\n",
      "3. Choose **only** from the provided candidates.\n",
      "4. Do not provide an algorithm, code to solve the task, or explanation just provide the link the choose among candidates.\n",
      "5. Just complete the 'Output' variable. \n",
      "6. Even though the proposed links are not related to the target you should **always** choose a link.\n",
      "\n",
      "##Input \n",
      "{\n",
      "    \"Source\": \"Aztec\",\n",
      "    \"Candidates\": \"['Capital', 'Government', 'Nahuatl language', 'Hern\\u00e1n Cort\\u00e9s', 'Mexico', '14th century', '15th century', '16th century', 'Mexico City', 'Mexico', 'Hern\\u00e1n Cort\\u00e9s', 'Sun', 'Nahuatl language', 'Gulf of Mexico', 'Gulf of Mexico', 'Smallpox', 'Holy Roman Empire', 'Hern\\u00e1n Cort\\u00e9s', 'Charles V, Holy Roman Emperor', 'Eagle', 'Quetzalcoatl', 'Maize', 'Cocoa', 'Mexico City', 'Nahuatl language', 'Mexico City']\",\n",
      "    \"Target\": \"Cell_(biology)\"\n",
      "}\n",
      "\n",
      "##Output\n",
      "You should only respond in the JSON format as described below\n",
      "Output format:\n",
      "\"thought\": \"<your short thought on what the user should do next, in a single line>\", \"next_article\": \"<chosen article for user to click on>\"\n",
      "\n",
      "This is an example : \n",
      "[USER]: \"source\": \"Animal\", \"target\": \"China\", \"links\": \"Dog;Biology;Eagle;Amazon_Forest\"\n",
      "[ASSISTANT]: \"thought\": \"China has a very strong connection to the United States, and the mascot for the United Statesis the Eagle. There is a link to Eagle on this article, so we should click on it.\", \"next_article\": \"Eagle\"\n",
      "\n",
      "Output:\n",
      "\"thought\": \"The article 'Mexico City' is related to 'Cell_(biology)' through the concept of 'Nahuatl language'. We should click on 'Nahuatl language'.\", \"next_article\": \"Nahuatl_language\"\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    out = (tokenizer.decode(model.generate(**input_tok, max_new_tokens=100)[0], skip_special_tokens=True))\n",
    "    print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "f1d54ae4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"['Tantalum', 'Rhenium', 'Molybdenum', 'Seaborgium', 'List of elements by name', 'Color', 'Xenon', 'Electron', 'Phase (matter)', 'Magnetism', 'Mohs scale of mineral hardness', 'Hafnium', 'Day', 'Tantalum', 'Day', 'Rhenium', 'Chemical element', 'Carbon', 'Steel', 'Carbon', 'Mining', 'Petroleum', 'Gas tungsten arc welding', 'Lead', 'Calcium', 'Magnesium', 'Spain', 'Portugal', 'Molybdenum', 'Cancer', 'Mineral', 'Iron', 'Manganese', 'Oxygen', 'Calcium', 'Bolivia', 'California', 'China', 'Portugal', 'Russia', 'Vietnam', 'South Korea', 'Carbon', 'Oxygen', 'Hafnium']\""
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_no_prompt[index]['current_page_links']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "a684e8a4",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'is_word_in_links' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[55], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mis_word_in_links\u001b[49m(out_extracted , test_no_prompt[index][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcurrent_page_links\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "\u001b[0;31mNameError\u001b[0m: name 'is_word_in_links' is not defined"
     ]
    }
   ],
   "source": [
    "is_word_in_links(out_extracted , test_no_prompt[index]['current_page_links'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "2520b5bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'China'"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_no_prompt[index]['next_page']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e08b487f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_id, add_bos_token=True, trust_remote_code=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22b93d7a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (env2)",
   "language": "python",
   "name": "env2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
